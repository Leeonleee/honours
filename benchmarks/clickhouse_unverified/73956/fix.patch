diff --git a/src/Core/Settings.cpp b/src/Core/Settings.cpp
index b1fd16640d2b..6c640943ad47 100644
--- a/src/Core/Settings.cpp
+++ b/src/Core/Settings.cpp
@@ -5871,6 +5871,10 @@ Allows creation of [JSON](../../sql-reference/data-types/newjson.md) data type.
 )", BETA) ALIAS(enable_json_type) \
     DECLARE(Bool, allow_general_join_planning, true, R"(
 Allows a more general join planning algorithm that can handle more complex conditions, but only works with hash join. If hash join is not enabled, then the usual join planning algorithm is used regardless of the value of this setting.
+)", 0) \
+    DECLARE(UInt64, merge_table_max_tables_to_look_for_schema_inference, 1000, R"(
+When creating a `Merge` table without an explicit schema or when using the `merge` table function, infer schema as a union of not more than the specified number of matching tables.
+If there is a larger number of tables, the schema will be inferred from the first specified number of tables.
 )", 0) \
     DECLARE(Bool, validate_enum_literals_in_opearators, false, R"(
 If enabled, validate enum literals in operators like `IN`, `NOT IN`, `==`, `!=` against the enum type and throw an exception if the literal is not a valid enum value.
diff --git a/src/Core/SettingsChangesHistory.cpp b/src/Core/SettingsChangesHistory.cpp
index e980f044a677..3fa5d3fe9211 100644
--- a/src/Core/SettingsChangesHistory.cpp
+++ b/src/Core/SettingsChangesHistory.cpp
@@ -93,6 +93,7 @@ const VersionToSettingsChangesMap & getSettingsChangesHistory()
             {"output_format_pretty_fallback_to_vertical", false, true, "A new setting"},
             {"output_format_pretty_fallback_to_vertical_max_rows_per_chunk", 0, 100, "A new setting"},
             {"output_format_pretty_fallback_to_vertical_min_table_width", 0, 1000, "A new setting"},
+            {"merge_table_max_tables_to_look_for_schema_inference", 1, 1000, "A new setting"},
             {"max_autoincrement_series", 1000, 1000, "A new setting"},
             {"validate_enum_literals_in_opearators", false, false, "A new setting"},
             {"allow_experimental_kusto_dialect", true, false, "A new setting"},
diff --git a/src/Formats/ReadSchemaUtils.cpp b/src/Formats/ReadSchemaUtils.cpp
index 6ad9fc0499ab..e144481d5a87 100644
--- a/src/Formats/ReadSchemaUtils.cpp
+++ b/src/Formats/ReadSchemaUtils.cpp
@@ -440,7 +440,6 @@ try
             Names names_order; /// Try to save original columns order;
             std::unordered_map<String, DataTypePtr> names_to_types;
 
-
             for (const auto & [schema, file_name] : schemas_for_union_mode)
             {
                 for (const auto & [name, type] : schema)
diff --git a/src/Interpreters/Aggregator.cpp b/src/Interpreters/Aggregator.cpp
index 7a826ad48805..c6aacb8a6e95 100644
--- a/src/Interpreters/Aggregator.cpp
+++ b/src/Interpreters/Aggregator.cpp
@@ -361,15 +361,16 @@ void Aggregator::Params::explain(WriteBuffer & out, size_t indent) const
 
     {
         /// Dump keys.
-        out << prefix << "Keys: ";
+        out << prefix << "Keys:";
 
         bool first = true;
         for (const auto & key : keys)
         {
-            if (!first)
+            if (first)
+                out << " ";
+            else
                 out << ", ";
             first = false;
-
             out << key;
         }
 
diff --git a/src/Interpreters/InterpreterInsertQuery.cpp b/src/Interpreters/InterpreterInsertQuery.cpp
index 3c47f758fef9..c8791f176c09 100644
--- a/src/Interpreters/InterpreterInsertQuery.cpp
+++ b/src/Interpreters/InterpreterInsertQuery.cpp
@@ -377,7 +377,7 @@ Chain InterpreterInsertQuery::buildSink(
     return out;
 }
 
-bool InterpreterInsertQuery::shouldAddSquashingFroStorage(const StoragePtr & table) const
+bool InterpreterInsertQuery::shouldAddSquashingForStorage(const StoragePtr & table) const
 {
     auto context_ptr = getContext();
     const Settings & settings = context_ptr->getSettingsRef();
@@ -464,8 +464,7 @@ std::pair<std::vector<Chain>, std::vector<Chain>> InterpreterInsertQuery::buildP
     StoragePtr table,
     size_t view_level,
     const StorageMetadataPtr & metadata_snapshot,
-    const Block & query_sample_block
-    )
+    const Block & query_sample_block)
 {
     chassert(presink_streams > 0);
     chassert(sink_streams > 0);
@@ -629,7 +628,7 @@ QueryPipeline InterpreterInsertQuery::buildInsertSelectPipeline(ASTInsertQuery &
 
     pipeline.resize(1);
 
-    if (shouldAddSquashingFroStorage(table))
+    if (shouldAddSquashingForStorage(table))
     {
         pipeline.addSimpleTransform(
             [&](const Block & in_header) -> ProcessorPtr
@@ -685,7 +684,7 @@ QueryPipeline InterpreterInsertQuery::buildInsertSelectPipeline(ASTInsertQuery &
 
     pipeline.resize(presink_chains.size());
 
-    if (shouldAddSquashingFroStorage(table))
+    if (shouldAddSquashingForStorage(table))
     {
         pipeline.addSimpleTransform(
             [&](const Block & in_header) -> ProcessorPtr
@@ -750,7 +749,7 @@ QueryPipeline InterpreterInsertQuery::buildInsertPipeline(ASTInsertQuery & query
 
     chain.addSource(std::make_shared<DeduplicationToken::AddTokenInfoTransform>(chain.getInputHeader()));
 
-    if (shouldAddSquashingFroStorage(table))
+    if (shouldAddSquashingForStorage(table))
     {
         bool table_prefers_large_blocks = table->prefersLargeBlocks();
 
diff --git a/src/Interpreters/InterpreterInsertQuery.h b/src/Interpreters/InterpreterInsertQuery.h
index cc1d7b100fa9..eda66d9fc3ce 100644
--- a/src/Interpreters/InterpreterInsertQuery.h
+++ b/src/Interpreters/InterpreterInsertQuery.h
@@ -67,7 +67,7 @@ class InterpreterInsertQuery : public IInterpreter, WithContext
 
     void addBuffer(std::unique_ptr<ReadBuffer> buffer) { owned_buffers.push_back(std::move(buffer)); }
 
-    bool shouldAddSquashingFroStorage(const StoragePtr & table) const;
+    bool shouldAddSquashingForStorage(const StoragePtr & table) const;
 
 private:
     static Block getSampleBlockImpl(const Names & names, const StoragePtr & table, const StorageMetadataPtr & metadata_snapshot, bool no_destination, bool allow_materialized);
diff --git a/src/Interpreters/addMissingDefaults.cpp b/src/Interpreters/addMissingDefaults.cpp
index 173478332f3d..b5cde92b50e6 100644
--- a/src/Interpreters/addMissingDefaults.cpp
+++ b/src/Interpreters/addMissingDefaults.cpp
@@ -46,7 +46,7 @@ ActionsDAG addMissingDefaults(
 
     FunctionOverloadResolverPtr func_builder_replicate = FunctionFactory::instance().get("replicate", context);
 
-    /// We take given columns from input block and missed columns without default value
+    /// We take given columns from the input block and missed columns without default value
     /// (default and materialized will be computed later).
     for (const auto & column : required_columns)
     {
diff --git a/src/Interpreters/addMissingDefaults.h b/src/Interpreters/addMissingDefaults.h
index 551583a0006f..7080b19ec60d 100644
--- a/src/Interpreters/addMissingDefaults.h
+++ b/src/Interpreters/addMissingDefaults.h
@@ -11,10 +11,10 @@ class ColumnsDescription;
 
 class ActionsDAG;
 
-/** Adds three types of columns into block
-  * 1. Columns, that are missed inside request, but present in table without defaults (missed columns)
-  * 2. Columns, that are missed inside request, but present in table with defaults (columns with default values)
-  * 3. Columns that materialized from other columns (materialized columns)
+/** Adds three types of columns into a block:
+  * 1. Columns, that are missed in the query, but present in the table without defaults (missed columns)
+  * 2. Columns, that are missed in the query, but present in the table with defaults (columns with default values)
+  * 3. Columns that are materialized from other columns (materialized columns)
   * Also can substitute NULL with DEFAULT value in case of INSERT SELECT query (null_as_default) if according setting is 1.
   * All three types of columns are materialized (not constants).
   */
diff --git a/src/Processors/QueryPlan/ExpressionStep.h b/src/Processors/QueryPlan/ExpressionStep.h
index 15fbbdad8078..f0bf62a1ca4d 100644
--- a/src/Processors/QueryPlan/ExpressionStep.h
+++ b/src/Processors/QueryPlan/ExpressionStep.h
@@ -12,7 +12,6 @@ class JoiningTransform;
 class ExpressionStep : public ITransformingStep
 {
 public:
-
     explicit ExpressionStep(const Header & input_header_, ActionsDAG actions_dag_);
     String getName() const override { return "Expression"; }
 
diff --git a/src/Processors/Transforms/buildPushingToViewsChain.cpp b/src/Processors/Transforms/buildPushingToViewsChain.cpp
index 3250ae932e69..78721c548eb9 100644
--- a/src/Processors/Transforms/buildPushingToViewsChain.cpp
+++ b/src/Processors/Transforms/buildPushingToViewsChain.cpp
@@ -374,7 +374,7 @@ std::optional<Chain> generateViewChain(
         bool check_access = !materialized_view->hasInnerTable() && materialized_view->getInMemoryMetadataPtr()->sql_security_type;
         out = interpreter.buildChain(inner_table, view_level + 1, inner_metadata_snapshot, insert_columns, thread_status_holder, view_counter_ms, check_access);
 
-        if (interpreter.shouldAddSquashingFroStorage(inner_table))
+        if (interpreter.shouldAddSquashingForStorage(inner_table))
         {
             bool table_prefers_large_blocks = inner_table->prefersLargeBlocks();
             const auto & settings = insert_context->getSettingsRef();
diff --git a/src/Storages/ColumnsDescription.cpp b/src/Storages/ColumnsDescription.cpp
index ef2251ae54ed..2beec76837df 100644
--- a/src/Storages/ColumnsDescription.cpp
+++ b/src/Storages/ColumnsDescription.cpp
@@ -386,7 +386,9 @@ void ColumnsDescription::modifyColumnOrder(const String & column_name, const Str
     };
 
     if (first)
+    {
         reorder_column([&]() { return columns.cbegin(); });
+    }
     else if (!after_column.empty() && column_name != after_column)
     {
         /// Checked first
diff --git a/src/Storages/StorageMerge.cpp b/src/Storages/StorageMerge.cpp
index f718496c892e..579e927721dd 100644
--- a/src/Storages/StorageMerge.cpp
+++ b/src/Storages/StorageMerge.cpp
@@ -1,4 +1,3 @@
-#include <algorithm>
 #include <functional>
 #include <iterator>
 #include <Analyzer/ConstantNode.h>
@@ -14,11 +13,9 @@
 #include <Columns/ColumnSet.h>
 #include <Columns/ColumnString.h>
 #include <Core/Settings.h>
-#include <Core/SortDescription.h>
 #include <DataTypes/DataTypeString.h>
+#include <DataTypes/getLeastSupertype.h>
 #include <DataTypes/IDataType.h>
-#include <Databases/IDatabase.h>
-#include <IO/WriteBufferFromString.h>
 #include <Interpreters/Context.h>
 #include <Interpreters/ExpressionActions.h>
 #include <Interpreters/IdentifierSemantic.h>
@@ -29,11 +26,13 @@
 #include <Interpreters/evaluateConstantExpression.h>
 #include <Interpreters/getHeaderForProcessingStage.h>
 #include <Interpreters/replaceAliasColumnsInQuery.h>
+#include <Interpreters/addMissingDefaults.h>
 #include <Parsers/ASTExpressionList.h>
 #include <Parsers/ASTFunction.h>
 #include <Parsers/ASTIdentifier.h>
 #include <Parsers/ASTLiteral.h>
 #include <Parsers/ASTSelectQuery.h>
+#include <Parsers/queryToString.h>
 #include <Planner/PlannerActionsVisitor.h>
 #include <Planner/Utils.h>
 #include <Processors/QueryPlan/BuildQueryPipelineSettings.h>
@@ -43,8 +42,6 @@
 #include <Processors/QueryPlan/QueryPlan.h>
 #include <Processors/QueryPlan/ReadFromMergeTree.h>
 #include <Processors/Sources/NullSource.h>
-#include <Processors/Sources/SourceFromSingleChunk.h>
-#include <Processors/Transforms/ExpressionTransform.h>
 #include <Processors/Transforms/FilterTransform.h>
 #include <Processors/Transforms/MaterializingTransform.h>
 #include <QueryPipeline/QueryPipelineBuilder.h>
@@ -57,8 +54,6 @@
 #include <Storages/StorageView.h>
 #include <Storages/VirtualColumnUtils.h>
 #include <Storages/checkAndGetLiteralArgument.h>
-#include <base/defines.h>
-#include <base/range.h>
 #include <Common/Exception.h>
 #include <Common/assert_cast.h>
 #include <Common/checkStackSize.h>
@@ -66,6 +61,7 @@
 #include <Core/NamesAndTypes.h>
 #include <Functions/FunctionFactory.h>
 
+
 namespace DB
 {
 namespace Setting
@@ -73,6 +69,7 @@ namespace Setting
     extern const SettingsBool allow_experimental_analyzer;
     extern const SettingsSeconds lock_acquire_timeout;
     extern const SettingsFloat max_streams_multiplier_for_merge_tables;
+    extern const SettingsUInt64 merge_table_max_tables_to_look_for_schema_inference;
 }
 
 namespace
@@ -82,6 +79,7 @@ bool columnIsPhysical(ColumnDefaultKind kind)
 {
     return kind == ColumnDefaultKind::Default || kind == ColumnDefaultKind::Materialized;
 }
+
 bool columnDefaultKindHasSameType(ColumnDefaultKind lhs, ColumnDefaultKind rhs)
 {
     if (lhs == rhs)
@@ -153,7 +151,9 @@ StorageMerge::StorageMerge(
         source_databases_and_tables_)
 {
     StorageInMemoryMetadata storage_metadata;
-    storage_metadata.setColumns(columns_.empty() ? getColumnsDescriptionFromSourceTables() : columns_);
+    storage_metadata.setColumns(columns_.empty()
+        ? getColumnsDescriptionFromSourceTables(context_->getSettingsRef()[Setting::merge_table_max_tables_to_look_for_schema_inference])
+        : columns_);
     storage_metadata.setComment(comment);
     setInMemoryMetadata(storage_metadata);
     setVirtuals(createVirtuals());
@@ -176,7 +176,9 @@ StorageMerge::StorageMerge(
         source_table_regexp_, {})
 {
     StorageInMemoryMetadata storage_metadata;
-    storage_metadata.setColumns(columns_.empty() ? getColumnsDescriptionFromSourceTables() : columns_);
+    storage_metadata.setColumns(columns_.empty()
+        ? getColumnsDescriptionFromSourceTables(context_->getSettingsRef()[Setting::merge_table_max_tables_to_look_for_schema_inference])
+        : columns_);
     storage_metadata.setComment(comment);
     setInMemoryMetadata(storage_metadata);
     setVirtuals(createVirtuals());
@@ -187,12 +189,56 @@ StorageMerge::DatabaseTablesIterators StorageMerge::getDatabaseIterators(Context
     return database_name_or_regexp.getDatabaseIterators(context_);
 }
 
-ColumnsDescription StorageMerge::getColumnsDescriptionFromSourceTables() const
+ColumnsDescription StorageMerge::unifyColumnsDescription(std::function<void(std::function<void(const StoragePtr &)>)> for_each_table)
 {
-    auto table = getFirstTable([](auto && t) { return t; });
-    if (!table)
+    ColumnsDescription res;
+
+    for_each_table([&res](auto && t)
+    {
+        auto structure = t->getInMemoryMetadataPtr()->getColumns();
+        String prev_column_name;
+        for (const ColumnDescription & column : structure)
+        {
+            if (!res.has(column.name))
+            {
+                res.add(column, prev_column_name);
+            }
+            else if (column != res.get(column.name))
+            {
+                res.modify(column.name, [&column](ColumnDescription & what)
+                {
+                    what.type = getLeastSupertypeOrVariant(DataTypes{what.type, column.type});
+                    if (what.default_desc != column.default_desc)
+                        what.default_desc = {};
+                });
+            }
+            prev_column_name = column.name;
+        }
+    });
+
+    if (res.empty())
         throw Exception{ErrorCodes::CANNOT_EXTRACT_TABLE_STRUCTURE, "There are no tables satisfied provided regexp, you must specify table structure manually"};
-    return table->getInMemoryMetadataPtr()->getColumns();
+
+    return res;
+}
+
+ColumnsDescription StorageMerge::getColumnsDescriptionFromSourceTables(size_t max_tables_to_look) const
+{
+    size_t table_num = 0;
+
+    return unifyColumnsDescription([&table_num, max_tables_to_look, this](std::function<void(const StoragePtr &)> callback)
+    {
+        getFirstTable([&table_num, &callback, max_tables_to_look](auto && t)
+        {
+            if (!t)
+                return false;
+
+            callback(t);
+
+            ++table_num;
+            return table_num >= max_tables_to_look;
+        });
+    });
 }
 
 template <typename F>
@@ -457,7 +503,7 @@ void ReadFromMerge::initializePipeline(QueryPipelineBuilder & pipeline, const Bu
 
         const auto storage = std::get<1>(table);
         const auto storage_metadata_snapshot = storage->getInMemoryMetadataPtr();
-        const auto nested_storage_snaphsot = storage->getStorageSnapshot(storage_metadata_snapshot, context);
+        const auto nested_storage_snapshot = storage->getStorageSnapshot(storage_metadata_snapshot, context);
 
         Names column_names_as_aliases;
         Aliases aliases;
@@ -518,7 +564,6 @@ void ReadFromMerge::filterTablesAndCreateChildrenPlans()
     }
 
     selected_tables = getSelectedTables(context, has_database_virtual_column, has_table_virtual_column);
-
     child_plans = createChildrenPlans(query_info);
 }
 
@@ -582,7 +627,7 @@ std::vector<ReadFromMerge::ChildPlan> ReadFromMerge::createChildrenPlans(SelectQ
         Aliases aliases;
         RowPolicyDataOpt row_policy_data_opt;
         auto storage_metadata_snapshot = storage->getInMemoryMetadataPtr();
-        auto nested_storage_snaphsot = storage->getStorageSnapshot(storage_metadata_snapshot, modified_context);
+        auto nested_storage_snapshot = storage->getStorageSnapshot(storage_metadata_snapshot, modified_context);
 
         Names column_names_as_aliases;
         Names real_column_names = column_names;
@@ -600,13 +645,13 @@ std::vector<ReadFromMerge::ChildPlan> ReadFromMerge::createChildrenPlans(SelectQ
         }
 
         auto modified_query_info
-            = getModifiedQueryInfo(modified_context, table, nested_storage_snaphsot, real_column_names, column_names_as_aliases, aliases);
+            = getModifiedQueryInfo(modified_context, table, nested_storage_snapshot, real_column_names, column_names_as_aliases, aliases);
 
         if (!context->getSettingsRef()[Setting::allow_experimental_analyzer])
         {
             auto storage_columns = storage_metadata_snapshot->getColumns();
             auto syntax_result = TreeRewriter(context).analyzeSelect(
-                modified_query_info.query, TreeRewriterResult({}, storage, nested_storage_snaphsot));
+                modified_query_info.query, TreeRewriterResult({}, storage, nested_storage_snapshot));
 
             bool with_aliases = common_processed_stage == QueryProcessingStage::FetchColumns && !storage_columns.getAliases().empty();
             if (with_aliases)
@@ -655,13 +700,17 @@ std::vector<ReadFromMerge::ChildPlan> ReadFromMerge::createChildrenPlans(SelectQ
             }
         }
 
+        Names column_names_to_read = column_names_as_aliases.empty() ? std::move(real_column_names) : std::move(column_names_as_aliases);
+
+        std::erase_if(column_names_to_read, [existing_columns = nested_storage_snapshot->getAllColumnsDescription()](const auto & column_name){ return !existing_columns.has(column_name); });
+
         auto child = createPlanForTable(
-            nested_storage_snaphsot,
+            nested_storage_snapshot,
             modified_query_info,
             common_processed_stage,
             required_max_block_size,
             table,
-            column_names_as_aliases.empty() ? std::move(real_column_names) : std::move(column_names_as_aliases),
+            column_names_to_read,
             row_policy_data_opt,
             modified_context,
             current_streams);
@@ -672,9 +721,9 @@ std::vector<ReadFromMerge::ChildPlan> ReadFromMerge::createChildrenPlans(SelectQ
         {
             addVirtualColumns(child, modified_query_info, common_processed_stage, table);
 
-            /// Subordinary tables could have different but convertible types, like numeric types of different width.
+            /// Source tables could have different but convertible types, like numeric types of different width.
             /// We must return streams with structure equals to structure of Merge table.
-            convertAndFilterSourceStream(common_header, modified_query_info, nested_storage_snaphsot, aliases, row_policy_data_opt, context, child);
+            convertAndFilterSourceStream(common_header, modified_query_info, nested_storage_snapshot, aliases, row_policy_data_opt, context, child);
 
             for (const auto & filter_info : pushed_down_filters)
             {
@@ -1163,7 +1212,7 @@ ReadFromMerge::ChildPlan ReadFromMerge::createPlanForTable(
     QueryProcessingStage::Enum processed_stage,
     UInt64 max_block_size,
     const StorageWithLockAndName & storage_with_lock,
-    Names && real_column_names,
+    const Names & real_column_names_read_from_the_source_table,
     const RowPolicyDataOpt & row_policy_data_opt,
     ContextMutablePtr modified_context,
     size_t streams_num) const
@@ -1172,7 +1221,7 @@ ReadFromMerge::ChildPlan ReadFromMerge::createPlanForTable(
 
     auto & modified_select = modified_query_info.query->as<ASTSelectQuery &>();
 
-    if (!InterpreterSelectQuery::isQueryWithFinal(modified_query_info) && storage->needRewriteQueryWithFinal(real_column_names))
+    if (!InterpreterSelectQuery::isQueryWithFinal(modified_query_info) && storage->needRewriteQueryWithFinal(real_column_names_read_from_the_source_table))
     {
         /// NOTE: It may not work correctly in some cases, because query was analyzed without final.
         /// However, it's needed for Materialized...SQL and it's unlikely that someone will use it with Merge tables.
@@ -1190,7 +1239,8 @@ ReadFromMerge::ChildPlan ReadFromMerge::createPlanForTable(
 
     if (processed_stage <= storage_stage)
     {
-        /// If there are only virtual columns in query, you must request at least one other column.
+        /// If there are only virtual columns in query, we must request at least one other column.
+        Names real_column_names = real_column_names_read_from_the_source_table;
         if (real_column_names.empty())
             real_column_names.push_back(ExpressionActions::getSmallestColumn(storage_snapshot_->metadata->getColumns().getAllPhysical()).name);
 
@@ -1485,7 +1535,6 @@ void ReadFromMerge::convertAndFilterSourceStream(
 {
     Block before_block_header = child.plan.getCurrentHeader();
 
-    auto storage_sample_block = snapshot->metadata->getSampleBlock();
     auto pipe_columns = before_block_header.getNamesAndTypesList();
 
     if (local_context->getSettingsRef()[Setting::allow_experimental_analyzer])
@@ -1529,26 +1578,62 @@ void ReadFromMerge::convertAndFilterSourceStream(
         }
     }
 
-    ActionsDAG::MatchColumnsMode convert_actions_match_columns_mode = ActionsDAG::MatchColumnsMode::Name;
-
-    /* Output headers may differ from what StorageMerge expects in some cases.
-     * When the child table engine produces a query plan for the stage after FetchColumns,
-     * execution names in the output header may be different.
-     * The same happens with StorageDistributed, even in the case of FetchColumns.
-     */
-    if (local_context->getSettingsRef()[Setting::allow_experimental_analyzer]
-        && (child.stage != QueryProcessingStage::FetchColumns || dynamic_cast<const StorageDistributed *>(&snapshot->storage) != nullptr))
-        convert_actions_match_columns_mode = ActionsDAG::MatchColumnsMode::Position;
-
+    /// This is the filter for the individual source table, that's why filtering has to be done before all structure adaptations.
     if (row_policy_data_opt)
         row_policy_data_opt->addFilterTransform(child.plan);
 
-    auto convert_actions_dag = ActionsDAG::makeConvertingActions(child.plan.getCurrentHeader().getColumnsWithTypeAndName(),
-                                                                header.getColumnsWithTypeAndName(),
-                                                                convert_actions_match_columns_mode);
+    /** Output headers may differ from what StorageMerge expects in some cases.
+      * When the child table engine produces a query plan for the stage after FetchColumns,
+      * execution names in the output header may be different.
+      * The same happens with StorageDistributed, even in the case of FetchColumns.
+      */
+
+    /** Convert types of columns according to the resulting Merge table.
+      * And convert column names to the expected ones.
+       */
+    ColumnsWithTypeAndName current_step_columns = child.plan.getCurrentHeader().getColumnsWithTypeAndName();
+    ColumnsWithTypeAndName converted_columns;
+    size_t size = current_step_columns.size();
+    converted_columns.reserve(current_step_columns.size());
+    for (size_t i = 0; i < size; ++i)
+    {
+        const auto & source_elem = current_step_columns[i];
+        if (header.has(source_elem.name))
+        {
+            converted_columns.push_back(header.getByName(source_elem.name));
+        }
+        else if (header.columns() == current_step_columns.size())
+        {
+            /// Virtual columns and columns read from Distributed tables (having different name but matched by position).
+            converted_columns.push_back(header.getByPosition(i));
+        }
+        else
+        {
+            /// Matching by name, but some columns are unneeded.
+            converted_columns.push_back(source_elem);
+        }
+    }
+
+    auto convert_actions_dag = ActionsDAG::makeConvertingActions(
+        current_step_columns,
+        converted_columns,
+        ActionsDAG::MatchColumnsMode::Position);
 
     auto expression_step = std::make_unique<ExpressionStep>(child.plan.getCurrentHeader(), std::move(convert_actions_dag));
     child.plan.addStep(std::move(expression_step));
+
+    /// Add missing columns for the resulting Merge table.
+    {
+        auto adding_missing_defaults_dag = addMissingDefaults(
+            child.plan.getCurrentHeader(),
+            header.getNamesAndTypesList(),
+            snapshot->getAllColumnsDescription(),
+            local_context,
+            false);
+
+        auto adding_missing_defaults_step = std::make_unique<ExpressionStep>(child.plan.getCurrentHeader(), std::move(adding_missing_defaults_dag));
+        child.plan.addStep(std::move(adding_missing_defaults_step));
+    }
 }
 
 const ReadFromMerge::StorageListWithLocks & ReadFromMerge::getSelectedTables()
diff --git a/src/Storages/StorageMerge.h b/src/Storages/StorageMerge.h
index 82f8fb78feca..7a8f11204e22 100644
--- a/src/Storages/StorageMerge.h
+++ b/src/Storages/StorageMerge.h
@@ -87,6 +87,10 @@ class StorageMerge final : public IStorage, WithContext
     using DatabaseTablesIterators = std::vector<DatabaseTablesIteratorPtr>;
     DatabaseTablesIterators getDatabaseIterators(ContextPtr context) const;
 
+    /// Returns a unified column structure among multiple tables.
+    /// Takes a function that invokes a callback for every table. NOTE: This is quite inconvenient.
+    static ColumnsDescription unifyColumnsDescription(std::function<void(std::function<void(const StoragePtr &)>)> for_each_table);
+
 private:
     /// (Database, Table, Lock, TableName)
     using StorageWithLockAndName = std::tuple<String, StoragePtr, TableLockHolder, String>;
@@ -123,7 +127,7 @@ class StorageMerge final : public IStorage, WithContext
 
     ColumnSizeByName getColumnSizes() const override;
 
-    ColumnsDescription getColumnsDescriptionFromSourceTables() const;
+    ColumnsDescription getColumnsDescriptionFromSourceTables(size_t max_tables_to_look) const;
 
     static VirtualColumnsDescription createVirtuals();
 
@@ -258,7 +262,7 @@ class ReadFromMerge final : public SourceStepWithFilter
         QueryProcessingStage::Enum processed_stage,
         UInt64 max_block_size,
         const StorageWithLockAndName & storage_with_lock,
-        Names && real_column_names,
+        const Names & real_column_names_read_from_the_source_table,
         const RowPolicyDataOpt & row_policy_data_opt,
         ContextMutablePtr modified_context,
         size_t streams_num) const;
diff --git a/src/TableFunctions/TableFunctionMerge.cpp b/src/TableFunctions/TableFunctionMerge.cpp
index cca0c2990f63..e6ada9e5fcaf 100644
--- a/src/TableFunctions/TableFunctionMerge.cpp
+++ b/src/TableFunctions/TableFunctionMerge.cpp
@@ -1,5 +1,6 @@
 #include <Common/OptimizedRegularExpression.h>
 #include <Common/typeid_cast.h>
+#include <Core/Settings.h>
 #include <Storages/StorageMerge.h>
 #include <Storages/checkAndGetLiteralArgument.h>
 #include <Parsers/ASTFunction.h>
@@ -7,8 +8,8 @@
 #include <Analyzer/FunctionNode.h>
 #include <Analyzer/TableFunctionNode.h>
 #include <Interpreters/evaluateConstantExpression.h>
-#include <Interpreters/Context.h>
 #include <Interpreters/DatabaseCatalog.h>
+#include <Interpreters/Context.h>
 #include <Access/ContextAccess.h>
 #include <TableFunctions/TableFunctionFactory.h>
 #include <TableFunctions/registerTableFunctions.h>
@@ -23,6 +24,11 @@ namespace ErrorCodes
     extern const int BAD_ARGUMENTS;
 }
 
+namespace Setting
+{
+    extern const SettingsUInt64 merge_table_max_tables_to_look_for_schema_inference;
+}
+
 namespace
 {
 
@@ -159,25 +165,35 @@ const TableFunctionMerge::DBToTableSetMap & TableFunctionMerge::getSourceDatabas
 
 ColumnsDescription TableFunctionMerge::getActualTableStructure(ContextPtr context, bool /*is_insert_query*/) const
 {
-    for (const auto & db_with_tables : getSourceDatabasesAndTables(context))
+    size_t table_num = 0;
+    size_t max_tables_to_look = context->getSettingsRef()[Setting::merge_table_max_tables_to_look_for_schema_inference];
+
+    return StorageMerge::unifyColumnsDescription([&table_num, &context, max_tables_to_look, this](std::function<void(const StoragePtr &)> callback)
     {
-        for (const auto & table : db_with_tables.second)
+        for (const auto & db_with_tables : getSourceDatabasesAndTables(context))
         {
-            auto storage = DatabaseCatalog::instance().tryGetTable(StorageID{db_with_tables.first, table}, context);
-            if (storage)
-                return ColumnsDescription{storage->getInMemoryMetadataPtr()->getColumns().getAllPhysical()};
+            for (const auto & table : db_with_tables.second)
+            {
+                if (table_num >= max_tables_to_look)
+                    return;
+
+                auto storage = DatabaseCatalog::instance().tryGetTable(StorageID{db_with_tables.first, table}, context);
+                if (storage)
+                {
+                    ++table_num;
+                    callback(storage);
+                }
+            }
         }
-    }
-
-    throwNoTablesMatchRegexp(source_database_name_or_regexp, source_table_regexp);
+    });
 }
 
 
-StoragePtr TableFunctionMerge::executeImpl(const ASTPtr & /*ast_function*/, ContextPtr context, const std::string & table_name, ColumnsDescription /*cached_columns*/, bool is_insert_query) const
+StoragePtr TableFunctionMerge::executeImpl(const ASTPtr & /*ast_function*/, ContextPtr context, const std::string & table_name, ColumnsDescription /*cached_columns*/, bool /*is_insert_query*/) const
 {
     auto res = std::make_shared<StorageMerge>(
         StorageID(getDatabaseName(), table_name),
-        getActualTableStructure(context, is_insert_query),
+        ColumnsDescription{},
         String{},
         source_database_name_or_regexp,
         database_is_regexp,
