{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 42322,
  "instance_id": "ClickHouse__ClickHouse-42322",
  "issue_numbers": [
    "41692"
  ],
  "base_commit": "edfc388b7c55841ac80aaebbd960ddee3c7dc483",
  "patch": "diff --git a/src/Interpreters/ClusterProxy/executeQuery.cpp b/src/Interpreters/ClusterProxy/executeQuery.cpp\nindex d974721627eb..923b4a767b7b 100644\n--- a/src/Interpreters/ClusterProxy/executeQuery.cpp\n+++ b/src/Interpreters/ClusterProxy/executeQuery.cpp\n@@ -7,6 +7,7 @@\n #include <Interpreters/ProcessList.h>\n #include <Interpreters/OptimizeShardingKeyRewriteInVisitor.h>\n #include <QueryPipeline/Pipe.h>\n+#include <Parsers/queryToString.h>\n #include <Processors/QueryPlan/QueryPlan.h>\n #include <Processors/QueryPlan/ReadFromRemote.h>\n #include <Processors/QueryPlan/UnionStep.h>\n@@ -26,7 +27,7 @@ namespace ErrorCodes\n namespace ClusterProxy\n {\n \n-ContextMutablePtr updateSettingsForCluster(const Cluster & cluster, ContextPtr context, const Settings & settings, Poco::Logger * log)\n+ContextMutablePtr updateSettingsForCluster(const Cluster & cluster, ContextPtr context, const Settings & settings, const StorageID & main_table, const SelectQueryInfo * query_info, Poco::Logger * log)\n {\n     Settings new_settings = settings;\n     new_settings.queue_max_wait_ms = Cluster::saturate(new_settings.queue_max_wait_ms, settings.max_execution_time);\n@@ -96,6 +97,20 @@ ContextMutablePtr updateSettingsForCluster(const Cluster & cluster, ContextPtr c\n         new_settings.limit.changed = false;\n     }\n \n+    /// Setting additional_table_filters may be applied to Distributed table.\n+    /// In case if query is executed up to WithMergableState on remote shard, it is impossible to filter on initiator.\n+    /// We need to propagate the setting, but change the table name from distributed to source.\n+    ///\n+    /// Here we don't try to analyze setting again. In case if query_info->additional_filter_ast is not empty, some filter was applied.\n+    /// It's just easier to add this filter for a source table.\n+    if (query_info && query_info->additional_filter_ast)\n+    {\n+        Tuple tuple;\n+        tuple.push_back(main_table.getShortName());\n+        tuple.push_back(queryToString(query_info->additional_filter_ast));\n+        new_settings.additional_table_filters.value.push_back(std::move(tuple));\n+    }\n+\n     auto new_context = Context::createCopy(context);\n     new_context->setSettings(new_settings);\n     return new_context;\n@@ -121,7 +136,7 @@ void executeQuery(\n     std::vector<QueryPlanPtr> plans;\n     SelectStreamFactory::Shards remote_shards;\n \n-    auto new_context = updateSettingsForCluster(*query_info.getCluster(), context, settings, log);\n+    auto new_context = updateSettingsForCluster(*query_info.getCluster(), context, settings, main_table, &query_info, log);\n \n     new_context->getClientInfo().distributed_depth += 1;\n \ndiff --git a/src/Interpreters/ClusterProxy/executeQuery.h b/src/Interpreters/ClusterProxy/executeQuery.h\nindex 1a5035015a76..ac88752ce74c 100644\n--- a/src/Interpreters/ClusterProxy/executeQuery.h\n+++ b/src/Interpreters/ClusterProxy/executeQuery.h\n@@ -35,7 +35,7 @@ class SelectStreamFactory;\n ///\n /// @return new Context with adjusted settings\n ContextMutablePtr updateSettingsForCluster(\n-    const Cluster & cluster, ContextPtr context, const Settings & settings, Poco::Logger * log = nullptr);\n+    const Cluster & cluster, ContextPtr context, const Settings & settings, const StorageID & main_table, const SelectQueryInfo * query_info = nullptr, Poco::Logger * log = nullptr);\n \n /// Execute a distributed query, creating a query plan, from which the query pipeline can be built.\n /// `stream_factory` object encapsulates the logic of creating plans for a different type of query\ndiff --git a/src/Storages/getStructureOfRemoteTable.cpp b/src/Storages/getStructureOfRemoteTable.cpp\nindex 3d104ada0b69..a93a480adb0d 100644\n--- a/src/Storages/getStructureOfRemoteTable.cpp\n+++ b/src/Storages/getStructureOfRemoteTable.cpp\n@@ -58,7 +58,7 @@ ColumnsDescription getStructureOfRemoteTableInShard(\n     }\n \n     ColumnsDescription res;\n-    auto new_context = ClusterProxy::updateSettingsForCluster(cluster, context, context->getSettingsRef());\n+    auto new_context = ClusterProxy::updateSettingsForCluster(cluster, context, context->getSettingsRef(), table_id);\n \n     /// Expect only needed columns from the result of DESC TABLE. NOTE 'comment' column is ignored for compatibility reasons.\n     Block sample_block\n@@ -169,7 +169,7 @@ ColumnsDescriptionByShardNum getExtendedObjectsOfRemoteTables(\n     const auto & shards_info = cluster.getShardsInfo();\n     auto query = \"DESC TABLE \" + remote_table_id.getFullTableName();\n \n-    auto new_context = ClusterProxy::updateSettingsForCluster(cluster, context, context->getSettingsRef());\n+    auto new_context = ClusterProxy::updateSettingsForCluster(cluster, context, context->getSettingsRef(), remote_table_id);\n     new_context->setSetting(\"describe_extend_object_types\", true);\n \n     /// Expect only needed columns from the result of DESC TABLE.\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02346_additional_filters.reference b/tests/queries/0_stateless/02346_additional_filters.reference\nindex 22d53173e717..0a08995223d6 100644\n--- a/tests/queries/0_stateless/02346_additional_filters.reference\n+++ b/tests/queries/0_stateless/02346_additional_filters.reference\n@@ -60,6 +60,14 @@ select * from remote('127.0.0.{1,2}', system.one) settings additional_table_filt\n 0\n 0\n select * from remote('127.0.0.{1,2}', system.one) settings additional_table_filters={'system.one' : 'dummy != 0'};\n+select * from distr_table settings additional_table_filters={'distr_table' : 'x = 2'};\n+2\tbb\n+2\tbb\n+select * from distr_table settings additional_table_filters={'distr_table' : 'x != 2 and x != 3'};\n+1\ta\n+4\tdddd\n+1\ta\n+4\tdddd\n select * from system.numbers limit 5;\n 0\n 1\ndiff --git a/tests/queries/0_stateless/02346_additional_filters.sql b/tests/queries/0_stateless/02346_additional_filters.sql\nindex 9e0bee4549ba..f6b665713ec8 100644\n--- a/tests/queries/0_stateless/02346_additional_filters.sql\n+++ b/tests/queries/0_stateless/02346_additional_filters.sql\n@@ -1,3 +1,4 @@\n+-- Tags: distributed\n drop table if exists table_1;\n drop table if exists table_2;\n drop table if exists v_numbers;\n@@ -6,6 +7,8 @@ drop table if exists mv_table;\n create table table_1 (x UInt32, y String) engine = MergeTree order by x;\n insert into table_1 values (1, 'a'), (2, 'bb'), (3, 'ccc'), (4, 'dddd');\n \n+CREATE TABLE distr_table (x UInt32, y String) ENGINE = Distributed(test_cluster_two_shards, currentDatabase(), 'table_1');\n+\n -- { echoOn }\n \n select * from table_1;\n@@ -29,6 +32,9 @@ select x from table_1 prewhere x != 2 where x != 2 settings additional_table_fil\n select * from remote('127.0.0.{1,2}', system.one) settings additional_table_filters={'system.one' : 'dummy = 0'};\n select * from remote('127.0.0.{1,2}', system.one) settings additional_table_filters={'system.one' : 'dummy != 0'};\n \n+select * from distr_table settings additional_table_filters={'distr_table' : 'x = 2'};\n+select * from distr_table settings additional_table_filters={'distr_table' : 'x != 2 and x != 3'};\n+\n select * from system.numbers limit 5;\n select * from system.numbers as t limit 5 settings additional_table_filters={'t' : 'number % 2 != 0'};\n select * from system.numbers limit 5 settings additional_table_filters={'system.numbers' : 'number != 3'};\ndiff --git a/tests/queries/0_stateless/02346_additional_filters_distr.reference b/tests/queries/0_stateless/02346_additional_filters_distr.reference\nnew file mode 100644\nindex 000000000000..81814b5e7bb4\n--- /dev/null\n+++ b/tests/queries/0_stateless/02346_additional_filters_distr.reference\n@@ -0,0 +1,3 @@\n+4\tdddd\n+5\ta\n+6\tbb\ndiff --git a/tests/queries/0_stateless/02346_additional_filters_distr.sql b/tests/queries/0_stateless/02346_additional_filters_distr.sql\nnew file mode 100644\nindex 000000000000..bc9c1715c72f\n--- /dev/null\n+++ b/tests/queries/0_stateless/02346_additional_filters_distr.sql\n@@ -0,0 +1,20 @@\n+-- Tags: no-parallel, distributed\n+\n+create database if not exists shard_0;\n+create database if not exists shard_1;\n+\n+drop table if exists dist_02346;\n+drop table if exists shard_0.data_02346;\n+drop table if exists shard_1.data_02346;\n+\n+create table shard_0.data_02346 (x UInt32, y String) engine = MergeTree order by x settings index_granularity = 2;\n+insert into shard_0.data_02346 values (1, 'a'), (2, 'bb'), (3, 'ccc'), (4, 'dddd');\n+\n+create table shard_1.data_02346 (x UInt32, y String) engine = MergeTree order by x settings index_granularity = 2;\n+insert into shard_1.data_02346 values (5, 'a'), (6, 'bb'), (7, 'ccc'), (8, 'dddd');\n+\n+create table dist_02346 (x UInt32, y String) engine=Distributed('test_cluster_two_shards_different_databases', /* default_database= */ '', data_02346);\n+\n+set max_rows_to_read=4;\n+\n+select * from dist_02346 order by x settings additional_table_filters={'dist_02346' : 'x > 3 and x < 7'};\ndiff --git a/tests/queries/0_stateless/02346_additional_filters_index.reference b/tests/queries/0_stateless/02346_additional_filters_index.reference\nnew file mode 100644\nindex 000000000000..d4b9509cb3c4\n--- /dev/null\n+++ b/tests/queries/0_stateless/02346_additional_filters_index.reference\n@@ -0,0 +1,30 @@\n+-- { echoOn }\n+set max_rows_to_read = 2;\n+select * from table_1 order by x settings additional_table_filters={'table_1' : 'x > 3'};\n+4\tdddd\n+select * from table_1 order by x settings additional_table_filters={'table_1' : 'x < 3'};\n+1\ta\n+2\tbb\n+select * from table_1 order by x settings additional_table_filters={'table_1' : 'length(y) >= 3'};\n+3\tccc\n+4\tdddd\n+select * from table_1 order by x settings additional_table_filters={'table_1' : 'length(y) < 3'};\n+1\ta\n+2\tbb\n+set max_rows_to_read = 4;\n+select * from distr_table order by x settings additional_table_filters={'distr_table' : 'x > 3'};\n+4\tdddd\n+4\tdddd\n+select * from distr_table order by x settings additional_table_filters={'distr_table' : 'x < 3'};\n+1\ta\n+1\ta\n+2\tbb\n+2\tbb\n+select * from distr_table order by x settings additional_table_filters={'distr_table' : 'length(y) > 3'};\n+4\tdddd\n+4\tdddd\n+select * from distr_table order by x settings additional_table_filters={'distr_table' : 'length(y) < 3'};\n+1\ta\n+1\ta\n+2\tbb\n+2\tbb\ndiff --git a/tests/queries/0_stateless/02346_additional_filters_index.sql b/tests/queries/0_stateless/02346_additional_filters_index.sql\nnew file mode 100644\nindex 000000000000..0d40cc1f898a\n--- /dev/null\n+++ b/tests/queries/0_stateless/02346_additional_filters_index.sql\n@@ -0,0 +1,24 @@\n+-- Tags: distributed\n+\n+create table table_1 (x UInt32, y String, INDEX a (length(y)) TYPE minmax GRANULARITY 1) engine = MergeTree order by x settings index_granularity = 2;\n+insert into table_1 values (1, 'a'), (2, 'bb'), (3, 'ccc'), (4, 'dddd');\n+\n+CREATE TABLE distr_table (x UInt32, y String) ENGINE = Distributed(test_cluster_two_shards, currentDatabase(), 'table_1');\n+\n+-- { echoOn }\n+set max_rows_to_read = 2;\n+\n+select * from table_1 order by x settings additional_table_filters={'table_1' : 'x > 3'};\n+select * from table_1 order by x settings additional_table_filters={'table_1' : 'x < 3'};\n+\n+select * from table_1 order by x settings additional_table_filters={'table_1' : 'length(y) >= 3'};\n+select * from table_1 order by x settings additional_table_filters={'table_1' : 'length(y) < 3'};\n+\n+set max_rows_to_read = 4;\n+\n+select * from distr_table order by x settings additional_table_filters={'distr_table' : 'x > 3'};\n+select * from distr_table order by x settings additional_table_filters={'distr_table' : 'x < 3'};\n+\n+select * from distr_table order by x settings additional_table_filters={'distr_table' : 'length(y) > 3'};\n+select * from distr_table order by x settings additional_table_filters={'distr_table' : 'length(y) < 3'};\n+\n",
  "problem_statement": "additional_table_filters with distributed table\nThis impacts the Grafana plugin.\r\n\r\nFrom https://github.com/grafana/clickhouse-datasource/issues/198\r\n\r\n\r\n    if an adhoc filter is specified for the field t1_distributed.f2\r\n        the following query will be built by the plugin SELECT f1 from t1_distributed settings additional_table_filters = {'t1_distributed': 'f2 = xxx'}\r\n        this query will actually not do its job of filtering\r\n        i guess it is coming from the fact that additional_table_filters are applied by clickhouse when it reads the table....but distributed tables are not read.....\r\n        if i replace in the built query, within the additional_table_filters settings, t1_distributed with t1_local (so a query like `SELECT f1 from t1_distributed settings additional_table_filters = {'t1_local': 'f2 = xxx'}), then it is working as expected\r\n    i gave a try to add an adhoc filter on the \"local\" table (while my \"main\" query is still on the distributed table) (ie define an adhoc filter on the fied t1_local.f2)\r\n        then the built query by the plugin does not include any additional_table_filters settings (i guess there is a check in order to add additional_table_filters only on the table used in the query)\r\n\r\n\r\n\r\n\n",
  "hints_text": "",
  "created_at": "2022-10-14T17:06:04Z",
  "modified_files": [
    "src/Interpreters/ClusterProxy/executeQuery.cpp",
    "src/Interpreters/ClusterProxy/executeQuery.h",
    "src/Storages/getStructureOfRemoteTable.cpp"
  ],
  "modified_test_files": [
    "tests/queries/0_stateless/02346_additional_filters.reference",
    "tests/queries/0_stateless/02346_additional_filters.sql",
    "b/tests/queries/0_stateless/02346_additional_filters_distr.reference",
    "b/tests/queries/0_stateless/02346_additional_filters_distr.sql",
    "b/tests/queries/0_stateless/02346_additional_filters_index.reference",
    "b/tests/queries/0_stateless/02346_additional_filters_index.sql"
  ]
}