{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 26423,
  "instance_id": "ClickHouse__ClickHouse-26423",
  "issue_numbers": [
    "25411"
  ],
  "base_commit": "bf1af34e5d03ccb4a0f8a85ec1359b803240e49a",
  "patch": "diff --git a/src/DataTypes/DataTypeInterval.h b/src/DataTypes/DataTypeInterval.h\nindex d66b329185d9..a44fd686b614 100644\n--- a/src/DataTypes/DataTypeInterval.h\n+++ b/src/DataTypes/DataTypeInterval.h\n@@ -36,6 +36,7 @@ class DataTypeInterval final : public DataTypeNumberBase<Int64>\n     bool isParametric() const override { return true; }\n     bool cannotBeStoredInTables() const override { return true; }\n     bool isCategorial() const override { return false; }\n+    bool canBeInsideNullable() const override { return true; }\n };\n \n }\ndiff --git a/src/Functions/IFunction.cpp b/src/Functions/IFunction.cpp\nindex 998d48941ba8..e3802b98abf6 100644\n--- a/src/Functions/IFunction.cpp\n+++ b/src/Functions/IFunction.cpp\n@@ -181,7 +181,10 @@ ColumnPtr IExecutableFunction::defaultImplementationForNulls(\n     {\n         // Default implementation for nulls returns null result for null arguments,\n         // so the result type must be nullable.\n-        assert(result_type->isNullable());\n+        if (!result_type->isNullable())\n+            throw Exception(ErrorCodes::LOGICAL_ERROR,\n+                            \"Function {} with Null argument and default implementation for Nulls \"\n+                            \"is expected to return Nullable result, got {}\", result_type->getName());\n \n         return result_type->createColumnConstWithDefaultValue(input_rows_count);\n     }\ndiff --git a/src/Interpreters/ExecuteScalarSubqueriesVisitor.cpp b/src/Interpreters/ExecuteScalarSubqueriesVisitor.cpp\nindex adddb0c33d97..f46cbdd24652 100644\n--- a/src/Interpreters/ExecuteScalarSubqueriesVisitor.cpp\n+++ b/src/Interpreters/ExecuteScalarSubqueriesVisitor.cpp\n@@ -1,8 +1,10 @@\n #include <Interpreters/ExecuteScalarSubqueriesVisitor.h>\n \n #include <Columns/ColumnTuple.h>\n+#include <Columns/ColumnNullable.h>\n #include <DataStreams/materializeBlock.h>\n #include <DataTypes/DataTypeTuple.h>\n+#include <DataTypes/DataTypeNullable.h>\n #include <IO/WriteHelpers.h>\n #include <Interpreters/Context.h>\n #include <Interpreters/InterpreterSelectWithUnionQuery.h>\n@@ -15,6 +17,7 @@\n #include <Parsers/ASTSubquery.h>\n #include <Parsers/ASTTablesInSelectQuery.h>\n #include <Parsers/ASTWithElement.h>\n+#include <Parsers/queryToString.h>\n #include <Processors/Executors/PullingAsyncPipelineExecutor.h>\n \n \n@@ -119,8 +122,24 @@ void ExecuteScalarSubqueriesMatcher::visit(const ASTSubquery & subquery, ASTPtr\n \n             if (block.rows() == 0)\n             {\n-                /// Interpret subquery with empty result as Null literal\n-                auto ast_new = std::make_unique<ASTLiteral>(Null());\n+                auto types = interpreter.getSampleBlock().getDataTypes();\n+                if (types.size() != 1)\n+                    types = {std::make_shared<DataTypeTuple>(types)};\n+\n+                auto & type = types[0];\n+                if (!type->isNullable())\n+                {\n+                    if (!type->canBeInsideNullable())\n+                        throw Exception(ErrorCodes::INCORRECT_RESULT_OF_SCALAR_SUBQUERY,\n+                                        \"Scalar subquery returned empty result of type {} which cannot be Nullable\",\n+                                        type->getName());\n+\n+                    type = makeNullable(type);\n+                }\n+\n+                ASTPtr ast_new = std::make_shared<ASTLiteral>(Null());\n+                ast_new = addTypeConversionToAST(std::move(ast_new), type->getName());\n+\n                 ast_new->setAlias(ast->tryGetAlias());\n                 ast = std::move(ast_new);\n                 return;\n@@ -140,10 +159,20 @@ void ExecuteScalarSubqueriesMatcher::visit(const ASTSubquery & subquery, ASTPtr\n         size_t columns = block.columns();\n \n         if (columns == 1)\n+        {\n+            auto & column = block.getByPosition(0);\n+            /// Here we wrap type to nullable if we can.\n+            /// It is needed cause if subquery return no rows, it's result will be Null.\n+            /// In case of many columns, do not check it cause tuple can't be nullable.\n+            if (!column.type->isNullable() && column.type->canBeInsideNullable())\n+            {\n+                column.type = makeNullable(column.type);\n+                column.column = makeNullable(column.column);\n+            }\n             scalar = block;\n+        }\n         else\n         {\n-\n             ColumnWithTypeAndName ctn;\n             ctn.type = std::make_shared<DataTypeTuple>(block.getDataTypes());\n             ctn.column = ColumnTuple::create(block.getColumns());\ndiff --git a/src/Interpreters/OptimizeIfWithConstantConditionVisitor.cpp b/src/Interpreters/OptimizeIfWithConstantConditionVisitor.cpp\nindex cdcf6f7dddd9..a8e2d371e051 100644\n--- a/src/Interpreters/OptimizeIfWithConstantConditionVisitor.cpp\n+++ b/src/Interpreters/OptimizeIfWithConstantConditionVisitor.cpp\n@@ -39,9 +39,12 @@ static bool tryExtractConstValueFromCondition(const ASTPtr & condition, bool & v\n                 const ASTPtr & type_ast = expr_list->children.at(1);\n                 if (const auto * type_literal = type_ast->as<ASTLiteral>())\n                 {\n-                    if (type_literal->value.getType() == Field::Types::String &&\n-                        type_literal->value.get<std::string>() == \"UInt8\")\n-                        return tryExtractConstValueFromCondition(expr_list->children.at(0), value);\n+                    if (type_literal->value.getType() == Field::Types::String)\n+                    {\n+                        const auto & type_str = type_literal->value.get<std::string>();\n+                        if (type_str == \"UInt8\" || type_str == \"Nullable(UInt8)\")\n+                            return tryExtractConstValueFromCondition(expr_list->children.at(0), value);\n+                    }\n                 }\n             }\n         }\ndiff --git a/src/Storages/MergeTree/KeyCondition.cpp b/src/Storages/MergeTree/KeyCondition.cpp\nindex e58d4ecfc073..235cadfba117 100644\n--- a/src/Storages/MergeTree/KeyCondition.cpp\n+++ b/src/Storages/MergeTree/KeyCondition.cpp\n@@ -531,6 +531,11 @@ bool KeyCondition::getConstant(const ASTPtr & expr, Block & block_with_constants\n         /// Simple literal\n         out_value = lit->value;\n         out_type = block_with_constants.getByName(column_name).type;\n+\n+        /// If constant is not Null, we can assume it's type is not Nullable as well.\n+        if (!out_value.isNull())\n+            out_type = removeNullable(out_type);\n+\n         return true;\n     }\n     else if (block_with_constants.has(column_name) && isColumnConst(*block_with_constants.getByName(column_name).column))\n@@ -539,6 +544,10 @@ bool KeyCondition::getConstant(const ASTPtr & expr, Block & block_with_constants\n         const auto & expr_info = block_with_constants.getByName(column_name);\n         out_value = (*expr_info.column)[0];\n         out_type = expr_info.type;\n+\n+        if (!out_value.isNull())\n+            out_type = removeNullable(out_type);\n+\n         return true;\n     }\n     else\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/00205_emptyscalar_subquery_type_mismatch_bug.reference b/tests/queries/0_stateless/00205_emptyscalar_subquery_type_mismatch_bug.reference\nnew file mode 100644\nindex 000000000000..e69de29bb2d1\ndiff --git a/tests/queries/0_stateless/00205_emptyscalar_subquery_type_mismatch_bug.sql b/tests/queries/0_stateless/00205_emptyscalar_subquery_type_mismatch_bug.sql\nnew file mode 100644\nindex 000000000000..aeac6be7d8fb\n--- /dev/null\n+++ b/tests/queries/0_stateless/00205_emptyscalar_subquery_type_mismatch_bug.sql\n@@ -0,0 +1,38 @@\n+\n+-- Bug reproduction form #25411\n+WITH a AS (select (select 1 WHERE 0) as b)\n+select 1\n+from system.one\n+cross join a\n+where a.b = 0;\n+\n+-- Reported query\n+drop table if exists t_q1ht4gq_5;\n+create table t_q1ht4gq_5 (c_zeij INTEGER NOT NULL, c_fehk75l TEXT, c_jz TEXT, c_wynzuek TEXT, c_nkt INTEGER NOT NULL, c_g TEXT, c_mc2 TEXT, primary key(c_nkt)) engine = MergeTree();\n+WITH\n+cte_0 AS (select\n+    subq_0.c6 as c2,\n+    case when 0<>0 then ((select c_zeij from t_q1ht4gq_5 order by c_zeij limit 1 offset 1)\n+           + subq_0.c4) else ((select c_zeij from t_q1ht4gq_5 order by c_zeij limit 1 offset 1)\n+           + subq_0.c4) end as c4\n+  from\n+    (select\n+          ref_0.c_nkt as c4,\n+          ref_0.c_nkt as c6\n+        from\n+          t_q1ht4gq_5 as ref_0\n+        ) as subq_0\n+  )\n+select\n+    ref_12.c_zeij as c3\n+  from\n+    t_q1ht4gq_5 as ref_12\n+  where (ref_12.c_jz not in (\n+          select\n+              ref_14.c_mc2 as c0\n+            from\n+              t_q1ht4gq_5 as ref_14\n+                cross join cte_0 as ref_15\n+            where ref_15.c4 > ref_15.c2));\n+\n+drop table if exists t_q1ht4gq_5;\ndiff --git a/tests/queries/0_stateless/00205_scalar_subqueries.reference b/tests/queries/0_stateless/00205_scalar_subqueries.reference\nindex 7b3ebbc75191..3e18045c8eda 100644\n--- a/tests/queries/0_stateless/00205_scalar_subqueries.reference\n+++ b/tests/queries/0_stateless/00205_scalar_subqueries.reference\n@@ -3,3 +3,6 @@\n 1\t1\n ('2015-01-02','Hello')\n ('2015-01-02','Hello')\t('2015-01-02','Hello')\t1\t1\n+\\N\n+(1,2)\n+[1]\ndiff --git a/tests/queries/0_stateless/00205_scalar_subqueries.sql b/tests/queries/0_stateless/00205_scalar_subqueries.sql\nindex 03bcd0a3ebce..c6cece662446 100644\n--- a/tests/queries/0_stateless/00205_scalar_subqueries.sql\n+++ b/tests/queries/0_stateless/00205_scalar_subqueries.sql\n@@ -8,3 +8,14 @@ SELECT (SELECT toDate('2015-01-02'), 'Hello') AS x, x, identity((SELECT 1)), ide\n -- SELECT (SELECT uniqState(''));\n \n  SELECT ( SELECT throwIf(1 + dummy) );  -- { serverError 395 }\n+\n+-- Scalar subquery with 0 rows must return Null\n+SELECT (SELECT 1 WHERE 0);\n+-- But tuple and array can't be inside nullable\n+SELECT (SELECT 1, 2 WHERE 0); -- { serverError 125 }\n+SELECT (SELECT [1] WHERE 0); -- { serverError 125 }\n+-- Works for not-empty casle\n+SELECT (SELECT 1, 2);\n+SELECT (SELECT [1]);\n+-- Several rows\n+SELECT (SELECT number FROM numbers(2)); -- { serverError 125 }\ndiff --git a/tests/queries/0_stateless/00597_push_down_predicate_long.reference b/tests/queries/0_stateless/00597_push_down_predicate_long.reference\nindex bd7d3cd81d46..3eaa1139c5df 100644\n--- a/tests/queries/0_stateless/00597_push_down_predicate_long.reference\n+++ b/tests/queries/0_stateless/00597_push_down_predicate_long.reference\n@@ -114,7 +114,7 @@ FROM\n (\n     SELECT\n         1 AS id,\n-        identity(CAST(1, \\'UInt8\\')) AS subquery\n+        identity(CAST(1, \\'Nullable(UInt8)\\')) AS subquery\n     WHERE subquery = 1\n )\n WHERE subquery = 1\ndiff --git a/tests/queries/0_stateless/01029_early_constant_folding.reference b/tests/queries/0_stateless/01029_early_constant_folding.reference\nindex 6063e08afe03..88139b7e2b80 100644\n--- a/tests/queries/0_stateless/01029_early_constant_folding.reference\n+++ b/tests/queries/0_stateless/01029_early_constant_folding.reference\n@@ -2,7 +2,7 @@ SELECT 1\n WHERE 0\n SELECT 1\n SELECT 1\n-WHERE (1 IN (0, 2)) AND (2 = (identity(CAST(2, \\'UInt8\\')) AS subquery))\n+WHERE (1 IN (0, 2)) AND (2 = (identity(CAST(2, \\'Nullable(UInt8)\\')) AS subquery))\n SELECT 1\n WHERE 1 IN ((\n     SELECT arrayJoin([1, 2, 3])\ndiff --git a/tests/queries/0_stateless/01611_constant_folding_subqueries.reference b/tests/queries/0_stateless/01611_constant_folding_subqueries.reference\nindex e46fd479413e..6128cd109e2f 100644\n--- a/tests/queries/0_stateless/01611_constant_folding_subqueries.reference\n+++ b/tests/queries/0_stateless/01611_constant_folding_subqueries.reference\n@@ -5,7 +5,7 @@ SELECT (SELECT * FROM system.numbers LIMIT 1 OFFSET 1) AS n, toUInt64(10 / n) FO\n 1,10\n EXPLAIN SYNTAX SELECT (SELECT * FROM system.numbers LIMIT 1 OFFSET 1) AS n, toUInt64(10 / n);\n SELECT\n-    identity(CAST(0, \\'UInt64\\')) AS n,\n+    identity(CAST(0, \\'Nullable(UInt64)\\')) AS n,\n     toUInt64(10 / n)\n SELECT * FROM (WITH (SELECT * FROM system.numbers LIMIT 1 OFFSET 1) AS n, toUInt64(10 / n) as q SELECT * FROM system.one WHERE q > 0);\n 0\ndiff --git a/tests/queries/0_stateless/01651_bugs_from_15889.reference b/tests/queries/0_stateless/01651_bugs_from_15889.reference\nindex 77ac542d4fbf..8b137891791f 100644\n--- a/tests/queries/0_stateless/01651_bugs_from_15889.reference\n+++ b/tests/queries/0_stateless/01651_bugs_from_15889.reference\n@@ -1,2 +1,1 @@\n-0\n \ndiff --git a/tests/queries/0_stateless/01651_bugs_from_15889.sql b/tests/queries/0_stateless/01651_bugs_from_15889.sql\nindex d0f1006da95d..4717a8dcc0d5 100644\n--- a/tests/queries/0_stateless/01651_bugs_from_15889.sql\n+++ b/tests/queries/0_stateless/01651_bugs_from_15889.sql\n@@ -55,7 +55,7 @@ WHERE (query_id =\n     WHERE current_database = currentDatabase() AND (query LIKE '%test cpu time query profiler%') AND (query NOT LIKE '%system%')\n     ORDER BY event_time DESC\n     LIMIT 1\n-)) AND (symbol LIKE '%Source%');\n+)) AND (symbol LIKE '%Source%'); -- { serverError 125 }\n \n \n WITH addressToSymbol(arrayJoin(trace)) AS symbol\n@@ -70,7 +70,7 @@ WHERE greaterOrEquals(event_date, ignore(ignore(ignore(NULL, '')), 256), yesterd\n     WHERE current_database = currentDatabase() AND (event_date >= yesterday()) AND (query LIKE '%test memory profiler%')\n     ORDER BY event_time DESC\n     LIMIT 1\n-)); -- { serverError 42 }\n+)); -- { serverError 125 }\n \n DROP TABLE IF EXISTS trace_log;\n \ndiff --git a/tests/queries/0_stateless/01756_optimize_skip_unused_shards_rewrite_in.reference b/tests/queries/0_stateless/01756_optimize_skip_unused_shards_rewrite_in.reference\nindex 65b7bf54f7ff..972f4c89bdfe 100644\n--- a/tests/queries/0_stateless/01756_optimize_skip_unused_shards_rewrite_in.reference\n+++ b/tests/queries/0_stateless/01756_optimize_skip_unused_shards_rewrite_in.reference\n@@ -1,17 +1,17 @@\n (0, 2)\n 0\t0\n 0\t0\n-WITH CAST(\\'default\\', \\'String\\') AS id_no SELECT one.dummy, ignore(id_no) FROM system.one WHERE dummy IN (0, 2)\n-WITH CAST(\\'default\\', \\'String\\') AS id_no SELECT one.dummy, ignore(id_no) FROM system.one WHERE dummy IN (0, 2)\n+WITH CAST(\\'default\\', \\'Nullable(String)\\') AS id_no SELECT one.dummy, ignore(id_no) FROM system.one WHERE dummy IN (0, 2)\n+WITH CAST(\\'default\\', \\'Nullable(String)\\') AS id_no SELECT one.dummy, ignore(id_no) FROM system.one WHERE dummy IN (0, 2)\n optimize_skip_unused_shards_rewrite_in(0, 2)\n 0\t0\n-WITH CAST(\\'default\\', \\'String\\') AS id_02 SELECT one.dummy, ignore(id_02) FROM system.one WHERE dummy IN tuple(0)\n-WITH CAST(\\'default\\', \\'String\\') AS id_02 SELECT one.dummy, ignore(id_02) FROM system.one WHERE dummy IN tuple(2)\n+WITH CAST(\\'default\\', \\'Nullable(String)\\') AS id_02 SELECT one.dummy, ignore(id_02) FROM system.one WHERE dummy IN tuple(0)\n+WITH CAST(\\'default\\', \\'Nullable(String)\\') AS id_02 SELECT one.dummy, ignore(id_02) FROM system.one WHERE dummy IN tuple(2)\n optimize_skip_unused_shards_rewrite_in(2,)\n-WITH CAST(\\'default\\', \\'String\\') AS id_2 SELECT one.dummy, ignore(id_2) FROM system.one WHERE dummy IN tuple(2)\n+WITH CAST(\\'default\\', \\'Nullable(String)\\') AS id_2 SELECT one.dummy, ignore(id_2) FROM system.one WHERE dummy IN tuple(2)\n optimize_skip_unused_shards_rewrite_in(0,)\n 0\t0\n-WITH CAST(\\'default\\', \\'String\\') AS id_0 SELECT one.dummy, ignore(id_0) FROM system.one WHERE dummy IN tuple(0)\n+WITH CAST(\\'default\\', \\'Nullable(String)\\') AS id_0 SELECT one.dummy, ignore(id_0) FROM system.one WHERE dummy IN tuple(0)\n 0\n 0\n errors\n",
  "problem_statement": "Bug report: Assertion `result_type->isNullable()' failed\n**Describe the bug**\r\n\r\nI used my fuzzing tool to test ClickHouse (v21.5.6.6-stable), and found an assertion failure by using specific sql.\r\n\r\n**Does it reproduce on recent release?**\r\n\r\nv21.5.6.6-stable\r\n\r\n**How to reproduce**\r\n\r\n* ClickHouse server version: v21.5.6.6-stable\r\n* Installation: \r\n```\r\n1. mkdir build; cd build\r\n2. cmake ..  \\\r\n        -DCMAKE_BUILD_TYPE=Debug     \\\r\n        -DENABLE_CLICKHOUSE_ALL=OFF     \\\r\n        -DENABLE_CLICKHOUSE_SERVER=ON     \\\r\n        -DENABLE_CLICKHOUSE_CLIENT=ON     \\\r\n        -DENABLE_LIBRARIES=OFF     \\\r\n        -DUSE_UNWIND=ON     \\\r\n        -DENABLE_UTILS=OFF     \\\r\n        -DENABLE_TESTS=OFF -DSANITIZE=address\r\n3. sudo make install\r\n```\r\n\r\n* Test command: \r\n```\r\n1. clickhouse-server &\r\n\r\n2. clickhouse-client --query '\r\ncreate table t_q1ht4gq_5 (\r\nc_zeij INTEGER NOT NULL,\r\nc_fehk75l TEXT ,\r\nc_jz TEXT ,\r\nc_wynzuek TEXT ,\r\nc_nkt INTEGER NOT NULL,\r\nc_g TEXT ,\r\nc_mc2 TEXT ,\r\nprimary key(c_nkt)\r\n) engine = MergeTree();'\r\n\r\n3. clickhouse-client --query '\r\nWITH\r\ncte_0 AS (select\r\n    subq_0.c6 as c2,\r\n    case when 0<>0 then ((select c_zeij from t_q1ht4gq_5 order by c_zeij limit 1 offset 1)\r\n           + subq_0.c4) else ((select c_zeij from t_q1ht4gq_5 order by c_zeij limit 1 offset 1)\r\n           + subq_0.c4) end as c4 \r\n  from\r\n    (select  \r\n          ref_0.c_nkt as c4, \r\n          ref_0.c_nkt as c6  \r\n        from \r\n          t_q1ht4gq_5 as ref_0\r\n        ) as subq_0\r\n  )\r\nselect\r\n    ref_12.c_zeij as c3\r\n  from\r\n    t_q1ht4gq_5 as ref_12\r\n  where (ref_12.c_jz not in (\r\n          select\r\n              ref_14.c_mc2 as c0\r\n            from\r\n              t_q1ht4gq_5 as ref_14\r\n                cross join cte_0 as ref_15\r\n            where ref_15.c4 > ref_15.c2))\r\n;'\r\n```\r\n\r\n**Expected behavior**\r\n\r\nNormally run.\r\n\r\n**Error message and/or stacktrace**\r\n\r\n```\r\nCode: 32. DB::Exception: Attempt to read after eof: while receiving packet from localhost:900\r\n```\r\n\r\n**Log file of ClickHouse Server**\r\n\r\n```\r\nProcessing configuration file 'config.xml'.\r\nThere is no file 'config.xml', will use embedded config.\r\nLogging trace to console\r\n2021.06.17 20:40:36.834407 [ 32415 ] {} <Trace> Pipe: Pipe capacity is 1.00 MiB\r\n2021.06.17 20:40:43.260089 [ 32415 ] {} <Information> : Starting ClickHouse 21.5.6.1 with revision 54450, build id: D418120B6778C79B, PID 32415\r\n2021.06.17 20:40:43.260757 [ 32415 ] {} <Information> : Set OOM score adjustment to 555\r\n2021.06.17 20:40:43.261943 [ 32415 ] {} <Information> Application: starting up\r\n2021.06.17 20:40:43.299861 [ 32415 ] {} <Warning> Application: Server was built in debug mode. It will work slowly.\r\n2021.06.17 20:40:43.300162 [ 32415 ] {} <Warning> Application: Server was built with sanitizer. It will work slowly.\r\n2021.06.17 20:41:33.539241 [ 32415 ] {} <Warning> Application: Calculated checksum of the binary: 3F2399641A58AB6899D4DE6968820D06. There is no information about the reference checksum.\r\n2021.06.17 20:41:33.539820 [ 32415 ] {} <Information> Application: It looks like the process has no CAP_IPC_LOCK capability, binary mlock will be disabled. It could happen due to incorrect ClickHouse package installation. You could resolve the problem manually with 'sudo setcap cap_ipc_lock=+ep /usr/local/bin/clickhouse'. Note that it will not work on 'nosuid' mounted filesystems.\r\n2021.06.17 20:41:33.540425 [ 32415 ] {} <Information> StatusFile: Status file ./status already exists - unclean restart. Contents:\r\nPID: 31500\r\nStarted at: 2021-06-17 20:37:24\r\nRevision: 54450\r\n\r\n2021.06.17 20:41:33.540817 [ 32415 ] {} <Debug> Application: rlimit on number of file descriptors is 1048576\r\n2021.06.17 20:41:33.541079 [ 32415 ] {} <Debug> Application: Initializing DateLUT.\r\n2021.06.17 20:41:33.541265 [ 32415 ] {} <Trace> Application: Initialized DateLUT with time zone 'Asia/Shanghai'.\r\n2021.06.17 20:41:33.541651 [ 32415 ] {} <Debug> Application: Setting up ./tmp/ to store temporary data in it\r\n2021.06.17 20:41:33.542406 [ 32415 ] {} <Debug> Application: Initiailizing interserver credentials.\r\n2021.06.17 20:41:33.570810 [ 32415 ] {} <Debug> ConfigReloader: Loading config 'config.xml'\r\nProcessing configuration file 'config.xml'.\r\nThere is no file 'config.xml', will use embedded config.\r\nSaved preprocessed configuration to './preprocessed_configs/config.xml'.\r\n2021.06.17 20:41:33.576967 [ 32415 ] {} <Debug> ConfigReloader: Loaded config 'config.xml', performing update on configuration\r\n2021.06.17 20:41:33.584385 [ 32415 ] {} <Information> Application: Setting max_server_memory_usage was set to 28.22 GiB (31.36 GiB available * 0.90 max_server_memory_usage_to_ram_ratio)\r\n2021.06.17 20:41:33.586544 [ 32415 ] {} <Debug> ConfigReloader: Loaded config 'config.xml', performed update on configuration\r\n2021.06.17 20:41:33.614348 [ 32415 ] {} <Debug> ConfigReloader: Loading config 'config.xml'\r\nProcessing configuration file 'config.xml'.\r\nThere is no file 'config.xml', will use embedded config.\r\nSaved preprocessed configuration to './preprocessed_configs/config.xml'.\r\n2021.06.17 20:41:33.620156 [ 32415 ] {} <Debug> ConfigReloader: Loaded config 'config.xml', performing update on configuration\r\n2021.06.17 20:41:33.653580 [ 32415 ] {} <Debug> ConfigReloader: Loaded config 'config.xml', performed update on configuration\r\n2021.06.17 20:41:33.659532 [ 32415 ] {} <Debug> Access(user directories): Added users.xml access storage 'users.xml', path: config.xml\r\n2021.06.17 20:41:33.662998 [ 32415 ] {} <Information> Application: Loading metadata from ./\r\n2021.06.17 20:41:33.666256 [ 32415 ] {} <Information> DatabaseAtomic (system): Total 0 tables and 0 dictionaries.\r\n2021.06.17 20:41:33.666403 [ 32415 ] {} <Information> DatabaseAtomic (system): Starting up tables.\r\n2021.06.17 20:41:35.443707 [ 32415 ] {} <Information> DatabaseAtomic (default): Total 0 tables and 0 dictionaries.\r\n2021.06.17 20:41:35.443962 [ 32415 ] {} <Information> DatabaseAtomic (default): Starting up tables.\r\n2021.06.17 20:41:35.460386 [ 32415 ] {} <Information> DatabaseAtomic (re_test_db): Total 1 tables and 0 dictionaries.\r\n2021.06.17 20:41:35.472996 [ 32617 ] {} <Debug> re_test_db.t_q1ht4gq_5 (0c4ce51e-840f-42f7-add8-6634c8677067): Loading data parts\r\n2021.06.17 20:41:35.473598 [ 32617 ] {} <Debug> re_test_db.t_q1ht4gq_5 (0c4ce51e-840f-42f7-add8-6634c8677067): There are no data parts\r\n2021.06.17 20:41:35.474639 [ 32415 ] {} <Information> DatabaseAtomic (re_test_db): Starting up tables.\r\n2021.06.17 20:41:35.475728 [ 32617 ] {} <Information> BackgroundSchedulePool/BgSchPool: Create BackgroundSchedulePool with 16 threads\r\n2021.06.17 20:41:35.494538 [ 32415 ] {} <Information> DatabaseCatalog: Found 4 partially dropped tables. Will load them and retry removal.\r\n2021.06.17 20:41:35.495689 [ 32617 ] {} <Information> DatabaseCatalog: Trying load partially dropped table re_test_db.t_q1ht4gq_5 (32d819e1-c9fb-4ab0-8170-5e75c4cfe8f4) from ./metadata_dropped/re_test_db.t_q1ht4gq_5.32d819e1-c9fb-4ab0-8170-5e75c4cfe8f4.sql\r\n2021.06.17 20:41:35.497318 [ 32637 ] {} <Information> DatabaseCatalog: Trying load partially dropped table re_test_db.t_q1ht4gq_5 (88e3180c-15bd-4aa4-af72-a89626a70dab) from ./metadata_dropped/re_test_db.t_q1ht4gq_5.88e3180c-15bd-4aa4-af72-a89626a70dab.sql\r\n2021.06.17 20:41:35.497425 [ 32635 ] {} <Information> DatabaseCatalog: Trying load partially dropped table re_test_db.t_q1ht4gq_5 (50cc7d75-6274-48b0-a944-9d528ff2cdd8) from ./metadata_dropped/re_test_db.t_q1ht4gq_5.50cc7d75-6274-48b0-a944-9d528ff2cdd8.sql\r\n2021.06.17 20:41:35.497463 [ 32636 ] {} <Information> DatabaseCatalog: Trying load partially dropped table re_test_db.t_q1ht4gq_5 (61a92440-26d4-4c45-8011-c788893650dc) from ./metadata_dropped/re_test_db.t_q1ht4gq_5.61a92440-26d4-4c45-8011-c788893650dc.sql\r\n2021.06.17 20:41:35.518976 [ 32617 ] {} <Debug> re_test_db.t_q1ht4gq_5 (32d819e1-c9fb-4ab0-8170-5e75c4cfe8f4): Loading data parts\r\n2021.06.17 20:41:35.519102 [ 32637 ] {} <Debug> re_test_db.t_q1ht4gq_5 (88e3180c-15bd-4aa4-af72-a89626a70dab): Loading data parts\r\n2021.06.17 20:41:35.519749 [ 32617 ] {} <Debug> re_test_db.t_q1ht4gq_5 (32d819e1-c9fb-4ab0-8170-5e75c4cfe8f4): There are no data parts\r\n2021.06.17 20:41:35.519796 [ 32637 ] {} <Debug> re_test_db.t_q1ht4gq_5 (88e3180c-15bd-4aa4-af72-a89626a70dab): There are no data parts\r\n2021.06.17 20:41:35.524137 [ 32635 ] {} <Debug> re_test_db.t_q1ht4gq_5 (50cc7d75-6274-48b0-a944-9d528ff2cdd8): Loading data parts\r\n2021.06.17 20:41:35.524195 [ 32636 ] {} <Debug> re_test_db.t_q1ht4gq_5 (61a92440-26d4-4c45-8011-c788893650dc): Loading data parts\r\n2021.06.17 20:41:35.524770 [ 32635 ] {} <Debug> re_test_db.t_q1ht4gq_5 (50cc7d75-6274-48b0-a944-9d528ff2cdd8): There are no data parts\r\n2021.06.17 20:41:35.524788 [ 32636 ] {} <Debug> re_test_db.t_q1ht4gq_5 (61a92440-26d4-4c45-8011-c788893650dc): There are no data parts\r\n2021.06.17 20:41:35.526129 [ 32415 ] {} <Debug> Application: Loaded metadata.\r\n2021.06.17 20:41:35.526315 [ 32415 ] {} <Information> Application: Query Profiler and TraceCollector are disabled because they cannot work under sanitizers when two different stack unwinding methods will interfere with each other.\r\n2021.06.17 20:41:35.526579 [ 32620 ] {} <Information> DatabaseCatalog: Have 4 tables in drop queue (0 of them are in use), will try drop re_test_db.t_q1ht4gq_5 (88e3180c-15bd-4aa4-af72-a89626a70dab)\r\n2021.06.17 20:41:35.526725 [ 32415 ] {} <Information> Application: It looks like the process has no CAP_SYS_NICE capability, the setting 'os_thread_priority' will have no effect. It could happen due to incorrect ClickHouse package installation. You could resolve the problem manually with 'sudo setcap cap_sys_nice=+ep /usr/local/bin/clickhouse'. Note that it will not work on 'nosuid' mounted filesystems.\r\n2021.06.17 20:41:35.527087 [ 32620 ] {} <Trace> re_test_db.t_q1ht4gq_5 (88e3180c-15bd-4aa4-af72-a89626a70dab): dropAllData: waiting for locks.\r\n2021.06.17 20:41:35.527359 [ 32620 ] {} <Trace> re_test_db.t_q1ht4gq_5 (88e3180c-15bd-4aa4-af72-a89626a70dab): dropAllData: removing data from memory.\r\n2021.06.17 20:41:35.527618 [ 32620 ] {} <Trace> re_test_db.t_q1ht4gq_5 (88e3180c-15bd-4aa4-af72-a89626a70dab): dropAllData: removing data from filesystem.\r\n2021.06.17 20:41:35.528823 [ 32620 ] {} <Trace> re_test_db.t_q1ht4gq_5 (88e3180c-15bd-4aa4-af72-a89626a70dab): dropAllData: done.\r\n2021.06.17 20:41:35.528955 [ 32415 ] {} <Information> Application: Listening for http://[::1]:8123\r\n2021.06.17 20:41:35.529356 [ 32620 ] {} <Information> DatabaseCatalog: Removing metadata ./metadata_dropped/re_test_db.t_q1ht4gq_5.88e3180c-15bd-4aa4-af72-a89626a70dab.sql of dropped table re_test_db.t_q1ht4gq_5 (88e3180c-15bd-4aa4-af72-a89626a70dab)\r\n2021.06.17 20:41:35.530037 [ 32415 ] {} <Information> Application: Listening for connections with native protocol (tcp): [::1]:9000\r\n2021.06.17 20:41:35.530416 [ 32619 ] {} <Trace> DatabaseCatalog: Not found any suitable tables to drop, still have 3 tables in drop queue (0 of them are in use). Will check again after 3 seconds\r\n2021.06.17 20:41:35.530819 [ 32415 ] {} <Information> Application: Listening for MySQL compatibility protocol: [::1]:9004\r\n2021.06.17 20:41:35.531607 [ 32415 ] {} <Information> Application: Listening for http://127.0.0.1:8123\r\n2021.06.17 20:41:35.532045 [ 32415 ] {} <Information> Application: Listening for connections with native protocol (tcp): 127.0.0.1:9000\r\n2021.06.17 20:41:35.532532 [ 32415 ] {} <Information> Application: Listening for MySQL compatibility protocol: 127.0.0.1:9004\r\n2021.06.17 20:41:35.533126 [ 32415 ] {} <Debug> AsynchronousMetrics: MemoryTracking: was 0.00 B, peak 0.00 B, will set to 1.34 GiB (RSS), difference: 1.34 GiB\r\n2021.06.17 20:41:35.533360 [ 32415 ] {} <Debug> MemoryTracker: Current memory usage (total): 1.34 GiB.\r\n2021.06.17 20:41:35.555381 [ 32415 ] {} <Information> DNSCacheUpdater: Update period 15 seconds\r\n2021.06.17 20:41:35.555820 [ 32415 ] {} <Information> Application: Available RAM: 31.36 GiB; physical cores: 12; logical cores: 12.\r\n2021.06.17 20:41:35.555897 [ 32621 ] {} <Debug> DNSResolver: Updating DNS cache\r\n2021.06.17 20:41:35.556327 [ 32621 ] {} <Debug> DNSResolver: Updated DNS cache\r\n2021.06.17 20:41:35.558515 [ 32415 ] {} <Information> Application: Ready for connections.\r\n2021.06.17 20:41:38.531592 [ 32620 ] {} <Information> DatabaseCatalog: Have 3 tables in drop queue (0 of them are in use), will try drop re_test_db.t_q1ht4gq_5 (61a92440-26d4-4c45-8011-c788893650dc)\r\n2021.06.17 20:41:38.532154 [ 32620 ] {} <Trace> re_test_db.t_q1ht4gq_5 (61a92440-26d4-4c45-8011-c788893650dc): dropAllData: waiting for locks.\r\n2021.06.17 20:41:38.532468 [ 32620 ] {} <Trace> re_test_db.t_q1ht4gq_5 (61a92440-26d4-4c45-8011-c788893650dc): dropAllData: removing data from memory.\r\n2021.06.17 20:41:38.532837 [ 32620 ] {} <Trace> re_test_db.t_q1ht4gq_5 (61a92440-26d4-4c45-8011-c788893650dc): dropAllData: removing data from filesystem.\r\n2021.06.17 20:41:38.534560 [ 32620 ] {} <Trace> re_test_db.t_q1ht4gq_5 (61a92440-26d4-4c45-8011-c788893650dc): dropAllData: done.\r\n2021.06.17 20:41:38.535194 [ 32620 ] {} <Information> DatabaseCatalog: Removing metadata ./metadata_dropped/re_test_db.t_q1ht4gq_5.61a92440-26d4-4c45-8011-c788893650dc.sql of dropped table re_test_db.t_q1ht4gq_5 (61a92440-26d4-4c45-8011-c788893650dc)\r\n2021.06.17 20:41:38.536869 [ 32621 ] {} <Trace> DatabaseCatalog: Not found any suitable tables to drop, still have 2 tables in drop queue (0 of them are in use). Will check again after 12 seconds\r\n2021.06.17 20:41:50.538183 [ 32625 ] {} <Information> DatabaseCatalog: Have 2 tables in drop queue (0 of them are in use), will try drop re_test_db.t_q1ht4gq_5 (50cc7d75-6274-48b0-a944-9d528ff2cdd8)\r\n2021.06.17 20:41:50.538876 [ 32625 ] {} <Trace> re_test_db.t_q1ht4gq_5 (50cc7d75-6274-48b0-a944-9d528ff2cdd8): dropAllData: waiting for locks.\r\n2021.06.17 20:41:50.539242 [ 32625 ] {} <Trace> re_test_db.t_q1ht4gq_5 (50cc7d75-6274-48b0-a944-9d528ff2cdd8): dropAllData: removing data from memory.\r\n2021.06.17 20:41:50.539592 [ 32625 ] {} <Trace> re_test_db.t_q1ht4gq_5 (50cc7d75-6274-48b0-a944-9d528ff2cdd8): dropAllData: removing data from filesystem.\r\n2021.06.17 20:41:50.541254 [ 32625 ] {} <Trace> re_test_db.t_q1ht4gq_5 (50cc7d75-6274-48b0-a944-9d528ff2cdd8): dropAllData: done.\r\n2021.06.17 20:41:50.541918 [ 32625 ] {} <Information> DatabaseCatalog: Removing metadata ./metadata_dropped/re_test_db.t_q1ht4gq_5.50cc7d75-6274-48b0-a944-9d528ff2cdd8.sql of dropped table re_test_db.t_q1ht4gq_5 (50cc7d75-6274-48b0-a944-9d528ff2cdd8)\r\n2021.06.17 20:41:50.543361 [ 32626 ] {} <Trace> DatabaseCatalog: Not found any suitable tables to drop, still have 1 tables in drop queue (0 of them are in use). Will check again after 132 seconds\r\n2021.06.17 20:41:50.556840 [ 32627 ] {} <Debug> DNSResolver: Updating DNS cache\r\n2021.06.17 20:41:50.557251 [ 32627 ] {} <Debug> DNSResolver: Updated DNS cache\r\n2021.06.17 20:41:51.515891 [ 32613 ] {} <Trace> TCPHandlerFactory: TCP Request. Address: 127.0.0.1:57958\r\n2021.06.17 20:41:51.518286 [ 32613 ] {} <Debug> TCPHandler: Connected ClickHouse client version 21.5.0, revision: 54448, user: default.\r\n2021.06.17 20:41:51.522732 [ 32613 ] {} <Trace> ContextAccess (default): Settings: readonly=0, allow_ddl=true, allow_introspection_functions=false\r\n2021.06.17 20:41:51.523594 [ 32613 ] {} <Trace> ContextAccess (default): List of all grants: GRANT ALL ON *.* WITH GRANT OPTION\r\n2021.06.17 20:41:51.524275 [ 32613 ] {} <Trace> ContextAccess (default): List of all grants including implicit: GRANT ALL ON *.* WITH GRANT OPTION\r\n2021.06.17 20:41:53.483966 [ 32613 ] {d2553833-0157-4096-b471-226bac4d82e8} <Debug> executeQuery: (from 127.0.0.1:57958, using production parser)  create table t_q1ht4gq_5 ( c_zeij INTEGER NOT NULL, c_fehk75l TEXT , c_jz TEXT , c_wynzuek TEXT , c_nkt INTEGER NOT NULL, c_g TEXT , c_mc2 TEXT , primary key(c_nkt) ) engine = MergeTree();\r\n2021.06.17 20:41:53.485256 [ 32613 ] {d2553833-0157-4096-b471-226bac4d82e8} <Trace> ContextAccess (default): Access granted: CREATE TABLE ON default.t_q1ht4gq_5\r\n2021.06.17 20:41:53.539214 [ 32613 ] {d2553833-0157-4096-b471-226bac4d82e8} <Debug> default.t_q1ht4gq_5 (e3fe7790-5077-42b4-9572-ca623ac3e4fb): Loading data parts\r\n2021.06.17 20:41:53.539954 [ 32613 ] {d2553833-0157-4096-b471-226bac4d82e8} <Debug> default.t_q1ht4gq_5 (e3fe7790-5077-42b4-9572-ca623ac3e4fb): There are no data parts\r\n2021.06.17 20:41:53.582449 [ 32613 ] {d2553833-0157-4096-b471-226bac4d82e8} <Debug> MemoryTracker: Peak memory usage (for query): 0.00 B.\r\n2021.06.17 20:41:53.583784 [ 32613 ] {} <Debug> TCPHandler: Processed in 0.11289809 sec.\r\n2021.06.17 20:41:53.584877 [ 32613 ] {} <Debug> TCPHandler: Done processing connection.\r\n2021.06.17 20:42:00.332290 [ 32613 ] {} <Trace> TCPHandlerFactory: TCP Request. Address: 127.0.0.1:57960\r\n2021.06.17 20:42:00.334155 [ 32613 ] {} <Debug> TCPHandler: Connected ClickHouse client version 21.5.0, revision: 54448, user: default.\r\n2021.06.17 20:42:02.375165 [ 32613 ] {3e73eaf7-99b8-459e-9213-d623f8bbe6d4} <Debug> executeQuery: (from 127.0.0.1:57960, using production parser)  WITH cte_0 AS (select subq_0.c6 as c2, case when 0<>0 then ((select c_zeij from t_q1ht4gq_5 order by c_zeij limit 1 offset 1) + subq_0.c4) else ((select c_zeij from t_q1ht4gq_5 order by c_zeij limit 1 offset 1) + subq_0.c4) end as c4 from (select ref_0.c_nkt as c4, ref_0.c_nkt as c6 from t_q1ht4gq_5 as ref_0 ) as subq_0 ) select ref_12.c_zeij as c3 from t_q1ht4gq_5 as ref_12 where (ref_12.c_jz not in ( select ref_14.c_mc2 as c0 from t_q1ht4gq_5 as ref_14 cross join cte_0 as ref_15 where ref_15.c4 > ref_15.c2)) ;\r\n2021.06.17 20:42:02.398051 [ 32613 ] {3e73eaf7-99b8-459e-9213-d623f8bbe6d4} <Trace> ContextAccess (default): Access granted: SELECT(c_nkt) ON default.t_q1ht4gq_5\r\n2021.06.17 20:42:02.403211 [ 32613 ] {3e73eaf7-99b8-459e-9213-d623f8bbe6d4} <Trace> ContextAccess (default): Access granted: SELECT(c_nkt) ON default.t_q1ht4gq_5\r\n2021.06.17 20:42:02.410950 [ 32613 ] {3e73eaf7-99b8-459e-9213-d623f8bbe6d4} <Trace> ContextAccess (default): Access granted: SELECT(c_zeij) ON default.t_q1ht4gq_5\r\n2021.06.17 20:42:02.436332 [ 32613 ] {3e73eaf7-99b8-459e-9213-d623f8bbe6d4} <Trace> ContextAccess (default): Access granted: SELECT(c_nkt) ON default.t_q1ht4gq_5\r\n2021.06.17 20:42:02.444426 [ 32613 ] {3e73eaf7-99b8-459e-9213-d623f8bbe6d4} <Trace> ContextAccess (default): Access granted: SELECT(c_zeij) ON default.t_q1ht4gq_5\r\n2021.06.17 20:42:02.447759 [ 32613 ] {3e73eaf7-99b8-459e-9213-d623f8bbe6d4} <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n2021.06.17 20:42:02.459083 [ 32656 ] {3e73eaf7-99b8-459e-9213-d623f8bbe6d4} <Trace> PipelineExecutor: Thread finished. Total time: 0.001007495 sec. Execution time: 0.00019242 sec. Processing time: 0.000722463 sec. Wait time: 9.2612e-05 sec.\r\n2021.06.17 20:42:02.466889 [ 32613 ] {3e73eaf7-99b8-459e-9213-d623f8bbe6d4} <Trace> ContextAccess (default): Access granted: SELECT(c_zeij) ON default.t_q1ht4gq_5\r\n2021.06.17 20:42:02.469941 [ 32613 ] {3e73eaf7-99b8-459e-9213-d623f8bbe6d4} <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n2021.06.17 20:42:02.480478 [ 32656 ] {3e73eaf7-99b8-459e-9213-d623f8bbe6d4} <Trace> PipelineExecutor: Thread finished. Total time: 0.001129093 sec. Execution time: 0.000155334 sec. Processing time: 0.000877237 sec. Wait time: 9.6522e-05 sec.\r\n2021.06.17 20:42:02.500658 [ 32613 ] {3e73eaf7-99b8-459e-9213-d623f8bbe6d4} <Trace> InterpreterSelectQuery: Running 'analyze' second time\r\n2021.06.17 20:42:02.505775 [ 32613 ] {3e73eaf7-99b8-459e-9213-d623f8bbe6d4} <Trace> ContextAccess (default): Access granted: SELECT(c_nkt) ON default.t_q1ht4gq_5\r\n2021.06.17 20:42:02.512319 [ 32613 ] {3e73eaf7-99b8-459e-9213-d623f8bbe6d4} <Trace> InterpreterSelectQuery: Running 'analyze' second time\r\n2021.06.17 20:42:02.531375 [ 32613 ] {3e73eaf7-99b8-459e-9213-d623f8bbe6d4} <Trace> InterpreterSelectQuery: Running 'analyze' second time\r\n2021.06.17 20:42:02.536219 [ 32613 ] {3e73eaf7-99b8-459e-9213-d623f8bbe6d4} <Trace> ContextAccess (default): Access granted: SELECT(c_nkt) ON default.t_q1ht4gq_5\r\n2021.06.17 20:42:02.542674 [ 32613 ] {3e73eaf7-99b8-459e-9213-d623f8bbe6d4} <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n2021.06.17 20:42:02.544544 [ 32613 ] {3e73eaf7-99b8-459e-9213-d623f8bbe6d4} <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\n2021.06.17 20:42:02.549745 [ 32613 ] {3e73eaf7-99b8-459e-9213-d623f8bbe6d4} <Debug> HashJoin: Right sample block: c2 Int32 Int32(size = 0), c4 Nullable(Nothing) Nullable(size = 0, Nothing(size = 0), UInt8(size = 0))\r\n2021.06.17 20:42:02.553503 [ 32613 ] {3e73eaf7-99b8-459e-9213-d623f8bbe6d4} <Trace> ContextAccess (default): Access granted: SELECT(c_mc2) ON default.t_q1ht4gq_5\r\n2021.06.17 20:42:02.554657 [ 32613 ] {3e73eaf7-99b8-459e-9213-d623f8bbe6d4} <Trace> InterpreterSelectQuery: FetchColumns -> Complete\r\nclickhouse-server: ../src/Functions/IFunction.cpp:263: DB::ColumnPtr DB::ExecutableFunctionAdaptor::defaultImplementationForNulls(const DB::ColumnsWithTypeAndName &, const DB::DataTypePtr &, size_t, bool) const: Assertion `result_type->isNullable()' failed.\r\n2021.06.17 20:42:02.557345 [ 32432 ] {} <Trace> BaseDaemon: Received signal 6\r\n2021.06.17 20:42:02.558289 [ 32739 ] {} <Fatal> BaseDaemon: ########################################\r\n2021.06.17 20:42:02.560063 [ 32739 ] {} <Fatal> BaseDaemon: (version 21.5.6.1, build id: D418120B6778C79B) (from thread 32613) (query_id: 3e73eaf7-99b8-459e-9213-d623f8bbe6d4) Received signal Aborted (6)\r\n2021.06.17 20:42:02.560812 [ 32739 ] {} <Fatal> BaseDaemon: \r\n2021.06.17 20:42:02.562125 [ 32739 ] {} <Fatal> BaseDaemon: Stack trace: 0x7f177c6eef47 0x7f177c6f08b1 0x7f177c6e042a 0x7f177c6e04a2 0x1f25c93b 0x1f25adb5 0x1f2625f1 0x44e17b8b 0x44e1357e 0x4daefaa0 0x4e0a085b 0x45570b82 0x45501cbe 0x454d2746 0x454c6f2a 0x47b6be7d 0x466db77d 0x466c1574 0x466bce75 0x465de395 0x4657ab0c 0x4659e454 0x465bbc15 0x454db328 0x454c2ec2 0x454ab159 0x454a48ff 0x47b76a5d 0x47b676aa 0x47b646f0 0x47d22feb 0x48b1418a 0x48a90f98 0x48a86600 0x4d02b55c 0x4d07cce5 0x508c5203 0x508c7962 0x51a754e6 0x51a5e2ce 0x51a56b10 0x7f177c0fa6db 0x7f177c7d1a3f\r\n2021.06.17 20:42:02.573895 [ 32739 ] {} <Fatal> BaseDaemon: 4. /build/glibc-2ORdQG/glibc-2.27/signal/../sysdeps/unix/sysv/linux/raise.c:51: __GI_raise @ 0x3ef47 in /usr/lib/debug/lib/x86_64-linux-gnu/libc-2.27.so\r\n2021.06.17 20:42:02.596775 [ 32739 ] {} <Fatal> BaseDaemon: 5. /build/glibc-2ORdQG/glibc-2.27/stdlib/abort.c:81: abort @ 0x408b1 in /usr/lib/debug/lib/x86_64-linux-gnu/libc-2.27.so\r\n2021.06.17 20:42:02.631400 [ 32739 ] {} <Fatal> BaseDaemon: 6. /build/glibc-2ORdQG/glibc-2.27/assert/assert.c:89: __assert_fail_base @ 0x3042a in /usr/lib/debug/lib/x86_64-linux-gnu/libc-2.27.so\r\n2021.06.17 20:42:02.813716 [ 32739 ] {} <Fatal> BaseDaemon: 7. ? @ 0x304a2 in /usr/lib/debug/lib/x86_64-linux-gnu/libc-2.27.so\r\n2021.06.17 20:42:05.557845 [ 32633 ] {} <Debug> DNSResolver: Updating DNS cache\r\n2021.06.17 20:42:05.558369 [ 32633 ] {} <Debug> DNSResolver: Updated DNS cache\r\n2021.06.17 20:42:17.822707 [ 32739 ] {} <Fatal> BaseDaemon: 8. /home/ssr/research-project/dbms-test/target-dbms/ClickHouse/build/../src/Functions/IFunction.cpp:0: DB::ExecutableFunctionAdaptor::defaultImplementationForNulls(std::__1::vector<DB::ColumnWithTypeAndName, std::__1::allocator<DB::ColumnWithTypeAndName> > const&, std::__1::shared_ptr<DB::IDataType const> const&, unsigned long, bool) const @ 0x1f25c93b in /usr/local/bin/clickhouse\r\n2021.06.17 20:42:20.559001 [ 32633 ] {} <Debug> DNSResolver: Updating DNS cache\r\n2021.06.17 20:42:20.559504 [ 32633 ] {} <Debug> DNSResolver: Updated DNS cache\r\nAborted (core dumped)\r\n```\n",
  "hints_text": "I've shortened the query causing this crash:\r\n\r\n```\r\nWITH a AS (select (select 1 WHERE 0) as b)\r\nselect 1\r\nfrom system.one\r\ncross join a\r\nwhere a.b = 0\r\n```\nProblem connected with type inference \r\n\r\n`query_plan.getCurrentDataStream().header` contains column `b` of type `Nullable(Nothing)` but in `result_header` it's `UInt8`\r\n\r\nNot sure what should be fixed, `getSampleBlock` or types in pipeline \r\n\r\nhttps://github.com/ClickHouse/ClickHouse/blob/a924a9dbacc1bd1506d4429d7e3d677cd97a2b38/src/Interpreters/InterpreterSelectQuery.cpp#L574-L583\r\n\r\ncc @KochetovNicolai \nOne of the reasons in this code:\r\nhttps://github.com/ClickHouse/ClickHouse/blob/a924a9dbacc1bd1506d4429d7e3d677cd97a2b38/src/Interpreters/ExecuteScalarSubqueriesVisitor.cpp#L99-L127\r\n\r\nThe point is that for joined table we need to know it's structure. If right table is subquery, we run InterpreterSelectQuery with only_analyze flag. In this case, we do not execute scalar subquery (`select 1 where 0` in our case), but take result type from subquery structure (`UInt8`).\r\nHowever, when we execute subquery, it returns 0 rows, and we replace it's value to Null (which type is `Nullable(Nothing)`). So, types are different with and without `only_analyze` flag for scalar subqueries with empty result.\nAlso, here\r\nhttps://github.com/ClickHouse/ClickHouse/blob/a924a9dbacc1bd1506d4429d7e3d677cd97a2b38/src/Interpreters/ExpressionActions.cpp#L796-L801\r\nwe do't apply `analyzed_join->rightConvertingActions()` to added columns. @vdimir probably, we should?\n> we do't apply `analyzed_join->rightConvertingActions()` to added columns. @vdimir probably, we should?\r\n\r\nIt's not required because `addJoinedColumnsAndCorrectTypes` adds columns with applied type conversion.\r\nhttps://github.com/ClickHouse/ClickHouse/blob/cb89a2be9783de646c95ee8c424ce6a664c7dffc/src/Interpreters/TableJoin.cpp#L275-L277",
  "created_at": "2021-07-16T13:51:22Z",
  "modified_files": [
    "src/DataTypes/DataTypeInterval.h",
    "src/Functions/IFunction.cpp",
    "src/Interpreters/ExecuteScalarSubqueriesVisitor.cpp",
    "src/Interpreters/OptimizeIfWithConstantConditionVisitor.cpp",
    "src/Storages/MergeTree/KeyCondition.cpp"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/00205_emptyscalar_subquery_type_mismatch_bug.sql",
    "tests/queries/0_stateless/00205_scalar_subqueries.reference",
    "tests/queries/0_stateless/00205_scalar_subqueries.sql",
    "tests/queries/0_stateless/00597_push_down_predicate_long.reference",
    "tests/queries/0_stateless/01029_early_constant_folding.reference",
    "tests/queries/0_stateless/01611_constant_folding_subqueries.reference",
    "tests/queries/0_stateless/01651_bugs_from_15889.reference",
    "tests/queries/0_stateless/01651_bugs_from_15889.sql",
    "tests/queries/0_stateless/01756_optimize_skip_unused_shards_rewrite_in.reference"
  ]
}