{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 35799,
  "instance_id": "ClickHouse__ClickHouse-35799",
  "issue_numbers": [
    "35751"
  ],
  "base_commit": "f6bfdcc0c91ddc6e7280f0bbf2efb0f3a6a4d5a0",
  "patch": "diff --git a/src/Parsers/ExpressionElementParsers.cpp b/src/Parsers/ExpressionElementParsers.cpp\nindex c51201750c5f..ef236388a044 100644\n--- a/src/Parsers/ExpressionElementParsers.cpp\n+++ b/src/Parsers/ExpressionElementParsers.cpp\n@@ -505,32 +505,34 @@ namespace\n \n     bool parseExtract(IParser::Pos & pos, ASTPtr & node, Expected & expected)\n     {\n-        ASTPtr expr;\n-\n+        IParser::Pos begin = pos;\n         IntervalKind interval_kind;\n-        if (!parseIntervalKind(pos, expected, interval_kind))\n+\n+        if (parseIntervalKind(pos, expected, interval_kind))\n         {\n-            ASTPtr expr_list;\n-            if (!ParserExpressionList(false, false).parse(pos, expr_list, expected))\n-                return false;\n+            ASTPtr expr;\n \n-            auto res = std::make_shared<ASTFunction>();\n-            res->name = \"extract\";\n-            res->arguments = expr_list;\n-            res->children.push_back(res->arguments);\n-            node = std::move(res);\n-            return true;\n+            ParserKeyword s_from(\"FROM\");\n+            ParserExpression elem_parser;\n+\n+            if (s_from.ignore(pos, expected) && elem_parser.parse(pos, expr, expected))\n+            {\n+                node = makeASTFunction(interval_kind.toNameOfFunctionExtractTimePart(), expr);\n+                return true;\n+            }\n         }\n \n-        ParserKeyword s_from(\"FROM\");\n-        if (!s_from.ignore(pos, expected))\n-            return false;\n+        pos = begin;\n \n-        ParserExpression elem_parser;\n-        if (!elem_parser.parse(pos, expr, expected))\n+        ASTPtr expr_list;\n+        if (!ParserExpressionList(false, false).parse(pos, expr_list, expected))\n             return false;\n \n-        node = makeASTFunction(interval_kind.toNameOfFunctionExtractTimePart(), expr);\n+        auto res = std::make_shared<ASTFunction>();\n+        res->name = \"extract\";\n+        res->arguments = expr_list;\n+        res->children.push_back(res->arguments);\n+        node = std::move(res);\n         return true;\n     }\n \n",
  "test_patch": "diff --git a/tests/queries/0_stateless/02247_fix_extract_parser.reference b/tests/queries/0_stateless/02247_fix_extract_parser.reference\nnew file mode 100644\nindex 000000000000..01e79c32a8c9\n--- /dev/null\n+++ b/tests/queries/0_stateless/02247_fix_extract_parser.reference\n@@ -0,0 +1,3 @@\n+1\n+2\n+3\ndiff --git a/tests/queries/0_stateless/02247_fix_extract_parser.sql b/tests/queries/0_stateless/02247_fix_extract_parser.sql\nnew file mode 100644\nindex 000000000000..9b721a6e830a\n--- /dev/null\n+++ b/tests/queries/0_stateless/02247_fix_extract_parser.sql\n@@ -0,0 +1,3 @@\n+WITH 'number: 1' as year SELECT extract(year, '\\\\d+');\n+WITH 'number: 2' as mm SELECT extract(mm, '\\\\d+');\n+WITH 'number: 3' as s SELECT extract(s, '\\\\d+');\n",
  "problem_statement": "Clickhouse cannot parse table definition after update to v22.3\nClickhouse server crashed after update from `yandex/clickhouse-server:21.11.3.6` to `clickhouse/clickhouse-server:22.3.2.2`\r\n\r\nSeems like some problem with parsing metadata file of mv:\r\n```\r\n\r\n2022.03.30 09:26:11.300637 [ 1 ] {} <Error> Application: DB::Exception: Syntax error (in file /var/lib/clickhouse/store/990/9909bef6-626f-4868-9909-bef6626f4868/jira_issue.sql): failed at position 5242 (',') (line 113, col 62): , '\\\\d+')), sprints)) AS first_sprint,\r\n    arrayReduce('max', arrayMap(s -> toUInt32OrNull(extract(s, '\\\\d+')), sprints)) AS last_sprint,\r\n    JSONExtractString(. Expected one of: FROM, end of query: Cannot parse definition from metadata file /var/lib/clickhouse/store/990/9909bef6-626f-4868-9909-bef6626f4868/jira_issue.sql\r\n2022.03.30 09:26:19.456468 [ 1 ] {} <Warning> Application: Calculated checksum of the binary: 51010DC62C0638E7259D2BDDE72C485C. There is no information about the reference checksum.\r\n2022.03.30 09:26:19.461712 [ 1 ] {} <Error> CertificateReloader: Cannot obtain modification time for certificate file /etc/clickhouse-server/server.crt, skipping update. errno: 2, strerror: No such file or directory\r\n2022.03.30 09:26:19.461753 [ 1 ] {} <Error> CertificateReloader: Cannot obtain modification time for key file /etc/clickhouse-server/server.key, skipping update. errno: 2, strerror: No such file or directory\r\n2022.03.30 09:26:19.462113 [ 1 ] {} <Error> CertificateReloader: Poco::Exception. Code: 1000, e.code() = 0, SSL context exception: Error loading private key from file /etc/clickhouse-server/server.key: error:02000002:system library:OPENSSL_internal:No such file or directory (version 22.3.2.1)\r\n2022.03.30 09:26:19.607711 [ 1 ] {} <Error> Application: Caught exception while loading metadata: Code: 62. DB::Exception: Syntax error (in file /var/lib/clickhouse/store/990/9909bef6-626f-4868-9909-bef6626f4868/jira_issue.sql): failed at position 5242 (',') (line 113, col 62): , '\\\\d+')), sprints)) AS first_sprint,\r\n    arrayReduce('max', arrayMap(s -> toUInt32OrNull(extract(s, '\\\\d+')), sprints)) AS last_sprint,\r\n    JSONExtractString(. Expected one of: FROM, end of query: Cannot parse definition from metadata file /var/lib/clickhouse/store/990/9909bef6-626f-4868-9909-bef6626f4868/jira_issue.sql. (SYNTAX_ERROR), Stack trace (when copying this message, always include the lines below):\r\n\r\n0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0xa4dde1a in /usr/bin/clickhouse\r\n1. DB::DatabaseOnDisk::parseQueryFromMetadata(Poco::Logger*, std::__1::shared_ptr<DB::Context const>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, bool, bool) @ 0x13e8d36d in /usr/bin/clickhouse\r\n2. ? @ 0x13f3337a in /usr/bin/clickhouse\r\n3. ThreadPoolImpl<ThreadFromGlobalPool>::worker(std::__1::__list_iterator<ThreadFromGlobalPool, void*>) @ 0xa5878ca in /usr/bin/clickhouse\r\n4. ThreadFromGlobalPool::ThreadFromGlobalPool<void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda0'()>(void&&, void ThreadPoolImpl<ThreadFromGlobalPool>::scheduleImpl<void>(std::__1::function<void ()>, int, std::__1::optional<unsigned long>)::'lambda0'()&&...)::'lambda'()::operator()() @ 0xa589a64 in /usr/bin/clickhouse\r\n5. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0xa584c97 in /usr/bin/clickhouse\r\n6. ? @ 0xa58881d in /usr/bin/clickhouse\r\n7. ? @ 0x7fd533101609 in ?\r\n8. __clone @ 0x7fd533026163 in ?\r\n (version 22.3.2.1)\r\n```\n",
  "hints_text": "Please share the contents of `/var/lib/clickhouse/store/990/9909bef6-626f-4868-9909-bef6626f4868/jira_issue.sql`\n> Please share the contents of `/var/lib/clickhouse/store/990/9909bef6-626f-4868-9909-bef6626f4868/jira_issue.sql`\r\n```\r\n\r\nATTACH MATERIALIZED VIEW _ UUID '11c85ac0-a7d5-41c3-91c8-5ac0a7d5d1c3' TO INNER UUID 'f2e28dd5-d419-4012-b2e2-8dd5d4196012'\r\n(\r\n    `ts` DateTime,\r\n    `id` Nullable(Int32),\r\n    `key` String,\r\n    `issue_link` String,\r\n    `parent_id` Nullable(Int32),\r\n    `parent_key` String,\r\n    `parent_status` String,\r\n    `parent_priority` String,\r\n    `created` Nullable(DateTime('Europe/Minsk')),\r\n    `updated` Nullable(DateTime('Europe/Minsk')),\r\n    `status_category_changed_date` Nullable(DateTime('Europe/Minsk')),\r\n    `self` String,\r\n    `summary` String,\r\n    `issuetype` String,\r\n    `project_key` String,\r\n    `country` String,\r\n    `priority` String,\r\n    `order` Int64,\r\n    `status` String,\r\n    `aggregatetimeoriginalestimate` Int64,\r\n    `timespent` Int64,\r\n    `resolution` String,\r\n    `reporter` String,\r\n    `reporterId` String,\r\n    `assignee` String,\r\n    `assigneeId` String,\r\n    `sprints` Array(String),\r\n    `first_sprint` Nullable(UInt32),\r\n    `last_sprint` Nullable(UInt32),\r\n    `epich_link` String,\r\n    `fix_versions_number` Array(String),\r\n    `fix_versions_description` Array(String),\r\n    `fix_versions_released` Array(UInt8),\r\n    `fix_versions_release_date` Array(Nullable(DateTime)),\r\n    `last_fix_version` Nullable(Float64),\r\n    `last_fix_version_description` String,\r\n    `last_fix_version_released` UInt8,\r\n    `last_fix_version_release_date` Nullable(DateTime),\r\n    `stakeholder` String,\r\n    `in_sprint_date` Nullable(DateTime('Europe/Minsk')),\r\n    `dev_start_date` Nullable(DateTime('Europe/Minsk')),\r\n    `background_field` String,\r\n    `delivered_to_prod` Nullable(DateTime),\r\n    `team` String,\r\n    `labels` Array(String),\r\n    `description_business` String,\r\n    `description_technical` String,\r\n    `approvers_list` String,\r\n    `third_party_credentials` String,\r\n    `cycle_time` Nullable(Int64),\r\n    `check_on_prod` Array(String),\r\n    `issuelinks_inward_id` Array(String),\r\n    `issuelinks_inward_key` Array(String),\r\n    `issuelinks_inward_status` Array(String),\r\n    `issuelinks_inward_issuetype` Array(String),\r\n    `issuelinks_outward_id` Array(String),\r\n    `issuelinks_outward_key` Array(String),\r\n    `issuelinks_outward_status` Array(String),\r\n    `issuelinks_outward_issuetype` Array(String),\r\n    `changelog_total` Int64,\r\n    `changelog_author` Array(String),\r\n    `changelog_created` Array(DateTime('Europe/Minsk')),\r\n    `changelog_field` Array(Array(String)),\r\n    `changelog_fromString` Array(Array(String)),\r\n    `changelog_toString` Array(Array(String)),\r\n    `worklog_total` String,\r\n    `worklog_authorId` Array(String),\r\n    `worklog_started` Array(DateTime('Europe/Minsk')),\r\n    `worklog_created` Array(DateTime('Europe/Minsk')),\r\n    `worklog_updated` Array(DateTime('Europe/Minsk')),\r\n    `worklog_timeSpentSeconds` Array(Int32),\r\n    `checklist_text` String,\r\n    `checklists_name` Array(String),\r\n    `checklists_items` Array(Array(Tuple(String, String)))\r\n)\r\nENGINE = ReplacingMergeTree(ts)\r\nORDER BY key\r\nSETTINGS index_granularity = 8192 AS\r\nWITH\r\n    'Europe/Minsk' AS time_zone,\r\n    '---\\\\s*([^\\n]+)' AS checklist_name_regexp,\r\n    '\\\\*\\\\s?\\\\[(\\\\S+)\\\\]\\\\s+([^\\n]+)' AS checklist_items_regexp\r\nSELECT\r\n    ts,\r\n    toInt32OrNull(JSONExtractString(raw, 'id')) AS id,\r\n    JSONExtractString(raw, 'key') AS key,\r\n    concat('<a href=\"https://xxxxxx/browse/', key, '\">', summary, '</a>') AS issue_link,\r\n    toInt32OrNull(JSONExtractString(raw, 'fields', 'parent', 'id')) AS parent_id,\r\n    JSONExtractString(raw, 'fields', 'parent', 'key') AS parent_key,\r\n    JSONExtractString(raw, 'fields', 'parent', 'fields', 'status', 'name') AS parent_status,\r\n    JSONExtractString(raw, 'fields', 'parent', 'fields', 'priority', 'name') AS parent_priority,\r\n    parseDateTimeBestEffortOrNull(JSONExtractString(raw, 'fields', 'created'), time_zone) AS created,\r\n    parseDateTimeBestEffortOrNull(JSONExtractString(raw, 'fields', 'updated'), time_zone) AS updated,\r\n    parseDateTimeBestEffortOrNull(JSONExtractString(raw, 'fields', 'statusCategoryChangedDate'), time_zone) AS status_category_changed_date,\r\n    JSONExtractString(raw, 'self') AS self,\r\n    JSONExtractString(raw, 'fields', 'summary') AS summary,\r\n    JSONExtractString(raw, 'fields', 'issuetype', 'name') AS issuetype,\r\n    JSONExtractString(raw, 'fields', 'project', 'key') AS project_key,\r\n    multiIf(project_key = 'NPK', 'KZ', replaceRegexpAll(project_key, '(MM|SL|PLZ)', '')) AS country,\r\n    JSONExtractString(raw, 'fields', 'priority', 'name') AS priority,\r\n    JSONExtractInt(raw, 'fields', 'Order') AS order,\r\n    JSONExtractString(raw, 'fields', 'status', 'name') AS status,\r\n    JSONExtractInt(raw, 'fields', 'aggregatetimeoriginalestimate') AS aggregatetimeoriginalestimate,\r\n    JSONExtractInt(raw, 'fields', 'timespent') AS timespent,\r\n    JSONExtractString(raw, 'fields', 'resolution', 'name') AS resolution,\r\n    JSONExtractString(raw, 'fields', 'reporter', 'displayName') AS reporter,\r\n    JSONExtractString(raw, 'fields', 'reporter', 'accountId') AS reporterId,\r\n    JSONExtractString(raw, 'fields', 'assignee', 'displayName') AS assignee,\r\n    JSONExtractString(raw, 'fields', 'assignee', 'accountId') AS assigneeId,\r\n    JSONExtract(JSON_QUERY(raw, '$.fields.customfield_10007[*].name'), 'Array(String)') AS sprints,\r\n    arrayReduce('min', arrayMap(s -> toUInt32OrNull(extract(s, '\\\\d+')), sprints)) AS first_sprint,\r\n    arrayReduce('max', arrayMap(s -> toUInt32OrNull(extract(s, '\\\\d+')), sprints)) AS last_sprint,\r\n    JSONExtractString(raw, 'fields', 'customfield_10008', 'value') AS epich_link,\r\n    JSONExtract(JSON_QUERY(raw, '$.fields.fixVersions[*].name'), 'Array(String)') AS fix_versions_number,\r\n    JSONExtract(JSON_QUERY(raw, '$.fields.fixVersions[*].description'), 'Array(String)') AS fix_versions_description,\r\n    JSONExtract(JSON_QUERY(raw, '$.fields.fixVersions[*].released'), 'Array(UInt8)') AS fix_versions_released,\r\n    arrayMap(d -> parseDateTimeBestEffortOrNull(JSONExtractString(d, 'releaseDate')), JSONExtract(JSON_QUERY(raw, '$.fields.fixVersions[*]'), 'Array(String)')) AS fix_versions_release_date,\r\n    arrayReduce('max', arrayMap(s -> toFloat64OrNull(extract(s, '[\\\\d\\\\.]+')), fix_versions_number)) AS last_fix_version,\r\n    fix_versions_description[-1] AS last_fix_version_description,\r\n    fix_versions_released[-1] AS last_fix_version_released,\r\n    fix_versions_release_date[-1] AS last_fix_version_release_date,\r\n    JSONExtractString(raw, 'fields', 'customfield_10400', 'value') AS stakeholder,\r\n    parseDateTimeBestEffortOrNull(JSONExtractString(raw, 'fields', 'customfield_12583'), time_zone) AS in_sprint_date,\r\n    parseDateTimeBestEffortOrNull(JSONExtractString(raw, 'fields', 'customfield_12628'), time_zone) AS dev_start_date,\r\n    JSONExtractString(raw, 'fields', 'customfield_10900', 1, 'value') AS background_field,\r\n    parseDateTimeBestEffortOrNull(JSONExtractString(raw, 'fields', 'customfield_10201')) AS delivered_to_prod,\r\n    JSONExtractString(raw, 'fields', 'customfield_10102', 'value') AS team,\r\n    JSONExtract(raw, 'fields', 'labels', 'Array(String)') AS labels,\r\n    JSONExtractString(raw, 'fields', 'Description (business)', 'value') AS description_business,\r\n    JSONExtractString(raw, 'fields', 'Description (technical)', 'value') AS description_technical,\r\n    JSONExtractString(raw, 'fields', 'Approvers list', 'value') AS approvers_list,\r\n    JSONExtractString(raw, 'fields', 'Third-party credentials', 'value') AS third_party_credentials,\r\n    JSONExtract(raw, 'fields', 'Cycle time', 'Nullable(Int64)') AS cycle_time,\r\n    JSONExtract(JSON_QUERY(raw, '$.fields.\"Check on prod\"[*].value'), 'Array(String)') AS check_on_prod,\r\n    JSONExtract(JSON_QUERY(raw, '$.fields.issuelinks[*].inwardIssue.id'), 'Array(String)') AS issuelinks_inward_id,\r\n    JSONExtract(JSON_QUERY(raw, '$.fields.issuelinks[*].inwardIssue.key'), 'Array(String)') AS issuelinks_inward_key,\r\n    JSONExtract(JSON_QUERY(raw, '$.fields.issuelinks[*].inwardIssue.fields.status.name'), 'Array(String)') AS issuelinks_inward_status,\r\n    JSONExtract(JSON_QUERY(raw, '$.fields.issuelinks[*].inwardIssue.fields.issuetype.name'), 'Array(String)') AS issuelinks_inward_issuetype,\r\n    JSONExtract(JSON_QUERY(raw, '$.fields.issuelinks[*].outwardIssue.id'), 'Array(String)') AS issuelinks_outward_id,\r\n    JSONExtract(JSON_QUERY(raw, '$.fields.issuelinks[*].outwardIssue.key'), 'Array(String)') AS issuelinks_outward_key,\r\n    JSONExtract(JSON_QUERY(raw, '$.fields.issuelinks[*].outwardIssue.fields.status.name'), 'Array(String)') AS issuelinks_outward_status,\r\n    JSONExtract(JSON_QUERY(raw, '$.fields.issuelinks[*].outwardIssue.fields.issuetype.name'), 'Array(String)') AS issuelinks_outward_issuetype,\r\n    JSONExtractInt(raw, 'changelog', 'total') AS changelog_total,\r\n    JSONExtract(JSON_QUERY(raw, '$.changelog.histories[*].author.accountId'), 'Array(String)') AS changelog_author,\r\n    arrayMap(d -> parseDateTimeBestEffort(d, time_zone), JSONExtract(JSON_QUERY(raw, '$.changelog.histories[*].created'), 'Array(String)')) AS changelog_created,\r\n    arrayMap(j -> JSONExtract(JSON_QUERY(j, '$.items[*].field'), 'Array(String)'), JSONExtract(raw, 'changelog', 'histories', 'Array(String)')) AS changelog_field,\r\n    arrayMap(j -> JSONExtract(JSON_QUERY(j, '$.items[*].fromString'), 'Array(String)'), JSONExtract(raw, 'changelog', 'histories', 'Array(String)')) AS changelog_fromString,\r\n    arrayMap(j -> JSONExtract(JSON_QUERY(j, '$.items[*].toString'), 'Array(String)'), JSONExtract(raw, 'changelog', 'histories', 'Array(String)')) AS changelog_toString,\r\n    JSONExtractRaw(raw, 'fields', 'worklog', 'total') AS worklog_total,\r\n    JSONExtract(JSON_QUERY(raw, '$.fields.worklog.worklogs[*].author.accountId'), 'Array(String)') AS worklog_authorId,\r\n    arrayMap(d -> parseDateTimeBestEffort(d, time_zone), JSONExtract(JSON_QUERY(raw, '$.fields.worklog.worklogs[*].started'), 'Array(String)')) AS worklog_started,\r\n    arrayMap(d -> parseDateTimeBestEffort(d, time_zone), JSONExtract(JSON_QUERY(raw, '$.fields.worklog.worklogs[*].created'), 'Array(String)')) AS worklog_created,\r\n    arrayMap(d -> parseDateTimeBestEffort(d, time_zone), JSONExtract(JSON_QUERY(raw, '$.fields.worklog.worklogs[*].updated'), 'Array(String)')) AS worklog_updated,\r\n    JSONExtract(JSON_QUERY(raw, '$.fields.worklog.worklogs[*].timeSpentSeconds'), 'Array(Int)') AS worklog_timeSpentSeconds,\r\n    JSONExtractString(raw, 'fields', 'Checklist Text') AS checklist_text,\r\n    extractAll(checklist_text, checklist_name_regexp) AS checklists_name,\r\n    if(length(checklists_name) > 0, arrayMap(s -> arrayMap(i -> (i[1], i[2]), extractAllGroupsVertical(s, checklist_items_regexp)), splitByRegexp(checklist_name_regexp, substring(checklist_text, position(checklist_text, checklists_name[1])))), []) AS checklists_items\r\nFROM jira.jira_issue_raw\r\n```\nConfirmed.\nWorkaround: edit this file and replace \r\n```\r\nextract(s, '\\\\d+')\r\n```\r\nto \r\n```\r\nextract(`s`, '\\\\d+')\r\n```",
  "created_at": "2022-03-31T11:43:56Z",
  "modified_files": [
    "src/Parsers/ExpressionElementParsers.cpp"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/02247_fix_extract_parser.reference",
    "b/tests/queries/0_stateless/02247_fix_extract_parser.sql"
  ]
}