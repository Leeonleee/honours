diff --git a/docker/test/fasttest/Dockerfile b/docker/test/fasttest/Dockerfile
index 9b4bb574f8f9..65ec078d3cac 100644
--- a/docker/test/fasttest/Dockerfile
+++ b/docker/test/fasttest/Dockerfile
@@ -52,10 +52,10 @@ RUN apt-get update \
         moreutils \
         ninja-build \
         psmisc \
-        python \
-        python-lxml \
-        python-requests \
-        python-termcolor \
+        python3 \
+        python3-lxml \
+        python3-requests \
+        python3-termcolor \
         qemu-user-static \
         rename \
         software-properties-common \
diff --git a/docker/test/integration/base/Dockerfile b/docker/test/integration/base/Dockerfile
index 3e4e88965e0f..b6a46f6d934e 100644
--- a/docker/test/integration/base/Dockerfile
+++ b/docker/test/integration/base/Dockerfile
@@ -4,7 +4,7 @@ FROM yandex/clickhouse-test-base
 RUN apt-get update \
     && env DEBIAN_FRONTEND=noninteractive apt-get -y install \
         tzdata \
-        python \
+        python3 \
         libreadline-dev \
         libicu-dev \
         bsdutils \
diff --git a/docker/test/integration/runner/Dockerfile b/docker/test/integration/runner/Dockerfile
index bfbe8da816f4..795d0d371f63 100644
--- a/docker/test/integration/runner/Dockerfile
+++ b/docker/test/integration/runner/Dockerfile
@@ -16,13 +16,13 @@ RUN apt-get update \
     iproute2 \
     module-init-tools \
     cgroupfs-mount \
-    python-pip \
+    python3-pip \
     tzdata \
     libreadline-dev \
     libicu-dev \
     bsdutils \
     curl \
-    python-pika \
+    python3-pika \
     liblua5.1-dev \
     luajit \
     libssl-dev \
@@ -37,7 +37,7 @@ RUN apt-get update \
 ENV TZ=Europe/Moscow
 RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && echo $TZ > /etc/timezone
 
-RUN pip install urllib3==1.23 pytest docker-compose==1.22.0 docker dicttoxml kazoo PyMySQL psycopg2==2.7.5 pymongo tzlocal kafka-python protobuf redis aerospike pytest-timeout minio rpm-confluent-schemaregistry grpcio grpcio-tools cassandra-driver
+RUN python3 -m pip install urllib3==1.23 pytest docker-compose==1.22.0 docker dicttoxml kazoo PyMySQL psycopg2==2.7.5 pymongo tzlocal kafka-python protobuf redis aerospike pytest-timeout minio grpcio grpcio-tools cassandra-driver confluent-kafka avro
 
 ENV DOCKER_CHANNEL stable
 ENV DOCKER_VERSION 17.09.1-ce
diff --git a/docker/test/performance-comparison/report.py b/docker/test/performance-comparison/report.py
index 69015c2ce1ad..1f55300661b4 100755
--- a/docker/test/performance-comparison/report.py
+++ b/docker/test/performance-comparison/report.py
@@ -312,7 +312,7 @@ def add_errors_explained():
 
 
 if args.report == 'main':
-    print(header_template.format())
+    print((header_template.format()))
 
     add_tested_commits()
 
@@ -571,14 +571,14 @@ def add_test_times():
         status = 'failure'
         message = 'Errors while building the report.'
 
-    print("""
+    print(("""
     <!--status: {status}-->
     <!--message: {message}-->
-    """.format(status=status, message=message))
+    """.format(status=status, message=message)))
 
 elif args.report == 'all-queries':
 
-    print(header_template.format())
+    print((header_template.format()))
 
     add_tested_commits()
 
diff --git a/docker/test/stateful/Dockerfile b/docker/test/stateful/Dockerfile
index 8a7aca80653f..07aad75a2eae 100644
--- a/docker/test/stateful/Dockerfile
+++ b/docker/test/stateful/Dockerfile
@@ -4,7 +4,7 @@ FROM yandex/clickhouse-stateless-test
 RUN apt-get update -y \
     && env DEBIAN_FRONTEND=noninteractive \
         apt-get install --yes --no-install-recommends \
-        python-requests \
+        python3-requests \
         llvm-9
 
 COPY s3downloader /s3downloader
diff --git a/docker/test/stateful/s3downloader b/docker/test/stateful/s3downloader
index fb49931f022b..363ece8dac66 100755
--- a/docker/test/stateful/s3downloader
+++ b/docker/test/stateful/s3downloader
@@ -1,4 +1,4 @@
-#!/usr/bin/env python
+#!/usr/bin/env python3
 # -*- coding: utf-8 -*-
 import os
 import sys
@@ -29,7 +29,7 @@ def dowload_with_progress(url, path):
     logging.info("Downloading from %s to temp path %s", url, path)
     for i in range(RETRIES_COUNT):
         try:
-            with open(path, 'w') as f:
+            with open(path, 'wb') as f:
                 response = requests.get(url, stream=True)
                 response.raise_for_status()
                 total_length = response.headers.get('content-length')
@@ -74,7 +74,7 @@ if __name__ == "__main__":
     parser = argparse.ArgumentParser(
         description="Simple tool for dowloading datasets for clickhouse from S3")
 
-    parser.add_argument('--dataset-names', required=True, nargs='+', choices=AVAILABLE_DATASETS.keys())
+    parser.add_argument('--dataset-names', required=True, nargs='+', choices=list(AVAILABLE_DATASETS.keys()))
     parser.add_argument('--url-prefix', default=DEFAULT_URL)
     parser.add_argument('--clickhouse-data-path', default='/var/lib/clickhouse/')
 
diff --git a/docker/test/stateful_with_coverage/Dockerfile b/docker/test/stateful_with_coverage/Dockerfile
index 839eea5cdc18..f5d66ed50136 100644
--- a/docker/test/stateful_with_coverage/Dockerfile
+++ b/docker/test/stateful_with_coverage/Dockerfile
@@ -6,7 +6,7 @@ RUN echo "deb [trusted=yes] http://apt.llvm.org/bionic/ llvm-toolchain-bionic-9
 RUN apt-get update -y \
     && env DEBIAN_FRONTEND=noninteractive \
         apt-get install --yes --no-install-recommends \
-        python-requests
+        python3-requests
 
 COPY s3downloader /s3downloader
 COPY run.sh /run.sh
diff --git a/docker/test/stateful_with_coverage/s3downloader b/docker/test/stateful_with_coverage/s3downloader
index fb49931f022b..a27c03a70f0d 100755
--- a/docker/test/stateful_with_coverage/s3downloader
+++ b/docker/test/stateful_with_coverage/s3downloader
@@ -1,4 +1,4 @@
-#!/usr/bin/env python
+#!/usr/bin/env python3
 # -*- coding: utf-8 -*-
 import os
 import sys
@@ -74,7 +74,7 @@ if __name__ == "__main__":
     parser = argparse.ArgumentParser(
         description="Simple tool for dowloading datasets for clickhouse from S3")
 
-    parser.add_argument('--dataset-names', required=True, nargs='+', choices=AVAILABLE_DATASETS.keys())
+    parser.add_argument('--dataset-names', required=True, nargs='+', choices=list(AVAILABLE_DATASETS.keys()))
     parser.add_argument('--url-prefix', default=DEFAULT_URL)
     parser.add_argument('--clickhouse-data-path', default='/var/lib/clickhouse/')
 
diff --git a/docker/test/stateless/Dockerfile b/docker/test/stateless/Dockerfile
index 516d8d5842b0..33eb1c291030 100644
--- a/docker/test/stateless/Dockerfile
+++ b/docker/test/stateless/Dockerfile
@@ -12,10 +12,10 @@ RUN apt-get update -y \
             ncdu \
             netcat-openbsd \
             openssl \
-            python \
-            python-lxml \
-            python-requests \
-            python-termcolor \
+            python3 \
+            python3-lxml \
+            python3-requests \
+            python3-termcolor \
             qemu-user-static \
             sudo \
             telnet \
diff --git a/docker/test/stateless_pytest/Dockerfile b/docker/test/stateless_pytest/Dockerfile
index 596e2686f495..674a60031878 100644
--- a/docker/test/stateless_pytest/Dockerfile
+++ b/docker/test/stateless_pytest/Dockerfile
@@ -3,10 +3,10 @@ FROM yandex/clickhouse-test-base
 
 RUN apt-get update -y && \
     apt-get install -y --no-install-recommends \
-        python-pip \
-        python-setuptools
+        python3-pip \
+        python3-setuptools
 
-RUN pip install \
+RUN python3 -m pip install \
     pytest \
     pytest-html \
     pytest-timeout \
@@ -17,4 +17,4 @@ CMD dpkg -i package_folder/clickhouse-common-static_*.deb; \
     dpkg -i package_folder/clickhouse-server_*.deb;  \
     dpkg -i package_folder/clickhouse-client_*.deb; \
     dpkg -i package_folder/clickhouse-test_*.deb; \
-    python -m pytest /usr/share/clickhouse-test/queries -n $(nproc) --html=test_output/report.html --self-contained-html
+    python3 -m pytest /usr/share/clickhouse-test/queries -n $(nproc) --html=test_output/report.html --self-contained-html
diff --git a/docker/test/stateless_unbundled/Dockerfile b/docker/test/stateless_unbundled/Dockerfile
index cb8cd158e5f5..f2fd28e40788 100644
--- a/docker/test/stateless_unbundled/Dockerfile
+++ b/docker/test/stateless_unbundled/Dockerfile
@@ -54,10 +54,10 @@ RUN apt-get --allow-unauthenticated update -y \
             perl \
             pigz \
             pkg-config \
-            python \
-            python-lxml \
-            python-requests \
-            python-termcolor \
+            python3 \
+            python3-lxml \
+            python3-requests \
+            python3-termcolor \
             qemu-user-static \
             sudo \
             telnet \
diff --git a/docker/test/stateless_with_coverage/Dockerfile b/docker/test/stateless_with_coverage/Dockerfile
index b76989de1cfe..1d6a85adf9e5 100644
--- a/docker/test/stateless_with_coverage/Dockerfile
+++ b/docker/test/stateless_with_coverage/Dockerfile
@@ -12,10 +12,10 @@ RUN apt-get update -y \
             fakeroot \
             debhelper \
             expect \
-            python \
-            python-lxml \
-            python-termcolor \
-            python-requests \
+            python3 \
+            python3-lxml \
+            python3-termcolor \
+            python3-requests \
             sudo \
             openssl \
             ncdu \
diff --git a/docker/test/stress/Dockerfile b/docker/test/stress/Dockerfile
index 6855a632df47..e1df32ec3d72 100644
--- a/docker/test/stress/Dockerfile
+++ b/docker/test/stress/Dockerfile
@@ -10,10 +10,10 @@ RUN apt-get update -y \
             debhelper \
             parallel \
             expect \
-            python \
-            python-lxml \
-            python-termcolor \
-            python-requests \
+            python3 \
+            python3-lxml \
+            python3-termcolor \
+            python3-requests \
             curl \
             sudo \
             openssl \
diff --git a/docker/test/stress/stress b/docker/test/stress/stress
index a36adda3aad9..a81391d56a73 100755
--- a/docker/test/stress/stress
+++ b/docker/test/stress/stress
@@ -1,4 +1,4 @@
-#!/usr/bin/env python
+#!/usr/bin/env python3
 # -*- coding: utf-8 -*-
 from multiprocessing import cpu_count
 from subprocess import Popen, check_call
diff --git a/docs/tools/test.py b/docs/tools/test.py
index d963d34df087..7d11157c986e 100755
--- a/docs/tools/test.py
+++ b/docs/tools/test.py
@@ -1,6 +1,5 @@
 #!/usr/bin/env python3
-# -*- coding: utf-8 -*-
-from __future__ import unicode_literals
+
 import logging
 import os
 import sys
diff --git a/src/Storages/tests/active_parts.py b/src/Storages/tests/active_parts.py
index 6872baf63684..a818a76017db 100644
--- a/src/Storages/tests/active_parts.py
+++ b/src/Storages/tests/active_parts.py
@@ -24,16 +24,16 @@
     parts[m1].append((i1, i2, l, s))
 
 for m, ps in sorted(parts.items()):
-    ps.sort(key=lambda (i1, i2, l, s): (i1, -i2, -l))
+    ps.sort(key=lambda i1_i2_l_s: (i1_i2_l_s[0], -i1_i2_l_s[1], -i1_i2_l_s[2]))
     (x2, y2, l2, s2) = (-1, -1, -1, -1)
     for x1, y1, l1, s1 in ps:
         if x1 >= x2 and y1 <= y2 and l1 < l2 and (x1, y1) != (x2, y2): # 2 contains 1
             pass
         elif x1 > y2: # 1 is to the right of 2
             if x1 != y2 + 1 and y2 != -1:
-                print # to see the missing numbers
+                print() # to see the missing numbers
             (x2, y2, l2, s2) = (x1, y1, l1, s1)
-            print s1
+            print(s1)
         else:
             raise Exception('invalid parts intersection: ' + s1 + ' and ' + s2)
-    print
+    print()
diff --git a/tests/clickhouse-test b/tests/clickhouse-test
index 2a9c95eb8305..348df2f93be5 100755
--- a/tests/clickhouse-test
+++ b/tests/clickhouse-test
@@ -1,5 +1,5 @@
-#!/usr/bin/env python2
-from __future__ import print_function
+#!/usr/bin/env python3
+
 import sys
 import os
 import os.path
@@ -23,7 +23,7 @@ try:
 except ImportError:
     termcolor = None
 from random import random
-import commands
+import subprocess
 import multiprocessing
 from contextlib import closing
 
@@ -99,7 +99,7 @@ def remove_control_characters(s):
     """
     def str_to_int(s, default, base=10):
         if int(s, base) < 0x10000:
-            return unichr(int(s, base))
+            return chr(int(s, base))
         return default
     s = re.sub(r"&#(\d+);?", lambda c: str_to_int(c.group(1), c.group(0)), s)
     s = re.sub(r"&#[xX]([0-9a-fA-F]+);?", lambda c: str_to_int(c.group(1), c.group(0), base=16), s)
@@ -129,8 +129,8 @@ def run_single_test(args, ext, server_logs_level, client_options, case_file, std
             return ''.join(random.choice(alphabet) for _ in range(length))
         database = 'test_{suffix}'.format(suffix=random_str())
 
-        clickhouse_proc_create = Popen(shlex.split(args.client), stdin=PIPE, stdout=PIPE, stderr=PIPE)
-        clickhouse_proc_create.communicate("CREATE DATABASE " + database + get_db_engine(args))
+        clickhouse_proc_create = Popen(shlex.split(args.client), stdin=PIPE, stdout=PIPE, stderr=PIPE, universal_newlines=True)
+        clickhouse_proc_create.communicate(("CREATE DATABASE " + database + get_db_engine(args)))
 
         os.environ["CLICKHOUSE_DATABASE"] = database
 
@@ -157,8 +157,8 @@ def run_single_test(args, ext, server_logs_level, client_options, case_file, std
         sleep(0.01)
 
     if not args.database:
-        clickhouse_proc_create = Popen(shlex.split(args.client), stdin=PIPE, stdout=PIPE, stderr=PIPE)
-        clickhouse_proc_create.communicate("DROP DATABASE " + database)
+        clickhouse_proc_create = Popen(shlex.split(args.client), stdin=PIPE, stdout=PIPE, stderr=PIPE, universal_newlines=True)
+        clickhouse_proc_create.communicate(("DROP DATABASE " + database))
 
     total_time = (datetime.now() - start_time).total_seconds()
 
@@ -166,10 +166,10 @@ def run_single_test(args, ext, server_logs_level, client_options, case_file, std
     os.system("LC_ALL=C sed -i -e 's/{test_db}/default/g' {file}".format(test_db=database, file=stdout_file))
     os.system("LC_ALL=C sed -i -e 's/{test_db}/default/g' {file}".format(test_db=database, file=stderr_file))
 
-    stdout = open(stdout_file, 'r').read() if os.path.exists(stdout_file) else ''
-    stdout = unicode(stdout, errors='replace', encoding='utf-8')
-    stderr = open(stderr_file, 'r').read() if os.path.exists(stderr_file) else ''
-    stderr = unicode(stderr, errors='replace', encoding='utf-8')
+    stdout = open(stdout_file, 'rb').read() if os.path.exists(stdout_file) else b''
+    stdout = str(stdout, errors='replace', encoding='utf-8')
+    stderr = open(stderr_file, 'rb').read() if os.path.exists(stderr_file) else b''
+    stderr = str(stderr, errors='replace', encoding='utf-8')
 
     return proc, stdout, stderr, total_time
 
@@ -300,8 +300,8 @@ def run_tests_array(all_tests_with_params):
                 else:
 
                     if args.testname:
-                        clickhouse_proc = Popen(shlex.split(args.client), stdin=PIPE, stdout=PIPE, stderr=PIPE)
-                        clickhouse_proc.communicate("SELECT 'Running test {suite}/{case} from pid={pid}';".format(pid = os.getpid(), case = case, suite = suite))
+                        clickhouse_proc = Popen(shlex.split(args.client), stdin=PIPE, stdout=PIPE, stderr=PIPE, universal_newlines=True)
+                        clickhouse_proc.communicate(("SELECT 'Running test {suite}/{case} from pid={pid}';".format(pid = os.getpid(), case = case, suite = suite)))
 
                         if clickhouse_proc.returncode != 0:
                             failures += 1
@@ -342,7 +342,7 @@ def run_tests_array(all_tests_with_params):
                             print(" - return code {}".format(proc.returncode))
 
                             if stderr:
-                                print(stderr.encode('utf-8'))
+                                print(stderr)
 
                             # Stop on fatal errors like segmentation fault. They are send to client via logs.
                             if ' <Fatal> ' in stderr:
@@ -360,22 +360,22 @@ def run_tests_array(all_tests_with_params):
                             failures_chain += 1
                             print(MSG_FAIL, end='')
                             print_test_time(total_time)
-                            print(" - having stderror:
{}".format(stderr.encode('utf-8')))
+                            print(" - having stderror:
{}".format(stderr))
                         elif 'Exception' in stdout:
                             failures += 1
                             failures_chain += 1
                             print(MSG_FAIL, end='')
                             print_test_time(total_time)
-                            print(" - having exception:
{}".format(stdout.encode('utf-8')))
+                            print(" - having exception:
{}".format(stdout))
                         elif not os.path.isfile(reference_file):
                             print(MSG_UNKNOWN, end='')
                             print_test_time(total_time)
                             print(" - no reference file")
                         else:
-                            result_is_different = subprocess.call(['diff', '-q', reference_file, stdout_file], stdout = PIPE)
+                            result_is_different = subprocess.call(['diff', '-q', reference_file, stdout_file], stdout=PIPE)
 
                             if result_is_different:
-                                diff = Popen(['diff', '-U', str(args.unified), reference_file, stdout_file], stdout = PIPE).communicate()[0]
+                                diff = Popen(['diff', '-U', str(args.unified), reference_file, stdout_file], stdout=PIPE, universal_newlines=True).communicate()[0]
                                 failures += 1
                                 print(MSG_FAIL, end='')
                                 print_test_time(total_time)
@@ -419,9 +419,9 @@ def check_server_started(client, retry_count):
     sys.stdout.flush()
     while retry_count > 0:
         clickhouse_proc = Popen(shlex.split(client), stdin=PIPE, stdout=PIPE, stderr=PIPE)
-        (stdout, stderr) = clickhouse_proc.communicate("SELECT 1")
+        (stdout, stderr) = clickhouse_proc.communicate(b"SELECT 1")
 
-        if clickhouse_proc.returncode == 0 and stdout.startswith("1"):
+        if clickhouse_proc.returncode == 0 and stdout.startswith(b"1"):
             print(" OK")
             sys.stdout.flush()
             return True
@@ -468,46 +468,46 @@ class BuildFlags(object):
 
 def collect_build_flags(client):
     clickhouse_proc = Popen(shlex.split(client), stdin=PIPE, stdout=PIPE, stderr=PIPE)
-    (stdout, stderr) = clickhouse_proc.communicate("SELECT value FROM system.build_options WHERE name = 'CXX_FLAGS'")
+    (stdout, stderr) = clickhouse_proc.communicate(b"SELECT value FROM system.build_options WHERE name = 'CXX_FLAGS'")
     result = []
 
     if clickhouse_proc.returncode == 0:
-        if '-fsanitize=thread' in stdout:
+        if b'-fsanitize=thread' in stdout:
             result.append(BuildFlags.THREAD)
-        elif '-fsanitize=address' in stdout:
+        elif b'-fsanitize=address' in stdout:
             result.append(BuildFlags.ADDRESS)
-        elif '-fsanitize=undefined' in stdout:
+        elif b'-fsanitize=undefined' in stdout:
             result.append(BuildFlags.UNDEFINED)
-        elif '-fsanitize=memory' in stdout:
+        elif b'-fsanitize=memory' in stdout:
             result.append(BuildFlags.MEMORY)
     else:
         raise Exception("Cannot get inforamtion about build from server errorcode {}, stderr {}".format(clickhouse_proc.returncode, stderr))
 
     clickhouse_proc = Popen(shlex.split(client), stdin=PIPE, stdout=PIPE, stderr=PIPE)
-    (stdout, stderr) = clickhouse_proc.communicate("SELECT value FROM system.build_options WHERE name = 'BUILD_TYPE'")
+    (stdout, stderr) = clickhouse_proc.communicate(b"SELECT value FROM system.build_options WHERE name = 'BUILD_TYPE'")
 
     if clickhouse_proc.returncode == 0:
-        if 'Debug' in stdout:
+        if b'Debug' in stdout:
             result.append(BuildFlags.DEBUG)
-        elif 'RelWithDebInfo' in stdout or 'Release' in stdout:
+        elif b'RelWithDebInfo' in stdout or b'Release' in stdout:
             result.append(BuildFlags.RELEASE)
     else:
         raise Exception("Cannot get inforamtion about build from server errorcode {}, stderr {}".format(clickhouse_proc.returncode, stderr))
 
     clickhouse_proc = Popen(shlex.split(client), stdin=PIPE, stdout=PIPE, stderr=PIPE)
-    (stdout, stderr) = clickhouse_proc.communicate("SELECT value FROM system.build_options WHERE name = 'UNBUNDLED'")
+    (stdout, stderr) = clickhouse_proc.communicate(b"SELECT value FROM system.build_options WHERE name = 'UNBUNDLED'")
 
     if clickhouse_proc.returncode == 0:
-        if 'ON' in stdout or '1' in stdout:
+        if b'ON' in stdout or b'1' in stdout:
             result.append(BuildFlags.UNBUNDLED)
     else:
         raise Exception("Cannot get inforamtion about build from server errorcode {}, stderr {}".format(clickhouse_proc.returncode, stderr))
 
     clickhouse_proc = Popen(shlex.split(client), stdin=PIPE, stdout=PIPE, stderr=PIPE)
-    (stdout, stderr) = clickhouse_proc.communicate("SELECT value FROM system.settings WHERE name = 'default_database_engine'")
+    (stdout, stderr) = clickhouse_proc.communicate(b"SELECT value FROM system.settings WHERE name = 'default_database_engine'")
 
     if clickhouse_proc.returncode == 0:
-        if 'Ordinary' in stdout:
+        if b'Ordinary' in stdout:
             result.append(BuildFlags.DATABASE_ORDINARY)
     else:
         raise Exception("Cannot get inforamtion about build from server errorcode {}, stderr {}".format(clickhouse_proc.returncode, stderr))
@@ -523,11 +523,11 @@ def main(args):
 
     def is_data_present():
         clickhouse_proc = Popen(shlex.split(args.client), stdin=PIPE, stdout=PIPE, stderr=PIPE)
-        (stdout, stderr) = clickhouse_proc.communicate("EXISTS TABLE test.hits")
+        (stdout, stderr) = clickhouse_proc.communicate(b"EXISTS TABLE test.hits")
         if clickhouse_proc.returncode != 0:
             raise CalledProcessError(clickhouse_proc.returncode, args.client, stderr)
 
-        return stdout.startswith('1')
+        return stdout.startswith(b'1')
 
     if not check_server_started(args.client, args.server_check_retries):
         raise Exception("clickhouse-server is not responding. Cannot execute 'SELECT 1' query.")
@@ -562,7 +562,7 @@ def main(args):
         stop_time = time() + args.global_time_limit
 
     if args.zookeeper is None:
-        code, out = commands.getstatusoutput(args.extract_from_config + " --try --config " + args.configserver + ' --key zookeeper | grep . | wc -l')
+        code, out = subprocess.getstatusoutput(args.extract_from_config + " --try --config " + args.configserver + ' --key zookeeper | grep . | wc -l')
         try:
             if int(out) > 0:
                 args.zookeeper = True
@@ -572,18 +572,18 @@ def main(args):
             args.zookeeper = False
 
     if args.shard is None:
-        code, out = commands.getstatusoutput(args.extract_from_config + " --try --config " + args.configserver + ' --key listen_host | grep -E "127.0.0.2|::"')
+        code, out = subprocess.getstatusoutput(args.extract_from_config + " --try --config " + args.configserver + ' --key listen_host | grep -E "127.0.0.2|::"')
         if out:
             args.shard = True
         else:
             args.shard = False
 
     if args.database and args.database != "test":
-        clickhouse_proc_create = Popen(shlex.split(args.client), stdin=PIPE, stdout=PIPE, stderr=PIPE)
-        clickhouse_proc_create.communicate("CREATE DATABASE IF NOT EXISTS " + args.database + get_db_engine(args))
+        clickhouse_proc_create = Popen(shlex.split(args.client), stdin=PIPE, stdout=PIPE, stderr=PIPE, universal_newlines=True)
+        clickhouse_proc_create.communicate(("CREATE DATABASE IF NOT EXISTS " + args.database + get_db_engine(args)))
 
-    clickhouse_proc_create = Popen(shlex.split(args.client), stdin=PIPE, stdout=PIPE, stderr=PIPE)
-    clickhouse_proc_create.communicate("CREATE DATABASE IF NOT EXISTS test" + get_db_engine(args))
+    clickhouse_proc_create = Popen(shlex.split(args.client), stdin=PIPE, stdout=PIPE, stderr=PIPE, universal_newlines=True)
+    clickhouse_proc_create.communicate(("CREATE DATABASE IF NOT EXISTS test" + get_db_engine(args)))
 
     def is_test_from_dir(suite_dir, case):
         case_file = os.path.join(suite_dir, case)
@@ -595,14 +595,14 @@ def main(args):
              return random()
 
        if -1 == item.find('_'):
-           return 99998
+           return 99998, ''
 
        prefix, suffix = item.split('_', 1)
 
        try:
            return int(prefix), suffix
        except ValueError:
-           return 99997
+           return 99997, ''
 
     total_tests_run = 0
     for suite in sorted(os.listdir(base_dir), key=sute_key_func):
@@ -650,7 +650,7 @@ def main(args):
                     return 99997
 
             all_tests = os.listdir(suite_dir)
-            all_tests = filter(lambda case: is_test_from_dir(suite_dir, case), all_tests)
+            all_tests = [case for case in all_tests if is_test_from_dir(suite_dir, case)]
             if args.test:
                 all_tests = [t for t in all_tests if any([re.search(r, t) for r in args.test])]
             all_tests.sort(key=key_func)
@@ -670,7 +670,7 @@ def main(args):
             if jobs > run_total:
                 run_total = jobs
 
-            batch_size = len(all_tests) / jobs
+            batch_size = len(all_tests) // jobs
             all_tests_array = []
             for i in range(0, len(all_tests), batch_size):
                 all_tests_array.append((all_tests[i:i+batch_size], suite, suite_dir, suite_tmp_dir, run_total))
diff --git a/tests/external_models/catboost/helpers/server.py b/tests/external_models/catboost/helpers/server.py
index 265898d8d415..8248b16e6df8 100644
--- a/tests/external_models/catboost/helpers/server.py
+++ b/tests/external_models/catboost/helpers/server.py
@@ -37,7 +37,7 @@ def wait_for_request(self, port, timeout=1):
 
             s.connect(('localhost', port))
         except socket.error as socketerror:
-            print "Error: ", socketerror
+            print("Error: ", socketerror)
             raise
 
     def shutdown(self, timeout=10):
diff --git a/tests/external_models/catboost/helpers/server_with_models.py b/tests/external_models/catboost/helpers/server_with_models.py
index ad9feea99fe3..e00da7b70279 100644
--- a/tests/external_models/catboost/helpers/server_with_models.py
+++ b/tests/external_models/catboost/helpers/server_with_models.py
@@ -1,6 +1,6 @@
-from server import ClickHouseServer
-from client import ClickHouseClient
-from table import ClickHouseTable
+from .server import ClickHouseServer
+from .client import ClickHouseClient
+from .table import ClickHouseTable
 import os
 import errno
 from shutil import rmtree
@@ -140,7 +140,7 @@ def _save_models(self):
         if not os.path.exists(self.models_dir):
             os.makedirs(self.models_dir)
 
-        for name, model in self.models.items():
+        for name, model in list(self.models.items()):
             model_path = os.path.join(self.models_dir, name + '.cbm')
             config_path = os.path.join(self.models_dir, name + '_model.xml')
             params = {
diff --git a/tests/external_models/catboost/helpers/table.py b/tests/external_models/catboost/helpers/table.py
index e6b05ac7b7b1..5f9b828c9f3d 100644
--- a/tests/external_models/catboost/helpers/table.py
+++ b/tests/external_models/catboost/helpers/table.py
@@ -1,5 +1,5 @@
-from server import ClickHouseServer
-from client import ClickHouseClient
+from .server import ClickHouseServer
+from .client import ClickHouseClient
 from pandas import DataFrame
 import os
 import threading
@@ -40,7 +40,7 @@ def _create_table_from_df(self):
         column_types = list(self.df.dtypes)
         column_names = list(self.df)
         schema = ', '.join((name + ' ' + self._convert(str(t)) for name, t in zip(column_names, column_types)))
-        print 'schema:', schema
+        print('schema:', schema)
 
         create_query = 'create table test.{} (date Date DEFAULT today(), {}) engine = MergeTree(date, (date), 8192)'
         self.client.query(create_query.format(self.table_name, schema))
@@ -58,10 +58,10 @@ def apply_model(self, model_name, float_columns, cat_columns):
         result = self.client.query(query.format(model_name, columns, self.table_name))
 
         def parse_row(row):
-            values = tuple(map(float, filter(len, map(str.strip, row.replace('(', '').replace(')', '').split(',')))))
+            values = tuple(map(float, list(filter(len, list(map(str.strip, row.replace('(', '').replace(')', '').split(',')))))))
             return values if len(values) != 1 else values[0]
 
-        return tuple(map(parse_row, filter(len, map(str.strip, result.split('
')))))
+        return tuple(map(parse_row, list(filter(len, list(map(str.strip, result.split('
')))))))
 
     def _drop_table(self):
         self.client.query('drop table test.{}'.format(self.table_name))
diff --git a/tests/external_models/catboost/helpers/train.py b/tests/external_models/catboost/helpers/train.py
index df81d7195535..34a6f8e958bb 100644
--- a/tests/external_models/catboost/helpers/train.py
+++ b/tests/external_models/catboost/helpers/train.py
@@ -19,10 +19,10 @@ def train_catboost_model(df, target, cat_features, params, verbose=True):
     if not isinstance(df, DataFrame):
         raise Exception('DataFrame object expected, but got ' + repr(df))
 
-    print 'features:', df.columns.tolist()
+    print('features:', df.columns.tolist())
 
     cat_features_index = list(df.columns.get_loc(feature) for feature in cat_features)
-    print 'cat features:', cat_features_index
+    print('cat features:', cat_features_index)
     model = CatBoostClassifier(**params)
     model.fit(df, target, cat_features=cat_features_index, verbose=verbose)
     return model
diff --git a/tests/external_models/catboost/test_apply_catboost_model/test.py b/tests/external_models/catboost/test_apply_catboost_model/test.py
index 00b9fe0dce1a..d266393bf48d 100644
--- a/tests/external_models/catboost/test_apply_catboost_model/test.py
+++ b/tests/external_models/catboost/test_apply_catboost_model/test.py
@@ -23,7 +23,7 @@ def check_predictions(test_name, target, pred_python, pred_ch, acc_threshold):
 
     acc = 1 - np.sum(np.abs(ch_class - np.array(target))) / (len(target) + .0)
     assert acc >= acc_threshold
-    print test_name, 'accuracy: {:.10f}'.format(acc)
+    print(test_name, 'accuracy: {:.10f}'.format(acc))
 
 
 def test_apply_float_features_only():
@@ -52,9 +52,9 @@ def target_filter(row):
     train_target = get_target(train_df)
     test_target = get_target(test_df)
 
-    print
-    print 'train target', train_target
-    print 'test target', test_target
+    print()
+    print('train target', train_target)
+    print('test target', test_target)
 
     params = {
         'iterations': 4,
@@ -71,8 +71,8 @@ def target_filter(row):
     with server:
         pred_ch = (np.array(server.apply_model(name, test_df, [])) > 0).astype(int)
 
-    print 'python predictions', pred_python
-    print 'clickhouse predictions', pred_ch
+    print('python predictions', pred_python)
+    print('clickhouse predictions', pred_ch)
 
     check_predictions(name, test_target, pred_python, pred_ch, 0.9)
 
@@ -105,9 +105,9 @@ def target_filter(row):
     train_target = get_target(train_df)
     test_target = get_target(test_df)
 
-    print
-    print 'train target', train_target
-    print 'test target', test_target
+    print()
+    print('train target', train_target)
+    print('test target', test_target)
 
     params = {
         'iterations': 6,
@@ -124,8 +124,8 @@ def target_filter(row):
     with server:
         pred_ch = (np.array(server.apply_model(name, test_df, [])) > 0).astype(int)
 
-    print 'python predictions', pred_python
-    print 'clickhouse predictions', pred_ch
+    print('python predictions', pred_python)
+    print('clickhouse predictions', pred_ch)
 
     check_predictions(name, test_target, pred_python, pred_ch, 0.9)
 
@@ -158,9 +158,9 @@ def target_filter(row):
     train_target = get_target(train_df)
     test_target = get_target(test_df)
 
-    print
-    print 'train target', train_target
-    print 'test target', test_target
+    print()
+    print('train target', train_target)
+    print('test target', test_target)
 
     params = {
         'iterations': 6,
@@ -177,8 +177,8 @@ def target_filter(row):
     with server:
         pred_ch = (np.array(server.apply_model(name, test_df, [])) > 0).astype(int)
 
-    print 'python predictions', pred_python
-    print 'clickhouse predictions', pred_ch
+    print('python predictions', pred_python)
+    print('clickhouse predictions', pred_ch)
 
     check_predictions(name, test_target, pred_python, pred_ch, 0.9)
 
@@ -211,9 +211,9 @@ def target_filter(row):
     train_target = get_target(train_df)
     test_target = get_target(test_df)
 
-    print
-    print 'train target', train_target
-    print 'test target', test_target
+    print()
+    print('train target', train_target)
+    print('test target', test_target)
 
     params = {
         'iterations': 6,
@@ -230,8 +230,8 @@ def target_filter(row):
     with server:
         pred_ch = (np.array(server.apply_model(name, test_df, [])) > 0).astype(int)
 
-    print 'python predictions', pred_python
-    print 'clickhouse predictions', pred_ch
+    print('python predictions', pred_python)
+    print('clickhouse predictions', pred_ch)
 
     check_predictions(name, test_target, pred_python, pred_ch, 0.9)
 
@@ -269,9 +269,9 @@ def target_filter(row):
     train_target = get_target(train_df)
     test_target = get_target(test_df)
 
-    print
-    print 'train target', train_target
-    print 'test target', test_target
+    print()
+    print('train target', train_target)
+    print('test target', test_target)
 
     params = {
         'iterations': 10,
@@ -288,7 +288,7 @@ def target_filter(row):
     with server:
         pred_ch = np.argmax(np.array(server.apply_model(name, test_df, [])), axis=1)
 
-    print 'python predictions', pred_python
-    print 'clickhouse predictions', pred_ch
+    print('python predictions', pred_python)
+    print('clickhouse predictions', pred_ch)
 
     check_predictions(name, test_target, pred_python, pred_ch, 0.9)
diff --git a/tests/integration/README.md b/tests/integration/README.md
index a3eb577d609d..94a6000d707b 100644
--- a/tests/integration/README.md
+++ b/tests/integration/README.md
@@ -12,11 +12,11 @@ You must install latest Docker from
 https://docs.docker.com/engine/installation/linux/docker-ce/ubuntu/#set-up-the-repository
 Don't use Docker from your system repository.
 
-* [pip](https://pypi.python.org/pypi/pip) and `libpq-dev`. To install: `sudo apt-get install python-pip libpq-dev zlib1g-dev libcrypto++-dev libssl-dev`
+* [pip](https://pypi.python.org/pypi/pip) and `libpq-dev`. To install: `sudo apt-get install python3-pip libpq-dev zlib1g-dev libcrypto++-dev libssl-dev`
 * [py.test](https://docs.pytest.org/) testing framework. To install: `sudo -H pip install pytest`
-* [docker-compose](https://docs.docker.com/compose/) and additional python libraries. To install: `sudo -H pip install urllib3==1.23 pytest docker-compose==1.22.0 docker dicttoxml kazoo PyMySQL psycopg2==2.7.5 pymongo tzlocal kafka-python protobuf redis aerospike pytest-timeout minio rpm-confluent-schemaregistry`
+* [docker-compose](https://docs.docker.com/compose/) and additional python libraries. To install: `sudo -H pip install urllib3==1.23 pytest docker-compose==1.22.0 docker dicttoxml kazoo PyMySQL psycopg2==2.7.5 pymongo tzlocal kafka-python protobuf redis aerospike pytest-timeout minio confluent-kafka avro
 
-(highly not recommended) If you really want to use OS packages on modern debian/ubuntu instead of "pip": `sudo apt install -y docker docker-compose python-pytest python-dicttoxml python-docker python-pymysql python-pymongo python-tzlocal python-kazoo python-psycopg2 python-kafka python-pytest-timeout python-minio`
+(highly not recommended) If you really want to use OS packages on modern debian/ubuntu instead of "pip": `sudo apt install -y docker docker-compose python3-pytest python3-dicttoxml python3-docker python3-pymysql python3-pymongo python3-tzlocal python3-kazoo python3-psycopg2 kafka-python python3-pytest-timeout python3-minio`
 
 If you want to run the tests under a non-privileged user, you must add this user to `docker` group: `sudo usermod -aG docker $USER` and re-login.
 (You must close all your sessions (for example, restart your computer))
diff --git a/tests/integration/helpers/client.py b/tests/integration/helpers/client.py
index deffa20753f8..a43440e41f74 100644
--- a/tests/integration/helpers/client.py
+++ b/tests/integration/helpers/client.py
@@ -31,7 +31,7 @@ def get_query_request(self, sql, stdin=None, timeout=None, settings=None, user=N
             command += ['--query', sql]
 
         if settings is not None:
-            for setting, value in settings.iteritems():
+            for setting, value in settings.items():
                 command += ['--' + setting, str(value)]
 
         if user is not None:
@@ -67,7 +67,7 @@ class QueryRuntimeException(Exception):
 class CommandRequest:
     def __init__(self, command, stdin=None, timeout=None, ignore_error=False):
         # Write data to tmp file to avoid PIPEs and execution blocking
-        stdin_file = tempfile.TemporaryFile()
+        stdin_file = tempfile.TemporaryFile(mode='w+')
         stdin_file.write(stdin)
         stdin_file.seek(0)
         self.stdout_file = tempfile.TemporaryFile()
@@ -80,7 +80,7 @@ def __init__(self, command, stdin=None, timeout=None, ignore_error=False):
         # can print some debug information there
         env = {}
         env["TSAN_OPTIONS"] = "verbosity=0"
-        self.process = sp.Popen(command, stdin=stdin_file, stdout=self.stdout_file, stderr=self.stderr_file, env=env)
+        self.process = sp.Popen(command, stdin=stdin_file, stdout=self.stdout_file, stderr=self.stderr_file, env=env, universal_newlines=True)
 
         self.timer = None
         self.process_finished_before_timeout = True
@@ -98,8 +98,8 @@ def get_answer(self):
         self.stdout_file.seek(0)
         self.stderr_file.seek(0)
 
-        stdout = self.stdout_file.read()
-        stderr = self.stderr_file.read()
+        stdout = self.stdout_file.read().decode()
+        stderr = self.stderr_file.read().decode()
 
         if self.timer is not None and not self.process_finished_before_timeout and not self.ignore_error:
             raise QueryTimeoutExceedException('Client timed out!')
@@ -115,8 +115,8 @@ def get_error(self):
         self.stdout_file.seek(0)
         self.stderr_file.seek(0)
 
-        stdout = self.stdout_file.read()
-        stderr = self.stderr_file.read()
+        stdout = self.stdout_file.read().decode()
+        stderr = self.stderr_file.read().decode()
 
         if self.timer is not None and not self.process_finished_before_timeout and not self.ignore_error:
             raise QueryTimeoutExceedException('Client timed out!')
@@ -131,8 +131,8 @@ def get_answer_and_error(self):
         self.stdout_file.seek(0)
         self.stderr_file.seek(0)
 
-        stdout = self.stdout_file.read()
-        stderr = self.stderr_file.read()
+        stdout = self.stdout_file.read().decode()
+        stderr = self.stderr_file.read().decode()
 
         if self.timer is not None and not self.process_finished_before_timeout and not self.ignore_error:
             raise QueryTimeoutExceedException('Client timed out!')
diff --git a/tests/integration/helpers/cluster.py b/tests/integration/helpers/cluster.py
index d99d8a17844d..6b24bc30460d 100644
--- a/tests/integration/helpers/cluster.py
+++ b/tests/integration/helpers/cluster.py
@@ -1,6 +1,6 @@
 import base64
 import errno
-import httplib
+import http.client
 import logging
 import os
 import os.path as p
@@ -12,7 +12,7 @@
 import subprocess
 import time
 import traceback
-import urllib
+import urllib.parse
 
 import cassandra.cluster
 import docker
@@ -21,7 +21,7 @@
 import pymysql
 import requests
 import xml.dom.minidom
-from confluent.schemaregistry.client import CachedSchemaRegistryClient
+from confluent_kafka.avro.cached_schema_registry_client import CachedSchemaRegistryClient
 from dicttoxml import dicttoxml
 from kazoo.client import KazooClient
 from kazoo.exceptions import KazooException
@@ -41,7 +41,7 @@
 def _create_env_file(path, variables, fname=DEFAULT_ENV_NAME):
     full_path = os.path.join(path, fname)
     with open(full_path, 'w') as f:
-        for var, value in variables.items():
+        for var, value in list(variables.items()):
             f.write("=".join([var, value]) + "
")
     return full_path
 
@@ -76,7 +76,7 @@ def get_docker_compose_path():
         if os.path.exists(os.path.dirname('/compose/')):
             return os.path.dirname('/compose/')  # default in docker runner container
         else:
-            print("Fallback docker_compose_path to LOCAL_DOCKER_COMPOSE_DIR: {}".format(LOCAL_DOCKER_COMPOSE_DIR))
+            print(("Fallback docker_compose_path to LOCAL_DOCKER_COMPOSE_DIR: {}".format(LOCAL_DOCKER_COMPOSE_DIR)))
             return LOCAL_DOCKER_COMPOSE_DIR
 
 
@@ -91,8 +91,8 @@ class ClickHouseCluster:
 
     def __init__(self, base_path, name=None, base_config_dir=None, server_bin_path=None, client_bin_path=None,
                  odbc_bridge_bin_path=None, zookeeper_config_path=None, custom_dockerd_host=None):
-        for param in os.environ.keys():
-            print "ENV %40s %s" % (param, os.environ[param])
+        for param in list(os.environ.keys()):
+            print("ENV %40s %s" % (param, os.environ[param]))
         self.base_dir = p.dirname(base_path)
         self.name = name if name is not None else ''
 
@@ -160,7 +160,7 @@ def __init__(self, base_path, name=None, base_config_dir=None, server_bin_path=N
 
         self.docker_client = None
         self.is_up = False
-        print "CLUSTER INIT base_config_dir:{}".format(self.base_config_dir)
+        print("CLUSTER INIT base_config_dir:{}".format(self.base_config_dir))
 
     def get_client_cmd(self):
         cmd = self.client_bin_path
@@ -386,7 +386,7 @@ def restart_instance_with_ip_change(self, node, new_ip):
     def get_instance_ip(self, instance_name):
         docker_id = self.get_instance_docker_id(instance_name)
         handle = self.docker_client.containers.get(docker_id)
-        return handle.attrs['NetworkSettings']['Networks'].values()[0]['IPAddress']
+        return list(handle.attrs['NetworkSettings']['Networks'].values())[0]['IPAddress']
 
     def get_container_id(self, instance_name):
         docker_id = self.get_instance_docker_id(instance_name)
@@ -395,22 +395,21 @@ def get_container_id(self, instance_name):
 
     def get_container_logs(self, instance_name):
         container_id = self.get_container_id(instance_name)
-        return self.docker_client.api.logs(container_id)
+        return self.docker_client.api.logs(container_id).decode()
 
     def exec_in_container(self, container_id, cmd, detach=False, nothrow=False, **kwargs):
         exec_id = self.docker_client.api.exec_create(container_id, cmd, **kwargs)
         output = self.docker_client.api.exec_start(exec_id, detach=detach)
 
-        output = output.decode('utf8')
         exit_code = self.docker_client.api.exec_inspect(exec_id)['ExitCode']
         if exit_code:
             container_info = self.docker_client.api.inspect_container(container_id)
             image_id = container_info.get('Image')
             image_info = self.docker_client.api.inspect_image(image_id)
-            print("Command failed in container {}: ".format(container_id))
+            print(("Command failed in container {}: ".format(container_id)))
             pprint.pprint(container_info)
             print("")
-            print("Container {} uses image {}: ".format(container_id, image_id))
+            print(("Container {} uses image {}: ".format(container_id, image_id)))
             pprint.pprint(image_info)
             print("")
             message = 'Cmd "{}" failed in container {}. Return code {}. Output: {}'.format(' '.join(cmd), container_id,
@@ -419,14 +418,17 @@ def exec_in_container(self, container_id, cmd, detach=False, nothrow=False, **kw
                 print(message)
             else:
                 raise Exception(message)
+        if not detach:
+            return output.decode()
         return output
 
     def copy_file_to_container(self, container_id, local_path, dest_path):
-        with open(local_path, 'r') as fdata:
+        with open(local_path, "r") as fdata:
             data = fdata.read()
-            encoded_data = base64.b64encode(data)
+            encodedBytes = base64.b64encode(data.encode("utf-8"))
+            encodedStr = str(encodedBytes, "utf-8")
             self.exec_in_container(container_id,
-                                   ["bash", "-c", "echo {} | base64 --decode > {}".format(encoded_data, dest_path)],
+                                   ["bash", "-c", "echo {} | base64 --decode > {}".format(encodedStr, dest_path)],
                                    user='root')
 
     def wait_mysql_to_start(self, timeout=60):
@@ -435,10 +437,10 @@ def wait_mysql_to_start(self, timeout=60):
             try:
                 conn = pymysql.connect(user='root', password='clickhouse', host='127.0.0.1', port=3308)
                 conn.close()
-                print "Mysql Started"
+                print("Mysql Started")
                 return
             except Exception as ex:
-                print "Can't connect to MySQL " + str(ex)
+                print("Can't connect to MySQL " + str(ex))
                 time.sleep(0.5)
 
         subprocess_call(['docker-compose', 'ps', '--services', '--all'])
@@ -451,10 +453,10 @@ def wait_postgres_to_start(self, timeout=60):
                 conn_string = "host='localhost' user='postgres' password='mysecretpassword'"
                 conn = psycopg2.connect(conn_string)
                 conn.close()
-                print "Postgres Started"
+                print("Postgres Started")
                 return
             except Exception as ex:
-                print "Can't connect to Postgres " + str(ex)
+                print("Can't connect to Postgres " + str(ex))
                 time.sleep(0.5)
 
         raise Exception("Cannot wait Postgres container")
@@ -466,10 +468,10 @@ def wait_zookeeper_to_start(self, timeout=60):
                 for instance in ['zoo1', 'zoo2', 'zoo3']:
                     conn = self.get_kazoo_client(instance)
                     conn.get_children('/')
-                print "All instances of ZooKeeper started"
+                print("All instances of ZooKeeper started")
                 return
             except Exception as ex:
-                print "Can't connect to ZooKeeper " + str(ex)
+                print("Can't connect to ZooKeeper " + str(ex))
                 time.sleep(0.5)
 
         raise Exception("Cannot wait ZooKeeper container")
@@ -480,10 +482,10 @@ def wait_hdfs_to_start(self, timeout=60):
         while time.time() - start < timeout:
             try:
                 hdfs_api.write_data("/somefilewithrandomname222", "1")
-                print "Connected to HDFS and SafeMode disabled! "
+                print("Connected to HDFS and SafeMode disabled! ")
                 return
             except Exception as ex:
-                print "Can't connect to HDFS " + str(ex)
+                print("Can't connect to HDFS " + str(ex))
                 time.sleep(1)
 
         raise Exception("Can't wait HDFS to start")
@@ -496,10 +498,10 @@ def wait_mongo_to_start(self, timeout=30):
         while time.time() - start < timeout:
             try:
                 connection.list_database_names()
-                print "Connected to Mongo dbs:", connection.list_database_names()
+                print("Connected to Mongo dbs:", connection.database_names())
                 return
             except Exception as ex:
-                print "Can't connect to Mongo " + str(ex)
+                print("Can't connect to Mongo " + str(ex))
                 time.sleep(1)
 
     def wait_minio_to_start(self, timeout=30, secure=False):
@@ -519,12 +521,12 @@ def wait_minio_to_start(self, timeout=30, secure=False):
 
                 minio_client.make_bucket(self.minio_bucket)
 
-                print("S3 bucket '%s' created", self.minio_bucket)
+                print(("S3 bucket '%s' created", self.minio_bucket))
 
                 self.minio_client = minio_client
                 return
             except Exception as ex:
-                print("Can't connect to Minio: %s", str(ex))
+                print(("Can't connect to Minio: %s", str(ex)))
                 time.sleep(1)
 
         raise Exception("Can't wait Minio to start")
@@ -539,7 +541,7 @@ def wait_schema_registry_to_start(self, timeout=10):
                 print("Connected to SchemaRegistry")
                 return
             except Exception as ex:
-                print("Can't connect to SchemaRegistry: %s", str(ex))
+                print(("Can't connect to SchemaRegistry: %s", str(ex)))
                 time.sleep(1)
 
     def wait_cassandra_to_start(self, timeout=30):
@@ -555,7 +557,7 @@ def wait_cassandra_to_start(self, timeout=30):
                 time.sleep(1)
 
     def start(self, destroy_dirs=True):
-        print "Cluster start called. is_up={}, destroy_dirs={}".format(self.is_up, destroy_dirs)
+        print("Cluster start called. is_up={}, destroy_dirs={}".format(self.is_up, destroy_dirs))
         if self.is_up:
             return
 
@@ -571,11 +573,11 @@ def start(self, destroy_dirs=True):
 
         try:
             if destroy_dirs and p.exists(self.instances_dir):
-                print("Removing instances dir %s", self.instances_dir)
+                print(("Removing instances dir %s", self.instances_dir))
                 shutil.rmtree(self.instances_dir)
 
-            for instance in self.instances.values():
-                print('Setup directory for instance: {} destroy_dirs: {}'.format(instance.name, destroy_dirs))
+            for instance in list(self.instances.values()):
+                print(('Setup directory for instance: {} destroy_dirs: {}'.format(instance.name, destroy_dirs)))
                 instance.create_dir(destroy_dir=destroy_dirs)
 
             self.docker_client = docker.from_env(version=self.docker_api_version)
@@ -676,12 +678,12 @@ def start(self, destroy_dirs=True):
                 self.wait_cassandra_to_start()
 
             clickhouse_start_cmd = self.base_cmd + ['up', '-d', '--no-recreate']
-            print("Trying to create ClickHouse instance by command %s", ' '.join(map(str, clickhouse_start_cmd)))
+            print(("Trying to create ClickHouse instance by command %s", ' '.join(map(str, clickhouse_start_cmd))))
             subprocess_check_call(clickhouse_start_cmd)
             print("ClickHouse instance created")
 
             start_deadline = time.time() + 20.0  # seconds
-            for instance in self.instances.itervalues():
+            for instance in self.instances.values():
                 instance.docker_client = self.docker_client
                 instance.ip_address = self.get_instance_ip(instance.name)
 
@@ -693,10 +695,10 @@ def start(self, destroy_dirs=True):
 
             self.is_up = True
 
-        except BaseException, e:
-            print "Failed to start cluster: "
-            print str(e)
-            print traceback.print_exc()
+        except BaseException as e:
+            print("Failed to start cluster: ")
+            print(str(e))
+            print(traceback.print_exc())
             raise
 
     def shutdown(self, kill=True):
@@ -705,7 +707,7 @@ def shutdown(self, kill=True):
             try:
                 subprocess.check_call(self.base_cmd + ['logs'], stdout=f)
             except Exception as e:
-                print "Unable to get logs from docker."
+                print("Unable to get logs from docker.")
             f.seek(0)
             for line in f:
                 if SANITIZER_SIGN in line:
@@ -716,18 +718,18 @@ def shutdown(self, kill=True):
             try:
                 subprocess_check_call(self.base_cmd + ['kill'])
             except Exception as e:
-                print "Kill command failed durung shutdown. {}".format(repr(e))
+                print("Kill command failed durung shutdown. {}".format(repr(e)))
 
         try:
             subprocess_check_call(self.base_cmd + ['down', '--volumes', '--remove-orphans'])
         except Exception as e:
-            print "Down + remove orphans failed durung shutdown. {}".format(repr(e))
+            print("Down + remove orphans failed durung shutdown. {}".format(repr(e)))
 
         self.is_up = False
 
         self.docker_client = None
 
-        for instance in self.instances.values():
+        for instance in list(self.instances.values()):
             instance.docker_client = None
             instance.ip_address = None
             instance.client = None
@@ -769,7 +771,7 @@ def run_kazoo_commands_with_retries(self, kazoo_callback, zoo_instance_name='zoo
                 kazoo_callback(self.get_kazoo_client(zoo_instance_name))
                 return
             except KazooException as e:
-                print repr(e)
+                print(repr(e))
                 time.sleep(sleep_for)
 
         kazoo_callback(self.get_kazoo_client(zoo_instance_name))
@@ -922,7 +924,7 @@ def query_with_retry(self, sql, stdin=None, timeout=None, settings=None, user=No
                     return result
                 time.sleep(sleep_time)
             except Exception as ex:
-                print "Retry {} got exception {}".format(i + 1, ex)
+                print("Retry {} got exception {}".format(i + 1, ex))
                 time.sleep(sleep_time)
 
         if result is not None:
@@ -954,28 +956,30 @@ def http_query(self, sql, data=None, params=None, user=None, password=None, expe
 
         params["query"] = sql
 
-        auth = ""
+        auth = None
         if user and password:
-            auth = "{}:{}@".format(user, password)
+            auth = requests.auth.HTTPBasicAuth(user, password)
         elif user:
-            auth = "{}@".format(user)
+            auth = requests.auth.HTTPBasicAuth(user, '')
+        url = "http://" + self.ip_address + ":8123/?" + urllib.parse.urlencode(params)
 
-        url = "http://" + auth + self.ip_address + ":8123/?" + urllib.urlencode(params)
-
-        open_result = urllib.urlopen(url, data)
+        if data:
+            r = requests.post(url, data, auth=auth)
+        else:
+            r = requests.get(url, auth=auth)
 
         def http_code_and_message():
-            return str(open_result.getcode()) + " " + httplib.responses[
-                open_result.getcode()] + ": " + open_result.read()
+            code = r.status_code
+            return str(code) + " " + http.client.responses[code] + ": " + r.text
 
         if expect_fail_and_get_error:
-            if open_result.getcode() == 200:
-                raise Exception("ClickHouse HTTP server is expected to fail, but succeeded: " + open_result.read())
+            if r.ok:
+                raise Exception("ClickHouse HTTP server is expected to fail, but succeeded: " + r.text)
             return http_code_and_message()
         else:
-            if open_result.getcode() != 200:
+            if not r.ok:
                 raise Exception("ClickHouse HTTP server returned " + http_code_and_message())
-            return open_result.read()
+            return r.text
 
     # Connects to the instance via HTTP interface, sends a query and returns the answer
     def http_request(self, url, method='GET', params=None, data=None, headers=None):
@@ -1161,9 +1165,9 @@ def odbc_drivers(self):
 
     def _create_odbc_config_file(self):
         with open(self.odbc_ini_path.split(':')[0], 'w') as f:
-            for driver_setup in self.odbc_drivers.values():
+            for driver_setup in list(self.odbc_drivers.values()):
                 f.write("[{}]
".format(driver_setup["DSN"]))
-                for key, value in driver_setup.items():
+                for key, value in list(driver_setup.items()):
                     if key != "DSN":
                         f.write(key + "=" + value + "
")
 
@@ -1183,16 +1187,16 @@ def create_dir(self, destroy_dir=True):
         instance_config_dir = p.abspath(p.join(self.path, 'configs'))
         os.makedirs(instance_config_dir)
 
-        print "Copy common default production configuration from {}".format(self.base_config_dir)
+        print("Copy common default production configuration from {}".format(self.base_config_dir))
         shutil.copyfile(p.join(self.base_config_dir, 'config.xml'), p.join(instance_config_dir, 'config.xml'))
         shutil.copyfile(p.join(self.base_config_dir, 'users.xml'), p.join(instance_config_dir, 'users.xml'))
 
-        print "Create directory for configuration generated in this helper"
+        print("Create directory for configuration generated in this helper")
         # used by all utils with any config
         conf_d_dir = p.abspath(p.join(instance_config_dir, 'conf.d'))
         os.mkdir(conf_d_dir)
 
-        print "Create directory for common tests configuration"
+        print("Create directory for common tests configuration")
         # used by server with main config.xml
         self.config_d_dir = p.abspath(p.join(instance_config_dir, 'config.d'))
         os.mkdir(self.config_d_dir)
@@ -1201,14 +1205,14 @@ def create_dir(self, destroy_dir=True):
         dictionaries_dir = p.abspath(p.join(instance_config_dir, 'dictionaries'))
         os.mkdir(dictionaries_dir)
 
-        print "Copy common configuration from helpers"
+        print("Copy common configuration from helpers")
         # The file is named with 0_ prefix to be processed before other configuration overloads.
         shutil.copy(p.join(HELPERS_DIR, '0_common_instance_config.xml'), self.config_d_dir)
         shutil.copy(p.join(HELPERS_DIR, '0_common_instance_users.xml'), users_d_dir)
         if len(self.custom_dictionaries_paths):
             shutil.copy(p.join(HELPERS_DIR, '0_common_enable_dictionaries.xml'), self.config_d_dir)
 
-        print "Generate and write macros file"
+        print("Generate and write macros file")
         macros = self.macros.copy()
         macros['instance'] = self.name
         with open(p.join(conf_d_dir, 'macros.xml'), 'w') as macros_config:
@@ -1222,7 +1226,7 @@ def create_dir(self, destroy_dir=True):
             shutil.copytree(self.kerberos_secrets_dir, p.abspath(p.join(self.path, 'secrets')))
 
         # Copy config.d configs
-        print "Copy custom test config files {} to {}".format(self.custom_main_config_paths, self.config_d_dir)
+        print("Copy custom test config files {} to {}".format(self.custom_main_config_paths, self.config_d_dir))
         for path in self.custom_main_config_paths:
             shutil.copy(path, self.config_d_dir)
 
@@ -1235,16 +1239,16 @@ def create_dir(self, destroy_dir=True):
             shutil.copy(path, dictionaries_dir)
 
         db_dir = p.abspath(p.join(self.path, 'database'))
-        print "Setup database dir {}".format(db_dir)
+        print("Setup database dir {}".format(db_dir))
         if self.clickhouse_path_dir is not None:
-            print "Database files taken from {}".format(self.clickhouse_path_dir)
+            print("Database files taken from {}".format(self.clickhouse_path_dir))
             shutil.copytree(self.clickhouse_path_dir, db_dir)
-            print "Database copied from {} to {}".format(self.clickhouse_path_dir, db_dir)
+            print("Database copied from {} to {}".format(self.clickhouse_path_dir, db_dir))
         else:
             os.mkdir(db_dir)
 
         logs_dir = p.abspath(p.join(self.path, 'logs'))
-        print "Setup logs dir {}".format(logs_dir)
+        print("Setup logs dir {}".format(logs_dir))
         os.mkdir(logs_dir)
 
         depends_on = []
@@ -1272,7 +1276,7 @@ def create_dir(self, destroy_dir=True):
 
         env_file = _create_env_file(os.path.dirname(self.docker_compose_path), self.env_variables)
 
-        print "Env {} stored in {}".format(self.env_variables, env_file)
+        print("Env {} stored in {}".format(self.env_variables, env_file))
 
         odbc_ini_path = ""
         if self.odbc_ini_path:
@@ -1284,7 +1288,7 @@ def create_dir(self, destroy_dir=True):
         if self.stay_alive:
             entrypoint_cmd = CLICKHOUSE_STAY_ALIVE_COMMAND
 
-        print "Entrypoint cmd: {}".format(entrypoint_cmd)
+        print("Entrypoint cmd: {}".format(entrypoint_cmd))
 
         networks = app_net = ipv4_address = ipv6_address = net_aliases = net_alias1 = ""
         if self.ipv4_address is not None or self.ipv6_address is not None or self.hostname != self.name:
diff --git a/tests/integration/helpers/external_sources.py b/tests/integration/helpers/external_sources.py
index a52cf7a02d80..47de9dd0caf1 100644
--- a/tests/integration/helpers/external_sources.py
+++ b/tests/integration/helpers/external_sources.py
@@ -176,7 +176,7 @@ def load_data(self, data, table_name):
         to_insert = []
         for row in data:
             row_dict = {}
-            for cell_name, cell_value in row.data.items():
+            for cell_name, cell_value in list(row.data.items()):
                 row_dict[cell_name] = self.converters[cell_name](cell_value)
             to_insert.append(row_dict)
 
@@ -387,7 +387,7 @@ def prepare(self, structure, table_name, cluster):
         self.node.exec_in_container([
             "bash",
             "-c",
-            "python2 /http_server.py --data-path={tbl} --schema={schema} --host={host} --port={port} --cert-path=/fake_cert.pem".format(
+            "python3 /http_server.py --data-path={tbl} --schema={schema} --host={host} --port={port} --cert-path=/fake_cert.pem".format(
                 tbl=path, schema=self._get_schema(), host=self.docker_hostname, port=self.http_port)
         ], detach=True)
         self.ordered_names = structure.get_ordered_names()
@@ -573,12 +573,14 @@ def compatible_with_layout(self, layout):
     def _flush_aerospike_db(self):
         keys = []
 
-        def handle_record((key, metadata, record)):
-            print("Handle record {} {}".format(key, record))
+        def handle_record(xxx_todo_changeme):
+            (key, metadata, record) = xxx_todo_changeme
+            print(("Handle record {} {}".format(key, record)))
             keys.append(key)
 
-        def print_record((key, metadata, record)):
-            print("Print record {} {}".format(key, record))
+        def print_record(xxx_todo_changeme1):
+            (key, metadata, record) = xxx_todo_changeme1
+            print(("Print record {} {}".format(key, record)))
 
         scan = self.client.scan(self.namespace, self.set)
         scan.foreach(handle_record)
diff --git a/tests/integration/helpers/hdfs_api.py b/tests/integration/helpers/hdfs_api.py
index 70111045ad21..d3afa9be8371 100644
--- a/tests/integration/helpers/hdfs_api.py
+++ b/tests/integration/helpers/hdfs_api.py
@@ -1,5 +1,5 @@
 # -*- coding: utf-8 -*-
-import StringIO
+import io
 import gzip
 import subprocess
 from tempfile import NamedTemporaryFile
@@ -14,7 +14,7 @@ def __init__(self, user):
         self.http_data_port = "50075"
         self.user = user
 
-    def read_data(self, path):
+    def read_data(self, path, universal_newlines=True):
         response = requests.get(
             "http://{host}:{port}/webhdfs/v1{path}?op=OPEN".format(host=self.host, port=self.http_proxy_port,
                                                                    path=path), allow_redirects=False)
@@ -27,7 +27,10 @@ def read_data(self, path):
         if response_data.status_code != 200:
             response_data.raise_for_status()
 
-        return response_data.content
+        if universal_newlines:
+            return response_data.text
+        else:
+            return response_data.content
 
     # Requests can't put file
     def _curl_to_put(self, filename, path, params):
@@ -35,12 +38,14 @@ def _curl_to_put(self, filename, path, params):
                                                                                 port=self.http_data_port, path=path,
                                                                                 params=params)
         cmd = "curl -s -i -X PUT -T {fname} '{url}'".format(fname=filename, url=url)
-        output = subprocess.check_output(cmd, shell=True)
+        output = subprocess.check_output(cmd, shell=True, universal_newlines=True)
         return output
 
     def write_data(self, path, content):
-        named_file = NamedTemporaryFile()
+        named_file = NamedTemporaryFile(mode='wb+')
         fpath = named_file.name
+        if isinstance(content, str):
+            content = content.encode()
         named_file.write(content)
         named_file.flush()
         response = requests.put(
@@ -58,10 +63,12 @@ def write_data(self, path, content):
             raise Exception("Can't create file on hdfs:
 {}".format(output))
 
     def write_gzip_data(self, path, content):
-        out = StringIO.StringIO()
-        with gzip.GzipFile(fileobj=out, mode="w") as f:
+        if isinstance(content, str):
+            content = content.encode()
+        out = io.BytesIO()
+        with gzip.GzipFile(fileobj=out, mode="wb") as f:
             f.write(content)
         self.write_data(path, out.getvalue())
 
     def read_gzip_data(self, path):
-        return gzip.GzipFile(fileobj=StringIO.StringIO(self.read_data(path))).read()
+        return gzip.GzipFile(fileobj=io.BytesIO(self.read_data(path, universal_newlines=False))).read().decode()
diff --git a/tests/integration/helpers/http_server.py b/tests/integration/helpers/http_server.py
index 83e134606e3f..e62096dd33f4 100644
--- a/tests/integration/helpers/http_server.py
+++ b/tests/integration/helpers/http_server.py
@@ -3,7 +3,7 @@
 import csv
 import socket
 import ssl
-from BaseHTTPServer import BaseHTTPRequestHandler, HTTPServer
+from http.server import BaseHTTPRequestHandler, HTTPServer
 
 
 # Decorator used to see if authentication works for external dictionary who use a HTTP source.
@@ -29,7 +29,7 @@ def do_GET(self):
         @check_auth
         def do_POST(self):
             ids = self.__read_and_decode_post_ids()
-            print "ids=", ids
+            print("ids=", ids)
             self.__send_headers()
             self.__send_data(ids)
 
@@ -43,26 +43,26 @@ def __send_data(self, only_ids=None):
                 reader = csv.reader(fl, delimiter='\t')
                 for row in reader:
                     if not only_ids or (row[0] in only_ids):
-                        self.wfile.write('\t'.join(row) + '
')
+                        self.wfile.write(('\t'.join(row) + '
').encode())
 
         def __read_and_decode_post_ids(self):
             data = self.__read_and_decode_post_data()
-            return filter(None, data.split())
+            return [_f for _f in data.split() if _f]
 
         def __read_and_decode_post_data(self):
             transfer_encoding = self.headers.get("Transfer-encoding")
             decoded = "";
             if transfer_encoding == "chunked":
                 while True:
-                    s = self.rfile.readline()
+                    s = self.rfile.readline().decode()
                     chunk_length = int(s, 16)
                     if not chunk_length:
                         break
-                    decoded += self.rfile.read(chunk_length)
-                    self.rfile.readline()
+                    decoded += self.rfile.read(chunk_length).decode()
+                    self.rfile.readline().decode()
             else:
                 content_length = int(self.headers.get("Content-Length", 0))
-                decoded = self.rfile.read(content_length)
+                decoded = self.rfile.read(content_length).decode()
             return decoded
 
     if address_family == "ipv6":
diff --git a/tests/integration/helpers/network.py b/tests/integration/helpers/network.py
index f6505e81c910..a237f7d3cc7c 100644
--- a/tests/integration/helpers/network.py
+++ b/tests/integration/helpers/network.py
@@ -183,7 +183,7 @@ def _exec_run(self, cmd, **kwargs):
         exit_code = self._docker_client.api.exec_inspect(handle)['ExitCode']
 
         if exit_code != 0:
-            print output
+            print(output)
             raise subprocess.CalledProcessError(exit_code, cmd)
 
         return output
diff --git a/tests/integration/helpers/test_tools.py b/tests/integration/helpers/test_tools.py
index 9fbffe418199..75ae8f67f7a9 100644
--- a/tests/integration/helpers/test_tools.py
+++ b/tests/integration/helpers/test_tools.py
@@ -1,14 +1,15 @@
 import difflib
 import time
+from io import IOBase
 
 
 class TSV:
     """Helper to get pretty diffs between expected and actual tab-separated value files"""
 
     def __init__(self, contents):
-        if isinstance(contents, file):
+        if isinstance(contents, IOBase):
             raw_lines = contents.readlines()
-        elif isinstance(contents, str) or isinstance(contents, unicode):
+        elif isinstance(contents, str) or isinstance(contents, str):
             raw_lines = contents.splitlines(True)
         elif isinstance(contents, list):
             raw_lines = ['\t'.join(map(str, l)) if isinstance(l, list) else str(l) for l in contents]
@@ -29,7 +30,7 @@ def __ne__(self, other):
             return self != TSV(other)
         return self.lines != other.lines
 
-    def diff(self, other, n1=None, n2=None):
+    def diff(self, other, n1='', n2=''):
         if not isinstance(other, TSV):
             return self.diff(TSV(other), n1=n1, n2=n2)
         return list(line.rstrip() for line in difflib.unified_diff(self.lines, other.lines, fromfile=n1, tofile=n2))[2:]
@@ -45,14 +46,14 @@ def toMat(contents):
 def assert_eq_with_retry(instance, query, expectation, retry_count=20, sleep_time=0.5, stdin=None, timeout=None,
                          settings=None, user=None, ignore_error=False):
     expectation_tsv = TSV(expectation)
-    for i in xrange(retry_count):
+    for i in range(retry_count):
         try:
             if TSV(instance.query(query, user=user, stdin=stdin, timeout=timeout, settings=settings,
                                   ignore_error=ignore_error)) == expectation_tsv:
                 break
             time.sleep(sleep_time)
         except Exception as ex:
-            print "assert_eq_with_retry retry {} exception {}".format(i + 1, ex)
+            print(("assert_eq_with_retry retry {} exception {}".format(i + 1, ex)))
             time.sleep(sleep_time)
     else:
         val = TSV(instance.query(query, user=user, stdin=stdin, timeout=timeout, settings=settings,
@@ -66,13 +67,13 @@ def assert_logs_contain(instance, substring):
         raise AssertionError("'{}' not found in logs".format(substring))
 
 def assert_logs_contain_with_retry(instance, substring, retry_count=20, sleep_time=0.5):
-    for i in xrange(retry_count):
+    for i in range(retry_count):
         try:
             if instance.contains_in_log(substring):
                 break
             time.sleep(sleep_time)
         except Exception as ex:
-            print "contains_in_log_with_retry retry {} exception {}".format(i + 1, ex)
+            print("contains_in_log_with_retry retry {} exception {}".format(i + 1, ex))
             time.sleep(sleep_time)
     else:
         raise AssertionError("'{}' not found in logs".format(substring))
diff --git a/tests/integration/helpers/uclient.py b/tests/integration/helpers/uclient.py
index 098e17a38dab..538722580af5 100644
--- a/tests/integration/helpers/uclient.py
+++ b/tests/integration/helpers/uclient.py
@@ -6,7 +6,7 @@
 
 sys.path.insert(0, os.path.join(CURDIR))
 
-import uexpect
+from . import uexpect
 
 prompt = ':\) '
 end_of_block = r'.*\r
.*\r
'
diff --git a/tests/integration/helpers/uexpect.py b/tests/integration/helpers/uexpect.py
index 873d9a749e0f..cd26e3ddbd3d 100644
--- a/tests/integration/helpers/uexpect.py
+++ b/tests/integration/helpers/uexpect.py
@@ -15,7 +15,7 @@
 import pty
 import re
 import time
-from Queue import Queue, Empty
+from queue import Queue, Empty
 from subprocess import Popen
 from threading import Thread, Event
 
@@ -118,7 +118,7 @@ def send(self, data, eol=None):
         return self.write(data + eol)
 
     def write(self, data):
-        return os.write(self.master, data)
+        return os.write(self.master, data.encode())
 
     def expect(self, pattern, timeout=None, escape=False):
         self.match = None
@@ -201,7 +201,8 @@ def spawn(command):
 def reader(process, out, queue, kill_event):
     while True:
         try:
-            data = os.read(out, 65536)
+            # TODO: there are some issues with 1<<16 buffer size
+            data = os.read(out, 1<<17).decode(errors='replace')
             queue.put(data)
         except:
             if kill_event.is_set():
diff --git a/tests/integration/runner b/tests/integration/runner
index 78d93af2929f..dbcb6f21732d 100755
--- a/tests/integration/runner
+++ b/tests/integration/runner
@@ -1,4 +1,4 @@
-#!/usr/bin/env python
+#!/usr/bin/env python3
 #-*- coding: utf-8 -*-
 import subprocess
 import os
@@ -188,5 +188,5 @@ if __name__ == "__main__":
         command=args.command
     )
 
-    print("Running pytest container as: '" + cmd + "'.")
+    print(("Running pytest container as: '" + cmd + "'."))
     subprocess.check_call(cmd, shell=True)
diff --git a/tests/integration/test_adaptive_granularity/test.py b/tests/integration/test_adaptive_granularity/test.py
index ec3169bb9955..12bfc22d7d94 100644
--- a/tests/integration/test_adaptive_granularity/test.py
+++ b/tests/integration/test_adaptive_granularity/test.py
@@ -371,7 +371,7 @@ def callback(n):
             node12.query("SYSTEM SYNC REPLICA table_with_default_granularity_new", timeout=120)
             break
         except Exception as ex:
-            print("Exception during replica sync", ex)
+            print(("Exception during replica sync", ex))
             node11.query("SYSTEM RESTART REPLICA table_with_default_granularity_new")
             node12.query("SYSTEM RESTART REPLICA table_with_default_granularity_new")
             time.sleep(2 * i)
@@ -386,7 +386,7 @@ def callback(n):
             node12.query("SYSTEM SYNC REPLICA table_with_default_granularity", timeout=120)
             break
         except Exception as ex:
-            print("Exception during replica sync", ex)
+            print(("Exception during replica sync", ex))
             node11.query("SYSTEM RESTART REPLICA table_with_default_granularity")
             node12.query("SYSTEM RESTART REPLICA table_with_default_granularity")
             time.sleep(2 * i)
diff --git a/tests/integration/test_cluster_copier/test.py b/tests/integration/test_cluster_copier/test.py
index 88dac06f1582..6a922dbfca72 100644
--- a/tests/integration/test_cluster_copier/test.py
+++ b/tests/integration/test_cluster_copier/test.py
@@ -50,8 +50,8 @@ def started_cluster():
             }
         }
 
-        for cluster_name, shards in clusters_schema.iteritems():
-            for shard_name, replicas in shards.iteritems():
+        for cluster_name, shards in clusters_schema.items():
+            for shard_name, replicas in shards.items():
                 for replica_name in replicas:
                     name = "s{}_{}_{}".format(cluster_name, shard_name, replica_name)
                     cluster.add_instance(name,
@@ -235,16 +235,16 @@ def execute_task(task, cmd_options):
     task.start()
 
     zk = cluster.get_kazoo_client('zoo1')
-    print "Use ZooKeeper server: {}:{}".format(zk.hosts[0][0], zk.hosts[0][1])
+    print("Use ZooKeeper server: {}:{}".format(zk.hosts[0][0], zk.hosts[0][1]))
 
     try:
         zk.delete("/clickhouse-copier", recursive=True)
     except kazoo.exceptions.NoNodeError:
-        print "No node /clickhouse-copier. It is Ok in first test."
+        print("No node /clickhouse-copier. It is Ok in first test.")
 
     zk_task_path = task.zk_task_path
     zk.ensure_path(zk_task_path)
-    zk.create(zk_task_path + "/description", task.copier_task_config)
+    zk.create(zk_task_path + "/description", task.copier_task_config.encode())
 
     # Run cluster-copier processes on each node
     docker_api = docker.from_env().api
@@ -256,19 +256,19 @@ def execute_task(task, cmd_options):
            '--base-dir', '/var/log/clickhouse-server/copier']
     cmd += cmd_options
 
-    copiers = random.sample(cluster.instances.keys(), 3)
+    copiers = random.sample(list(cluster.instances.keys()), 3)
 
     for instance_name in copiers:
         instance = cluster.instances[instance_name]
         container = instance.get_docker_handle()
         instance.copy_file_to_container(os.path.join(CURRENT_TEST_DIR, "configs/config-copier.xml"),
                                         "/etc/clickhouse-server/config-copier.xml")
-        print "Copied copier config to {}".format(instance.name)
+        print("Copied copier config to {}".format(instance.name))
         exec_id = docker_api.exec_create(container.id, cmd, stderr=True)
         output = docker_api.exec_start(exec_id).decode('utf8')
         print(output)
         copiers_exec_ids.append(exec_id)
-        print "Copier for {} ({}) has started".format(instance.name, instance.ip_address)
+        print("Copier for {} ({}) has started".format(instance.name, instance.ip_address))
 
     # Wait for copiers stopping and check their return codes
     for exec_id, instance_name in zip(copiers_exec_ids, copiers):
@@ -362,6 +362,6 @@ def test_no_arg(started_cluster):
 
 if __name__ == '__main__':
     with contextmanager(started_cluster)() as cluster:
-        for name, instance in cluster.instances.items():
-            print name, instance.ip_address
-        raw_input("Cluster created, press any key to destroy...")
+        for name, instance in list(cluster.instances.items()):
+            print(name, instance.ip_address)
+        input("Cluster created, press any key to destroy...")
diff --git a/tests/integration/test_cluster_copier/trivial_test.py b/tests/integration/test_cluster_copier/trivial_test.py
index 035faf0bb9fa..8a43440ac90c 100644
--- a/tests/integration/test_cluster_copier/trivial_test.py
+++ b/tests/integration/test_cluster_copier/trivial_test.py
@@ -27,8 +27,8 @@ def started_cluster():
 
         cluster = ClickHouseCluster(__file__)
 
-        for cluster_name, shards in clusters_schema.iteritems():
-            for shard_name, replicas in shards.iteritems():
+        for cluster_name, shards in clusters_schema.items():
+            for shard_name, replicas in shards.items():
                 for replica_name in replicas:
                     name = "s{}_{}_{}".format(cluster_name, shard_name, replica_name)
                     cluster.add_instance(name,
@@ -83,7 +83,7 @@ def execute_task(task, cmd_options):
     task.start()
 
     zk = cluster.get_kazoo_client('zoo1')
-    print "Use ZooKeeper server: {}:{}".format(zk.hosts[0][0], zk.hosts[0][1])
+    print("Use ZooKeeper server: {}:{}".format(zk.hosts[0][0], zk.hosts[0][1]))
 
     zk_task_path = task.zk_task_path
     zk.ensure_path(zk_task_path)
@@ -101,16 +101,16 @@ def execute_task(task, cmd_options):
 
     print(cmd)
 
-    for instance_name, instance in cluster.instances.iteritems():
+    for instance_name, instance in cluster.instances.items():
         container = instance.get_docker_handle()
         exec_id = docker_api.exec_create(container.id, cmd, stderr=True)
         docker_api.exec_start(exec_id, detach=True)
 
         copiers_exec_ids.append(exec_id)
-        print "Copier for {} ({}) has started".format(instance.name, instance.ip_address)
+        print("Copier for {} ({}) has started".format(instance.name, instance.ip_address))
 
     # Wait for copiers stopping and check their return codes
-    for exec_id, instance in zip(copiers_exec_ids, cluster.instances.itervalues()):
+    for exec_id, instance in zip(copiers_exec_ids, iter(cluster.instances.values())):
         while True:
             res = docker_api.exec_inspect(exec_id)
             if not res['Running']:
@@ -175,6 +175,6 @@ def test_trivial_copy_with_move_fault(started_cluster, use_sample_offset):
 
 if __name__ == '__main__':
     with contextmanager(started_cluster)() as cluster:
-        for name, instance in cluster.instances.items():
-            print name, instance.ip_address
-        raw_input("Cluster created, press any key to destroy...")
+        for name, instance in list(cluster.instances.items()):
+            print(name, instance.ip_address)
+        input("Cluster created, press any key to destroy...")
diff --git a/tests/integration/test_concurrent_queries_for_user_restriction/test.py b/tests/integration/test_concurrent_queries_for_user_restriction/test.py
index e287eb763ced..279e0dfe4398 100644
--- a/tests/integration/test_concurrent_queries_for_user_restriction/test.py
+++ b/tests/integration/test_concurrent_queries_for_user_restriction/test.py
@@ -26,14 +26,14 @@ def test_exception_message(started_cluster):
     assert node1.query("select number from nums order by number") == "0
1
"
 
     def node_busy(_):
-        for i in xrange(10):
+        for i in range(10):
             node1.query("select sleep(2)", user='default')
 
     busy_pool = Pool(3)
-    busy_pool.map_async(node_busy, xrange(3))
+    busy_pool.map_async(node_busy, range(3))
     time.sleep(1)  # wait a little until polling starts
     try:
         assert node2.query("select number from remote('node1', 'default', 'nums')", user='good') == "0
1
"
     except Exception as ex:
-        print ex.message
+        print(ex.message)
         assert False, "Exception thrown while max_concurrent_queries_for_user is not exceeded"
diff --git a/tests/integration/test_concurrent_ttl_merges/test.py b/tests/integration/test_concurrent_ttl_merges/test.py
index f77ae5996d17..f067e65f58aa 100644
--- a/tests/integration/test_concurrent_ttl_merges/test.py
+++ b/tests/integration/test_concurrent_ttl_merges/test.py
@@ -66,7 +66,7 @@ def test_no_ttl_merges_in_busy_pool(started_cluster):
     node1.query("ALTER TABLE test_ttl UPDATE data = data + 1 WHERE sleepEachRow(1) = 0")
 
     while count_running_mutations(node1, "test_ttl") < 6:
-        print "Mutations count", count_running_mutations(node1, "test_ttl")
+        print("Mutations count", count_running_mutations(node1, "test_ttl"))
         assert count_ttl_merges_in_background_pool(node1, "test_ttl") == 0
         time.sleep(0.5)
 
@@ -74,7 +74,7 @@ def test_no_ttl_merges_in_busy_pool(started_cluster):
 
     rows_count = []
     while count_running_mutations(node1, "test_ttl") == 6:
-        print "Mutations count after start TTL", count_running_mutations(node1, "test_ttl")
+        print("Mutations count after start TTL", count_running_mutations(node1, "test_ttl"))
         rows_count.append(int(node1.query("SELECT count() FROM test_ttl").strip()))
         time.sleep(0.5)
 
diff --git a/tests/integration/test_config_substitutions/test.py b/tests/integration/test_config_substitutions/test.py
index 3a2d0d982810..565cd1c0e977 100644
--- a/tests/integration/test_config_substitutions/test.py
+++ b/tests/integration/test_config_substitutions/test.py
@@ -19,7 +19,7 @@
 def start_cluster():
     try:
         def create_zk_roots(zk):
-            zk.create(path="/setting/max_query_size", value="77777", makepath=True)
+            zk.create(path="/setting/max_query_size", value=b"77777", makepath=True)
 
         cluster.add_zookeeper_startup_command(create_zk_roots)
 
diff --git a/tests/integration/test_consistant_parts_after_move_partition/test.py b/tests/integration/test_consistant_parts_after_move_partition/test.py
index 05e721ee5ea6..2070c8cb3f8a 100644
--- a/tests/integration/test_consistant_parts_after_move_partition/test.py
+++ b/tests/integration/test_consistant_parts_after_move_partition/test.py
@@ -33,7 +33,7 @@ def start_cluster():
         initialize_database([node1, node2], 1)
         yield cluster
     except Exception as ex:
-        print ex
+        print(ex)
     finally:
         cluster.shutdown()
 
diff --git a/tests/integration/test_consistent_parts_after_clone_replica/test.py b/tests/integration/test_consistent_parts_after_clone_replica/test.py
index 60b91bcb282d..784f94397af7 100644
--- a/tests/integration/test_consistent_parts_after_clone_replica/test.py
+++ b/tests/integration/test_consistent_parts_after_clone_replica/test.py
@@ -29,7 +29,7 @@ def start_cluster():
         fill_nodes([node1, node2], 1)
         yield cluster
     except Exception as ex:
-        print ex
+        print(ex)
     finally:
         cluster.shutdown()
 
diff --git a/tests/integration/test_cross_replication/test.py b/tests/integration/test_cross_replication/test.py
index 9171fea5547d..8a118934c938 100644
--- a/tests/integration/test_cross_replication/test.py
+++ b/tests/integration/test_cross_replication/test.py
@@ -83,11 +83,11 @@ def test(started_cluster):
         assert_eq_with_retry(node2, "SELECT * FROM distributed ORDER BY id", expected_from_distributed)
 
         with pytest.raises(Exception):
-            print node3.query_with_retry("SELECT * FROM distributed ORDER BY id", retry_count=5)
+            print(node3.query_with_retry("SELECT * FROM distributed ORDER BY id", retry_count=5))
 
 
 if __name__ == '__main__':
     with contextmanager(started_cluster)() as cluster:
-        for name, instance in cluster.instances.items():
-            print name, instance.ip_address
-        raw_input("Cluster created, press any key to destroy...")
+        for name, instance in list(cluster.instances.items()):
+            print(name, instance.ip_address)
+        input("Cluster created, press any key to destroy...")
diff --git a/tests/integration/test_delayed_replica_failover/test.py b/tests/integration/test_delayed_replica_failover/test.py
index f657edae6fb0..18184c3304d3 100644
--- a/tests/integration/test_delayed_replica_failover/test.py
+++ b/tests/integration/test_delayed_replica_failover/test.py
@@ -98,12 +98,12 @@ def test(started_cluster):
 
         # If we forbid stale replicas, the query must fail.
         with pytest.raises(Exception):
-            print instance_with_dist_table.query('''
+            print(instance_with_dist_table.query('''
 SELECT count() FROM distributed SETTINGS
     load_balancing='in_order',
     max_replica_delay_for_distributed_queries=1,
     fallback_to_stale_replicas_for_distributed_queries=0
-''')
+'''))
 
         # Now partition off the remote replica of the local shard and test that failover still works.
         pm.partition_instances(node_1_1, node_1_2, port=9000)
diff --git a/tests/integration/test_dictionaries_all_layouts_separate_sources/common.py b/tests/integration/test_dictionaries_all_layouts_separate_sources/common.py
index 0411b5d94758..ef6d133893ac 100644
--- a/tests/integration/test_dictionaries_all_layouts_separate_sources/common.py
+++ b/tests/integration/test_dictionaries_all_layouts_separate_sources/common.py
@@ -113,12 +113,12 @@ def create_dictionaries(self, source_):
                 self.layout_to_dictionary[layout] = get_dict(source_, Layout(layout), self.fields)
 
     def prepare(self, cluster_):
-        for _, dictionary in self.layout_to_dictionary.items():
+        for _, dictionary in list(self.layout_to_dictionary.items()):
             dictionary.prepare_source(cluster_)
             dictionary.load_data(self.data)
 
     def execute(self, layout_name, node):
-        if not self.layout_to_dictionary.has_key(layout_name):
+        if layout_name not in self.layout_to_dictionary:
             raise RuntimeError("Source doesn't support layout: {}".format(layout_name))
 
         dct = self.layout_to_dictionary[layout_name]
@@ -170,12 +170,12 @@ def create_dictionaries(self, source_):
                 self.layout_to_dictionary[layout] = get_dict(source_, Layout(layout), self.fields)
 
     def prepare(self, cluster_):
-        for _, dictionary in self.layout_to_dictionary.items():
+        for _, dictionary in list(self.layout_to_dictionary.items()):
             dictionary.prepare_source(cluster_)
             dictionary.load_data(self.data)
 
     def execute(self, layout_name, node):
-        if not self.layout_to_dictionary.has_key(layout_name):
+        if layout_name not in self.layout_to_dictionary:
             raise RuntimeError("Source doesn't support layout: {}".format(layout_name))
 
         dct = self.layout_to_dictionary[layout_name]
@@ -213,13 +213,13 @@ def create_dictionaries(self, source_):
                 self.layout_to_dictionary[layout] = get_dict(source_, Layout(layout), self.fields)
 
     def prepare(self, cluster_):
-        for _, dictionary in self.layout_to_dictionary.items():
+        for _, dictionary in list(self.layout_to_dictionary.items()):
             dictionary.prepare_source(cluster_)
             dictionary.load_data(self.data)
 
     def execute(self, layout_name, node):
 
-        if not self.layout_to_dictionary.has_key(layout_name):
+        if layout_name not in self.layout_to_dictionary:
             raise RuntimeError("Source doesn't support layout: {}".format(layout_name))
 
         dct = self.layout_to_dictionary[layout_name]
diff --git a/tests/integration/test_dictionaries_complex_key_cache_string/test.py b/tests/integration/test_dictionaries_complex_key_cache_string/test.py
index c8969aee63e0..a01e60af47d0 100644
--- a/tests/integration/test_dictionaries_complex_key_cache_string/test.py
+++ b/tests/integration/test_dictionaries_complex_key_cache_string/test.py
@@ -42,7 +42,7 @@ def test_memory_consumption(cluster):
     allocated_first = int(node.query("select bytes_allocated from system.dictionaries where name = 'radars'").strip())
 
     alloc_array = []
-    for i in xrange(5):
+    for i in range(5):
         node.query("select dictGetString('radars', 'client_id', tuple(toString(number))) from numbers(0, 5000)")
 
         allocated = int(node.query("select bytes_allocated from system.dictionaries where name = 'radars'").strip())
@@ -51,7 +51,7 @@ def test_memory_consumption(cluster):
     # size doesn't grow
     assert all(allocated_first >= a for a in alloc_array)
 
-    for i in xrange(5):
+    for i in range(5):
         node.query("select dictGetString('radars', 'client_id', tuple(toString(number))) from numbers(0, 5000)")
 
         allocated = int(node.query("select bytes_allocated from system.dictionaries where name = 'radars'").strip())
diff --git a/tests/integration/test_dictionaries_redis/test.py b/tests/integration/test_dictionaries_redis/test.py
index 385580816e0a..d08734af5470 100644
--- a/tests/integration/test_dictionaries_redis/test.py
+++ b/tests/integration/test_dictionaries_redis/test.py
@@ -106,7 +106,7 @@ def setup_module(module):
         for source in sources:
             for layout in LAYOUTS:
                 if not source.compatible_with_layout(layout):
-                    print "Source", source.name, "incompatible with layout", layout.name
+                    print("Source", source.name, "incompatible with layout", layout.name)
                     continue
 
                 fields = KEY_FIELDS[layout.layout_type] + [field]
@@ -128,9 +128,9 @@ def started_cluster():
         assert len(FIELDS) == len(VALUES)
         for dicts in DICTIONARIES:
             for dictionary in dicts:
-                print "Preparing", dictionary.name
+                print("Preparing", dictionary.name)
                 dictionary.prepare_source(cluster)
-                print "Prepared"
+                print("Prepared")
 
         yield cluster
 
@@ -138,9 +138,9 @@ def started_cluster():
         cluster.shutdown()
 
 
-@pytest.mark.parametrize("id", range(len(FIELDS)))
+@pytest.mark.parametrize("id", list(range(len(FIELDS))))
 def test_redis_dictionaries(started_cluster, id):
-    print 'id:', id
+    print('id:', id)
 
     dicts = DICTIONARIES[id]
     values = VALUES[id]
@@ -173,7 +173,7 @@ def test_redis_dictionaries(started_cluster, id):
         node.query("system reload dictionary {}".format(dct.name))
 
         for query, answer in queries_with_answers:
-            print query
+            print(query)
             assert node.query(query) == str(answer) + '
'
 
     # Checks, that dictionaries can be reloaded.
diff --git a/tests/integration/test_dictionaries_select_all/generate_dictionaries.py b/tests/integration/test_dictionaries_select_all/generate_dictionaries.py
index 5c92d0d67e86..109ecea438e7 100644
--- a/tests/integration/test_dictionaries_select_all/generate_dictionaries.py
+++ b/tests/integration/test_dictionaries_select_all/generate_dictionaries.py
@@ -1,5 +1,6 @@
 import difflib
 import os
+from functools import reduce
 
 files = ['key_simple.tsv', 'key_complex_integers.tsv', 'key_complex_mixed.tsv']
 
@@ -78,8 +79,9 @@ def generate_dictionaries(path, structure):
     '''
 
     dictionary_skeleton = \
-        dictionary_skeleton % reduce(lambda xml, (type, default): xml + attribute_skeleton % (type, type, default),
-                                     zip(types, implicit_defaults), '')
+        dictionary_skeleton % reduce(
+            lambda xml, type_default: xml + attribute_skeleton % (type_default[0], type_default[0], type_default[1]),
+            list(zip(types, implicit_defaults)), '')
 
     source_clickhouse = '''
     <clickhouse>
@@ -195,7 +197,7 @@ def __init__(self, source_file_name):
                     String_ String,
                     Date_ Date, DateTime_ DateTime, Parent UInt64'''
 
-        self.names_and_types = map(str.split, self.structure.split(','))
+        self.names_and_types = list(map(str.split, self.structure.split(',')))
         self.keys_names_and_types = self.names_and_types[:6]
         self.values_names_and_types = self.names_and_types[6:]
         self.source_file_name = source_file_name
@@ -223,10 +225,10 @@ def wrap_value(pair):
         def make_tuple(line):
             row = tuple(line.split('\t'))
             self.rows.append(row)
-            return '(' + ','.join(map(wrap_value, zip(row, types))) + ')'
+            return '(' + ','.join(map(wrap_value, list(zip(row, types)))) + ')'
 
         values = ','.join(map(make_tuple, lines))
-        print query % (self.structure, values)
+        print(query % (self.structure, values))
         instance.query(query % (self.structure, values))
 
     def get_structure_for_keys(self, keys, enable_parent=True):
@@ -245,7 +247,7 @@ def compare_rows_by_keys(self, keys, values, lines, add_not_found_rows=True):
         for row in rows:
             key = '\t'.join(row[:len(keys)])
             value = '\t'.join(row[len(keys):])
-            if key in lines_map.keys():
+            if key in list(lines_map.keys()):
                 pattern_value = lines_map[key]
                 del lines_map[key]
                 if not value == pattern_value:
@@ -256,7 +258,7 @@ def compare_rows_by_keys(self, keys, values, lines, add_not_found_rows=True):
                 diff.append((key + '\t' + value, ''))
 
         if add_not_found_rows:
-            for key, value in lines_map.items():
+            for key, value in list(lines_map.items()):
                 diff.append(('', key + '\t' + value))
 
         if not diff:
diff --git a/tests/integration/test_dictionaries_select_all/test.py b/tests/integration/test_dictionaries_select_all/test.py
index 5b8d39a7a631..5331f51f4c7d 100644
--- a/tests/integration/test_dictionaries_select_all/test.py
+++ b/tests/integration/test_dictionaries_select_all/test.py
@@ -4,7 +4,7 @@
 from helpers.cluster import ClickHouseCluster
 from helpers.test_tools import TSV
 
-from generate_dictionaries import generate_structure, generate_dictionaries, DictionaryTestTable
+from .generate_dictionaries import generate_structure, generate_dictionaries, DictionaryTestTable
 
 SCRIPT_DIR = os.path.dirname(os.path.realpath(__file__))
 
@@ -32,7 +32,7 @@ def started_cluster():
         cluster.start()
         test_table.create_clickhouse_source(instance)
         for line in TSV(instance.query('select name from system.dictionaries')).lines:
-            print line,
+            print(line, end=' ')
 
         yield cluster
 
@@ -72,7 +72,7 @@ def test_select_all(dictionary_structure):
     result = TSV(query('select * from test.{0}'.format(name)))
 
     diff = test_table.compare_by_keys(keys, result.lines, use_parent, add_not_found_rows=True)
-    print test_table.process_diff(diff)
+    print(test_table.process_diff(diff))
     assert not diff
 
 
@@ -103,7 +103,7 @@ def test_select_all_from_cached(cached_dictionary_structure):
     for i in range(4):
         result = TSV(query('select * from test.{0}'.format(name)))
         diff = test_table.compare_by_keys(keys, result.lines, use_parent, add_not_found_rows=False)
-        print test_table.process_diff(diff)
+        print(test_table.process_diff(diff))
         assert not diff
 
         key = []
@@ -120,5 +120,5 @@ def test_select_all_from_cached(cached_dictionary_structure):
 
     result = TSV(query('select * from test.{0}'.format(name)))
     diff = test_table.compare_by_keys(keys, result.lines, use_parent, add_not_found_rows=True)
-    print test_table.process_diff(diff)
+    print(test_table.process_diff(diff))
     assert not diff
diff --git a/tests/integration/test_dictionary_allow_read_expired_keys/test_default_reading.py b/tests/integration/test_dictionary_allow_read_expired_keys/test_default_reading.py
index 1266c37dcd37..416bbe089aa4 100644
--- a/tests/integration/test_dictionary_allow_read_expired_keys/test_default_reading.py
+++ b/tests/integration/test_dictionary_allow_read_expired_keys/test_default_reading.py
@@ -1,4 +1,4 @@
-from __future__ import print_function
+
 
 import time
 
diff --git a/tests/integration/test_dictionary_allow_read_expired_keys/test_default_string.py b/tests/integration/test_dictionary_allow_read_expired_keys/test_default_string.py
index 2aa6fb448cad..caabdf12c665 100644
--- a/tests/integration/test_dictionary_allow_read_expired_keys/test_default_string.py
+++ b/tests/integration/test_dictionary_allow_read_expired_keys/test_default_string.py
@@ -1,4 +1,4 @@
-from __future__ import print_function
+
 
 import os
 import random
diff --git a/tests/integration/test_dictionary_allow_read_expired_keys/test_dict_get.py b/tests/integration/test_dictionary_allow_read_expired_keys/test_dict_get.py
index 9de0b3be4eb8..7097bd15bb7b 100644
--- a/tests/integration/test_dictionary_allow_read_expired_keys/test_dict_get.py
+++ b/tests/integration/test_dictionary_allow_read_expired_keys/test_dict_get.py
@@ -1,4 +1,4 @@
-from __future__ import print_function
+
 
 import time
 
diff --git a/tests/integration/test_dictionary_allow_read_expired_keys/test_dict_get_or_default.py b/tests/integration/test_dictionary_allow_read_expired_keys/test_dict_get_or_default.py
index 31f0e469555d..2aecb8691fbb 100644
--- a/tests/integration/test_dictionary_allow_read_expired_keys/test_dict_get_or_default.py
+++ b/tests/integration/test_dictionary_allow_read_expired_keys/test_dict_get_or_default.py
@@ -1,4 +1,4 @@
-from __future__ import print_function
+
 
 import time
 
diff --git a/tests/integration/test_dictionary_custom_settings/http_server.py b/tests/integration/test_dictionary_custom_settings/http_server.py
index 20487ccf4475..bd5ce22dbac7 100644
--- a/tests/integration/test_dictionary_custom_settings/http_server.py
+++ b/tests/integration/test_dictionary_custom_settings/http_server.py
@@ -3,7 +3,7 @@
 import csv
 import socket
 import ssl
-from BaseHTTPServer import BaseHTTPRequestHandler, HTTPServer
+from http.server import BaseHTTPRequestHandler, HTTPServer
 
 
 # Decorator used to see if authentication works for external dictionary who use a HTTP source.
@@ -29,7 +29,7 @@ def do_GET(self):
         @check_auth
         def do_POST(self):
             ids = self.__read_and_decode_post_ids()
-            print "ids=", ids
+            print("ids=", ids)
             self.__send_headers()
             self.__send_data(ids)
 
@@ -43,11 +43,11 @@ def __send_data(self, only_ids=None):
                 reader = csv.reader(fl, delimiter='\t')
                 for row in reader:
                     if not only_ids or (row[0] in only_ids):
-                        self.wfile.write('\t'.join(row) + '
')
+                        self.wfile.write(('\t'.join(row) + '
').encode())
 
         def __read_and_decode_post_ids(self):
             data = self.__read_and_decode_post_data()
-            return filter(None, data.split())
+            return [_f for _f in data.split() if _f]
 
         def __read_and_decode_post_data(self):
             transfer_encoding = self.headers.get("Transfer-encoding")
@@ -58,11 +58,11 @@ def __read_and_decode_post_data(self):
                     chunk_length = int(s, 16)
                     if not chunk_length:
                         break
-                    decoded += self.rfile.read(chunk_length)
+                    decoded += self.rfile.read(chunk_length).decode()
                     self.rfile.readline()
             else:
                 content_length = int(self.headers.get("Content-Length", 0))
-                decoded = self.rfile.read(content_length)
+                decoded = self.rfile.read(content_length).decode()
             return decoded
 
     if address_family == "ipv6":
diff --git a/tests/integration/test_dictionary_custom_settings/test.py b/tests/integration/test_dictionary_custom_settings/test.py
index 022822c8a806..aa6a16afb519 100644
--- a/tests/integration/test_dictionary_custom_settings/test.py
+++ b/tests/integration/test_dictionary_custom_settings/test.py
@@ -26,7 +26,7 @@ def prepare():
     node.exec_in_container([
         "bash",
         "-c",
-        "python2 /http_server.py --data-path={tbl} --schema=http --host=localhost --port=5555".format(
+        "python3 /http_server.py --data-path={tbl} --schema=http --host=localhost --port=5555".format(
             tbl=path)
     ], detach=True)
 
diff --git a/tests/integration/test_disk_types/test.py b/tests/integration/test_disk_types/test.py
index a97b90af27da..c748653bc827 100644
--- a/tests/integration/test_disk_types/test.py
+++ b/tests/integration/test_disk_types/test.py
@@ -33,5 +33,5 @@ def test_different_types(cluster):
 
 def test_select_by_type(cluster):
     node = cluster.instances["node"]
-    for name, disk_type in disk_types.items():
+    for name, disk_type in list(disk_types.items()):
         assert node.query("SELECT name FROM system.disks WHERE type='" + disk_type + "'") == name + "
"
diff --git a/tests/integration/test_distributed_ddl/cluster.py b/tests/integration/test_distributed_ddl/cluster.py
index efd6ce7e65cf..811eb94bad43 100644
--- a/tests/integration/test_distributed_ddl/cluster.py
+++ b/tests/integration/test_distributed_ddl/cluster.py
@@ -26,12 +26,12 @@ def prepare(self, replace_hostnames_with_ips=True):
                 main_configs += [os.path.join(self.test_config_dir, f) for f in
                                  ["server.crt", "server.key", "dhparam.pem", "config.d/ssl_conf.xml"]]
 
-            for i in xrange(4):
+            for i in range(4):
                 self.add_instance(
                     'ch{}'.format(i + 1),
                     main_configs=main_configs,
                     user_configs=user_configs,
-                    macros={"layer": 0, "shard": i / 2 + 1, "replica": i % 2 + 1},
+                    macros={"layer": 0, "shard": i // 2 + 1, "replica": i % 2 + 1},
                     with_zookeeper=True)
 
             self.start()
@@ -62,11 +62,11 @@ def prepare(self, replace_hostnames_with_ips=True):
             self.ddl_check_query(instance, "CREATE DATABASE IF NOT EXISTS test ON CLUSTER 'cluster'")
 
         except Exception as e:
-            print e
+            print(e)
             raise
 
     def sync_replicas(self, table, timeout=5):
-        for instance in self.instances.values():
+        for instance in list(self.instances.values()):
             instance.query("SYSTEM SYNC REPLICA {}".format(table), timeout=timeout)
 
     def check_all_hosts_successfully_executed(self, tsv_content, num_hosts=None):
@@ -90,7 +90,7 @@ def ddl_check_query(self, instance, query, num_hosts=None, settings=None):
     def replace_domains_to_ip_addresses_in_cluster_config(self, instances_to_replace):
         clusters_config = open(p.join(self.base_dir, '{}/config.d/clusters.xml'.format(self.test_config_dir))).read()
 
-        for inst_name, inst in self.instances.items():
+        for inst_name, inst in list(self.instances.items()):
             clusters_config = clusters_config.replace(inst_name, str(inst.ip_address))
 
         for inst_name in instances_to_replace:
@@ -113,7 +113,7 @@ def insert_reliable(instance, query_insert):
         Make retries in case of UNKNOWN_STATUS_OF_INSERT or zkutil::KeeperException errors
         """
 
-        for i in xrange(100):
+        for i in range(100):
             try:
                 instance.query(query_insert)
                 return
diff --git a/tests/integration/test_distributed_ddl/test.py b/tests/integration/test_distributed_ddl/test.py
index 9f01fa7ed5b1..f0e78dfec414 100755
--- a/tests/integration/test_distributed_ddl/test.py
+++ b/tests/integration/test_distributed_ddl/test.py
@@ -27,7 +27,7 @@ def test_cluster(request):
 
         # Check query log to ensure that DDL queries are not executed twice
         time.sleep(1.5)
-        for instance in cluster.instances.values():
+        for instance in list(cluster.instances.values()):
             cluster.ddl_check_there_are_no_dublicates(instance)
 
         cluster.pm_random_drops.heal_all()
@@ -133,12 +133,12 @@ def test_simple_alters(test_cluster):
 ENGINE = Distributed('{cluster}', default, merge, i)
 """)
 
-    for i in xrange(0, 4, 2):
+    for i in range(0, 4, 2):
         k = (i / 2) * 2
         test_cluster.instances['ch{}'.format(i + 1)].query("INSERT INTO merge (i) VALUES ({})({})".format(k, k + 1))
 
     assert TSV(instance.query("SELECT i FROM all_merge_32 ORDER BY i")) == TSV(
-        ''.join(['{}
'.format(x) for x in xrange(4)]))
+        ''.join(['{}
'.format(x) for x in range(4)]))
 
     time.sleep(5)
     test_cluster.ddl_check_query(instance, "ALTER TABLE merge ON CLUSTER '{cluster}' MODIFY COLUMN i Int64")
@@ -147,19 +147,19 @@ def test_simple_alters(test_cluster):
                                  "ALTER TABLE merge ON CLUSTER '{cluster}' ADD COLUMN s String DEFAULT toString(i) FORMAT TSV")
 
     assert TSV(instance.query("SELECT i, s FROM all_merge_64 ORDER BY i")) == TSV(
-        ''.join(['{}\t{}
'.format(x, x) for x in xrange(4)]))
+        ''.join(['{}\t{}
'.format(x, x) for x in range(4)]))
 
-    for i in xrange(0, 4, 2):
+    for i in range(0, 4, 2):
         k = (i / 2) * 2 + 4
         test_cluster.instances['ch{}'.format(i + 1)].query(
             "INSERT INTO merge (p, i) VALUES (31, {})(31, {})".format(k, k + 1))
 
     assert TSV(instance.query("SELECT i, s FROM all_merge_64 ORDER BY i")) == TSV(
-        ''.join(['{}\t{}
'.format(x, x) for x in xrange(8)]))
+        ''.join(['{}\t{}
'.format(x, x) for x in range(8)]))
 
     test_cluster.ddl_check_query(instance, "ALTER TABLE merge ON CLUSTER '{cluster}' DETACH PARTITION 197002")
     assert TSV(instance.query("SELECT i, s FROM all_merge_64 ORDER BY i")) == TSV(
-        ''.join(['{}\t{}
'.format(x, x) for x in xrange(4)]))
+        ''.join(['{}\t{}
'.format(x, x) for x in range(4)]))
 
     test_cluster.ddl_check_query(instance, "DROP TABLE merge ON CLUSTER '{cluster}'")
     test_cluster.ddl_check_query(instance, "DROP TABLE all_merge_32 ON CLUSTER '{cluster}'")
@@ -170,7 +170,7 @@ def test_macro(test_cluster):
     instance = test_cluster.instances['ch2']
     test_cluster.ddl_check_query(instance, "CREATE TABLE tab ON CLUSTER '{cluster}' (value UInt8) ENGINE = Memory")
 
-    for i in xrange(4):
+    for i in range(4):
         test_cluster.insert_reliable(test_cluster.instances['ch{}'.format(i + 1)],
                                      "INSERT INTO tab VALUES ({})".format(i))
 
@@ -359,6 +359,6 @@ def test_replicated_without_arguments(test_cluster):
 
 if __name__ == '__main__':
     with contextmanager(test_cluster)() as ctx_cluster:
-        for name, instance in ctx_cluster.instances.items():
-            print name, instance.ip_address
-        raw_input("Cluster created, press any key to destroy...")
+        for name, instance in list(ctx_cluster.instances.items()):
+            print(name, instance.ip_address)
+        input("Cluster created, press any key to destroy...")
diff --git a/tests/integration/test_distributed_ddl/test_replicated_alter.py b/tests/integration/test_distributed_ddl/test_replicated_alter.py
index 840803f61efe..bd95f5660b75 100644
--- a/tests/integration/test_distributed_ddl/test_replicated_alter.py
+++ b/tests/integration/test_distributed_ddl/test_replicated_alter.py
@@ -26,7 +26,7 @@ def test_cluster(request):
 
         # Check query log to ensure that DDL queries are not executed twice
         time.sleep(1.5)
-        for instance in cluster.instances.values():
+        for instance in list(cluster.instances.values()):
             cluster.ddl_check_there_are_no_dublicates(instance)
 
         cluster.pm_random_drops.heal_all()
@@ -59,36 +59,36 @@ def test_replicated_alters(test_cluster):
 ENGINE = Distributed(cluster, default, merge_for_alter, i)
 """)
 
-    for i in xrange(4):
-        k = (i / 2) * 2
+    for i in range(4):
+        k = (i // 2) * 2
         test_cluster.insert_reliable(test_cluster.instances['ch{}'.format(i + 1)],
                                      "INSERT INTO merge_for_alter (i) VALUES ({})({})".format(k, k + 1))
 
     test_cluster.sync_replicas("merge_for_alter")
 
     assert TSV(instance.query("SELECT i FROM all_merge_32 ORDER BY i")) == TSV(
-        ''.join(['{}
'.format(x) for x in xrange(4)]))
+        ''.join(['{}
'.format(x) for x in range(4)]))
 
     test_cluster.ddl_check_query(instance, "ALTER TABLE merge_for_alter ON CLUSTER cluster MODIFY COLUMN i Int64")
     test_cluster.ddl_check_query(instance,
                                  "ALTER TABLE merge_for_alter ON CLUSTER cluster ADD COLUMN s String DEFAULT toString(i)")
 
     assert TSV(instance.query("SELECT i, s FROM all_merge_64 ORDER BY i")) == TSV(
-        ''.join(['{}\t{}
'.format(x, x) for x in xrange(4)]))
+        ''.join(['{}\t{}
'.format(x, x) for x in range(4)]))
 
-    for i in xrange(4):
-        k = (i / 2) * 2 + 4
+    for i in range(4):
+        k = (i // 2) * 2 + 4
         test_cluster.insert_reliable(test_cluster.instances['ch{}'.format(i + 1)],
                                      "INSERT INTO merge_for_alter (p, i) VALUES (31, {})(31, {})".format(k, k + 1))
 
     test_cluster.sync_replicas("merge_for_alter")
 
     assert TSV(instance.query("SELECT i, s FROM all_merge_64 ORDER BY i")) == TSV(
-        ''.join(['{}\t{}
'.format(x, x) for x in xrange(8)]))
+        ''.join(['{}\t{}
'.format(x, x) for x in range(8)]))
 
     test_cluster.ddl_check_query(instance, "ALTER TABLE merge_for_alter ON CLUSTER cluster DETACH PARTITION 197002")
     assert TSV(instance.query("SELECT i, s FROM all_merge_64 ORDER BY i")) == TSV(
-        ''.join(['{}\t{}
'.format(x, x) for x in xrange(4)]))
+        ''.join(['{}\t{}
'.format(x, x) for x in range(4)]))
 
     test_cluster.ddl_check_query(instance, "DROP TABLE merge_for_alter ON CLUSTER cluster")
 
diff --git a/tests/integration/test_distributed_inter_server_secret/test.py b/tests/integration/test_distributed_inter_server_secret/test.py
index b39f9dec8612..bd9e6d111ca1 100644
--- a/tests/integration/test_distributed_inter_server_secret/test.py
+++ b/tests/integration/test_distributed_inter_server_secret/test.py
@@ -25,7 +25,7 @@ def make_instance(name, cfg):
 ])
 
 def bootstrap():
-    for n in cluster.instances.values():
+    for n in list(cluster.instances.values()):
         n.query('DROP TABLE IF EXISTS data')
         n.query('DROP TABLE IF EXISTS dist')
         n.query('CREATE TABLE data (key Int) Engine=Memory()')
diff --git a/tests/integration/test_distributed_load_balancing/test.py b/tests/integration/test_distributed_load_balancing/test.py
index b227c57fb04e..e7b86a210bdb 100644
--- a/tests/integration/test_distributed_load_balancing/test.py
+++ b/tests/integration/test_distributed_load_balancing/test.py
@@ -18,7 +18,7 @@
 
 
 def bootstrap():
-    for n in cluster.instances.values():
+    for n in list(cluster.instances.values()):
         # At startup, server loads configuration files.
         #
         # However ConfigReloader does not know about already loaded files
@@ -90,7 +90,7 @@ def get_node(query_node, table='dist', *args, **kwargs):
 
     query_node.query('SELECT * FROM ' + table, *args, **kwargs)
 
-    for n in cluster.instances.values():
+    for n in list(cluster.instances.values()):
         n.query('SYSTEM FLUSH LOGS')
 
     rows = query_node.query("""
diff --git a/tests/integration/test_distributed_over_distributed/test.py b/tests/integration/test_distributed_over_distributed/test.py
index 716bc66d629c..410a03a6af11 100644
--- a/tests/integration/test_distributed_over_distributed/test.py
+++ b/tests/integration/test_distributed_over_distributed/test.py
@@ -1,7 +1,7 @@
 # This test is a subset of the 01223_dist_on_dist.
 # (just in case, with real separate instances).
 
-from __future__ import print_function
+
 
 import pytest
 from helpers.cluster import ClickHouseCluster
@@ -51,7 +51,7 @@ def started_cluster():
         cluster.shutdown()
 
 
-@pytest.mark.parametrize("node", NODES.values())
+@pytest.mark.parametrize("node", list(NODES.values()))
 @pytest.mark.parametrize("source",
                          ["distributed_over_distributed_table", "cluster('test_cluster', default, distributed_table)"])
 class TestDistributedOverDistributedSuite:
diff --git a/tests/integration/test_distributed_over_live_view/test.py b/tests/integration/test_distributed_over_live_view/test.py
index 9e62aaad9820..78b90024ebf8 100644
--- a/tests/integration/test_distributed_over_live_view/test.py
+++ b/tests/integration/test_distributed_over_live_view/test.py
@@ -1,4 +1,4 @@
-from __future__ import print_function
+
 
 import sys
 import time
@@ -9,6 +9,9 @@
 
 cluster = ClickHouseCluster(__file__)
 
+# log = sys.stdout
+log = None
+
 NODES = {'node' + str(i): cluster.add_instance(
     'node' + str(i),
     main_configs=['configs/remote_servers.xml'],
@@ -63,12 +66,11 @@ def poll_query(node, query, expected, timeout):
         pass
     assert node.query(query) == expected
 
-@pytest.mark.parametrize("node", NODES.values()[:1])
+@pytest.mark.parametrize("node", list(NODES.values())[:1])
 @pytest.mark.parametrize("source", ["lv_over_distributed_table"])
 class TestLiveViewOverDistributedSuite:
     def test_distributed_over_live_view_order_by_node(self, started_cluster, node, source):
-        log = sys.stdout
-        node0, node1 = NODES.values()
+        node0, node1 = list(NODES.values())
 
         select_query = "SELECT * FROM distributed_over_lv ORDER BY node, key FORMAT CSV"
         select_query_dist_table = "SELECT * FROM distributed_table ORDER BY node, key FORMAT CSV"
@@ -118,8 +120,7 @@ def test_distributed_over_live_view_order_by_node(self, started_cluster, node, s
             client1.expect(prompt)
 
     def test_distributed_over_live_view_order_by_key(self, started_cluster, node, source):
-        log = sys.stdout
-        node0, node1 = NODES.values()
+        node0, node1 = list(NODES.values())
 
         select_query = "SELECT * FROM distributed_over_lv ORDER BY key, node FORMAT CSV"
         select_count_query = "SELECT count() FROM distributed_over_lv"
@@ -160,8 +161,7 @@ def test_distributed_over_live_view_order_by_key(self, started_cluster, node, so
             client1.expect(prompt)
 
     def test_distributed_over_live_view_group_by_node(self, started_cluster, node, source):
-        log = sys.stdout
-        node0, node1 = NODES.values()
+        node0, node1 = list(NODES.values())
 
         select_query = "SELECT node, SUM(value) FROM distributed_over_lv GROUP BY node ORDER BY node FORMAT CSV"
 
@@ -204,8 +204,7 @@ def test_distributed_over_live_view_group_by_node(self, started_cluster, node, s
             client1.expect(prompt)
 
     def test_distributed_over_live_view_group_by_key(self, started_cluster, node, source):
-        log = sys.stdout
-        node0, node1 = NODES.values()
+        node0, node1 = list(NODES.values())
 
         select_query = "SELECT key, SUM(value) FROM distributed_over_lv GROUP BY key ORDER BY key FORMAT CSV"
 
@@ -249,8 +248,7 @@ def test_distributed_over_live_view_group_by_key(self, started_cluster, node, so
             client1.expect(prompt)
 
     def test_distributed_over_live_view_sum(self, started_cluster, node, source):
-        log = sys.stdout
-        node0, node1 = NODES.values()
+        node0, node1 = list(NODES.values())
 
         with client(name="client1> ", log=log, command=" ".join(node0.client.command)) as client1, \
                 client(name="client2> ", log=log, command=" ".join(node1.client.command)) as client2:
diff --git a/tests/integration/test_distributed_respect_user_timeouts/test.py b/tests/integration/test_distributed_respect_user_timeouts/test.py
index e5d9d0c1857d..c19323b20497 100644
--- a/tests/integration/test_distributed_respect_user_timeouts/test.py
+++ b/tests/integration/test_distributed_respect_user_timeouts/test.py
@@ -103,7 +103,7 @@ def started_cluster(request):
     try:
         cluster.start()
 
-        for node_id, node in NODES.items():
+        for node_id, node in list(NODES.items()):
             node.query(CREATE_TABLES_SQL)
             node.query(INSERT_SQL_TEMPLATE.format(node_id=node_id))
 
@@ -155,7 +155,7 @@ def test_reconnect(started_cluster, node_name, first_user, query_base):
 
     with PartitionManager() as pm:
         # Break the connection.
-        pm.partition_instances(*NODES.values())
+        pm.partition_instances(*list(NODES.values()))
 
         # Now it shouldn't:
         _check_timeout_and_exception(node, first_user, query_base, query)
diff --git a/tests/integration/test_drop_replica/test.py b/tests/integration/test_drop_replica/test.py
index fac8802b2f93..f3af9dcb9807 100644
--- a/tests/integration/test_drop_replica/test.py
+++ b/tests/integration/test_drop_replica/test.py
@@ -65,7 +65,7 @@ def start_cluster():
         yield cluster
 
     except Exception as ex:
-        print ex
+        print(ex)
 
     finally:
         cluster.shutdown()
diff --git a/tests/integration/test_fetch_partition_from_auxiliary_zookeeper/test.py b/tests/integration/test_fetch_partition_from_auxiliary_zookeeper/test.py
index 9ad56d4fb17c..f9c10d68fe3e 100644
--- a/tests/integration/test_fetch_partition_from_auxiliary_zookeeper/test.py
+++ b/tests/integration/test_fetch_partition_from_auxiliary_zookeeper/test.py
@@ -1,4 +1,4 @@
-from __future__ import print_function
+
 
 import pytest
 from helpers.client import QueryRuntimeException
diff --git a/tests/integration/test_format_avro_confluent/test.py b/tests/integration/test_format_avro_confluent/test.py
index 67d153053333..cc0068017358 100644
--- a/tests/integration/test_format_avro_confluent/test.py
+++ b/tests/integration/test_format_avro_confluent/test.py
@@ -3,7 +3,7 @@
 
 import avro.schema
 import pytest
-from confluent.schemaregistry.serializers import MessageSerializer
+from confluent_kafka.avro.serializer.message_serializer import MessageSerializer
 from helpers.cluster import ClickHouseCluster, ClickHouseInstance
 
 logging.getLogger().setLevel(logging.INFO)
diff --git a/tests/integration/test_grant_and_revoke/test.py b/tests/integration/test_grant_and_revoke/test.py
index 073578edaa5e..0404120907d5 100644
--- a/tests/integration/test_grant_and_revoke/test.py
+++ b/tests/integration/test_grant_and_revoke/test.py
@@ -226,8 +226,8 @@ def test_introspection():
 
     assert instance.query(
         "SELECT * from system.grants WHERE user_name IN ('A', 'B') ORDER BY user_name, access_type, grant_option") == \
-           TSV([["A", "\N", "SELECT", "test", "table", "\N", 0, 0],
-                ["B", "\N", "CREATE", "\N", "\N", "\N", 0, 1]])
+           TSV([["A", "\\N", "SELECT", "test", "table", "\\N", 0, 0],
+                ["B", "\\N", "CREATE", "\\N", "\\N", "\\N", 0, 1]])
 
 
 def test_current_database():
diff --git a/tests/integration/test_graphite_merge_tree/test.py b/tests/integration/test_graphite_merge_tree/test.py
index 319fdb816ff5..502004d2dfea 100644
--- a/tests/integration/test_graphite_merge_tree/test.py
+++ b/tests/integration/test_graphite_merge_tree/test.py
@@ -301,7 +301,7 @@ def test_path_dangling_pointer(graphite_table):
                       "AND table='graphite2'"))
         if parts == 1:
             break
-        print('Parts', parts)
+        print(('Parts', parts))
 
     assert TSV(
         q("SELECT value, timestamp, date, updated FROM test.graphite2")
diff --git a/tests/integration/test_host_ip_change/test.py b/tests/integration/test_host_ip_change/test.py
index 951af699a5f8..7525914e8038 100644
--- a/tests/integration/test_host_ip_change/test.py
+++ b/tests/integration/test_host_ip_change/test.py
@@ -35,7 +35,7 @@ def cluster_without_dns_cache_update():
         yield cluster
 
     except Exception as ex:
-        print ex
+        print(ex)
 
     finally:
         cluster.shutdown()
@@ -90,7 +90,7 @@ def cluster_with_dns_cache_update():
         yield cluster
 
     except Exception as ex:
-        print ex
+        print(ex)
 
     finally:
         cluster.shutdown()
@@ -117,7 +117,7 @@ def test_ip_change_update_dns_cache(cluster_with_dns_cache_update):
     curl_result = node4.exec_in_container(["bash", "-c", "curl -s 'node3:8123'"])
     assert curl_result == 'Ok.
'
     cat_resolv = node4.exec_in_container(["bash", "-c", "cat /etc/resolv.conf"])
-    print("RESOLV {}".format(cat_resolv))
+    print(("RESOLV {}".format(cat_resolv)))
 
     assert_eq_with_retry(node4, "SELECT * FROM remote('node3', 'system', 'one')", "0", sleep_time=0.5)
 
diff --git a/tests/integration/test_http_handlers_config/test.py b/tests/integration/test_http_handlers_config/test.py
index 06602ba3ca32..818a1e54640c 100644
--- a/tests/integration/test_http_handlers_config/test.py
+++ b/tests/integration/test_http_handlers_config/test.py
@@ -1,6 +1,6 @@
 import contextlib
 import os
-import urllib
+import urllib.request, urllib.parse, urllib.error
 
 from helpers.cluster import ClickHouseCluster
 
@@ -22,7 +22,7 @@ def add_instance(self, name, config_dir):
 def test_dynamic_query_handler():
     with contextlib.closing(
             SimpleCluster(ClickHouseCluster(__file__), "dynamic_handler", "test_dynamic_handler")) as cluster:
-        test_query = urllib.quote_plus('SELECT * FROM system.settings WHERE name = \'max_threads\'')
+        test_query = urllib.parse.quote_plus('SELECT * FROM system.settings WHERE name = \'max_threads\'')
 
         assert 404 == cluster.instance.http_request('?max_threads=1', method='GET', headers={'XXX': 'xxx'}).status_code
 
@@ -54,11 +54,11 @@ def test_predefined_query_handler():
         assert 500 == cluster.instance.http_request('test_predefined_handler_get?max_threads=1', method='GET',
                                                     headers={'XXX': 'xxx'}).status_code
 
-        assert 'max_threads\t1
' == cluster.instance.http_request(
+        assert b'max_threads\t1
' == cluster.instance.http_request(
             'test_predefined_handler_get?max_threads=1&setting_name=max_threads', method='GET',
             headers={'XXX': 'xxx'}).content
 
-        assert 'max_threads\t1
max_alter_threads\t1
' == cluster.instance.http_request(
+        assert b'max_threads\t1
max_alter_threads\t1
' == cluster.instance.http_request(
             'query_param_with_url/max_threads?max_threads=1&max_alter_threads=1',
             headers={'XXX': 'max_alter_threads'}).content
 
@@ -79,7 +79,7 @@ def test_fixed_static_handler():
         assert 'text/html; charset=UTF-8' == \
                cluster.instance.http_request('test_get_fixed_static_handler', method='GET',
                                              headers={'XXX': 'xxx'}).headers['Content-Type']
-        assert 'Test get static handler and fix content' == cluster.instance.http_request(
+        assert b'Test get static handler and fix content' == cluster.instance.http_request(
             'test_get_fixed_static_handler', method='GET', headers={'XXX': 'xxx'}).content
 
 
@@ -100,7 +100,7 @@ def test_config_static_handler():
         assert 'text/plain; charset=UTF-8' == \
                cluster.instance.http_request('test_get_config_static_handler', method='GET',
                                              headers={'XXX': 'xxx'}).headers['Content-Type']
-        assert 'Test get static handler and config content' == cluster.instance.http_request(
+        assert b'Test get static handler and config content' == cluster.instance.http_request(
             'test_get_config_static_handler', method='GET', headers={'XXX': 'xxx'}).content
 
 
@@ -126,7 +126,7 @@ def test_absolute_path_static_handler():
         assert 'text/html; charset=UTF-8' == \
                cluster.instance.http_request('test_get_absolute_path_static_handler', method='GET',
                                              headers={'XXX': 'xxx'}).headers['Content-Type']
-        assert '<html><body>Absolute Path File</body></html>
' == cluster.instance.http_request(
+        assert b'<html><body>Absolute Path File</body></html>
' == cluster.instance.http_request(
             'test_get_absolute_path_static_handler', method='GET', headers={'XXX': 'xxx'}).content
 
 
@@ -152,7 +152,7 @@ def test_relative_path_static_handler():
         assert 'text/html; charset=UTF-8' == \
                cluster.instance.http_request('test_get_relative_path_static_handler', method='GET',
                                              headers={'XXX': 'xxx'}).headers['Content-Type']
-        assert '<html><body>Relative Path File</body></html>
' == cluster.instance.http_request(
+        assert b'<html><body>Relative Path File</body></html>
' == cluster.instance.http_request(
             'test_get_relative_path_static_handler', method='GET', headers={'XXX': 'xxx'}).content
 
 
@@ -160,19 +160,19 @@ def test_defaults_http_handlers():
     with contextlib.closing(
             SimpleCluster(ClickHouseCluster(__file__), "defaults_handlers", "test_defaults_handlers")) as cluster:
         assert 200 == cluster.instance.http_request('', method='GET').status_code
-        assert 'Default server response' == cluster.instance.http_request('', method='GET').content
+        assert b'Default server response' == cluster.instance.http_request('', method='GET').content
 
         assert 200 == cluster.instance.http_request('ping', method='GET').status_code
-        assert 'Ok.
' == cluster.instance.http_request('ping', method='GET').content
+        assert b'Ok.
' == cluster.instance.http_request('ping', method='GET').content
 
         assert 200 == cluster.instance.http_request('replicas_status', method='get').status_code
-        assert 'Ok.
' == cluster.instance.http_request('replicas_status', method='get').content
+        assert b'Ok.
' == cluster.instance.http_request('replicas_status', method='get').content
 
         assert 200 == cluster.instance.http_request('replicas_status?verbose=1', method='get').status_code
-        assert '' == cluster.instance.http_request('replicas_status?verbose=1', method='get').content
+        assert b'' == cluster.instance.http_request('replicas_status?verbose=1', method='get').content
 
         assert 200 == cluster.instance.http_request('?query=SELECT+1', method='GET').status_code
-        assert '1
' == cluster.instance.http_request('?query=SELECT+1', method='GET').content
+        assert b'1
' == cluster.instance.http_request('?query=SELECT+1', method='GET').content
 
 
 def test_prometheus_handler():
@@ -186,7 +186,7 @@ def test_prometheus_handler():
                                                     headers={'XXX': 'xxx'}).status_code
 
         assert 200 == cluster.instance.http_request('test_prometheus', method='GET', headers={'XXX': 'xxx'}).status_code
-        assert 'ClickHouseProfileEvents_Query' in cluster.instance.http_request('test_prometheus', method='GET',
+        assert b'ClickHouseProfileEvents_Query' in cluster.instance.http_request('test_prometheus', method='GET',
                                                                                 headers={'XXX': 'xxx'}).content
 
 
@@ -203,5 +203,5 @@ def test_replicas_status_handler():
 
         assert 200 == cluster.instance.http_request('test_replicas_status', method='GET',
                                                     headers={'XXX': 'xxx'}).status_code
-        assert 'Ok.
' == cluster.instance.http_request('test_replicas_status', method='GET',
+        assert b'Ok.
' == cluster.instance.http_request('test_replicas_status', method='GET',
                                                         headers={'XXX': 'xxx'}).content
diff --git a/tests/integration/test_https_replication/test.py b/tests/integration/test_https_replication/test.py
index 84c2744923d6..dbb6874718ca 100644
--- a/tests/integration/test_https_replication/test.py
+++ b/tests/integration/test_https_replication/test.py
@@ -75,7 +75,7 @@ def insert_data_and_check(num):
     closing_pool = Pool(1)
     inserting_pool = Pool(5)
     cres = closing_pool.map_async(close, [random.randint(1, 3) for _ in range(10)])
-    ires = inserting_pool.map_async(insert_data_and_check, range(100))
+    ires = inserting_pool.map_async(insert_data_and_check, list(range(100)))
 
     cres.wait()
     ires.wait()
diff --git a/tests/integration/test_insert_into_distributed_sync_async/test.py b/tests/integration/test_insert_into_distributed_sync_async/test.py
index 30c80e50c438..372ed04cd2c9 100755
--- a/tests/integration/test_insert_into_distributed_sync_async/test.py
+++ b/tests/integration/test_insert_into_distributed_sync_async/test.py
@@ -1,4 +1,3 @@
-#!/usr/bin/env python2
 import os
 import sys
 from contextlib import contextmanager
@@ -119,6 +118,6 @@ def test_async_inserts_into_local_shard(started_cluster):
 
 if __name__ == '__main__':
     with contextmanager(started_cluster)() as cluster:
-        for name, instance in cluster.instances.items():
-            print name, instance.ip_address
-        raw_input("Cluster created, press any key to destroy...")
+        for name, instance in list(cluster.instances.items()):
+            print(name, instance.ip_address)
+        input("Cluster created, press any key to destroy...")
diff --git a/tests/integration/test_live_view_over_distributed/test.py b/tests/integration/test_live_view_over_distributed/test.py
index 67ff4d8dfe7c..a21eeb772e55 100644
--- a/tests/integration/test_live_view_over_distributed/test.py
+++ b/tests/integration/test_live_view_over_distributed/test.py
@@ -1,4 +1,4 @@
-from __future__ import print_function
+
 
 import sys
 
@@ -7,6 +7,8 @@
 from helpers.uclient import client, prompt, end_of_block
 
 cluster = ClickHouseCluster(__file__)
+# log = sys.stdout
+log = None
 
 NODES = {'node' + str(i): cluster.add_instance(
     'node' + str(i),
@@ -55,7 +57,7 @@ def started_cluster():
         cluster.shutdown()
 
 
-@pytest.mark.parametrize("node", NODES.values()[:1])
+@pytest.mark.parametrize("node", list(NODES.values())[:1])
 @pytest.mark.parametrize("source", ["lv_over_distributed_table"])
 class TestLiveViewOverDistributedSuite:
     def test_select_with_order_by_node(self, started_cluster, node, source):
@@ -87,7 +89,6 @@ def test_select_sum(self, started_cluster, node, source):
                == "22
"
 
     def test_watch_live_view_order_by_node(self, started_cluster, node, source):
-        log = sys.stdout
         command = " ".join(node.client.command)
         args = dict(log=log, command=command)
 
@@ -130,7 +131,6 @@ def test_watch_live_view_order_by_node(self, started_cluster, node, source):
             client1.expect('"node3",3,3,3')
 
     def test_watch_live_view_order_by_key(self, started_cluster, node, source):
-        log = sys.stdout
         command = " ".join(node.client.command)
         args = dict(log=log, command=command)
 
@@ -173,7 +173,6 @@ def test_watch_live_view_order_by_key(self, started_cluster, node, source):
             client1.expect('"node3",3,3,3')
 
     def test_watch_live_view_group_by_node(self, started_cluster, node, source):
-        log = sys.stdout
         command = " ".join(node.client.command)
         args = dict(log=log, command=command)
 
@@ -208,7 +207,6 @@ def test_watch_live_view_group_by_node(self, started_cluster, node, source):
             client1.expect('"node3",3,3')
 
     def test_watch_live_view_group_by_key(self, started_cluster, node, source):
-        log = sys.stdout
         command = " ".join(node.client.command)
         args = dict(log=log, command=command)
         sep = ' \xe2\x94\x82'
@@ -245,7 +243,6 @@ def test_watch_live_view_group_by_key(self, started_cluster, node, source):
             client1.expect('3,3,3')
 
     def test_watch_live_view_sum(self, started_cluster, node, source):
-        log = sys.stdout
         command = " ".join(node.client.command)
         args = dict(log=log, command=command)
 
diff --git a/tests/integration/test_materialize_mysql_database/materialize_with_ddl.py b/tests/integration/test_materialize_mysql_database/materialize_with_ddl.py
index 813e72fe7a7e..3990f7dbd333 100644
--- a/tests/integration/test_materialize_mysql_database/materialize_with_ddl.py
+++ b/tests/integration/test_materialize_mysql_database/materialize_with_ddl.py
@@ -11,7 +11,7 @@ def check_query(clickhouse_node, query, result_set, retry_count=3, interval_seco
         if result_set == lastest_result:
             return
 
-        print lastest_result
+        print(lastest_result)
         time.sleep(interval_seconds)
 
     assert lastest_result == result_set
diff --git a/tests/integration/test_materialize_mysql_database/test.py b/tests/integration/test_materialize_mysql_database/test.py
index 81a69dd7c543..237df999c62a 100644
--- a/tests/integration/test_materialize_mysql_database/test.py
+++ b/tests/integration/test_materialize_mysql_database/test.py
@@ -6,7 +6,7 @@
 import pytest
 from helpers.cluster import ClickHouseCluster, get_docker_compose_path
 
-import materialize_with_ddl
+from . import materialize_with_ddl
 
 DOCKER_COMPOSE_PATH = get_docker_compose_path()
 
@@ -50,10 +50,10 @@ def wait_mysql_to_start(self, timeout=60):
         while time.time() - start < timeout:
             try:
                 self.alloc_connection()
-                print "Mysql Started"
+                print("Mysql Started")
                 return
             except Exception as ex:
-                print "Can't connect to MySQL " + str(ex)
+                print("Can't connect to MySQL " + str(ex))
                 time.sleep(0.5)
 
         subprocess.check_call(['docker-compose', 'ps', '--services', 'all'])
@@ -119,8 +119,8 @@ def test_materialize_database_ddl_with_mysql_5_7(started_cluster, started_mysql_
         materialize_with_ddl.alter_modify_column_with_materialize_mysql_database(clickhouse_node, started_mysql_5_7,
                                                                                  "mysql1")
     except:
-        print(clickhouse_node.query(
-            "select '
', thread_id, query_id, arrayStringConcat(arrayMap(x -> concat(demangle(addressToSymbol(x)), '
    ', addressToLine(x)), trace), '
') AS sym from system.stack_trace format TSVRaw"))
+        print((clickhouse_node.query(
+            "select '
', thread_id, query_id, arrayStringConcat(arrayMap(x -> concat(demangle(addressToSymbol(x)), '
    ', addressToLine(x)), trace), '
') AS sym from system.stack_trace format TSVRaw")))
         raise
 
 
diff --git a/tests/integration/test_max_http_connections_for_replication/test.py b/tests/integration/test_max_http_connections_for_replication/test.py
index 5ef45c2a893a..2dc4e2a8810c 100644
--- a/tests/integration/test_max_http_connections_for_replication/test.py
+++ b/tests/integration/test_max_http_connections_for_replication/test.py
@@ -44,12 +44,12 @@ def start_small_cluster():
 
 def test_single_endpoint_connections_count(start_small_cluster):
     def task(count):
-        print("Inserting ten times from {}".format(count))
-        for i in xrange(count, count + 10):
+        print(("Inserting ten times from {}".format(count)))
+        for i in range(count, count + 10):
             node1.query("insert into test_table values ('2017-06-16', {}, 0)".format(i))
 
     p = Pool(10)
-    p.map(task, xrange(0, 100, 10))
+    p.map(task, range(0, 100, 10))
 
     assert_eq_with_retry(node1, "select count() from test_table", "100")
     assert_eq_with_retry(node2, "select count() from test_table", "100")
@@ -97,17 +97,17 @@ def start_big_cluster():
 
 def test_multiple_endpoint_connections_count(start_big_cluster):
     def task(count):
-        print("Inserting ten times from {}".format(count))
+        print(("Inserting ten times from {}".format(count)))
         if (count / 10) % 2 == 1:
             node = node3
         else:
             node = node4
 
-        for i in xrange(count, count + 10):
+        for i in range(count, count + 10):
             node.query("insert into test_table values ('2017-06-16', {}, 0)".format(i))
 
     p = Pool(10)
-    p.map(task, xrange(0, 100, 10))
+    p.map(task, range(0, 100, 10))
 
     assert_eq_with_retry(node3, "select count() from test_table", "100")
     assert_eq_with_retry(node4, "select count() from test_table", "100")
diff --git a/tests/integration/test_merge_table_over_distributed/test.py b/tests/integration/test_merge_table_over_distributed/test.py
index 2e73bd09ded2..ab2948671266 100644
--- a/tests/integration/test_merge_table_over_distributed/test.py
+++ b/tests/integration/test_merge_table_over_distributed/test.py
@@ -68,6 +68,6 @@ def test_select_table_name_from_merge_over_distributed(started_cluster):
 
 if __name__ == '__main__':
     with contextmanager(started_cluster)() as cluster:
-        for name, instance in cluster.instances.items():
-            print name, instance.ip_address
-        raw_input("Cluster created, press any key to destroy...")
+        for name, instance in list(cluster.instances.items()):
+            print(name, instance.ip_address)
+        input("Cluster created, press any key to destroy...")
diff --git a/tests/integration/test_multiple_disks/test.py b/tests/integration/test_multiple_disks/test.py
index d12c7f7b3575..5058bcf368ed 100644
--- a/tests/integration/test_multiple_disks/test.py
+++ b/tests/integration/test_multiple_disks/test.py
@@ -954,7 +954,7 @@ def test_mutate_to_another_disk(start_cluster, name, engine):
         if node1.query("SELECT latest_fail_reason FROM system.mutations WHERE table = '{}'".format(name)) == "":
             assert node1.query("SELECT sum(endsWith(s1, 'x')) FROM {}".format(name)) == "25
"
         else:  # mutation failed, let's try on another disk
-            print "Mutation failed"
+            print("Mutation failed")
             node1.query("OPTIMIZE TABLE {} FINAL".format(name))
             node1.query("ALTER TABLE {} UPDATE s1 = concat(s1, 'x') WHERE 1".format(name))
             retry = 20
@@ -1114,7 +1114,7 @@ def test_download_appropriate_disk(start_cluster):
 
         for _ in range(10):
             try:
-                print "Syncing replica"
+                print("Syncing replica")
                 node2.query("SYSTEM SYNC REPLICA replicated_table_for_download")
                 break
             except:
diff --git a/tests/integration/test_mutations_hardlinks/test.py b/tests/integration/test_mutations_hardlinks/test.py
index b1e538b123b1..7ac7fe12108b 100644
--- a/tests/integration/test_mutations_hardlinks/test.py
+++ b/tests/integration/test_mutations_hardlinks/test.py
@@ -122,7 +122,7 @@ def mutate():
             if int(result.strip()) == 2:
                 break
         except:
-            print "Result", result
+            print("Result", result)
             pass
 
         time.sleep(0.5)
diff --git a/tests/integration/test_mutations_with_merge_tree/test.py b/tests/integration/test_mutations_with_merge_tree/test.py
index 25bc0df8e7cf..65eaee215777 100644
--- a/tests/integration/test_mutations_with_merge_tree/test.py
+++ b/tests/integration/test_mutations_with_merge_tree/test.py
@@ -44,8 +44,8 @@ def get_done_mutations(instance):
             all_done = True
             break
 
-    print instance_test_mutations.query(
-        "SELECT mutation_id, command, parts_to_do, is_done FROM system.mutations WHERE table = 'test_mutations_with_ast_elements' SETTINGS force_index_by_date = 0, force_primary_key = 0 FORMAT TSVWithNames")
+    print(instance_test_mutations.query(
+        "SELECT mutation_id, command, parts_to_do, is_done FROM system.mutations WHERE table = 'test_mutations_with_ast_elements' SETTINGS force_index_by_date = 0, force_primary_key = 0 FORMAT TSVWithNames"))
     assert all_done
 
 
diff --git a/tests/integration/test_mysql_database_engine/test.py b/tests/integration/test_mysql_database_engine/test.py
index a8824b383abc..23424c550b20 100644
--- a/tests/integration/test_mysql_database_engine/test.py
+++ b/tests/integration/test_mysql_database_engine/test.py
@@ -44,7 +44,7 @@ def execute(query):
                     res = "
".join(rows)
                 return res
 
-            if isinstance(execution_query, (str, bytes, unicode)):
+            if isinstance(execution_query, (str, bytes)):
                 return execute(execution_query)
             else:
                 return [execute(q) for q in execution_query]
@@ -256,7 +256,7 @@ def do_execute(query):
             res = node.query(query, **kwargs)
             return res if isinstance(res, int) else res.rstrip('
\r')
 
-        if isinstance(query, (str, bytes, unicode)):
+        if isinstance(query, (str, bytes)):
             return do_execute(query)
         else:
             return [do_execute(q) for q in query]
diff --git a/tests/integration/test_mysql_protocol/test.py b/tests/integration/test_mysql_protocol/test.py
index 3e737dc26447..04cbef59af7a 100644
--- a/tests/integration/test_mysql_protocol/test.py
+++ b/tests/integration/test_mysql_protocol/test.py
@@ -98,7 +98,7 @@ def test_mysql_client(mysql_client, server_address):
         -e "SELECT 1;"
     '''.format(host=server_address, port=server_port), demux=True)
 
-    assert stdout == '
'.join(['1', '1', ''])
+    assert stdout.decode() == '
'.join(['1', '1', ''])
 
     code, (stdout, stderr) = mysql_client.exec_run('''
         mysql --protocol tcp -h {host} -P {port} default -u default --password=123
@@ -106,13 +106,13 @@ def test_mysql_client(mysql_client, server_address):
         -e "SELECT '' as b;"
     '''.format(host=server_address, port=server_port), demux=True)
 
-    assert stdout == '
'.join(['a', '1', 'b', '', ''])
+    assert stdout.decode() == '
'.join(['a', '1', 'b', '', ''])
 
     code, (stdout, stderr) = mysql_client.exec_run('''
         mysql --protocol tcp -h {host} -P {port} default -u default --password=abc -e "select 1 as a;"
     '''.format(host=server_address, port=server_port), demux=True)
 
-    assert stderr == 'mysql: [Warning] Using a password on the command line interface can be insecure.
' \
+    assert stderr.decode() == 'mysql: [Warning] Using a password on the command line interface can be insecure.
' \
                      'ERROR 516 (00000): default: Authentication failed: password is incorrect or there is no user with such name
'
 
     code, (stdout, stderr) = mysql_client.exec_run('''
@@ -122,8 +122,8 @@ def test_mysql_client(mysql_client, server_address):
         -e "use system2;"
     '''.format(host=server_address, port=server_port), demux=True)
 
-    assert stdout == 'count()
1
'
-    assert stderr[0:182] == "mysql: [Warning] Using a password on the command line interface can be insecure.
" \
+    assert stdout.decode() == 'count()
1
'
+    assert stderr[0:182].decode() == "mysql: [Warning] Using a password on the command line interface can be insecure.
" \
                             "ERROR 81 (00000) at line 1: Code: 81, e.displayText() = DB::Exception: Database system2 doesn't exist"
 
     code, (stdout, stderr) = mysql_client.exec_run('''
@@ -140,7 +140,7 @@ def test_mysql_client(mysql_client, server_address):
         -e "SELECT * FROM tmp ORDER BY tmp_column;"
     '''.format(host=server_address, port=server_port), demux=True)
 
-    assert stdout == '
'.join(['column', '0', '0', '1', '1', '5', '5', 'tmp_column', '0', '1', ''])
+    assert stdout.decode() == '
'.join(['column', '0', '0', '1', '1', '5', '5', 'tmp_column', '0', '1', ''])
 
 
 def test_mysql_client_exception(mysql_client, server_address):
@@ -150,7 +150,7 @@ def test_mysql_client_exception(mysql_client, server_address):
         -e "CREATE TABLE default.t1_remote_mysql AS mysql('127.0.0.1:10086','default','t1_local','default','');"
     '''.format(host=server_address, port=server_port), demux=True)
 
-    assert stderr[0:266] == "mysql: [Warning] Using a password on the command line interface can be insecure.
" \
+    assert stderr[0:266].decode() == "mysql: [Warning] Using a password on the command line interface can be insecure.
" \
                             "ERROR 1000 (00000) at line 1: Poco::Exception. Code: 1000, e.code() = 2002, e.displayText() = mysqlxx::ConnectionFailed: Can't connect to MySQL server on '127.0.0.1' (115) ((nullptr):0)"
 
 
@@ -188,14 +188,14 @@ def test_mysql_replacement_query(mysql_client, server_address):
         --password=123 -e "select database();"
     '''.format(host=server_address, port=server_port), demux=True)
     assert code == 0
-    assert stdout == 'database()
default
'
+    assert stdout.decode() == 'database()
default
'
 
     code, (stdout, stderr) = mysql_client.exec_run('''
         mysql --protocol tcp -h {host} -P {port} default -u default
         --password=123 -e "select DATABASE();"
     '''.format(host=server_address, port=server_port), demux=True)
     assert code == 0
-    assert stdout == 'DATABASE()
default
'
+    assert stdout.decode() == 'DATABASE()
default
'
 
 
 def test_mysql_explain(mysql_client, server_address):
@@ -238,6 +238,7 @@ def test_mysql_federated(mysql_server, server_address):
         node.query('''INSERT INTO mysql_federated.test VALUES (0), (1), (5)''', settings={"password": "123"})
 
         def check_retryable_error_in_stderr(stderr):
+            stderr = stderr.decode()
             return ("Can't connect to local MySQL server through socket" in stderr
                     or "MySQL server has gone away" in stderr
                     or "Server shutdown in progress" in stderr)
@@ -252,8 +253,8 @@ def check_retryable_error_in_stderr(stderr):
         '''.format(host=server_address, port=server_port), demux=True)
 
         if code != 0:
-            print("stdout", stdout)
-            print("stderr", stderr)
+            print(("stdout", stdout))
+            print(("stderr", stderr))
             if try_num + 1 < retries and check_retryable_error_in_stderr(stderr):
                 time.sleep(1)
                 continue
@@ -266,14 +267,14 @@ def check_retryable_error_in_stderr(stderr):
         '''.format(host=server_address, port=server_port), demux=True)
 
         if code != 0:
-            print("stdout", stdout)
-            print("stderr", stderr)
+            print(("stdout", stdout))
+            print(("stderr", stderr))
             if try_num + 1 < retries and check_retryable_error_in_stderr(stderr):
                 time.sleep(1)
                 continue
         assert code == 0
 
-        assert stdout == '
'.join(['col', '0', '1', '5', ''])
+        assert stdout.decode() == '
'.join(['col', '0', '1', '5', ''])
 
         code, (stdout, stderr) = mysql_server.exec_run('''
             mysql
@@ -282,14 +283,14 @@ def check_retryable_error_in_stderr(stderr):
         '''.format(host=server_address, port=server_port), demux=True)
 
         if code != 0:
-            print("stdout", stdout)
-            print("stderr", stderr)
+            print(("stdout", stdout))
+            print(("stderr", stderr))
             if try_num + 1 < retries and check_retryable_error_in_stderr(stderr):
                 time.sleep(1)
                 continue
         assert code == 0
 
-        assert stdout == '
'.join(['col', '0', '0', '1', '1', '5', '5', ''])
+        assert stdout.decode() == '
'.join(['col', '0', '0', '1', '1', '5', '5', ''])
 
 
 def test_mysql_set_variables(mysql_client, server_address):
@@ -362,7 +363,7 @@ def test_python_client(server_address):
 
 def test_golang_client(server_address, golang_container):
     # type: (str, Container) -> None
-    with open(os.path.join(SCRIPT_DIR, 'golang.reference')) as fp:
+    with open(os.path.join(SCRIPT_DIR, 'golang.reference'), 'rb') as fp:
         reference = fp.read()
 
     code, (stdout, stderr) = golang_container.exec_run(
@@ -370,7 +371,7 @@ def test_golang_client(server_address, golang_container):
         'abc'.format(host=server_address, port=server_port), demux=True)
 
     assert code == 1
-    assert stderr == "Error 81: Database abc doesn't exist
"
+    assert stderr.decode() == "Error 81: Database abc doesn't exist
"
 
     code, (stdout, stderr) = golang_container.exec_run(
         './main --host {host} --port {port} --user default --password 123 --database '
@@ -391,31 +392,31 @@ def test_php_client(server_address, php_container):
     code, (stdout, stderr) = php_container.exec_run(
         'php -f test.php {host} {port} default 123'.format(host=server_address, port=server_port), demux=True)
     assert code == 0
-    assert stdout == 'tables
'
+    assert stdout.decode() == 'tables
'
 
     code, (stdout, stderr) = php_container.exec_run(
         'php -f test_ssl.php {host} {port} default 123'.format(host=server_address, port=server_port), demux=True)
     assert code == 0
-    assert stdout == 'tables
'
+    assert stdout.decode() == 'tables
'
 
     code, (stdout, stderr) = php_container.exec_run(
         'php -f test.php {host} {port} user_with_double_sha1 abacaba'.format(host=server_address, port=server_port),
         demux=True)
     assert code == 0
-    assert stdout == 'tables
'
+    assert stdout.decode() == 'tables
'
 
     code, (stdout, stderr) = php_container.exec_run(
         'php -f test_ssl.php {host} {port} user_with_double_sha1 abacaba'.format(host=server_address, port=server_port),
         demux=True)
     assert code == 0
-    assert stdout == 'tables
'
+    assert stdout.decode() == 'tables
'
 
 
 def test_mysqljs_client(server_address, nodejs_container):
     code, (_, stderr) = nodejs_container.exec_run(
         'node test.js {host} {port} user_with_sha256 abacaba'.format(host=server_address, port=server_port), demux=True)
     assert code == 1
-    assert 'MySQL is requesting the sha256_password authentication method, which is not supported.' in stderr
+    assert 'MySQL is requesting the sha256_password authentication method, which is not supported.' in stderr.decode()
 
     code, (_, stderr) = nodejs_container.exec_run(
         'node test.js {host} {port} user_with_empty_password ""'.format(host=server_address, port=server_port),
@@ -449,21 +450,21 @@ def test_java_client(server_address, java_container):
         'java JavaConnectorTest --host {host} --port {port} --user user_with_empty_password --database '
         'default'.format(host=server_address, port=server_port), demux=True)
     assert code == 0
-    assert stdout == reference
+    assert stdout.decode() == reference
 
     # non-empty password passed.
     code, (stdout, stderr) = java_container.exec_run(
         'java JavaConnectorTest --host {host} --port {port} --user default --password 123 --database '
         'default'.format(host=server_address, port=server_port), demux=True)
     assert code == 0
-    assert stdout == reference
+    assert stdout.decode() == reference
 
     # double-sha1 password passed.
     code, (stdout, stderr) = java_container.exec_run(
         'java JavaConnectorTest --host {host} --port {port} --user user_with_double_sha1 --password abacaba  --database '
         'default'.format(host=server_address, port=server_port), demux=True)
     assert code == 0
-    assert stdout == reference
+    assert stdout.decode() == reference
 
 
 def test_types(server_address):
diff --git a/tests/integration/test_no_local_metadata_node/test.py b/tests/integration/test_no_local_metadata_node/test.py
index ae69f5e1384b..f976cc005bd9 100644
--- a/tests/integration/test_no_local_metadata_node/test.py
+++ b/tests/integration/test_no_local_metadata_node/test.py
@@ -47,7 +47,7 @@ def test_table_start_without_metadata(start_cluster):
 
     node1.query("DETACH TABLE test")
 
-    zk_cli.set("/clickhouse/table/test_table/replicas/1/metadata", "")
+    zk_cli.set("/clickhouse/table/test_table/replicas/1/metadata", b"")
 
     node1.query("ATTACH TABLE test")
 
diff --git a/tests/integration/test_non_default_compression/test.py b/tests/integration/test_non_default_compression/test.py
index 4706d8efbdde..03210e47081a 100644
--- a/tests/integration/test_non_default_compression/test.py
+++ b/tests/integration/test_non_default_compression/test.py
@@ -82,7 +82,7 @@ def test_preconfigured_custom_codec(start_cluster):
     assert node3.query(
         "SELECT max(length(data)) from compression_codec_multiple_with_key GROUP BY data ORDER BY max(length(data)) DESC LIMIT 1") == "10000
"
 
-    for i in xrange(10):
+    for i in range(10):
         node3.query(
             "INSERT INTO compression_codec_multiple_with_key VALUES(toDate('2018-10-12'), {}, '{}', 88.88)".format(i,
                                                                                                                    ''.join(
diff --git a/tests/integration/test_odbc_interaction/test.py b/tests/integration/test_odbc_interaction/test.py
index f527b4cc66e2..028137cef125 100644
--- a/tests/integration/test_odbc_interaction/test.py
+++ b/tests/integration/test_odbc_interaction/test.py
@@ -60,7 +60,7 @@ def started_cluster():
         cluster.start()
         sqlite_db = node1.odbc_drivers["SQLite3"]["Database"]
 
-        print "sqlite data received"
+        print("sqlite data received")
         node1.exec_in_container(
             ["bash", "-c", "echo 'CREATE TABLE t1(x INTEGER PRIMARY KEY ASC, y, z);' | sqlite3 {}".format(sqlite_db)],
             privileged=True, user='root')
@@ -73,18 +73,18 @@ def started_cluster():
         node1.exec_in_container(
             ["bash", "-c", "echo 'CREATE TABLE t4(X INTEGER PRIMARY KEY ASC, Y, Z);' | sqlite3 {}".format(sqlite_db)],
             privileged=True, user='root')
-        print "sqlite tables created"
+        print("sqlite tables created")
         mysql_conn = get_mysql_conn()
-        print "mysql connection received"
+        print("mysql connection received")
         ## create mysql db and table
         create_mysql_db(mysql_conn, 'clickhouse')
-        print "mysql database created"
+        print("mysql database created")
 
         postgres_conn = get_postgres_conn()
-        print "postgres connection received"
+        print("postgres connection received")
 
         create_postgres_db(postgres_conn, 'clickhouse')
-        print "postgres db created"
+        print("postgres db created")
 
         cursor = postgres_conn.cursor()
         cursor.execute(
@@ -259,7 +259,7 @@ def test_postgres_odbc_hached_dictionary_no_tty_pipe_overflow(started_cluster):
     conn = get_postgres_conn()
     cursor = conn.cursor()
     cursor.execute("insert into clickhouse.test_table values(3, 'xxx')")
-    for i in xrange(100):
+    for i in range(100):
         try:
             node1.query("system reload dictionary postgres_odbc_hashed", timeout=5)
         except Exception as ex:
diff --git a/tests/integration/test_partition/test.py b/tests/integration/test_partition/test.py
index 679c6fb8c5b5..b5facb5f4b2b 100644
--- a/tests/integration/test_partition/test.py
+++ b/tests/integration/test_partition/test.py
@@ -52,7 +52,7 @@ def partition_complex_assert_columns_txt():
     for part_name in parts.lines:
         path_to_columns = path_to_parts + part_name + '/columns.txt'
         # 2 header lines + 3 columns
-        assert exec_bash('cat {} | wc -l'.format(path_to_columns)) == u'5
'
+        assert exec_bash('cat {} | wc -l'.format(path_to_columns)) == '5
'
 
 
 def partition_complex_assert_checksums():
@@ -145,7 +145,7 @@ def cannot_attach_active_part_table(started_cluster):
 
 def test_cannot_attach_active_part(cannot_attach_active_part_table):
     error = instance.client.query_and_get_error("ALTER TABLE test.attach_active ATTACH PART '../1_2_2_0'")
-    print error
+    print(error)
     assert 0 <= error.find('Invalid part name')
 
     res = q("SElECT name FROM system.parts WHERE table='attach_active' AND database='test' ORDER BY name")
diff --git a/tests/integration/test_parts_delete_zookeeper/test.py b/tests/integration/test_parts_delete_zookeeper/test.py
index 7489b2411f93..8a4aafaa55ca 100644
--- a/tests/integration/test_parts_delete_zookeeper/test.py
+++ b/tests/integration/test_parts_delete_zookeeper/test.py
@@ -26,7 +26,7 @@ def start_cluster():
         yield cluster
 
     except Exception as ex:
-        print ex
+        print(ex)
 
     finally:
         cluster.shutdown()
diff --git a/tests/integration/test_postgresql_protocol/test.py b/tests/integration/test_postgresql_protocol/test.py
index 513bb75fcab1..52c911cb9391 100644
--- a/tests/integration/test_postgresql_protocol/test.py
+++ b/tests/integration/test_postgresql_protocol/test.py
@@ -1,6 +1,6 @@
 # -*- coding: utf-8 -*-
 
-from __future__ import print_function
+
 
 import datetime
 import decimal
@@ -81,10 +81,10 @@ def test_psql_client(psql_client, server_address):
     cmd_prefix += "--no-align --field-separator=' ' "
 
     code, (stdout, stderr) = psql_client.exec_run(cmd_prefix + '-c "SELECT 1 as a"', demux=True)
-    assert stdout == '
'.join(['a', '1', '(1 row)', ''])
+    assert stdout.decode() == '
'.join(['a', '1', '(1 row)', ''])
 
     code, (stdout, stderr) = psql_client.exec_run(cmd_prefix + '''-c "SELECT '' as a"''', demux=True)
-    assert stdout == '
'.join(['a', '', '(1 row)', ''])
+    assert stdout.decode() == '
'.join(['a', '', '(1 row)', ''])
 
     code, (stdout, stderr) = psql_client.exec_run(
         cmd_prefix + '-c ' +
@@ -98,7 +98,7 @@ def test_psql_client(psql_client, server_address):
         ''',
         demux=True
     )
-    assert stdout == '
'.join(['column', '0', '0', '1', '1', '5', '5', '(6 rows)', ''])
+    assert stdout.decode() == '
'.join(['column', '0', '0', '1', '1', '5', '5', '(6 rows)', ''])
 
     code, (stdout, stderr) = psql_client.exec_run(
         cmd_prefix + '-c ' +
@@ -110,7 +110,7 @@ def test_psql_client(psql_client, server_address):
         ''',
         demux=True
     )
-    assert stdout == '
'.join(['tmp_column', '0', '1', '(2 rows)', ''])
+    assert stdout.decode() == '
'.join(['tmp_column', '0', '1', '(2 rows)', ''])
 
 
 def test_python_client(server_address):
@@ -157,4 +157,4 @@ def test_java_client(server_address, java_container):
         'default'.format(host=server_address, port=server_port), demux=True)
     print(stdout, stderr, file=sys.stderr)
     assert code == 0
-    assert stdout == reference
+    assert stdout.decode() == reference
diff --git a/tests/integration/test_prometheus_endpoint/test.py b/tests/integration/test_prometheus_endpoint/test.py
index 909dbf139b98..06276803c3d0 100644
--- a/tests/integration/test_prometheus_endpoint/test.py
+++ b/tests/integration/test_prometheus_endpoint/test.py
@@ -1,4 +1,4 @@
-from __future__ import print_function
+
 
 import re
 import time
diff --git a/tests/integration/test_quota/test.py b/tests/integration/test_quota/test.py
index 5d2a4acffe6b..0614150ee071 100644
--- a/tests/integration/test_quota/test.py
+++ b/tests/integration/test_quota/test.py
@@ -15,14 +15,14 @@
 def check_system_quotas(canonical):
     canonical_tsv = TSV(canonical)
     r = TSV(instance.query("SELECT * FROM system.quotas ORDER BY name"))
-    print("system_quotas: {},
canonical: {}".format(r, TSV(canonical_tsv)))
+    print(("system_quotas: {},
canonical: {}".format(r, TSV(canonical_tsv))))
     assert r == canonical_tsv
 
 
 def system_quota_limits(canonical):
     canonical_tsv = TSV(canonical)
     r = TSV(instance.query("SELECT * FROM system.quota_limits ORDER BY quota_name, duration"))
-    print("system_quota_limits: {},
canonical: {}".format(r, TSV(canonical_tsv)))
+    print(("system_quota_limits: {},
canonical: {}".format(r, TSV(canonical_tsv))))
     assert r == canonical_tsv
 
 
@@ -32,7 +32,7 @@ def system_quota_usage(canonical):
             "result_bytes, max_result_bytes, read_rows, max_read_rows, read_bytes, max_read_bytes, max_execution_time " \
             "FROM system.quota_usage ORDER BY duration"
     r = TSV(instance.query(query))
-    print("system_quota_usage: {},
canonical: {}".format(r, TSV(canonical_tsv)))
+    print(("system_quota_usage: {},
canonical: {}".format(r, TSV(canonical_tsv))))
     assert r == canonical_tsv
 
 
@@ -42,7 +42,7 @@ def system_quotas_usage(canonical):
             "result_bytes, max_result_bytes, read_rows, max_read_rows, read_bytes, max_read_bytes, max_execution_time " \
             "FROM system.quotas_usage ORDER BY quota_name, quota_key, duration"
     r = TSV(instance.query(query))
-    print("system_quotas_usage: {},
canonical: {}".format(r, TSV(canonical_tsv)))
+    print(("system_quotas_usage: {},
canonical: {}".format(r, TSV(canonical_tsv))))
     assert r == canonical_tsv
 
 
@@ -81,18 +81,18 @@ def reset_quotas_and_usage_info():
 def test_quota_from_users_xml():
     check_system_quotas([["myQuota", "e651da9c-a748-8703-061a-7e5e5096dae7", "users.xml", "['user_name']", [31556952],
                           0, "['default']", "[]"]])
-    system_quota_limits([["myQuota", 31556952, 0, 1000, "\N", "\N", "\N", 1000, "\N", "\N"]])
-    system_quota_usage([["myQuota", "default", 31556952, 0, 1000, 0, "\N", 0, "\N", 0, "\N", 0, 1000, 0, "\N", "\N"]])
+    system_quota_limits([["myQuota", 31556952, 0, 1000, "\\N", "\\N", "\\N", 1000, "\\N", "\\N"]])
+    system_quota_usage([["myQuota", "default", 31556952, 0, 1000, 0, "\\N", 0, "\\N", 0, "\\N", 0, 1000, 0, "\\N", "\\N"]])
     system_quotas_usage(
-        [["myQuota", "default", 1, 31556952, 0, 1000, 0, "\N", 0, "\N", 0, "\N", 0, 1000, 0, "\N", "\N"]])
+        [["myQuota", "default", 1, 31556952, 0, 1000, 0, "\\N", 0, "\\N", 0, "\\N", 0, 1000, 0, "\\N", "\\N"]])
 
     instance.query("SELECT * from test_table")
     system_quota_usage(
-        [["myQuota", "default", 31556952, 1, 1000, 0, "\N", 50, "\N", 200, "\N", 50, 1000, 200, "\N", "\N"]])
+        [["myQuota", "default", 31556952, 1, 1000, 0, "\\N", 50, "\\N", 200, "\\N", 50, 1000, 200, "\\N", "\\N"]])
 
     instance.query("SELECT COUNT() from test_table")
     system_quota_usage(
-        [["myQuota", "default", 31556952, 2, 1000, 0, "\N", 51, "\N", 208, "\N", 50, 1000, 200, "\N", "\N"]])
+        [["myQuota", "default", 31556952, 2, 1000, 0, "\\N", 51, "\\N", 208, "\\N", 50, 1000, 200, "\\N", "\\N"]])
 
 
 def test_simpliest_quota():
@@ -102,11 +102,11 @@ def test_simpliest_quota():
                           "['default']", "[]"]])
     system_quota_limits("")
     system_quota_usage(
-        [["myQuota", "default", "\N", "\N", "\N", "\N", "\N", "\N", "\N", "\N", "\N", "\N", "\N", "\N", "\N", "\N"]])
+        [["myQuota", "default", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N"]])
 
     instance.query("SELECT * from test_table")
     system_quota_usage(
-        [["myQuota", "default", "\N", "\N", "\N", "\N", "\N", "\N", "\N", "\N", "\N", "\N", "\N", "\N", "\N", "\N"]])
+        [["myQuota", "default", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N"]])
 
 
 def test_tracking_quota():
@@ -114,16 +114,16 @@ def test_tracking_quota():
     copy_quota_xml('tracking.xml')
     check_system_quotas([["myQuota", "e651da9c-a748-8703-061a-7e5e5096dae7", "users.xml", "['user_name']", "[31556952]",
                           0, "['default']", "[]"]])
-    system_quota_limits([["myQuota", 31556952, 0, "\N", "\N", "\N", "\N", "\N", "\N", "\N"]])
-    system_quota_usage([["myQuota", "default", 31556952, 0, "\N", 0, "\N", 0, "\N", 0, "\N", 0, "\N", 0, "\N", "\N"]])
+    system_quota_limits([["myQuota", 31556952, 0, "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N"]])
+    system_quota_usage([["myQuota", "default", 31556952, 0, "\\N", 0, "\\N", 0, "\\N", 0, "\\N", 0, "\\N", 0, "\\N", "\\N"]])
 
     instance.query("SELECT * from test_table")
     system_quota_usage(
-        [["myQuota", "default", 31556952, 1, "\N", 0, "\N", 50, "\N", 200, "\N", 50, "\N", 200, "\N", "\N"]])
+        [["myQuota", "default", 31556952, 1, "\\N", 0, "\\N", 50, "\\N", 200, "\\N", 50, "\\N", 200, "\\N", "\\N"]])
 
     instance.query("SELECT COUNT() from test_table")
     system_quota_usage(
-        [["myQuota", "default", 31556952, 2, "\N", 0, "\N", 51, "\N", 208, "\N", 50, "\N", 200, "\N", "\N"]])
+        [["myQuota", "default", 31556952, 2, "\\N", 0, "\\N", 51, "\\N", 208, "\\N", 50, "\\N", 200, "\\N", "\\N"]])
 
 
 def test_exceed_quota():
@@ -131,55 +131,55 @@ def test_exceed_quota():
     copy_quota_xml('tiny_limits.xml')
     check_system_quotas([["myQuota", "e651da9c-a748-8703-061a-7e5e5096dae7", "users.xml", "['user_name']", "[31556952]",
                           0, "['default']", "[]"]])
-    system_quota_limits([["myQuota", 31556952, 0, 1, 1, 1, "\N", 1, "\N", "\N"]])
-    system_quota_usage([["myQuota", "default", 31556952, 0, 1, 0, 1, 0, 1, 0, "\N", 0, 1, 0, "\N", "\N"]])
+    system_quota_limits([["myQuota", 31556952, 0, 1, 1, 1, "\\N", 1, "\\N", "\\N"]])
+    system_quota_usage([["myQuota", "default", 31556952, 0, 1, 0, 1, 0, 1, 0, "\\N", 0, 1, 0, "\\N", "\\N"]])
 
     assert re.search("Quota.*has\ been\ exceeded", instance.query_and_get_error("SELECT * from test_table"))
-    system_quota_usage([["myQuota", "default", 31556952, 1, 1, 1, 1, 0, 1, 0, "\N", 50, 1, 0, "\N", "\N"]])
+    system_quota_usage([["myQuota", "default", 31556952, 1, 1, 1, 1, 0, 1, 0, "\\N", 50, 1, 0, "\\N", "\\N"]])
 
     # Change quota, now the limits are enough to execute queries.
     copy_quota_xml('normal_limits.xml')
     check_system_quotas([["myQuota", "e651da9c-a748-8703-061a-7e5e5096dae7", "users.xml", "['user_name']", "[31556952]",
                           0, "['default']", "[]"]])
-    system_quota_limits([["myQuota", 31556952, 0, 1000, "\N", "\N", "\N", 1000, "\N", "\N"]])
-    system_quota_usage([["myQuota", "default", 31556952, 1, 1000, 1, "\N", 0, "\N", 0, "\N", 50, 1000, 0, "\N", "\N"]])
+    system_quota_limits([["myQuota", 31556952, 0, 1000, "\\N", "\\N", "\\N", 1000, "\\N", "\\N"]])
+    system_quota_usage([["myQuota", "default", 31556952, 1, 1000, 1, "\\N", 0, "\\N", 0, "\\N", 50, 1000, 0, "\\N", "\\N"]])
 
     instance.query("SELECT * from test_table")
     system_quota_usage(
-        [["myQuota", "default", 31556952, 2, 1000, 1, "\N", 50, "\N", 200, "\N", 100, 1000, 200, "\N", "\N"]])
+        [["myQuota", "default", 31556952, 2, 1000, 1, "\\N", 50, "\\N", 200, "\\N", 100, 1000, 200, "\\N", "\\N"]])
 
 
 def test_add_remove_interval():
     check_system_quotas([["myQuota", "e651da9c-a748-8703-061a-7e5e5096dae7", "users.xml", "['user_name']", [31556952],
                           0, "['default']", "[]"]])
-    system_quota_limits([["myQuota", 31556952, 0, 1000, "\N", "\N", "\N", 1000, "\N", "\N"]])
-    system_quota_usage([["myQuota", "default", 31556952, 0, 1000, 0, "\N", 0, "\N", 0, "\N", 0, 1000, 0, "\N", "\N"]])
+    system_quota_limits([["myQuota", 31556952, 0, 1000, "\\N", "\\N", "\\N", 1000, "\\N", "\\N"]])
+    system_quota_usage([["myQuota", "default", 31556952, 0, 1000, 0, "\\N", 0, "\\N", 0, "\\N", 0, 1000, 0, "\\N", "\\N"]])
 
     # Add interval.
     copy_quota_xml('two_intervals.xml')
     check_system_quotas([["myQuota", "e651da9c-a748-8703-061a-7e5e5096dae7", "users.xml", "['user_name']",
                           "[31556952,63113904]", 0, "['default']", "[]"]])
-    system_quota_limits([["myQuota", 31556952, 0, 1000, "\N", "\N", "\N", 1000, "\N", "\N"],
-                         ["myQuota", 63113904, 1, "\N", "\N", "\N", 30000, "\N", 20000, 120]])
-    system_quota_usage([["myQuota", "default", 31556952, 0, 1000, 0, "\N", 0, "\N", 0, "\N", 0, 1000, 0, "\N", "\N"],
-                        ["myQuota", "default", 63113904, 0, "\N", 0, "\N", 0, "\N", 0, 30000, 0, "\N", 0, 20000, 120]])
+    system_quota_limits([["myQuota", 31556952, 0, 1000, "\\N", "\\N", "\\N", 1000, "\\N", "\\N"],
+                         ["myQuota", 63113904, 1, "\\N", "\\N", "\\N", 30000, "\\N", 20000, 120]])
+    system_quota_usage([["myQuota", "default", 31556952, 0, 1000, 0, "\\N", 0, "\\N", 0, "\\N", 0, 1000, 0, "\\N", "\\N"],
+                        ["myQuota", "default", 63113904, 0, "\\N", 0, "\\N", 0, "\\N", 0, 30000, 0, "\\N", 0, 20000, 120]])
 
     instance.query("SELECT * from test_table")
     system_quota_usage(
-        [["myQuota", "default", 31556952, 1, 1000, 0, "\N", 50, "\N", 200, "\N", 50, 1000, 200, "\N", "\N"],
-         ["myQuota", "default", 63113904, 1, "\N", 0, "\N", 50, "\N", 200, 30000, 50, "\N", 200, 20000, 120]])
+        [["myQuota", "default", 31556952, 1, 1000, 0, "\\N", 50, "\\N", 200, "\\N", 50, 1000, 200, "\\N", "\\N"],
+         ["myQuota", "default", 63113904, 1, "\\N", 0, "\\N", 50, "\\N", 200, 30000, 50, "\\N", 200, 20000, 120]])
 
     # Remove interval.
     copy_quota_xml('normal_limits.xml')
     check_system_quotas([["myQuota", "e651da9c-a748-8703-061a-7e5e5096dae7", "users.xml", "['user_name']", [31556952],
                           0, "['default']", "[]"]])
-    system_quota_limits([["myQuota", 31556952, 0, 1000, "\N", "\N", "\N", 1000, "\N", "\N"]])
+    system_quota_limits([["myQuota", 31556952, 0, 1000, "\\N", "\\N", "\\N", 1000, "\\N", "\\N"]])
     system_quota_usage(
-        [["myQuota", "default", 31556952, 1, 1000, 0, "\N", 50, "\N", 200, "\N", 50, 1000, 200, "\N", "\N"]])
+        [["myQuota", "default", 31556952, 1, 1000, 0, "\\N", 50, "\\N", 200, "\\N", 50, 1000, 200, "\\N", "\\N"]])
 
     instance.query("SELECT * from test_table")
     system_quota_usage(
-        [["myQuota", "default", 31556952, 2, 1000, 0, "\N", 100, "\N", 400, "\N", 100, 1000, 400, "\N", "\N"]])
+        [["myQuota", "default", 31556952, 2, 1000, 0, "\\N", 100, "\\N", 400, "\\N", 100, 1000, 400, "\\N", "\\N"]])
 
     # Remove all intervals.
     copy_quota_xml('simpliest.xml')
@@ -187,26 +187,26 @@ def test_add_remove_interval():
                           "['default']", "[]"]])
     system_quota_limits("")
     system_quota_usage(
-        [["myQuota", "default", "\N", "\N", "\N", "\N", "\N", "\N", "\N", "\N", "\N", "\N", "\N", "\N", "\N", "\N"]])
+        [["myQuota", "default", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N"]])
 
     instance.query("SELECT * from test_table")
     system_quota_usage(
-        [["myQuota", "default", "\N", "\N", "\N", "\N", "\N", "\N", "\N", "\N", "\N", "\N", "\N", "\N", "\N", "\N"]])
+        [["myQuota", "default", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", "\\N"]])
 
     # Add one interval back.
     copy_quota_xml('normal_limits.xml')
     check_system_quotas([["myQuota", "e651da9c-a748-8703-061a-7e5e5096dae7", "users.xml", "['user_name']", [31556952],
                           0, "['default']", "[]"]])
-    system_quota_limits([["myQuota", 31556952, 0, 1000, "\N", "\N", "\N", 1000, "\N", "\N"]])
-    system_quota_usage([["myQuota", "default", 31556952, 0, 1000, 0, "\N", 0, "\N", 0, "\N", 0, 1000, 0, "\N", "\N"]])
+    system_quota_limits([["myQuota", 31556952, 0, 1000, "\\N", "\\N", "\\N", 1000, "\\N", "\\N"]])
+    system_quota_usage([["myQuota", "default", 31556952, 0, 1000, 0, "\\N", 0, "\\N", 0, "\\N", 0, 1000, 0, "\\N", "\\N"]])
 
 
 def test_add_remove_quota():
     check_system_quotas([["myQuota", "e651da9c-a748-8703-061a-7e5e5096dae7", "users.xml", "['user_name']", [31556952],
                           0, "['default']", "[]"]])
-    system_quota_limits([["myQuota", 31556952, 0, 1000, "\N", "\N", "\N", 1000, "\N", "\N"]])
+    system_quota_limits([["myQuota", 31556952, 0, 1000, "\\N", "\\N", "\\N", 1000, "\\N", "\\N"]])
     system_quotas_usage(
-        [["myQuota", "default", 1, 31556952, 0, 1000, 0, "\N", 0, "\N", 0, "\N", 0, 1000, 0, "\N", "\N"]])
+        [["myQuota", "default", 1, 31556952, 0, 1000, 0, "\\N", 0, "\\N", 0, "\\N", 0, 1000, 0, "\\N", "\\N"]])
 
     # Add quota.
     copy_quota_xml('two_quotas.xml')
@@ -214,19 +214,19 @@ def test_add_remove_quota():
                           0, "['default']", "[]"],
                          ["myQuota2", "4590510c-4d13-bf21-ec8a-c2187b092e73", "users.xml", "['client_key','user_name']",
                           "[3600,2629746]", 0, "[]", "[]"]])
-    system_quota_limits([["myQuota", 31556952, 0, 1000, "\N", "\N", "\N", 1000, "\N", "\N"],
-                         ["myQuota2", 3600, 1, "\N", "\N", 4000, 400000, 4000, 400000, 60],
-                         ["myQuota2", 2629746, 0, "\N", "\N", "\N", "\N", "\N", "\N", 1800]])
+    system_quota_limits([["myQuota", 31556952, 0, 1000, "\\N", "\\N", "\\N", 1000, "\\N", "\\N"],
+                         ["myQuota2", 3600, 1, "\\N", "\\N", 4000, 400000, 4000, 400000, 60],
+                         ["myQuota2", 2629746, 0, "\\N", "\\N", "\\N", "\\N", "\\N", "\\N", 1800]])
     system_quotas_usage(
-        [["myQuota", "default", 1, 31556952, 0, 1000, 0, "\N", 0, "\N", 0, "\N", 0, 1000, 0, "\N", "\N"]])
+        [["myQuota", "default", 1, 31556952, 0, 1000, 0, "\\N", 0, "\\N", 0, "\\N", 0, 1000, 0, "\\N", "\\N"]])
 
     # Drop quota.
     copy_quota_xml('normal_limits.xml')
     check_system_quotas([["myQuota", "e651da9c-a748-8703-061a-7e5e5096dae7", "users.xml", "['user_name']", "[31556952]",
                           0, "['default']", "[]"]])
-    system_quota_limits([["myQuota", 31556952, 0, 1000, "\N", "\N", "\N", 1000, "\N", "\N"]])
+    system_quota_limits([["myQuota", 31556952, 0, 1000, "\\N", "\\N", "\\N", 1000, "\\N", "\\N"]])
     system_quotas_usage(
-        [["myQuota", "default", 1, 31556952, 0, 1000, 0, "\N", 0, "\N", 0, "\N", 0, 1000, 0, "\N", "\N"]])
+        [["myQuota", "default", 1, 31556952, 0, 1000, 0, "\\N", 0, "\\N", 0, "\\N", 0, 1000, 0, "\\N", "\\N"]])
 
     # Drop all quotas.
     copy_quota_xml('no_quotas.xml')
@@ -238,15 +238,15 @@ def test_add_remove_quota():
     copy_quota_xml('normal_limits.xml')
     check_system_quotas([["myQuota", "e651da9c-a748-8703-061a-7e5e5096dae7", "users.xml", "['user_name']", "[31556952]",
                           0, "['default']", "[]"]])
-    system_quota_limits([["myQuota", 31556952, 0, 1000, "\N", "\N", "\N", 1000, "\N", "\N"]])
+    system_quota_limits([["myQuota", 31556952, 0, 1000, "\\N", "\\N", "\\N", 1000, "\\N", "\\N"]])
     system_quotas_usage(
-        [["myQuota", "default", 1, 31556952, 0, 1000, 0, "\N", 0, "\N", 0, "\N", 0, 1000, 0, "\N", "\N"]])
+        [["myQuota", "default", 1, 31556952, 0, 1000, 0, "\\N", 0, "\\N", 0, "\\N", 0, 1000, 0, "\\N", "\\N"]])
 
 
 def test_reload_users_xml_by_timer():
     check_system_quotas([["myQuota", "e651da9c-a748-8703-061a-7e5e5096dae7", "users.xml", "['user_name']", "[31556952]",
                           0, "['default']", "[]"]])
-    system_quota_limits([["myQuota", 31556952, 0, 1000, "\N", "\N", "\N", 1000, "\N", "\N"]])
+    system_quota_limits([["myQuota", 31556952, 0, 1000, "\\N", "\\N", "\\N", 1000, "\\N", "\\N"]])
 
     time.sleep(1)  # The modification time of the 'quota.xml' file should be different,
     # because config files are reload by timer only when the modification time is changed.
@@ -255,7 +255,7 @@ def test_reload_users_xml_by_timer():
         ["myQuota", "e651da9c-a748-8703-061a-7e5e5096dae7", "users.xml", ['user_name'], "[31556952]", 0, "['default']",
          "[]"]])
     assert_eq_with_retry(instance, "SELECT * FROM system.quota_limits",
-                         [["myQuota", 31556952, 0, 1, 1, 1, "\N", 1, "\N", "\N"]])
+                         [["myQuota", 31556952, 0, 1, 1, 1, "\\N", 1, "\\N", "\\N"]])
 
 
 def test_dcl_introspection():
diff --git a/tests/integration/test_random_inserts/test.py b/tests/integration/test_random_inserts/test.py
index f43581b64828..a06649dba525 100644
--- a/tests/integration/test_random_inserts/test.py
+++ b/tests/integration/test_random_inserts/test.py
@@ -55,7 +55,7 @@ def test_random_inserts(started_cluster):
             cmd = ['/bin/bash', bash_script, node.ip_address, str(min_timestamp), str(max_timestamp),
                    str(cluster.get_client_cmd())]
             inserters.append(CommandRequest(cmd, timeout=DURATION_SECONDS * 2, stdin=''))
-            print node.name, node.ip_address
+            print(node.name, node.ip_address)
 
         for inserter in inserters:
             inserter.get_answer()
@@ -105,8 +105,8 @@ def do_insert(self, thread_num):
                     self.total_inserted += 2 * x + 1
                 self.mtx.release()
 
-            except Exception, e:
-                print 'Exception:', e
+            except Exception as e:
+                print('Exception:', e)
 
             x += 2
             self.stop_ev.wait(0.1 + random.random() / 10)
diff --git a/tests/integration/test_recompression_ttl/test.py b/tests/integration/test_recompression_ttl/test.py
index 9a96151d04a5..e74ae928b51a 100644
--- a/tests/integration/test_recompression_ttl/test.py
+++ b/tests/integration/test_recompression_ttl/test.py
@@ -16,7 +16,7 @@ def started_cluster():
         yield cluster
 
     except Exception as ex:
-        print ex
+        print(ex)
 
     finally:
         cluster.shutdown()
diff --git a/tests/integration/test_recovery_replica/test.py b/tests/integration/test_recovery_replica/test.py
index 74e773cfb835..9320a176f1ea 100644
--- a/tests/integration/test_recovery_replica/test.py
+++ b/tests/integration/test_recovery_replica/test.py
@@ -31,7 +31,7 @@ def start_cluster():
         yield cluster
 
     except Exception as ex:
-        print ex
+        print(ex)
 
     finally:
         cluster.shutdown()
diff --git a/tests/integration/test_reload_max_table_size_to_drop/test.py b/tests/integration/test_reload_max_table_size_to_drop/test.py
index d6bdcc839455..5f2083d742ec 100644
--- a/tests/integration/test_reload_max_table_size_to_drop/test.py
+++ b/tests/integration/test_reload_max_table_size_to_drop/test.py
@@ -34,8 +34,7 @@ def test_reload_max_table_size_to_drop(start_cluster):
     config = open(CONFIG_PATH, 'r')
     config_lines = config.readlines()
     config.close()
-    config_lines = map(lambda line: line.replace("<max_table_size_to_drop>1", "<max_table_size_to_drop>1000000"),
-                       config_lines)
+    config_lines = [line.replace("<max_table_size_to_drop>1", "<max_table_size_to_drop>1000000") for line in config_lines]
     config = open(CONFIG_PATH, 'w')
     config.writelines(config_lines)
     config.close()
diff --git a/tests/integration/test_reload_zookeeper/test.py b/tests/integration/test_reload_zookeeper/test.py
index 66df5a1a1267..35958c954172 100644
--- a/tests/integration/test_reload_zookeeper/test.py
+++ b/tests/integration/test_reload_zookeeper/test.py
@@ -65,7 +65,7 @@ def wait_zookeeper_node_to_start(zk_nodes, timeout=60):
                 print("All instances of ZooKeeper started")
                 return
             except Exception as ex:
-                print("Can't connect to ZooKeeper " + str(ex))
+                print(("Can't connect to ZooKeeper " + str(ex)))
                 time.sleep(0.5)
 
     node.query("INSERT INTO test_table(date, id) select today(), number FROM numbers(1000)")
diff --git a/tests/integration/test_reloading_storage_configuration/test.py b/tests/integration/test_reloading_storage_configuration/test.py
index 0c3139c7fddc..edcba4e8a604 100644
--- a/tests/integration/test_reloading_storage_configuration/test.py
+++ b/tests/integration/test_reloading_storage_configuration/test.py
@@ -82,7 +82,7 @@ def add_policy(node, name, volumes):
     root = tree.getroot()
     new_policy = ET.Element(name)
     new_volumes = ET.Element("volumes")
-    for volume, disks in volumes.items():
+    for volume, disks in list(volumes.items()):
         new_volume = ET.Element(volume)
         for disk in disks:
             new_disk = ET.Element("disk")
diff --git a/tests/integration/test_rename_column/test.py b/tests/integration/test_rename_column/test.py
index b7ab8a75ba5d..0e5cc9f5d9d3 100644
--- a/tests/integration/test_rename_column/test.py
+++ b/tests/integration/test_rename_column/test.py
@@ -1,4 +1,4 @@
-from __future__ import print_function
+
 
 import random
 import time
diff --git a/tests/integration/test_replicated_merge_tree_s3/test.py b/tests/integration/test_replicated_merge_tree_s3/test.py
index 4d19793d0b20..3b3540ef1b89 100644
--- a/tests/integration/test_replicated_merge_tree_s3/test.py
+++ b/tests/integration/test_replicated_merge_tree_s3/test.py
@@ -63,13 +63,13 @@ def create_table(cluster, additional_settings=None):
         create_table_statement += ","
         create_table_statement += additional_settings
 
-    cluster.instances.values()[0].query(create_table_statement)
+    list(cluster.instances.values())[0].query(create_table_statement)
 
 
 @pytest.fixture(autouse=True)
 def drop_table(cluster):
     yield
-    for node in cluster.instances.values():
+    for node in list(cluster.instances.values()):
         node.query("DROP TABLE IF EXISTS s3_test")
 
     minio = cluster.minio_client
diff --git a/tests/integration/test_replicated_mutations/test.py b/tests/integration/test_replicated_mutations/test.py
index cf3cef3a9e61..40a2b15ffaff 100644
--- a/tests/integration/test_replicated_mutations/test.py
+++ b/tests/integration/test_replicated_mutations/test.py
@@ -90,7 +90,7 @@ def do_insert(self, thread_num, partitions_num):
                 i += 1
 
             try:
-                print 'thread {}: insert for {}: {}'.format(thread_num, date_str, ','.join(str(x) for x in xs))
+                print('thread {}: insert for {}: {}'.format(thread_num, date_str, ','.join(str(x) for x in xs)))
                 random.choice(self.nodes).query("INSERT INTO test_mutations FORMAT TSV", payload)
 
                 with self.mtx:
@@ -99,8 +99,8 @@ def do_insert(self, thread_num, partitions_num):
                     self.total_inserted_xs += sum(xs)
                     self.total_inserted_rows += len(xs)
 
-            except Exception, e:
-                print 'Exception while inserting,', e
+            except Exception as e:
+                print('Exception while inserting,', e)
                 self.exceptions.append(e)
             finally:
                 with self.mtx:
@@ -128,7 +128,7 @@ def do_delete(self, thread_num):
                 continue
 
             try:
-                print 'thread {}: delete {} * {}'.format(thread_num, to_delete_count, x)
+                print('thread {}: delete {} * {}'.format(thread_num, to_delete_count, x))
                 random.choice(self.nodes).query("ALTER TABLE test_mutations DELETE WHERE x = {}".format(x))
 
                 with self.mtx:
@@ -137,8 +137,8 @@ def do_delete(self, thread_num):
                     self.total_deleted_xs += to_delete_count * x
                     self.total_deleted_rows += to_delete_count
 
-            except Exception, e:
-                print 'Exception while deleting,', e
+            except Exception as e:
+                print('Exception while deleting,', e)
             finally:
                 with self.mtx:
                     self.currently_deleting_xs.remove(x)
@@ -186,10 +186,10 @@ def test_mutations(started_cluster):
 
     all_done = wait_for_mutations(nodes, runner.total_mutations)
 
-    print "Total mutations: ", runner.total_mutations
+    print("Total mutations: ", runner.total_mutations)
     for node in nodes:
-        print node.query(
-            "SELECT mutation_id, command, parts_to_do, is_done FROM system.mutations WHERE table = 'test_mutations' FORMAT TSVWithNames")
+        print(node.query(
+            "SELECT mutation_id, command, parts_to_do, is_done FROM system.mutations WHERE table = 'test_mutations' FORMAT TSVWithNames"))
     assert all_done
 
     expected_sum = runner.total_inserted_xs - runner.total_deleted_xs
@@ -233,10 +233,10 @@ def test_mutations_dont_prevent_merges(started_cluster, nodes):
         t.join()
 
     for node in nodes:
-        print node.query(
-            "SELECT mutation_id, command, parts_to_do, is_done FROM system.mutations WHERE table = 'test_mutations' FORMAT TSVWithNames")
-        print node.query(
-            "SELECT partition, count(name), sum(active), sum(active*rows) FROM system.parts WHERE table ='test_mutations' GROUP BY partition FORMAT TSVWithNames")
+        print(node.query(
+            "SELECT mutation_id, command, parts_to_do, is_done FROM system.mutations WHERE table = 'test_mutations' FORMAT TSVWithNames"))
+        print(node.query(
+            "SELECT partition, count(name), sum(active), sum(active*rows) FROM system.parts WHERE table ='test_mutations' GROUP BY partition FORMAT TSVWithNames"))
 
     assert all_done
     assert all([str(e).find("Too many parts") < 0 for e in runner.exceptions])
diff --git a/tests/integration/test_replicated_parse_zk_metadata/test.py b/tests/integration/test_replicated_parse_zk_metadata/test.py
index 4bdd77393b38..d8b6685ddcda 100644
--- a/tests/integration/test_replicated_parse_zk_metadata/test.py
+++ b/tests/integration/test_replicated_parse_zk_metadata/test.py
@@ -33,7 +33,7 @@ def test_replicated_engine_parse_metadata_on_attach():
     # and successfully accepted by the server.
     #
     # This metadata was obtain from the server without #11325
-    zk.set('/ch/tables/default/data/replicas/node/metadata', """
+    zk.set('/ch/tables/default/data/replicas/node/metadata', b"""
 metadata format version: 1
 date column: 
 sampling expression: 
diff --git a/tests/integration/test_replication_without_zookeeper/test.py b/tests/integration/test_replication_without_zookeeper/test.py
index 90f060d991a6..26347b47d365 100644
--- a/tests/integration/test_replication_without_zookeeper/test.py
+++ b/tests/integration/test_replication_without_zookeeper/test.py
@@ -23,7 +23,7 @@ def start_cluster():
         yield cluster
 
     except Exception as ex:
-        print ex
+        print(ex)
 
     finally:
         cluster.shutdown()
diff --git a/tests/integration/test_role/test.py b/tests/integration/test_role/test.py
index 31fddd3df8ce..ccd3477ed722 100644
--- a/tests/integration/test_role/test.py
+++ b/tests/integration/test_role/test.py
@@ -184,15 +184,15 @@ def test_introspection():
 
     assert instance.query(
         "SELECT * from system.grants WHERE user_name IN ('A', 'B') OR role_name IN ('R1', 'R2') ORDER BY user_name, role_name, access_type, grant_option") == \
-           TSV([["A", "\N", "SELECT", "test", "table", "\N", 0, 0],
-                ["B", "\N", "CREATE", "\N", "\N", "\N", 0, 1],
-                ["\N", "R2", "SELECT", "test", "table", "\N", 0, 0],
-                ["\N", "R2", "SELECT", "test", "table", "x", 1, 0]])
+           TSV([["A", "\\N", "SELECT", "test", "table", "\\N", 0, 0],
+                ["B", "\\N", "CREATE", "\\N", "\\N", "\\N", 0, 1],
+                ["\\N", "R2", "SELECT", "test", "table", "\\N", 0, 0],
+                ["\\N", "R2", "SELECT", "test", "table", "x", 1, 0]])
 
     assert instance.query(
         "SELECT * from system.role_grants WHERE user_name IN ('A', 'B') OR role_name IN ('R1', 'R2') ORDER BY user_name, role_name, granted_role_name") == \
-           TSV([["A", "\N", "R1", 1, 0],
-                ["B", "\N", "R2", 1, 1]])
+           TSV([["A", "\\N", "R1", 1, 0],
+                ["B", "\\N", "R2", 1, 1]])
 
     assert instance.query("SELECT * from system.current_roles ORDER BY role_name", user='A') == TSV([["R1", 0, 1]])
     assert instance.query("SELECT * from system.current_roles ORDER BY role_name", user='B') == TSV([["R2", 1, 1]])
diff --git a/tests/integration/test_send_crash_reports/fake_sentry_server.py b/tests/integration/test_send_crash_reports/fake_sentry_server.py
index 49463bdb1332..fa40f642e417 100644
--- a/tests/integration/test_send_crash_reports/fake_sentry_server.py
+++ b/tests/integration/test_send_crash_reports/fake_sentry_server.py
@@ -1,17 +1,18 @@
-import BaseHTTPServer
+import http.server
 
 RESULT_PATH = '/result.txt'
 
 
-class SentryHandler(BaseHTTPServer.BaseHTTPRequestHandler):
+class SentryHandler(http.server.BaseHTTPRequestHandler):
     def do_POST(self):
         post_data = self.__read_and_decode_post_data()
         with open(RESULT_PATH, 'w') as f:
+            content_length = self.headers.get("content-length")
             if self.headers.get("content-type") != "application/x-sentry-envelope":
                 f.write("INCORRECT_CONTENT_TYPE")
-            elif self.headers.get("content-length") < 3000:
-                f.write("INCORRECT_CONTENT_LENGTH")
-            elif '"http://6f33034cfe684dd7a3ab9875e57b1c8d@localhost:9500/5226277"' not in post_data:
+            elif int(content_length) < 200:
+                f.write("INCORRECT_CONTENT_LENGTH:" + content_length + '
' + post_data.decode())
+            elif b'"http://6f33034cfe684dd7a3ab9875e57b1c8d@localhost:9500/5226277"' not in post_data:
                 f.write('INCORRECT_POST_DATA')
             else:
                 f.write("OK")
@@ -19,7 +20,7 @@ def do_POST(self):
 
     def __read_and_decode_post_data(self):
         transfer_encoding = self.headers.get("transfer-Encoding")
-        decoded = ""
+        decoded = b""
         if transfer_encoding == "chunked":
             while True:
                 s = self.rfile.readline()
@@ -37,7 +38,7 @@ def __read_and_decode_post_data(self):
 if __name__ == "__main__":
     with open(RESULT_PATH, 'w') as f:
         f.write("INITIAL_STATE")
-    httpd = BaseHTTPServer.HTTPServer(("localhost", 9500,), SentryHandler)
+    httpd = http.server.HTTPServer(("localhost", 9500,), SentryHandler)
     try:
         httpd.serve_forever()
     finally:
diff --git a/tests/integration/test_send_crash_reports/test.py b/tests/integration/test_send_crash_reports/test.py
index 4c832d9d67c1..a3c35ca1537c 100644
--- a/tests/integration/test_send_crash_reports/test.py
+++ b/tests/integration/test_send_crash_reports/test.py
@@ -5,7 +5,7 @@
 import helpers.test_tools
 import pytest
 
-import fake_sentry_server
+from . import fake_sentry_server
 
 SCRIPT_DIR = os.path.dirname(os.path.realpath(__file__))
 
@@ -25,7 +25,7 @@ def started_node():
 
 def test_send_segfault(started_node, ):
     started_node.copy_file_to_container(os.path.join(SCRIPT_DIR, "fake_sentry_server.py"), "/fake_sentry_server.py")
-    started_node.exec_in_container(["bash", "-c", "python2 /fake_sentry_server.py"], detach=True, user="root")
+    started_node.exec_in_container(["bash", "-c", "python3 /fake_sentry_server.py > /fake_sentry_server.log 2>&1"], detach=True, user="root")
     time.sleep(0.5)
     started_node.exec_in_container(["bash", "-c", "pkill -11 clickhouse"], user="root")
 
diff --git a/tests/integration/test_settings_constraints/test.py b/tests/integration/test_settings_constraints/test.py
index 90e639685f03..18c80d9c1da2 100644
--- a/tests/integration/test_settings_constraints/test.py
+++ b/tests/integration/test_settings_constraints/test.py
@@ -116,7 +116,7 @@ def assert_query_settings(instance, query, settings, result=None, exception=None
     # session level settings
     queries = ""
 
-    for k, v in settings.items():
+    for k, v in list(settings.items()):
         queries += "SET {}={};
".format(k, v)
 
     queries += query
diff --git a/tests/integration/test_settings_profile/test.py b/tests/integration/test_settings_profile/test.py
index f7901dc1fe6c..5345ef9a4746 100644
--- a/tests/integration/test_settings_profile/test.py
+++ b/tests/integration/test_settings_profile/test.py
@@ -59,7 +59,7 @@ def test_smoke():
         "SET max_memory_usage = 120000000", user="robin")
     assert system_settings_profile("xyz") == [["xyz", "local directory", 1, 0, "['robin']", "[]"]]
     assert system_settings_profile_elements(profile_name="xyz") == [
-        ["xyz", "\N", "\N", 0, "max_memory_usage", 100000001, 90000000, 110000000, "\N", "\N"]]
+        ["xyz", "\\N", "\\N", 0, "max_memory_usage", 100000001, 90000000, 110000000, "\\N", "\\N"]]
 
     instance.query("ALTER SETTINGS PROFILE xyz TO NONE")
     assert instance.query(
@@ -81,7 +81,7 @@ def test_smoke():
     assert "Setting max_memory_usage shouldn't be greater than 110000000" in instance.query_and_get_error(
         "SET max_memory_usage = 120000000", user="robin")
     assert system_settings_profile_elements(user_name="robin") == [
-        ["\N", "robin", "\N", 0, "\N", "\N", "\N", "\N", "\N", "xyz"]]
+        ["\\N", "robin", "\\N", 0, "\\N", "\\N", "\\N", "\\N", "\\N", "xyz"]]
 
     instance.query("ALTER USER robin SETTINGS NONE")
     assert instance.query("SHOW CREATE USER robin") == "CREATE USER robin
"
@@ -108,10 +108,10 @@ def test_settings_from_granted_role():
         "SET max_memory_usage = 120000000", user="robin")
     assert system_settings_profile("xyz") == [["xyz", "local directory", 2, 0, "[]", "[]"]]
     assert system_settings_profile_elements(profile_name="xyz") == [
-        ["xyz", "\N", "\N", 0, "max_memory_usage", 100000001, "\N", 110000000, "\N", "\N"],
-        ["xyz", "\N", "\N", 1, "max_ast_depth", 2000, "\N", "\N", "\N", "\N"]]
+        ["xyz", "\\N", "\\N", 0, "max_memory_usage", 100000001, "\\N", 110000000, "\\N", "\\N"],
+        ["xyz", "\\N", "\\N", 1, "max_ast_depth", 2000, "\\N", "\\N", "\\N", "\\N"]]
     assert system_settings_profile_elements(role_name="worker") == [
-        ["\N", "\N", "worker", 0, "\N", "\N", "\N", "\N", "\N", "xyz"]]
+        ["\\N", "\\N", "worker", 0, "\\N", "\\N", "\\N", "\\N", "\\N", "xyz"]]
 
     instance.query("REVOKE worker FROM robin")
     assert instance.query("SELECT value FROM system.settings WHERE name = 'max_memory_usage'",
@@ -159,10 +159,10 @@ def test_inheritance():
 
     assert system_settings_profile("xyz") == [["xyz", "local directory", 1, 0, "[]", "[]"]]
     assert system_settings_profile_elements(profile_name="xyz") == [
-        ["xyz", "\N", "\N", 0, "max_memory_usage", 100000002, "\N", "\N", 1, "\N"]]
+        ["xyz", "\\N", "\\N", 0, "max_memory_usage", 100000002, "\\N", "\\N", 1, "\\N"]]
     assert system_settings_profile("alpha") == [["alpha", "local directory", 1, 0, "['robin']", "[]"]]
     assert system_settings_profile_elements(profile_name="alpha") == [
-        ["alpha", "\N", "\N", 0, "\N", "\N", "\N", "\N", "\N", "xyz"]]
+        ["alpha", "\\N", "\\N", 0, "\\N", "\\N", "\\N", "\\N", "\\N", "xyz"]]
     assert system_settings_profile_elements(user_name="robin") == []
 
 
diff --git a/tests/integration/test_storage_hdfs/test.py b/tests/integration/test_storage_hdfs/test.py
index ed2a4e0140d0..996df28ac810 100644
--- a/tests/integration/test_storage_hdfs/test.py
+++ b/tests/integration/test_storage_hdfs/test.py
@@ -58,21 +58,21 @@ def test_read_write_storage_with_globs(started_cluster):
         node1.query("insert into HDFSStorageWithEnum values (1, 'NEW', 4.2)")
         assert False, "Exception have to be thrown"
     except Exception as ex:
-        print ex
+        print(ex)
         assert "in readonly mode" in str(ex)
 
     try:
         node1.query("insert into HDFSStorageWithQuestionMark values (1, 'NEW', 4.2)")
         assert False, "Exception have to be thrown"
     except Exception as ex:
-        print ex
+        print(ex)
         assert "in readonly mode" in str(ex)
 
     try:
         node1.query("insert into HDFSStorageWithAsterisk values (1, 'NEW', 4.2)")
         assert False, "Exception have to be thrown"
     except Exception as ex:
-        print ex
+        print(ex)
         assert "in readonly mode" in str(ex)
 
 
@@ -104,20 +104,20 @@ def test_bad_hdfs_uri(started_cluster):
         node1.query(
             "create table BadStorage1 (id UInt32, name String, weight Float64) ENGINE = HDFS('hads:hgsdfs100500:9000/other_storage', 'TSV')")
     except Exception as ex:
-        print ex
+        print(ex)
         assert "Illegal HDFS URI" in str(ex)
     try:
         node1.query(
             "create table BadStorage2 (id UInt32, name String, weight Float64) ENGINE = HDFS('hdfs://hdfs100500:9000/other_storage', 'TSV')")
     except Exception as ex:
-        print ex
+        print(ex)
         assert "Unable to create builder to connect to HDFS" in str(ex)
 
     try:
         node1.query(
             "create table BadStorage3 (id UInt32, name String, weight Float64) ENGINE = HDFS('hdfs://hdfs1:9000/<>', 'TSV')")
     except Exception as ex:
-        print ex
+        print(ex)
         assert "Unable to open HDFS file" in str(ex)
 
 
diff --git a/tests/integration/test_storage_kafka/test.py b/tests/integration/test_storage_kafka/test.py
index 90422bf98e9b..ae7eed555323 100644
--- a/tests/integration/test_storage_kafka/test.py
+++ b/tests/integration/test_storage_kafka/test.py
@@ -7,10 +7,11 @@
 import time
 
 import avro.schema
+from confluent_kafka.avro.cached_schema_registry_client import CachedSchemaRegistryClient
+from confluent_kafka.avro.serializer.message_serializer import MessageSerializer
+
 import kafka.errors
 import pytest
-from confluent.schemaregistry.client import CachedSchemaRegistryClient
-from confluent.schemaregistry.serializers.MessageSerializer import MessageSerializer
 from google.protobuf.internal.encoder import _VarintBytes
 from helpers.client import QueryRuntimeException
 from helpers.cluster import ClickHouseCluster
@@ -28,7 +29,7 @@
 # to create kafka_pb2.py
 protoc --python_out=. kafka.proto
 """
-import kafka_pb2
+from . import kafka_pb2
 
 # TODO: add test for run-time offset update in CH, if we manually update it on Kafka side.
 # TODO: add test for SELECT LIMIT is working.
@@ -69,40 +70,38 @@ def wait_kafka_is_available(max_retries=50):
             print("Waiting for Kafka to start up")
             time.sleep(1)
 
+def producer_serializer(x):
+    return x.encode() if isinstance(x, str) else x
 
 def kafka_produce(topic, messages, timestamp=None):
-    producer = KafkaProducer(bootstrap_servers="localhost:9092")
+    producer = KafkaProducer(bootstrap_servers="localhost:9092", value_serializer=producer_serializer)
     for message in messages:
         producer.send(topic=topic, value=message, timestamp_ms=timestamp)
         producer.flush()
 
-
-#    print ("Produced {} messages for topic {}".format(len(messages), topic))
-
-
 def kafka_consume(topic):
     consumer = KafkaConsumer(bootstrap_servers="localhost:9092", auto_offset_reset="earliest")
     consumer.subscribe(topics=(topic))
-    for toppar, messages in consumer.poll(5000).items():
+    for toppar, messages in list(consumer.poll(5000).items()):
         if toppar.topic == topic:
             for message in messages:
-                yield message.value
+                yield message.value.decode()
     consumer.unsubscribe()
     consumer.close()
 
 
 def kafka_produce_protobuf_messages(topic, start_index, num_messages):
-    data = ''
+    data = b''
     for i in range(start_index, start_index + num_messages):
         msg = kafka_pb2.KeyValuePair()
         msg.key = i
         msg.value = str(i)
         serialized_msg = msg.SerializeToString()
         data = data + _VarintBytes(len(serialized_msg)) + serialized_msg
-    producer = KafkaProducer(bootstrap_servers="localhost:9092")
+    producer = KafkaProducer(bootstrap_servers="localhost:9092", value_serializer=producer_serializer)
     producer.send(topic=topic, value=data)
     producer.flush()
-    print("Produced {} messages for topic {}".format(num_messages, topic))
+    print(("Produced {} messages for topic {}".format(num_messages, topic)))
 
 
 def avro_confluent_message(schema_registry_client, value):
@@ -285,9 +284,9 @@ def test_kafka_formats(kafka_cluster):
         # clickhouse-client ... | xxd -ps -c 200 | tr -d '
' | sed 's/\(..\)/\\x\1/g'
         'Native': {
             'data_sample': [
-                '\x05\x01\x02\x69\x64\x05\x49\x6e\x74\x36\x34\x00\x00\x00\x00\x00\x00\x00\x00\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x06\x55\x49\x6e\x74\x31\x36\x00\x00\x04\x76\x61\x6c\x31\x06\x53\x74\x72\x69\x6e\x67\x02\x41\x4d\x04\x76\x61\x6c\x32\x07\x46\x6c\x6f\x61\x74\x33\x32\x00\x00\x00\x3f\x04\x76\x61\x6c\x33\x05\x55\x49\x6e\x74\x38\x01',
-                '\x05\x0f\x02\x69\x64\x05\x49\x6e\x74\x36\x34\x01\x00\x00\x00\x00\x00\x00\x00\x02\x00\x00\x00\x00\x00\x00\x00\x03\x00\x00\x00\x00\x00\x00\x00\x04\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x06\x00\x00\x00\x00\x00\x00\x00\x07\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00\x00\x00\x00\x00\x00\x09\x00\x00\x00\x00\x00\x00\x00\x0a\x00\x00\x00\x00\x00\x00\x00\x0b\x00\x00\x00\x00\x00\x00\x00\x0c\x00\x00\x00\x00\x00\x00\x00\x0d\x00\x00\x00\x00\x00\x00\x00\x0e\x00\x00\x00\x00\x00\x00\x00\x0f\x00\x00\x00\x00\x00\x00\x00\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x06\x55\x49\x6e\x74\x31\x36\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x04\x76\x61\x6c\x31\x06\x53\x74\x72\x69\x6e\x67\x02\x41\x4d\x02\x41\x4d\x02\x41\x4d\x02\x41\x4d\x02\x41\x4d\x02\x41\x4d\x02\x41\x4d\x02\x41\x4d\x02\x41\x4d\x02\x41\x4d\x02\x41\x4d\x02\x41\x4d\x02\x41\x4d\x02\x41\x4d\x02\x41\x4d\x04\x76\x61\x6c\x32\x07\x46\x6c\x6f\x61\x74\x33\x32\x00\x00\x00\x3f\x00\x00\x00\x3f\x00\x00\x00\x3f\x00\x00\x00\x3f\x00\x00\x00\x3f\x00\x00\x00\x3f\x00\x00\x00\x3f\x00\x00\x00\x3f\x00\x00\x00\x3f\x00\x00\x00\x3f\x00\x00\x00\x3f\x00\x00\x00\x3f\x00\x00\x00\x3f\x00\x00\x00\x3f\x00\x00\x00\x3f\x04\x76\x61\x6c\x33\x05\x55\x49\x6e\x74\x38\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01',
-                '\x05\x01\x02\x69\x64\x05\x49\x6e\x74\x36\x34\x00\x00\x00\x00\x00\x00\x00\x00\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x06\x55\x49\x6e\x74\x31\x36\x00\x00\x04\x76\x61\x6c\x31\x06\x53\x74\x72\x69\x6e\x67\x02\x41\x4d\x04\x76\x61\x6c\x32\x07\x46\x6c\x6f\x61\x74\x33\x32\x00\x00\x00\x3f\x04\x76\x61\x6c\x33\x05\x55\x49\x6e\x74\x38\x01',
+                b'\x05\x01\x02\x69\x64\x05\x49\x6e\x74\x36\x34\x00\x00\x00\x00\x00\x00\x00\x00\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x06\x55\x49\x6e\x74\x31\x36\x00\x00\x04\x76\x61\x6c\x31\x06\x53\x74\x72\x69\x6e\x67\x02\x41\x4d\x04\x76\x61\x6c\x32\x07\x46\x6c\x6f\x61\x74\x33\x32\x00\x00\x00\x3f\x04\x76\x61\x6c\x33\x05\x55\x49\x6e\x74\x38\x01',
+                b'\x05\x0f\x02\x69\x64\x05\x49\x6e\x74\x36\x34\x01\x00\x00\x00\x00\x00\x00\x00\x02\x00\x00\x00\x00\x00\x00\x00\x03\x00\x00\x00\x00\x00\x00\x00\x04\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x06\x00\x00\x00\x00\x00\x00\x00\x07\x00\x00\x00\x00\x00\x00\x00\x08\x00\x00\x00\x00\x00\x00\x00\x09\x00\x00\x00\x00\x00\x00\x00\x0a\x00\x00\x00\x00\x00\x00\x00\x0b\x00\x00\x00\x00\x00\x00\x00\x0c\x00\x00\x00\x00\x00\x00\x00\x0d\x00\x00\x00\x00\x00\x00\x00\x0e\x00\x00\x00\x00\x00\x00\x00\x0f\x00\x00\x00\x00\x00\x00\x00\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x06\x55\x49\x6e\x74\x31\x36\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x04\x76\x61\x6c\x31\x06\x53\x74\x72\x69\x6e\x67\x02\x41\x4d\x02\x41\x4d\x02\x41\x4d\x02\x41\x4d\x02\x41\x4d\x02\x41\x4d\x02\x41\x4d\x02\x41\x4d\x02\x41\x4d\x02\x41\x4d\x02\x41\x4d\x02\x41\x4d\x02\x41\x4d\x02\x41\x4d\x02\x41\x4d\x04\x76\x61\x6c\x32\x07\x46\x6c\x6f\x61\x74\x33\x32\x00\x00\x00\x3f\x00\x00\x00\x3f\x00\x00\x00\x3f\x00\x00\x00\x3f\x00\x00\x00\x3f\x00\x00\x00\x3f\x00\x00\x00\x3f\x00\x00\x00\x3f\x00\x00\x00\x3f\x00\x00\x00\x3f\x00\x00\x00\x3f\x00\x00\x00\x3f\x00\x00\x00\x3f\x00\x00\x00\x3f\x00\x00\x00\x3f\x04\x76\x61\x6c\x33\x05\x55\x49\x6e\x74\x38\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01',
+                b'\x05\x01\x02\x69\x64\x05\x49\x6e\x74\x36\x34\x00\x00\x00\x00\x00\x00\x00\x00\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x06\x55\x49\x6e\x74\x31\x36\x00\x00\x04\x76\x61\x6c\x31\x06\x53\x74\x72\x69\x6e\x67\x02\x41\x4d\x04\x76\x61\x6c\x32\x07\x46\x6c\x6f\x61\x74\x33\x32\x00\x00\x00\x3f\x04\x76\x61\x6c\x33\x05\x55\x49\x6e\x74\x38\x01',
                 # ''
                 # On empty message exception happens: DB::Exception: Attempt to read after eof
                 # /src/IO/VarInt.h:122: DB::throwReadAfterEOF() @ 0x15c34487 in /usr/bin/clickhouse
@@ -301,9 +300,9 @@ def test_kafka_formats(kafka_cluster):
         },
         'MsgPack': {
             'data_sample': [
-                '\x00\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01',
-                '\x01\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01\x02\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01\x03\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01\x04\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01\x05\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01\x06\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01\x07\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01\x08\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01\x09\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01\x0a\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01\x0b\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01\x0c\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01\x0d\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01\x0e\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01\x0f\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01',
-                '\x00\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01',
+                b'\x00\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01',
+                b'\x01\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01\x02\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01\x03\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01\x04\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01\x05\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01\x06\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01\x07\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01\x08\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01\x09\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01\x0a\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01\x0b\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01\x0c\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01\x0d\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01\x0e\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01\x0f\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01',
+                b'\x00\x00\xa2\x41\x4d\xca\x3f\x00\x00\x00\x01',
                 # ''
                 # On empty message exception happens: Unexpected end of file while parsing msgpack object.: (at row 1)
                 # coming from Processors/Formats/Impl/MsgPackRowInputFormat.cpp:170
@@ -311,9 +310,9 @@ def test_kafka_formats(kafka_cluster):
         },
         'RowBinary': {
             'data_sample': [
-                '\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01',
-                '\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x02\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x03\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x04\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x07\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x08\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x09\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x0a\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x0b\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x0c\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x0d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x0f\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01',
-                '\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01',
+                b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01',
+                b'\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x02\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x03\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x04\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x07\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x08\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x09\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x0a\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x0b\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x0c\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x0d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x0f\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01',
+                b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01',
                 # ''
                 # On empty message exception happens: DB::Exception: Cannot read all data. Bytes read: 0. Bytes expected: 8.
                 # /src/IO/ReadBuffer.h:157: DB::ReadBuffer::readStrict(char*, unsigned long) @ 0x15c6894d in /usr/bin/clickhouse
@@ -325,9 +324,9 @@ def test_kafka_formats(kafka_cluster):
         },
         'RowBinaryWithNamesAndTypes': {
             'data_sample': [
-                '\x05\x02\x69\x64\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x04\x76\x61\x6c\x31\x04\x76\x61\x6c\x32\x04\x76\x61\x6c\x33\x05\x49\x6e\x74\x36\x34\x06\x55\x49\x6e\x74\x31\x36\x06\x53\x74\x72\x69\x6e\x67\x07\x46\x6c\x6f\x61\x74\x33\x32\x05\x55\x49\x6e\x74\x38\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01',
-                '\x05\x02\x69\x64\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x04\x76\x61\x6c\x31\x04\x76\x61\x6c\x32\x04\x76\x61\x6c\x33\x05\x49\x6e\x74\x36\x34\x06\x55\x49\x6e\x74\x31\x36\x06\x53\x74\x72\x69\x6e\x67\x07\x46\x6c\x6f\x61\x74\x33\x32\x05\x55\x49\x6e\x74\x38\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x02\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x03\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x04\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x07\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x08\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x09\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x0a\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x0b\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x0c\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x0d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x0f\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01',
-                '\x05\x02\x69\x64\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x04\x76\x61\x6c\x31\x04\x76\x61\x6c\x32\x04\x76\x61\x6c\x33\x05\x49\x6e\x74\x36\x34\x06\x55\x49\x6e\x74\x31\x36\x06\x53\x74\x72\x69\x6e\x67\x07\x46\x6c\x6f\x61\x74\x33\x32\x05\x55\x49\x6e\x74\x38\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01',
+                b'\x05\x02\x69\x64\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x04\x76\x61\x6c\x31\x04\x76\x61\x6c\x32\x04\x76\x61\x6c\x33\x05\x49\x6e\x74\x36\x34\x06\x55\x49\x6e\x74\x31\x36\x06\x53\x74\x72\x69\x6e\x67\x07\x46\x6c\x6f\x61\x74\x33\x32\x05\x55\x49\x6e\x74\x38\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01',
+                b'\x05\x02\x69\x64\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x04\x76\x61\x6c\x31\x04\x76\x61\x6c\x32\x04\x76\x61\x6c\x33\x05\x49\x6e\x74\x36\x34\x06\x55\x49\x6e\x74\x31\x36\x06\x53\x74\x72\x69\x6e\x67\x07\x46\x6c\x6f\x61\x74\x33\x32\x05\x55\x49\x6e\x74\x38\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x02\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x03\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x04\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x07\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x08\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x09\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x0a\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x0b\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x0c\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x0d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01\x0f\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01',
+                b'\x05\x02\x69\x64\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x04\x76\x61\x6c\x31\x04\x76\x61\x6c\x32\x04\x76\x61\x6c\x33\x05\x49\x6e\x74\x36\x34\x06\x55\x49\x6e\x74\x31\x36\x06\x53\x74\x72\x69\x6e\x67\x07\x46\x6c\x6f\x61\x74\x33\x32\x05\x55\x49\x6e\x74\x38\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x41\x4d\x00\x00\x00\x3f\x01',
                 # ''
                 # !!! On empty message segfault: Address not mapped to object
                 # /contrib/FastMemcpy/FastMemcpy.h:666: memcpy_fast @ 0x21742d65 in /usr/bin/clickhouse
@@ -340,9 +339,9 @@ def test_kafka_formats(kafka_cluster):
         },
         'Protobuf': {
             'data_sample': [
-                '\x0b\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01',
-                '\x0d\x08\x01\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01\x0d\x08\x02\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01\x0d\x08\x03\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01\x0d\x08\x04\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01\x0d\x08\x05\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01\x0d\x08\x06\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01\x0d\x08\x07\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01\x0d\x08\x08\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01\x0d\x08\x09\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01\x0d\x08\x0a\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01\x0d\x08\x0b\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01\x0d\x08\x0c\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01\x0d\x08\x0d\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01\x0d\x08\x0e\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01\x0d\x08\x0f\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01',
-                '\x0b\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01',
+                b'\x0b\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01',
+                b'\x0d\x08\x01\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01\x0d\x08\x02\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01\x0d\x08\x03\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01\x0d\x08\x04\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01\x0d\x08\x05\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01\x0d\x08\x06\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01\x0d\x08\x07\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01\x0d\x08\x08\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01\x0d\x08\x09\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01\x0d\x08\x0a\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01\x0d\x08\x0b\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01\x0d\x08\x0c\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01\x0d\x08\x0d\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01\x0d\x08\x0e\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01\x0d\x08\x0f\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01',
+                b'\x0b\x1a\x02\x41\x4d\x25\x00\x00\x00\x3f\x28\x01',
                 # ''
                 # On empty message exception: Attempt to read after eof
                 # /src/IO/ReadBuffer.h:184: DB::ReadBuffer::throwReadAfterEOF() @ 0x15c9699b in /usr/bin/clickhouse
@@ -355,9 +354,9 @@ def test_kafka_formats(kafka_cluster):
         },
         'ORC': {
             'data_sample': [
-                '\x4f\x52\x43\x11\x00\x00\x0a\x06\x12\x04\x08\x01\x50\x00\x2b\x00\x00\x0a\x13\x0a\x03\x00\x00\x00\x12\x0c\x08\x01\x12\x06\x08\x00\x10\x00\x18\x00\x50\x00\x30\x00\x00\xe3\x12\xe7\x62\x65\x00\x01\x21\x3e\x0e\x46\x25\x0e\x2e\x46\x03\x21\x46\x03\x09\xa6\x00\x06\x00\x32\x00\x00\xe3\x92\xe4\x62\x65\x00\x01\x21\x01\x0e\x46\x25\x2e\x2e\x26\x47\x5f\x21\x20\x96\x60\x09\x60\x00\x00\x36\x00\x00\xe3\x92\xe1\x62\x65\x00\x01\x21\x61\x0e\x46\x23\x5e\x2e\x46\x03\x21\x66\x03\x3d\x53\x29\x10\x11\xc0\x00\x00\x2b\x00\x00\x0a\x13\x0a\x03\x00\x00\x00\x12\x0c\x08\x01\x12\x06\x08\x02\x10\x02\x18\x02\x50\x00\x05\x00\x00\xff\x00\x03\x00\x00\x30\x07\x00\x00\x40\x00\x80\x05\x00\x00\x41\x4d\x07\x00\x00\x42\x00\x80\x03\x00\x00\x0a\x07\x00\x00\x42\x00\x80\x05\x00\x00\xff\x01\x88\x00\x00\x4d\xca\xc1\x0a\x80\x30\x0c\x03\xd0\x2e\x6b\xcb\x98\x17\xf1\x14\x50\xfc\xff\xcf\xb4\x66\x1e\x3c\x84\x47\x9a\xce\x1c\xb9\x1b\xb7\xf9\xda\x48\x09\x9e\xb2\xf3\x92\xce\x5b\x86\xf6\x56\x7f\x21\x41\x2f\x51\xa6\x7a\xd7\x1d\xe5\xea\xae\x3d\xca\xd5\x83\x71\x60\xd8\x17\xfc\x62\x0f\xa8\x00\x00\xe3\x4a\xe6\x62\xe1\x60\x0c\x60\xe0\xe2\xe3\x60\x14\x62\xe3\x60\x10\x60\x90\x60\x08\x60\x88\x60\xe5\x12\xe0\x60\x54\xe2\xe0\x62\x34\x10\x62\x34\x90\x60\x02\x8a\x70\x71\x09\x01\x45\xb8\xb8\x98\x1c\x7d\x85\x80\x58\x82\x05\x28\xc6\xcd\x25\xca\xc1\x68\xc4\x0b\x52\xc5\x6c\xa0\x67\x2a\x05\x22\xc0\x4a\x21\x86\x31\x09\x30\x81\xb5\xb2\x02\x00\x36\x01\x00\x25\x8c\xbd\x0a\xc2\x30\x14\x85\x73\x6f\x92\xf6\x92\x6a\x09\x01\x21\x64\x92\x4e\x75\x91\x58\x71\xc9\x64\x27\x5d\x2c\x1d\x5d\xfd\x59\xc4\x42\x37\x5f\xc0\x17\xe8\x23\x9b\xc6\xe1\x3b\x70\x0f\xdf\xb9\xc4\xf5\x17\x5d\x41\x5c\x4f\x60\x37\xeb\x53\x0d\x55\x4d\x0b\x23\x01\xb9\x90\x2e\xbf\x0f\xe3\xe3\xdd\x8d\x0e\x5f\x4f\x27\x3e\xb7\x61\x97\xb2\x49\xb9\xaf\x90\x20\x92\x27\x32\x2a\x6b\xf4\xf3\x0d\x1e\x82\x20\xe8\x59\x28\x09\x4c\x46\x4c\x33\xcb\x7a\x76\x95\x41\x47\x9f\x14\x78\x03\xde\x62\x6c\x54\x30\xb1\x51\x0a\xdb\x8b\x89\x58\x11\xbb\x22\xac\x08\x9a\xe5\x6c\x71\xbf\x3d\xb8\x39\x92\xfa\x7f\x86\x1a\xd3\x54\x1e\xa7\xee\xcc\x7e\x08\x9e\x01\x10\x01\x18\x80\x80\x10\x22\x02\x00\x0c\x28\x57\x30\x06\x82\xf4\x03\x03\x4f\x52\x43\x18',
-                '\x4f\x52\x43\x11\x00\x00\x0a\x06\x12\x04\x08\x0f\x50\x00\x2b\x00\x00\x0a\x13\x0a\x03\x00\x00\x00\x12\x0c\x08\x0f\x12\x06\x08\x00\x10\x00\x18\x00\x50\x00\x30\x00\x00\xe3\x12\xe7\x62\x65\x00\x01\x21\x3e\x0e\x7e\x25\x0e\x2e\x46\x43\x21\x46\x4b\x09\xad\x00\x06\x00\x33\x00\x00\x0a\x17\x0a\x03\x00\x00\x00\x12\x10\x08\x0f\x22\x0a\x0a\x02\x41\x4d\x12\x02\x41\x4d\x18\x3c\x50\x00\x3a\x00\x00\xe3\x92\xe1\x62\x65\x00\x01\x21\x61\x0e\x7e\x23\x5e\x2e\x46\x03\x21\x66\x03\x3d\x53\x29\x66\x73\x3d\xd3\x00\x06\x00\x2b\x00\x00\x0a\x13\x0a\x03\x00\x00\x00\x12\x0c\x08\x0f\x12\x06\x08\x02\x10\x02\x18\x1e\x50\x00\x05\x00\x00\x0c\x00\x2b\x00\x00\x31\x32\x33\x34\x35\x36\x37\x38\x39\x31\x30\x31\x31\x31\x32\x31\x33\x31\x34\x31\x35\x09\x00\x00\x06\x01\x03\x02\x09\x00\x00\xc0\x0e\x00\x00\x07\x00\x00\x42\x00\x80\x05\x00\x00\x41\x4d\x0a\x00\x00\xe3\xe2\x42\x01\x00\x09\x00\x00\xc0\x0e\x02\x00\x05\x00\x00\x0c\x01\x94\x00\x00\x2d\xca\xc1\x0e\x80\x30\x08\x03\xd0\xc1\x60\x2e\xf3\x62\x76\x6a\xe2\x0e\xfe\xff\x57\x5a\x3b\x0f\xe4\x51\xe8\x68\xbd\x5d\x05\xe7\xf8\x34\x40\x3a\x6e\x59\xb1\x64\xe0\x91\xa9\xbf\xb1\x97\xd2\x95\x9d\x1e\xca\x55\x3a\x6d\xb4\xd2\xdd\x0b\x74\x9a\x74\xf7\x12\x39\xbd\x97\x7f\x7c\x06\xbb\xa6\x8d\x97\x17\xb4\x00\x00\xe3\x4a\xe6\x62\xe1\xe0\x0f\x60\xe0\xe2\xe3\xe0\x17\x62\xe3\x60\x10\x60\x90\x60\x08\x60\x88\x60\xe5\x12\xe0\xe0\x57\xe2\xe0\x62\x34\x14\x62\xb4\x94\xd0\x02\x8a\xc8\x73\x09\x01\x45\xb8\xb8\x98\x1c\x7d\x85\x80\x58\xc2\x06\x28\x26\xc4\x25\xca\xc1\x6f\xc4\xcb\xc5\x68\x20\xc4\x6c\xa0\x67\x2a\xc5\x6c\xae\x67\x0a\x14\xe6\x87\x1a\xc6\x24\xc0\x24\x21\x07\x32\x0c\x00\x4a\x01\x00\xe3\x60\x16\x58\xc3\x24\xc5\xcd\xc1\x2c\x30\x89\x51\xc2\x4b\xc1\x57\x83\x5f\x49\x83\x83\x47\x88\x95\x91\x89\x99\x85\x55\x8a\x3d\x29\x27\x3f\x39\xdb\x2f\x5f\x8a\x29\x33\x45\x8a\xa5\x2c\x31\xc7\x10\x4c\x1a\x81\x49\x63\x25\x26\x0e\x46\x20\x66\x07\x63\x36\x0e\x3e\x0d\x26\x03\x10\x9f\xd1\x80\xdf\x8a\x85\x83\x3f\x80\xc1\x8a\x8f\x83\x5f\x88\x8d\x83\x41\x80\x41\x82\x21\x80\x21\x82\xd5\x4a\x80\x83\x5f\x89\x83\x8b\xd1\x50\x88\xd1\x52\x42\x0b\x28\x22\x6f\x25\x04\x14\xe1\xe2\x62\x72\xf4\x15\x02\x62\x09\x1b\xa0\x98\x90\x95\x28\x07\xbf\x11\x2f\x17\xa3\x81\x10\xb3\x81\x9e\xa9\x14\xb3\xb9\x9e\x29\x50\x98\x1f\x6a\x18\x93\x00\x93\x84\x1c\xc8\x30\x87\x09\x7e\x1e\x0c\x00\x08\xa8\x01\x10\x01\x18\x80\x80\x10\x22\x02\x00\x0c\x28\x5d\x30\x06\x82\xf4\x03\x03\x4f\x52\x43\x18',
-                '\x4f\x52\x43\x11\x00\x00\x0a\x06\x12\x04\x08\x01\x50\x00\x2b\x00\x00\x0a\x13\x0a\x03\x00\x00\x00\x12\x0c\x08\x01\x12\x06\x08\x00\x10\x00\x18\x00\x50\x00\x30\x00\x00\xe3\x12\xe7\x62\x65\x00\x01\x21\x3e\x0e\x46\x25\x0e\x2e\x46\x03\x21\x46\x03\x09\xa6\x00\x06\x00\x32\x00\x00\xe3\x92\xe4\x62\x65\x00\x01\x21\x01\x0e\x46\x25\x2e\x2e\x26\x47\x5f\x21\x20\x96\x60\x09\x60\x00\x00\x36\x00\x00\xe3\x92\xe1\x62\x65\x00\x01\x21\x61\x0e\x46\x23\x5e\x2e\x46\x03\x21\x66\x03\x3d\x53\x29\x10\x11\xc0\x00\x00\x2b\x00\x00\x0a\x13\x0a\x03\x00\x00\x00\x12\x0c\x08\x01\x12\x06\x08\x02\x10\x02\x18\x02\x50\x00\x05\x00\x00\xff\x00\x03\x00\x00\x30\x07\x00\x00\x40\x00\x80\x05\x00\x00\x41\x4d\x07\x00\x00\x42\x00\x80\x03\x00\x00\x0a\x07\x00\x00\x42\x00\x80\x05\x00\x00\xff\x01\x88\x00\x00\x4d\xca\xc1\x0a\x80\x30\x0c\x03\xd0\x2e\x6b\xcb\x98\x17\xf1\x14\x50\xfc\xff\xcf\xb4\x66\x1e\x3c\x84\x47\x9a\xce\x1c\xb9\x1b\xb7\xf9\xda\x48\x09\x9e\xb2\xf3\x92\xce\x5b\x86\xf6\x56\x7f\x21\x41\x2f\x51\xa6\x7a\xd7\x1d\xe5\xea\xae\x3d\xca\xd5\x83\x71\x60\xd8\x17\xfc\x62\x0f\xa8\x00\x00\xe3\x4a\xe6\x62\xe1\x60\x0c\x60\xe0\xe2\xe3\x60\x14\x62\xe3\x60\x10\x60\x90\x60\x08\x60\x88\x60\xe5\x12\xe0\x60\x54\xe2\xe0\x62\x34\x10\x62\x34\x90\x60\x02\x8a\x70\x71\x09\x01\x45\xb8\xb8\x98\x1c\x7d\x85\x80\x58\x82\x05\x28\xc6\xcd\x25\xca\xc1\x68\xc4\x0b\x52\xc5\x6c\xa0\x67\x2a\x05\x22\xc0\x4a\x21\x86\x31\x09\x30\x81\xb5\xb2\x02\x00\x36\x01\x00\x25\x8c\xbd\x0a\xc2\x30\x14\x85\x73\x6f\x92\xf6\x92\x6a\x09\x01\x21\x64\x92\x4e\x75\x91\x58\x71\xc9\x64\x27\x5d\x2c\x1d\x5d\xfd\x59\xc4\x42\x37\x5f\xc0\x17\xe8\x23\x9b\xc6\xe1\x3b\x70\x0f\xdf\xb9\xc4\xf5\x17\x5d\x41\x5c\x4f\x60\x37\xeb\x53\x0d\x55\x4d\x0b\x23\x01\xb9\x90\x2e\xbf\x0f\xe3\xe3\xdd\x8d\x0e\x5f\x4f\x27\x3e\xb7\x61\x97\xb2\x49\xb9\xaf\x90\x20\x92\x27\x32\x2a\x6b\xf4\xf3\x0d\x1e\x82\x20\xe8\x59\x28\x09\x4c\x46\x4c\x33\xcb\x7a\x76\x95\x41\x47\x9f\x14\x78\x03\xde\x62\x6c\x54\x30\xb1\x51\x0a\xdb\x8b\x89\x58\x11\xbb\x22\xac\x08\x9a\xe5\x6c\x71\xbf\x3d\xb8\x39\x92\xfa\x7f\x86\x1a\xd3\x54\x1e\xa7\xee\xcc\x7e\x08\x9e\x01\x10\x01\x18\x80\x80\x10\x22\x02\x00\x0c\x28\x57\x30\x06\x82\xf4\x03\x03\x4f\x52\x43\x18',
+                b'\x4f\x52\x43\x11\x00\x00\x0a\x06\x12\x04\x08\x01\x50\x00\x2b\x00\x00\x0a\x13\x0a\x03\x00\x00\x00\x12\x0c\x08\x01\x12\x06\x08\x00\x10\x00\x18\x00\x50\x00\x30\x00\x00\xe3\x12\xe7\x62\x65\x00\x01\x21\x3e\x0e\x46\x25\x0e\x2e\x46\x03\x21\x46\x03\x09\xa6\x00\x06\x00\x32\x00\x00\xe3\x92\xe4\x62\x65\x00\x01\x21\x01\x0e\x46\x25\x2e\x2e\x26\x47\x5f\x21\x20\x96\x60\x09\x60\x00\x00\x36\x00\x00\xe3\x92\xe1\x62\x65\x00\x01\x21\x61\x0e\x46\x23\x5e\x2e\x46\x03\x21\x66\x03\x3d\x53\x29\x10\x11\xc0\x00\x00\x2b\x00\x00\x0a\x13\x0a\x03\x00\x00\x00\x12\x0c\x08\x01\x12\x06\x08\x02\x10\x02\x18\x02\x50\x00\x05\x00\x00\xff\x00\x03\x00\x00\x30\x07\x00\x00\x40\x00\x80\x05\x00\x00\x41\x4d\x07\x00\x00\x42\x00\x80\x03\x00\x00\x0a\x07\x00\x00\x42\x00\x80\x05\x00\x00\xff\x01\x88\x00\x00\x4d\xca\xc1\x0a\x80\x30\x0c\x03\xd0\x2e\x6b\xcb\x98\x17\xf1\x14\x50\xfc\xff\xcf\xb4\x66\x1e\x3c\x84\x47\x9a\xce\x1c\xb9\x1b\xb7\xf9\xda\x48\x09\x9e\xb2\xf3\x92\xce\x5b\x86\xf6\x56\x7f\x21\x41\x2f\x51\xa6\x7a\xd7\x1d\xe5\xea\xae\x3d\xca\xd5\x83\x71\x60\xd8\x17\xfc\x62\x0f\xa8\x00\x00\xe3\x4a\xe6\x62\xe1\x60\x0c\x60\xe0\xe2\xe3\x60\x14\x62\xe3\x60\x10\x60\x90\x60\x08\x60\x88\x60\xe5\x12\xe0\x60\x54\xe2\xe0\x62\x34\x10\x62\x34\x90\x60\x02\x8a\x70\x71\x09\x01\x45\xb8\xb8\x98\x1c\x7d\x85\x80\x58\x82\x05\x28\xc6\xcd\x25\xca\xc1\x68\xc4\x0b\x52\xc5\x6c\xa0\x67\x2a\x05\x22\xc0\x4a\x21\x86\x31\x09\x30\x81\xb5\xb2\x02\x00\x36\x01\x00\x25\x8c\xbd\x0a\xc2\x30\x14\x85\x73\x6f\x92\xf6\x92\x6a\x09\x01\x21\x64\x92\x4e\x75\x91\x58\x71\xc9\x64\x27\x5d\x2c\x1d\x5d\xfd\x59\xc4\x42\x37\x5f\xc0\x17\xe8\x23\x9b\xc6\xe1\x3b\x70\x0f\xdf\xb9\xc4\xf5\x17\x5d\x41\x5c\x4f\x60\x37\xeb\x53\x0d\x55\x4d\x0b\x23\x01\xb9\x90\x2e\xbf\x0f\xe3\xe3\xdd\x8d\x0e\x5f\x4f\x27\x3e\xb7\x61\x97\xb2\x49\xb9\xaf\x90\x20\x92\x27\x32\x2a\x6b\xf4\xf3\x0d\x1e\x82\x20\xe8\x59\x28\x09\x4c\x46\x4c\x33\xcb\x7a\x76\x95\x41\x47\x9f\x14\x78\x03\xde\x62\x6c\x54\x30\xb1\x51\x0a\xdb\x8b\x89\x58\x11\xbb\x22\xac\x08\x9a\xe5\x6c\x71\xbf\x3d\xb8\x39\x92\xfa\x7f\x86\x1a\xd3\x54\x1e\xa7\xee\xcc\x7e\x08\x9e\x01\x10\x01\x18\x80\x80\x10\x22\x02\x00\x0c\x28\x57\x30\x06\x82\xf4\x03\x03\x4f\x52\x43\x18',
+                b'\x4f\x52\x43\x11\x00\x00\x0a\x06\x12\x04\x08\x0f\x50\x00\x2b\x00\x00\x0a\x13\x0a\x03\x00\x00\x00\x12\x0c\x08\x0f\x12\x06\x08\x00\x10\x00\x18\x00\x50\x00\x30\x00\x00\xe3\x12\xe7\x62\x65\x00\x01\x21\x3e\x0e\x7e\x25\x0e\x2e\x46\x43\x21\x46\x4b\x09\xad\x00\x06\x00\x33\x00\x00\x0a\x17\x0a\x03\x00\x00\x00\x12\x10\x08\x0f\x22\x0a\x0a\x02\x41\x4d\x12\x02\x41\x4d\x18\x3c\x50\x00\x3a\x00\x00\xe3\x92\xe1\x62\x65\x00\x01\x21\x61\x0e\x7e\x23\x5e\x2e\x46\x03\x21\x66\x03\x3d\x53\x29\x66\x73\x3d\xd3\x00\x06\x00\x2b\x00\x00\x0a\x13\x0a\x03\x00\x00\x00\x12\x0c\x08\x0f\x12\x06\x08\x02\x10\x02\x18\x1e\x50\x00\x05\x00\x00\x0c\x00\x2b\x00\x00\x31\x32\x33\x34\x35\x36\x37\x38\x39\x31\x30\x31\x31\x31\x32\x31\x33\x31\x34\x31\x35\x09\x00\x00\x06\x01\x03\x02\x09\x00\x00\xc0\x0e\x00\x00\x07\x00\x00\x42\x00\x80\x05\x00\x00\x41\x4d\x0a\x00\x00\xe3\xe2\x42\x01\x00\x09\x00\x00\xc0\x0e\x02\x00\x05\x00\x00\x0c\x01\x94\x00\x00\x2d\xca\xc1\x0e\x80\x30\x08\x03\xd0\xc1\x60\x2e\xf3\x62\x76\x6a\xe2\x0e\xfe\xff\x57\x5a\x3b\x0f\xe4\x51\xe8\x68\xbd\x5d\x05\xe7\xf8\x34\x40\x3a\x6e\x59\xb1\x64\xe0\x91\xa9\xbf\xb1\x97\xd2\x95\x9d\x1e\xca\x55\x3a\x6d\xb4\xd2\xdd\x0b\x74\x9a\x74\xf7\x12\x39\xbd\x97\x7f\x7c\x06\xbb\xa6\x8d\x97\x17\xb4\x00\x00\xe3\x4a\xe6\x62\xe1\xe0\x0f\x60\xe0\xe2\xe3\xe0\x17\x62\xe3\x60\x10\x60\x90\x60\x08\x60\x88\x60\xe5\x12\xe0\xe0\x57\xe2\xe0\x62\x34\x14\x62\xb4\x94\xd0\x02\x8a\xc8\x73\x09\x01\x45\xb8\xb8\x98\x1c\x7d\x85\x80\x58\xc2\x06\x28\x26\xc4\x25\xca\xc1\x6f\xc4\xcb\xc5\x68\x20\xc4\x6c\xa0\x67\x2a\xc5\x6c\xae\x67\x0a\x14\xe6\x87\x1a\xc6\x24\xc0\x24\x21\x07\x32\x0c\x00\x4a\x01\x00\xe3\x60\x16\x58\xc3\x24\xc5\xcd\xc1\x2c\x30\x89\x51\xc2\x4b\xc1\x57\x83\x5f\x49\x83\x83\x47\x88\x95\x91\x89\x99\x85\x55\x8a\x3d\x29\x27\x3f\x39\xdb\x2f\x5f\x8a\x29\x33\x45\x8a\xa5\x2c\x31\xc7\x10\x4c\x1a\x81\x49\x63\x25\x26\x0e\x46\x20\x66\x07\x63\x36\x0e\x3e\x0d\x26\x03\x10\x9f\xd1\x80\xdf\x8a\x85\x83\x3f\x80\xc1\x8a\x8f\x83\x5f\x88\x8d\x83\x41\x80\x41\x82\x21\x80\x21\x82\xd5\x4a\x80\x83\x5f\x89\x83\x8b\xd1\x50\x88\xd1\x52\x42\x0b\x28\x22\x6f\x25\x04\x14\xe1\xe2\x62\x72\xf4\x15\x02\x62\x09\x1b\xa0\x98\x90\x95\x28\x07\xbf\x11\x2f\x17\xa3\x81\x10\xb3\x81\x9e\xa9\x14\xb3\xb9\x9e\x29\x50\x98\x1f\x6a\x18\x93\x00\x93\x84\x1c\xc8\x30\x87\x09\x7e\x1e\x0c\x00\x08\xa8\x01\x10\x01\x18\x80\x80\x10\x22\x02\x00\x0c\x28\x5d\x30\x06\x82\xf4\x03\x03\x4f\x52\x43\x18',
+                b'\x4f\x52\x43\x11\x00\x00\x0a\x06\x12\x04\x08\x01\x50\x00\x2b\x00\x00\x0a\x13\x0a\x03\x00\x00\x00\x12\x0c\x08\x01\x12\x06\x08\x00\x10\x00\x18\x00\x50\x00\x30\x00\x00\xe3\x12\xe7\x62\x65\x00\x01\x21\x3e\x0e\x46\x25\x0e\x2e\x46\x03\x21\x46\x03\x09\xa6\x00\x06\x00\x32\x00\x00\xe3\x92\xe4\x62\x65\x00\x01\x21\x01\x0e\x46\x25\x2e\x2e\x26\x47\x5f\x21\x20\x96\x60\x09\x60\x00\x00\x36\x00\x00\xe3\x92\xe1\x62\x65\x00\x01\x21\x61\x0e\x46\x23\x5e\x2e\x46\x03\x21\x66\x03\x3d\x53\x29\x10\x11\xc0\x00\x00\x2b\x00\x00\x0a\x13\x0a\x03\x00\x00\x00\x12\x0c\x08\x01\x12\x06\x08\x02\x10\x02\x18\x02\x50\x00\x05\x00\x00\xff\x00\x03\x00\x00\x30\x07\x00\x00\x40\x00\x80\x05\x00\x00\x41\x4d\x07\x00\x00\x42\x00\x80\x03\x00\x00\x0a\x07\x00\x00\x42\x00\x80\x05\x00\x00\xff\x01\x88\x00\x00\x4d\xca\xc1\x0a\x80\x30\x0c\x03\xd0\x2e\x6b\xcb\x98\x17\xf1\x14\x50\xfc\xff\xcf\xb4\x66\x1e\x3c\x84\x47\x9a\xce\x1c\xb9\x1b\xb7\xf9\xda\x48\x09\x9e\xb2\xf3\x92\xce\x5b\x86\xf6\x56\x7f\x21\x41\x2f\x51\xa6\x7a\xd7\x1d\xe5\xea\xae\x3d\xca\xd5\x83\x71\x60\xd8\x17\xfc\x62\x0f\xa8\x00\x00\xe3\x4a\xe6\x62\xe1\x60\x0c\x60\xe0\xe2\xe3\x60\x14\x62\xe3\x60\x10\x60\x90\x60\x08\x60\x88\x60\xe5\x12\xe0\x60\x54\xe2\xe0\x62\x34\x10\x62\x34\x90\x60\x02\x8a\x70\x71\x09\x01\x45\xb8\xb8\x98\x1c\x7d\x85\x80\x58\x82\x05\x28\xc6\xcd\x25\xca\xc1\x68\xc4\x0b\x52\xc5\x6c\xa0\x67\x2a\x05\x22\xc0\x4a\x21\x86\x31\x09\x30\x81\xb5\xb2\x02\x00\x36\x01\x00\x25\x8c\xbd\x0a\xc2\x30\x14\x85\x73\x6f\x92\xf6\x92\x6a\x09\x01\x21\x64\x92\x4e\x75\x91\x58\x71\xc9\x64\x27\x5d\x2c\x1d\x5d\xfd\x59\xc4\x42\x37\x5f\xc0\x17\xe8\x23\x9b\xc6\xe1\x3b\x70\x0f\xdf\xb9\xc4\xf5\x17\x5d\x41\x5c\x4f\x60\x37\xeb\x53\x0d\x55\x4d\x0b\x23\x01\xb9\x90\x2e\xbf\x0f\xe3\xe3\xdd\x8d\x0e\x5f\x4f\x27\x3e\xb7\x61\x97\xb2\x49\xb9\xaf\x90\x20\x92\x27\x32\x2a\x6b\xf4\xf3\x0d\x1e\x82\x20\xe8\x59\x28\x09\x4c\x46\x4c\x33\xcb\x7a\x76\x95\x41\x47\x9f\x14\x78\x03\xde\x62\x6c\x54\x30\xb1\x51\x0a\xdb\x8b\x89\x58\x11\xbb\x22\xac\x08\x9a\xe5\x6c\x71\xbf\x3d\xb8\x39\x92\xfa\x7f\x86\x1a\xd3\x54\x1e\xa7\xee\xcc\x7e\x08\x9e\x01\x10\x01\x18\x80\x80\x10\x22\x02\x00\x0c\x28\x57\x30\x06\x82\xf4\x03\x03\x4f\x52\x43\x18',
                 # ''
                 # On empty message exception:  IOError: File size too small, Stack trace (when copying this message, always include the lines below):
                 # /src/Processors/Formats/Impl/ORCBlockInputFormat.cpp:36: DB::ORCBlockInputFormat::generate() @ 0x1df282a6 in /usr/bin/clickhouse
@@ -366,9 +365,9 @@ def test_kafka_formats(kafka_cluster):
         },
         'CapnProto': {
             'data_sample': [
-                '\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00',
-                '\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x02\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x03\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x04\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x07\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x08\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x09\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x0a\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x0b\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x0c\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x0d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x0f\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00',
-                '\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00',
+                b'\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00',
+                b'\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x02\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x03\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x04\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x05\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x07\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x08\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x09\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x0a\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x0b\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x0c\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x0d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x0f\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00',
+                b'\x00\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x02\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x3f\x01\x00\x00\x00\x1a\x00\x00\x00\x41\x4d\x00\x00\x00\x00\x00\x00',
                 # ''
                 # On empty message exception: Cannot read all data. Bytes read: 0. Bytes expected: 4.
                 # /src/IO/ReadBuffer.h:157: DB::ReadBuffer::readStrict(char*, unsigned long) @ 0x15c6894d in /usr/bin/clickhouse
@@ -404,30 +403,30 @@ def test_kafka_formats(kafka_cluster):
         # /src/DataStreams/copyData.cpp:63: DB::copyData(DB::IBlockInputStream&, DB::IBlockOutputStream&, std::__1::atomic<bool>*) @ 0x1c9e9fc7 in /usr/bin/clickhouse
         # /src/Storages/Kafka/StorageKafka.cpp:565: DB::StorageKafka::streamToViews() @ 0x1d8cc3fa in /usr/bin/clickhouse
         #     # 'data_sample' : [
-        #     #     '\x50\x41\x52\x31\x15\x04\x15\x10\x15\x14\x4c\x15\x02\x15\x04\x12\x00\x00\x08\x1c\x00\x00\x00\x00\x00\x00\x00\x00\x15\x00\x15\x06\x15\x0a\x2c\x15\x02\x15\x04\x15\x06\x15\x06\x1c\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x16\x00\x28\x08\x00\x00\x00\x00\x00\x00\x00\x00\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x03\x08\x01\x02\x00\x26\xbc\x01\x1c\x15\x04\x19\x35\x04\x00\x06\x19\x18\x02\x69\x64\x15\x02\x16\x02\x16\xac\x01\x16\xb4\x01\x26\x38\x26\x08\x1c\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x16\x00\x28\x08\x00\x00\x00\x00\x00\x00\x00\x00\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x15\x04\x15\x08\x15\x0c\x4c\x15\x02\x15\x04\x12\x00\x00\x04\x0c\x00\x00\x00\x00\x15\x00\x15\x06\x15\x0a\x2c\x15\x02\x15\x04\x15\x06\x15\x06\x1c\x36\x00\x28\x04\x00\x00\x00\x00\x18\x04\x00\x00\x00\x00\x00\x00\x00\x03\x08\x01\x02\x00\x26\xc8\x03\x1c\x15\x02\x19\x35\x04\x00\x06\x19\x18\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x15\x02\x16\x02\x16\x6c\x16\x74\x26\xfc\x02\x26\xd4\x02\x1c\x36\x00\x28\x04\x00\x00\x00\x00\x18\x04\x00\x00\x00\x00\x00\x00\x00\x15\x04\x15\x0c\x15\x10\x4c\x15\x02\x15\x04\x12\x00\x00\x06\x14\x02\x00\x00\x00\x41\x4d\x15\x00\x15\x06\x15\x0a\x2c\x15\x02\x15\x04\x15\x06\x15\x06\x1c\x36\x00\x28\x02\x41\x4d\x18\x02\x41\x4d\x00\x00\x00\x03\x08\x01\x02\x00\x26\xa2\x05\x1c\x15\x0c\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x31\x15\x02\x16\x02\x16\x68\x16\x70\x26\xde\x04\x26\xb2\x04\x1c\x36\x00\x28\x02\x41\x4d\x18\x02\x41\x4d\x00\x00\x00\x15\x04\x15\x08\x15\x0c\x4c\x15\x02\x15\x04\x12\x00\x00\x04\x0c\x00\x00\x00\x3f\x15\x00\x15\x06\x15\x0a\x2c\x15\x02\x15\x04\x15\x06\x15\x06\x1c\x18\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x16\x00\x28\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x00\x00\x00\x03\x08\x01\x02\x00\x26\x8a\x07\x1c\x15\x08\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x32\x15\x02\x16\x02\x16\x84\x01\x16\x8c\x01\x26\xa6\x06\x26\xfe\x05\x1c\x18\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x16\x00\x28\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x00\x00\x00\x15\x04\x15\x08\x15\x0c\x4c\x15\x02\x15\x04\x12\x00\x00\x04\x0c\x01\x00\x00\x00\x15\x00\x15\x06\x15\x0a\x2c\x15\x02\x15\x04\x15\x06\x15\x06\x1c\x36\x00\x28\x04\x01\x00\x00\x00\x18\x04\x01\x00\x00\x00\x00\x00\x00\x03\x08\x01\x02\x00\x26\xfe\x08\x1c\x15\x02\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x33\x15\x02\x16\x02\x16\x6c\x16\x74\x26\xb2\x08\x26\x8a\x08\x1c\x36\x00\x28\x04\x01\x00\x00\x00\x18\x04\x01\x00\x00\x00\x00\x00\x00\x15\x02\x19\x6c\x35\x00\x18\x06\x73\x63\x68\x65\x6d\x61\x15\x0a\x00\x15\x04\x25\x00\x18\x02\x69\x64\x00\x15\x02\x25\x00\x18\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x25\x18\x4c\xac\x13\x10\x12\x00\x00\x00\x15\x0c\x25\x00\x18\x04\x76\x61\x6c\x31\x25\x00\x4c\x1c\x00\x00\x00\x15\x08\x25\x00\x18\x04\x76\x61\x6c\x32\x00\x15\x02\x25\x00\x18\x04\x76\x61\x6c\x33\x25\x16\x4c\xac\x13\x08\x12\x00\x00\x00\x16\x02\x19\x1c\x19\x5c\x26\xbc\x01\x1c\x15\x04\x19\x35\x04\x00\x06\x19\x18\x02\x69\x64\x15\x02\x16\x02\x16\xac\x01\x16\xb4\x01\x26\x38\x26\x08\x1c\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x16\x00\x28\x08\x00\x00\x00\x00\x00\x00\x00\x00\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x26\xc8\x03\x1c\x15\x02\x19\x35\x04\x00\x06\x19\x18\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x15\x02\x16\x02\x16\x6c\x16\x74\x26\xfc\x02\x26\xd4\x02\x1c\x36\x00\x28\x04\x00\x00\x00\x00\x18\x04\x00\x00\x00\x00\x00\x00\x00\x26\xa2\x05\x1c\x15\x0c\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x31\x15\x02\x16\x02\x16\x68\x16\x70\x26\xde\x04\x26\xb2\x04\x1c\x36\x00\x28\x02\x41\x4d\x18\x02\x41\x4d\x00\x00\x00\x26\x8a\x07\x1c\x15\x08\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x32\x15\x02\x16\x02\x16\x84\x01\x16\x8c\x01\x26\xa6\x06\x26\xfe\x05\x1c\x18\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x16\x00\x28\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x00\x00\x00\x26\xfe\x08\x1c\x15\x02\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x33\x15\x02\x16\x02\x16\x6c\x16\x74\x26\xb2\x08\x26\x8a\x08\x1c\x36\x00\x28\x04\x01\x00\x00\x00\x18\x04\x01\x00\x00\x00\x00\x00\x00\x16\x98\x05\x16\x02\x00\x28\x22\x70\x61\x72\x71\x75\x65\x74\x2d\x63\x70\x70\x20\x76\x65\x72\x73\x69\x6f\x6e\x20\x31\x2e\x35\x2e\x31\x2d\x53\x4e\x41\x50\x53\x48\x4f\x54\x19\x5c\x1c\x00\x00\x1c\x00\x00\x1c\x00\x00\x1c\x00\x00\x1c\x00\x00\x00\xc4\x01\x00\x00\x50\x41\x52\x31',
-        #     #     '\x50\x41\x52\x31\x15\x04\x15\xf0\x01\x15\x90\x01\x4c\x15\x1e\x15\x04\x12\x00\x00\x78\x04\x01\x00\x09\x01\x00\x02\x09\x07\x04\x00\x03\x0d\x08\x00\x04\x0d\x08\x00\x05\x0d\x08\x00\x06\x0d\x08\x00\x07\x0d\x08\x00\x08\x0d\x08\x00\x09\x0d\x08\x00\x0a\x0d\x08\x00\x0b\x0d\x08\x00\x0c\x0d\x08\x00\x0d\x0d\x08\x3c\x0e\x00\x00\x00\x00\x00\x00\x00\x0f\x00\x00\x00\x00\x00\x00\x00\x15\x00\x15\x14\x15\x18\x2c\x15\x1e\x15\x04\x15\x06\x15\x06\x1c\x18\x08\x0f\x00\x00\x00\x00\x00\x00\x00\x18\x08\x01\x00\x00\x00\x00\x00\x00\x00\x16\x00\x28\x08\x0f\x00\x00\x00\x00\x00\x00\x00\x18\x08\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0a\x24\x04\x05\x10\x32\x54\x76\x98\xba\xdc\x0e\x26\xca\x02\x1c\x15\x04\x19\x35\x04\x00\x06\x19\x18\x02\x69\x64\x15\x02\x16\x1e\x16\x9e\x03\x16\xc2\x02\x26\xb8\x01\x26\x08\x1c\x18\x08\x0f\x00\x00\x00\x00\x00\x00\x00\x18\x08\x01\x00\x00\x00\x00\x00\x00\x00\x16\x00\x28\x08\x0f\x00\x00\x00\x00\x00\x00\x00\x18\x08\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x15\x04\x15\x08\x15\x0c\x4c\x15\x02\x15\x04\x12\x00\x00\x04\x0c\x00\x00\x00\x00\x15\x00\x15\x06\x15\x0a\x2c\x15\x1e\x15\x04\x15\x06\x15\x06\x1c\x36\x00\x28\x04\x00\x00\x00\x00\x18\x04\x00\x00\x00\x00\x00\x00\x00\x03\x08\x01\x1e\x00\x26\xd8\x04\x1c\x15\x02\x19\x35\x04\x00\x06\x19\x18\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x15\x02\x16\x1e\x16\x6c\x16\x74\x26\x8c\x04\x26\xe4\x03\x1c\x36\x00\x28\x04\x00\x00\x00\x00\x18\x04\x00\x00\x00\x00\x00\x00\x00\x15\x04\x15\x0c\x15\x10\x4c\x15\x02\x15\x04\x12\x00\x00\x06\x14\x02\x00\x00\x00\x41\x4d\x15\x00\x15\x06\x15\x0a\x2c\x15\x1e\x15\x04\x15\x06\x15\x06\x1c\x36\x00\x28\x02\x41\x4d\x18\x02\x41\x4d\x00\x00\x00\x03\x08\x01\x1e\x00\x26\xb2\x06\x1c\x15\x0c\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x31\x15\x02\x16\x1e\x16\x68\x16\x70\x26\xee\x05\x26\xc2\x05\x1c\x36\x00\x28\x02\x41\x4d\x18\x02\x41\x4d\x00\x00\x00\x15\x04\x15\x08\x15\x0c\x4c\x15\x02\x15\x04\x12\x00\x00\x04\x0c\x00\x00\x00\x3f\x15\x00\x15\x06\x15\x0a\x2c\x15\x1e\x15\x04\x15\x06\x15\x06\x1c\x18\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x16\x00\x28\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x00\x00\x00\x03\x08\x01\x1e\x00\x26\x9a\x08\x1c\x15\x08\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x32\x15\x02\x16\x1e\x16\x84\x01\x16\x8c\x01\x26\xb6\x07\x26\x8e\x07\x1c\x18\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x16\x00\x28\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x00\x00\x00\x15\x04\x15\x08\x15\x0c\x4c\x15\x02\x15\x04\x12\x00\x00\x04\x0c\x01\x00\x00\x00\x15\x00\x15\x06\x15\x0a\x2c\x15\x1e\x15\x04\x15\x06\x15\x06\x1c\x36\x00\x28\x04\x01\x00\x00\x00\x18\x04\x01\x00\x00\x00\x00\x00\x00\x03\x08\x01\x1e\x00\x26\x8e\x0a\x1c\x15\x02\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x33\x15\x02\x16\x1e\x16\x6c\x16\x74\x26\xc2\x09\x26\x9a\x09\x1c\x36\x00\x28\x04\x01\x00\x00\x00\x18\x04\x01\x00\x00\x00\x00\x00\x00\x15\x02\x19\x6c\x35\x00\x18\x06\x73\x63\x68\x65\x6d\x61\x15\x0a\x00\x15\x04\x25\x00\x18\x02\x69\x64\x00\x15\x02\x25\x00\x18\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x25\x18\x4c\xac\x13\x10\x12\x00\x00\x00\x15\x0c\x25\x00\x18\x04\x76\x61\x6c\x31\x25\x00\x4c\x1c\x00\x00\x00\x15\x08\x25\x00\x18\x04\x76\x61\x6c\x32\x00\x15\x02\x25\x00\x18\x04\x76\x61\x6c\x33\x25\x16\x4c\xac\x13\x08\x12\x00\x00\x00\x16\x1e\x19\x1c\x19\x5c\x26\xca\x02\x1c\x15\x04\x19\x35\x04\x00\x06\x19\x18\x02\x69\x64\x15\x02\x16\x1e\x16\x9e\x03\x16\xc2\x02\x26\xb8\x01\x26\x08\x1c\x18\x08\x0f\x00\x00\x00\x00\x00\x00\x00\x18\x08\x01\x00\x00\x00\x00\x00\x00\x00\x16\x00\x28\x08\x0f\x00\x00\x00\x00\x00\x00\x00\x18\x08\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x26\xd8\x04\x1c\x15\x02\x19\x35\x04\x00\x06\x19\x18\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x15\x02\x16\x1e\x16\x6c\x16\x74\x26\x8c\x04\x26\xe4\x03\x1c\x36\x00\x28\x04\x00\x00\x00\x00\x18\x04\x00\x00\x00\x00\x00\x00\x00\x26\xb2\x06\x1c\x15\x0c\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x31\x15\x02\x16\x1e\x16\x68\x16\x70\x26\xee\x05\x26\xc2\x05\x1c\x36\x00\x28\x02\x41\x4d\x18\x02\x41\x4d\x00\x00\x00\x26\x9a\x08\x1c\x15\x08\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x32\x15\x02\x16\x1e\x16\x84\x01\x16\x8c\x01\x26\xb6\x07\x26\x8e\x07\x1c\x18\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x16\x00\x28\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x00\x00\x00\x26\x8e\x0a\x1c\x15\x02\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x33\x15\x02\x16\x1e\x16\x6c\x16\x74\x26\xc2\x09\x26\x9a\x09\x1c\x36\x00\x28\x04\x01\x00\x00\x00\x18\x04\x01\x00\x00\x00\x00\x00\x00\x16\xa6\x06\x16\x1e\x00\x28\x22\x70\x61\x72\x71\x75\x65\x74\x2d\x63\x70\x70\x20\x76\x65\x72\x73\x69\x6f\x6e\x20\x31\x2e\x35\x2e\x31\x2d\x53\x4e\x41\x50\x53\x48\x4f\x54\x19\x5c\x1c\x00\x00\x1c\x00\x00\x1c\x00\x00\x1c\x00\x00\x1c\x00\x00\x00\xc5\x01\x00\x00\x50\x41\x52\x31',
-        #     #     '\x50\x41\x52\x31\x15\x04\x15\x10\x15\x14\x4c\x15\x02\x15\x04\x12\x00\x00\x08\x1c\x00\x00\x00\x00\x00\x00\x00\x00\x15\x00\x15\x06\x15\x0a\x2c\x15\x02\x15\x04\x15\x06\x15\x06\x1c\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x16\x00\x28\x08\x00\x00\x00\x00\x00\x00\x00\x00\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x03\x08\x01\x02\x00\x26\xbc\x01\x1c\x15\x04\x19\x35\x04\x00\x06\x19\x18\x02\x69\x64\x15\x02\x16\x02\x16\xac\x01\x16\xb4\x01\x26\x38\x26\x08\x1c\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x16\x00\x28\x08\x00\x00\x00\x00\x00\x00\x00\x00\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x15\x04\x15\x08\x15\x0c\x4c\x15\x02\x15\x04\x12\x00\x00\x04\x0c\x00\x00\x00\x00\x15\x00\x15\x06\x15\x0a\x2c\x15\x02\x15\x04\x15\x06\x15\x06\x1c\x36\x00\x28\x04\x00\x00\x00\x00\x18\x04\x00\x00\x00\x00\x00\x00\x00\x03\x08\x01\x02\x00\x26\xc8\x03\x1c\x15\x02\x19\x35\x04\x00\x06\x19\x18\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x15\x02\x16\x02\x16\x6c\x16\x74\x26\xfc\x02\x26\xd4\x02\x1c\x36\x00\x28\x04\x00\x00\x00\x00\x18\x04\x00\x00\x00\x00\x00\x00\x00\x15\x04\x15\x0c\x15\x10\x4c\x15\x02\x15\x04\x12\x00\x00\x06\x14\x02\x00\x00\x00\x41\x4d\x15\x00\x15\x06\x15\x0a\x2c\x15\x02\x15\x04\x15\x06\x15\x06\x1c\x36\x00\x28\x02\x41\x4d\x18\x02\x41\x4d\x00\x00\x00\x03\x08\x01\x02\x00\x26\xa2\x05\x1c\x15\x0c\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x31\x15\x02\x16\x02\x16\x68\x16\x70\x26\xde\x04\x26\xb2\x04\x1c\x36\x00\x28\x02\x41\x4d\x18\x02\x41\x4d\x00\x00\x00\x15\x04\x15\x08\x15\x0c\x4c\x15\x02\x15\x04\x12\x00\x00\x04\x0c\x00\x00\x00\x3f\x15\x00\x15\x06\x15\x0a\x2c\x15\x02\x15\x04\x15\x06\x15\x06\x1c\x18\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x16\x00\x28\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x00\x00\x00\x03\x08\x01\x02\x00\x26\x8a\x07\x1c\x15\x08\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x32\x15\x02\x16\x02\x16\x84\x01\x16\x8c\x01\x26\xa6\x06\x26\xfe\x05\x1c\x18\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x16\x00\x28\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x00\x00\x00\x15\x04\x15\x08\x15\x0c\x4c\x15\x02\x15\x04\x12\x00\x00\x04\x0c\x01\x00\x00\x00\x15\x00\x15\x06\x15\x0a\x2c\x15\x02\x15\x04\x15\x06\x15\x06\x1c\x36\x00\x28\x04\x01\x00\x00\x00\x18\x04\x01\x00\x00\x00\x00\x00\x00\x03\x08\x01\x02\x00\x26\xfe\x08\x1c\x15\x02\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x33\x15\x02\x16\x02\x16\x6c\x16\x74\x26\xb2\x08\x26\x8a\x08\x1c\x36\x00\x28\x04\x01\x00\x00\x00\x18\x04\x01\x00\x00\x00\x00\x00\x00\x15\x02\x19\x6c\x35\x00\x18\x06\x73\x63\x68\x65\x6d\x61\x15\x0a\x00\x15\x04\x25\x00\x18\x02\x69\x64\x00\x15\x02\x25\x00\x18\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x25\x18\x4c\xac\x13\x10\x12\x00\x00\x00\x15\x0c\x25\x00\x18\x04\x76\x61\x6c\x31\x25\x00\x4c\x1c\x00\x00\x00\x15\x08\x25\x00\x18\x04\x76\x61\x6c\x32\x00\x15\x02\x25\x00\x18\x04\x76\x61\x6c\x33\x25\x16\x4c\xac\x13\x08\x12\x00\x00\x00\x16\x02\x19\x1c\x19\x5c\x26\xbc\x01\x1c\x15\x04\x19\x35\x04\x00\x06\x19\x18\x02\x69\x64\x15\x02\x16\x02\x16\xac\x01\x16\xb4\x01\x26\x38\x26\x08\x1c\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x16\x00\x28\x08\x00\x00\x00\x00\x00\x00\x00\x00\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x26\xc8\x03\x1c\x15\x02\x19\x35\x04\x00\x06\x19\x18\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x15\x02\x16\x02\x16\x6c\x16\x74\x26\xfc\x02\x26\xd4\x02\x1c\x36\x00\x28\x04\x00\x00\x00\x00\x18\x04\x00\x00\x00\x00\x00\x00\x00\x26\xa2\x05\x1c\x15\x0c\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x31\x15\x02\x16\x02\x16\x68\x16\x70\x26\xde\x04\x26\xb2\x04\x1c\x36\x00\x28\x02\x41\x4d\x18\x02\x41\x4d\x00\x00\x00\x26\x8a\x07\x1c\x15\x08\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x32\x15\x02\x16\x02\x16\x84\x01\x16\x8c\x01\x26\xa6\x06\x26\xfe\x05\x1c\x18\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x16\x00\x28\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x00\x00\x00\x26\xfe\x08\x1c\x15\x02\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x33\x15\x02\x16\x02\x16\x6c\x16\x74\x26\xb2\x08\x26\x8a\x08\x1c\x36\x00\x28\x04\x01\x00\x00\x00\x18\x04\x01\x00\x00\x00\x00\x00\x00\x16\x98\x05\x16\x02\x00\x28\x22\x70\x61\x72\x71\x75\x65\x74\x2d\x63\x70\x70\x20\x76\x65\x72\x73\x69\x6f\x6e\x20\x31\x2e\x35\x2e\x31\x2d\x53\x4e\x41\x50\x53\x48\x4f\x54\x19\x5c\x1c\x00\x00\x1c\x00\x00\x1c\x00\x00\x1c\x00\x00\x1c\x00\x00\x00\xc4\x01\x00\x00\x50\x41\x52\x31',
+        #     #     b'\x50\x41\x52\x31\x15\x04\x15\x10\x15\x14\x4c\x15\x02\x15\x04\x12\x00\x00\x08\x1c\x00\x00\x00\x00\x00\x00\x00\x00\x15\x00\x15\x06\x15\x0a\x2c\x15\x02\x15\x04\x15\x06\x15\x06\x1c\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x16\x00\x28\x08\x00\x00\x00\x00\x00\x00\x00\x00\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x03\x08\x01\x02\x00\x26\xbc\x01\x1c\x15\x04\x19\x35\x04\x00\x06\x19\x18\x02\x69\x64\x15\x02\x16\x02\x16\xac\x01\x16\xb4\x01\x26\x38\x26\x08\x1c\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x16\x00\x28\x08\x00\x00\x00\x00\x00\x00\x00\x00\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x15\x04\x15\x08\x15\x0c\x4c\x15\x02\x15\x04\x12\x00\x00\x04\x0c\x00\x00\x00\x00\x15\x00\x15\x06\x15\x0a\x2c\x15\x02\x15\x04\x15\x06\x15\x06\x1c\x36\x00\x28\x04\x00\x00\x00\x00\x18\x04\x00\x00\x00\x00\x00\x00\x00\x03\x08\x01\x02\x00\x26\xc8\x03\x1c\x15\x02\x19\x35\x04\x00\x06\x19\x18\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x15\x02\x16\x02\x16\x6c\x16\x74\x26\xfc\x02\x26\xd4\x02\x1c\x36\x00\x28\x04\x00\x00\x00\x00\x18\x04\x00\x00\x00\x00\x00\x00\x00\x15\x04\x15\x0c\x15\x10\x4c\x15\x02\x15\x04\x12\x00\x00\x06\x14\x02\x00\x00\x00\x41\x4d\x15\x00\x15\x06\x15\x0a\x2c\x15\x02\x15\x04\x15\x06\x15\x06\x1c\x36\x00\x28\x02\x41\x4d\x18\x02\x41\x4d\x00\x00\x00\x03\x08\x01\x02\x00\x26\xa2\x05\x1c\x15\x0c\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x31\x15\x02\x16\x02\x16\x68\x16\x70\x26\xde\x04\x26\xb2\x04\x1c\x36\x00\x28\x02\x41\x4d\x18\x02\x41\x4d\x00\x00\x00\x15\x04\x15\x08\x15\x0c\x4c\x15\x02\x15\x04\x12\x00\x00\x04\x0c\x00\x00\x00\x3f\x15\x00\x15\x06\x15\x0a\x2c\x15\x02\x15\x04\x15\x06\x15\x06\x1c\x18\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x16\x00\x28\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x00\x00\x00\x03\x08\x01\x02\x00\x26\x8a\x07\x1c\x15\x08\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x32\x15\x02\x16\x02\x16\x84\x01\x16\x8c\x01\x26\xa6\x06\x26\xfe\x05\x1c\x18\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x16\x00\x28\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x00\x00\x00\x15\x04\x15\x08\x15\x0c\x4c\x15\x02\x15\x04\x12\x00\x00\x04\x0c\x01\x00\x00\x00\x15\x00\x15\x06\x15\x0a\x2c\x15\x02\x15\x04\x15\x06\x15\x06\x1c\x36\x00\x28\x04\x01\x00\x00\x00\x18\x04\x01\x00\x00\x00\x00\x00\x00\x03\x08\x01\x02\x00\x26\xfe\x08\x1c\x15\x02\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x33\x15\x02\x16\x02\x16\x6c\x16\x74\x26\xb2\x08\x26\x8a\x08\x1c\x36\x00\x28\x04\x01\x00\x00\x00\x18\x04\x01\x00\x00\x00\x00\x00\x00\x15\x02\x19\x6c\x35\x00\x18\x06\x73\x63\x68\x65\x6d\x61\x15\x0a\x00\x15\x04\x25\x00\x18\x02\x69\x64\x00\x15\x02\x25\x00\x18\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x25\x18\x4c\xac\x13\x10\x12\x00\x00\x00\x15\x0c\x25\x00\x18\x04\x76\x61\x6c\x31\x25\x00\x4c\x1c\x00\x00\x00\x15\x08\x25\x00\x18\x04\x76\x61\x6c\x32\x00\x15\x02\x25\x00\x18\x04\x76\x61\x6c\x33\x25\x16\x4c\xac\x13\x08\x12\x00\x00\x00\x16\x02\x19\x1c\x19\x5c\x26\xbc\x01\x1c\x15\x04\x19\x35\x04\x00\x06\x19\x18\x02\x69\x64\x15\x02\x16\x02\x16\xac\x01\x16\xb4\x01\x26\x38\x26\x08\x1c\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x16\x00\x28\x08\x00\x00\x00\x00\x00\x00\x00\x00\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x26\xc8\x03\x1c\x15\x02\x19\x35\x04\x00\x06\x19\x18\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x15\x02\x16\x02\x16\x6c\x16\x74\x26\xfc\x02\x26\xd4\x02\x1c\x36\x00\x28\x04\x00\x00\x00\x00\x18\x04\x00\x00\x00\x00\x00\x00\x00\x26\xa2\x05\x1c\x15\x0c\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x31\x15\x02\x16\x02\x16\x68\x16\x70\x26\xde\x04\x26\xb2\x04\x1c\x36\x00\x28\x02\x41\x4d\x18\x02\x41\x4d\x00\x00\x00\x26\x8a\x07\x1c\x15\x08\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x32\x15\x02\x16\x02\x16\x84\x01\x16\x8c\x01\x26\xa6\x06\x26\xfe\x05\x1c\x18\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x16\x00\x28\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x00\x00\x00\x26\xfe\x08\x1c\x15\x02\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x33\x15\x02\x16\x02\x16\x6c\x16\x74\x26\xb2\x08\x26\x8a\x08\x1c\x36\x00\x28\x04\x01\x00\x00\x00\x18\x04\x01\x00\x00\x00\x00\x00\x00\x16\x98\x05\x16\x02\x00\x28\x22\x70\x61\x72\x71\x75\x65\x74\x2d\x63\x70\x70\x20\x76\x65\x72\x73\x69\x6f\x6e\x20\x31\x2e\x35\x2e\x31\x2d\x53\x4e\x41\x50\x53\x48\x4f\x54\x19\x5c\x1c\x00\x00\x1c\x00\x00\x1c\x00\x00\x1c\x00\x00\x1c\x00\x00\x00\xc4\x01\x00\x00\x50\x41\x52\x31',
+        #     #     b'\x50\x41\x52\x31\x15\x04\x15\xf0\x01\x15\x90\x01\x4c\x15\x1e\x15\x04\x12\x00\x00\x78\x04\x01\x00\x09\x01\x00\x02\x09\x07\x04\x00\x03\x0d\x08\x00\x04\x0d\x08\x00\x05\x0d\x08\x00\x06\x0d\x08\x00\x07\x0d\x08\x00\x08\x0d\x08\x00\x09\x0d\x08\x00\x0a\x0d\x08\x00\x0b\x0d\x08\x00\x0c\x0d\x08\x00\x0d\x0d\x08\x3c\x0e\x00\x00\x00\x00\x00\x00\x00\x0f\x00\x00\x00\x00\x00\x00\x00\x15\x00\x15\x14\x15\x18\x2c\x15\x1e\x15\x04\x15\x06\x15\x06\x1c\x18\x08\x0f\x00\x00\x00\x00\x00\x00\x00\x18\x08\x01\x00\x00\x00\x00\x00\x00\x00\x16\x00\x28\x08\x0f\x00\x00\x00\x00\x00\x00\x00\x18\x08\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0a\x24\x04\x05\x10\x32\x54\x76\x98\xba\xdc\x0e\x26\xca\x02\x1c\x15\x04\x19\x35\x04\x00\x06\x19\x18\x02\x69\x64\x15\x02\x16\x1e\x16\x9e\x03\x16\xc2\x02\x26\xb8\x01\x26\x08\x1c\x18\x08\x0f\x00\x00\x00\x00\x00\x00\x00\x18\x08\x01\x00\x00\x00\x00\x00\x00\x00\x16\x00\x28\x08\x0f\x00\x00\x00\x00\x00\x00\x00\x18\x08\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x15\x04\x15\x08\x15\x0c\x4c\x15\x02\x15\x04\x12\x00\x00\x04\x0c\x00\x00\x00\x00\x15\x00\x15\x06\x15\x0a\x2c\x15\x1e\x15\x04\x15\x06\x15\x06\x1c\x36\x00\x28\x04\x00\x00\x00\x00\x18\x04\x00\x00\x00\x00\x00\x00\x00\x03\x08\x01\x1e\x00\x26\xd8\x04\x1c\x15\x02\x19\x35\x04\x00\x06\x19\x18\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x15\x02\x16\x1e\x16\x6c\x16\x74\x26\x8c\x04\x26\xe4\x03\x1c\x36\x00\x28\x04\x00\x00\x00\x00\x18\x04\x00\x00\x00\x00\x00\x00\x00\x15\x04\x15\x0c\x15\x10\x4c\x15\x02\x15\x04\x12\x00\x00\x06\x14\x02\x00\x00\x00\x41\x4d\x15\x00\x15\x06\x15\x0a\x2c\x15\x1e\x15\x04\x15\x06\x15\x06\x1c\x36\x00\x28\x02\x41\x4d\x18\x02\x41\x4d\x00\x00\x00\x03\x08\x01\x1e\x00\x26\xb2\x06\x1c\x15\x0c\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x31\x15\x02\x16\x1e\x16\x68\x16\x70\x26\xee\x05\x26\xc2\x05\x1c\x36\x00\x28\x02\x41\x4d\x18\x02\x41\x4d\x00\x00\x00\x15\x04\x15\x08\x15\x0c\x4c\x15\x02\x15\x04\x12\x00\x00\x04\x0c\x00\x00\x00\x3f\x15\x00\x15\x06\x15\x0a\x2c\x15\x1e\x15\x04\x15\x06\x15\x06\x1c\x18\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x16\x00\x28\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x00\x00\x00\x03\x08\x01\x1e\x00\x26\x9a\x08\x1c\x15\x08\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x32\x15\x02\x16\x1e\x16\x84\x01\x16\x8c\x01\x26\xb6\x07\x26\x8e\x07\x1c\x18\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x16\x00\x28\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x00\x00\x00\x15\x04\x15\x08\x15\x0c\x4c\x15\x02\x15\x04\x12\x00\x00\x04\x0c\x01\x00\x00\x00\x15\x00\x15\x06\x15\x0a\x2c\x15\x1e\x15\x04\x15\x06\x15\x06\x1c\x36\x00\x28\x04\x01\x00\x00\x00\x18\x04\x01\x00\x00\x00\x00\x00\x00\x03\x08\x01\x1e\x00\x26\x8e\x0a\x1c\x15\x02\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x33\x15\x02\x16\x1e\x16\x6c\x16\x74\x26\xc2\x09\x26\x9a\x09\x1c\x36\x00\x28\x04\x01\x00\x00\x00\x18\x04\x01\x00\x00\x00\x00\x00\x00\x15\x02\x19\x6c\x35\x00\x18\x06\x73\x63\x68\x65\x6d\x61\x15\x0a\x00\x15\x04\x25\x00\x18\x02\x69\x64\x00\x15\x02\x25\x00\x18\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x25\x18\x4c\xac\x13\x10\x12\x00\x00\x00\x15\x0c\x25\x00\x18\x04\x76\x61\x6c\x31\x25\x00\x4c\x1c\x00\x00\x00\x15\x08\x25\x00\x18\x04\x76\x61\x6c\x32\x00\x15\x02\x25\x00\x18\x04\x76\x61\x6c\x33\x25\x16\x4c\xac\x13\x08\x12\x00\x00\x00\x16\x1e\x19\x1c\x19\x5c\x26\xca\x02\x1c\x15\x04\x19\x35\x04\x00\x06\x19\x18\x02\x69\x64\x15\x02\x16\x1e\x16\x9e\x03\x16\xc2\x02\x26\xb8\x01\x26\x08\x1c\x18\x08\x0f\x00\x00\x00\x00\x00\x00\x00\x18\x08\x01\x00\x00\x00\x00\x00\x00\x00\x16\x00\x28\x08\x0f\x00\x00\x00\x00\x00\x00\x00\x18\x08\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x26\xd8\x04\x1c\x15\x02\x19\x35\x04\x00\x06\x19\x18\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x15\x02\x16\x1e\x16\x6c\x16\x74\x26\x8c\x04\x26\xe4\x03\x1c\x36\x00\x28\x04\x00\x00\x00\x00\x18\x04\x00\x00\x00\x00\x00\x00\x00\x26\xb2\x06\x1c\x15\x0c\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x31\x15\x02\x16\x1e\x16\x68\x16\x70\x26\xee\x05\x26\xc2\x05\x1c\x36\x00\x28\x02\x41\x4d\x18\x02\x41\x4d\x00\x00\x00\x26\x9a\x08\x1c\x15\x08\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x32\x15\x02\x16\x1e\x16\x84\x01\x16\x8c\x01\x26\xb6\x07\x26\x8e\x07\x1c\x18\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x16\x00\x28\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x00\x00\x00\x26\x8e\x0a\x1c\x15\x02\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x33\x15\x02\x16\x1e\x16\x6c\x16\x74\x26\xc2\x09\x26\x9a\x09\x1c\x36\x00\x28\x04\x01\x00\x00\x00\x18\x04\x01\x00\x00\x00\x00\x00\x00\x16\xa6\x06\x16\x1e\x00\x28\x22\x70\x61\x72\x71\x75\x65\x74\x2d\x63\x70\x70\x20\x76\x65\x72\x73\x69\x6f\x6e\x20\x31\x2e\x35\x2e\x31\x2d\x53\x4e\x41\x50\x53\x48\x4f\x54\x19\x5c\x1c\x00\x00\x1c\x00\x00\x1c\x00\x00\x1c\x00\x00\x1c\x00\x00\x00\xc5\x01\x00\x00\x50\x41\x52\x31',
+        #     #     b'\x50\x41\x52\x31\x15\x04\x15\x10\x15\x14\x4c\x15\x02\x15\x04\x12\x00\x00\x08\x1c\x00\x00\x00\x00\x00\x00\x00\x00\x15\x00\x15\x06\x15\x0a\x2c\x15\x02\x15\x04\x15\x06\x15\x06\x1c\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x16\x00\x28\x08\x00\x00\x00\x00\x00\x00\x00\x00\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x03\x08\x01\x02\x00\x26\xbc\x01\x1c\x15\x04\x19\x35\x04\x00\x06\x19\x18\x02\x69\x64\x15\x02\x16\x02\x16\xac\x01\x16\xb4\x01\x26\x38\x26\x08\x1c\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x16\x00\x28\x08\x00\x00\x00\x00\x00\x00\x00\x00\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x15\x04\x15\x08\x15\x0c\x4c\x15\x02\x15\x04\x12\x00\x00\x04\x0c\x00\x00\x00\x00\x15\x00\x15\x06\x15\x0a\x2c\x15\x02\x15\x04\x15\x06\x15\x06\x1c\x36\x00\x28\x04\x00\x00\x00\x00\x18\x04\x00\x00\x00\x00\x00\x00\x00\x03\x08\x01\x02\x00\x26\xc8\x03\x1c\x15\x02\x19\x35\x04\x00\x06\x19\x18\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x15\x02\x16\x02\x16\x6c\x16\x74\x26\xfc\x02\x26\xd4\x02\x1c\x36\x00\x28\x04\x00\x00\x00\x00\x18\x04\x00\x00\x00\x00\x00\x00\x00\x15\x04\x15\x0c\x15\x10\x4c\x15\x02\x15\x04\x12\x00\x00\x06\x14\x02\x00\x00\x00\x41\x4d\x15\x00\x15\x06\x15\x0a\x2c\x15\x02\x15\x04\x15\x06\x15\x06\x1c\x36\x00\x28\x02\x41\x4d\x18\x02\x41\x4d\x00\x00\x00\x03\x08\x01\x02\x00\x26\xa2\x05\x1c\x15\x0c\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x31\x15\x02\x16\x02\x16\x68\x16\x70\x26\xde\x04\x26\xb2\x04\x1c\x36\x00\x28\x02\x41\x4d\x18\x02\x41\x4d\x00\x00\x00\x15\x04\x15\x08\x15\x0c\x4c\x15\x02\x15\x04\x12\x00\x00\x04\x0c\x00\x00\x00\x3f\x15\x00\x15\x06\x15\x0a\x2c\x15\x02\x15\x04\x15\x06\x15\x06\x1c\x18\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x16\x00\x28\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x00\x00\x00\x03\x08\x01\x02\x00\x26\x8a\x07\x1c\x15\x08\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x32\x15\x02\x16\x02\x16\x84\x01\x16\x8c\x01\x26\xa6\x06\x26\xfe\x05\x1c\x18\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x16\x00\x28\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x00\x00\x00\x15\x04\x15\x08\x15\x0c\x4c\x15\x02\x15\x04\x12\x00\x00\x04\x0c\x01\x00\x00\x00\x15\x00\x15\x06\x15\x0a\x2c\x15\x02\x15\x04\x15\x06\x15\x06\x1c\x36\x00\x28\x04\x01\x00\x00\x00\x18\x04\x01\x00\x00\x00\x00\x00\x00\x03\x08\x01\x02\x00\x26\xfe\x08\x1c\x15\x02\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x33\x15\x02\x16\x02\x16\x6c\x16\x74\x26\xb2\x08\x26\x8a\x08\x1c\x36\x00\x28\x04\x01\x00\x00\x00\x18\x04\x01\x00\x00\x00\x00\x00\x00\x15\x02\x19\x6c\x35\x00\x18\x06\x73\x63\x68\x65\x6d\x61\x15\x0a\x00\x15\x04\x25\x00\x18\x02\x69\x64\x00\x15\x02\x25\x00\x18\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x25\x18\x4c\xac\x13\x10\x12\x00\x00\x00\x15\x0c\x25\x00\x18\x04\x76\x61\x6c\x31\x25\x00\x4c\x1c\x00\x00\x00\x15\x08\x25\x00\x18\x04\x76\x61\x6c\x32\x00\x15\x02\x25\x00\x18\x04\x76\x61\x6c\x33\x25\x16\x4c\xac\x13\x08\x12\x00\x00\x00\x16\x02\x19\x1c\x19\x5c\x26\xbc\x01\x1c\x15\x04\x19\x35\x04\x00\x06\x19\x18\x02\x69\x64\x15\x02\x16\x02\x16\xac\x01\x16\xb4\x01\x26\x38\x26\x08\x1c\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x16\x00\x28\x08\x00\x00\x00\x00\x00\x00\x00\x00\x18\x08\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x26\xc8\x03\x1c\x15\x02\x19\x35\x04\x00\x06\x19\x18\x07\x62\x6c\x6f\x63\x6b\x4e\x6f\x15\x02\x16\x02\x16\x6c\x16\x74\x26\xfc\x02\x26\xd4\x02\x1c\x36\x00\x28\x04\x00\x00\x00\x00\x18\x04\x00\x00\x00\x00\x00\x00\x00\x26\xa2\x05\x1c\x15\x0c\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x31\x15\x02\x16\x02\x16\x68\x16\x70\x26\xde\x04\x26\xb2\x04\x1c\x36\x00\x28\x02\x41\x4d\x18\x02\x41\x4d\x00\x00\x00\x26\x8a\x07\x1c\x15\x08\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x32\x15\x02\x16\x02\x16\x84\x01\x16\x8c\x01\x26\xa6\x06\x26\xfe\x05\x1c\x18\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x16\x00\x28\x04\x00\x00\x00\x3f\x18\x04\x00\x00\x00\x3f\x00\x00\x00\x26\xfe\x08\x1c\x15\x02\x19\x35\x04\x00\x06\x19\x18\x04\x76\x61\x6c\x33\x15\x02\x16\x02\x16\x6c\x16\x74\x26\xb2\x08\x26\x8a\x08\x1c\x36\x00\x28\x04\x01\x00\x00\x00\x18\x04\x01\x00\x00\x00\x00\x00\x00\x16\x98\x05\x16\x02\x00\x28\x22\x70\x61\x72\x71\x75\x65\x74\x2d\x63\x70\x70\x20\x76\x65\x72\x73\x69\x6f\x6e\x20\x31\x2e\x35\x2e\x31\x2d\x53\x4e\x41\x50\x53\x48\x4f\x54\x19\x5c\x1c\x00\x00\x1c\x00\x00\x1c\x00\x00\x1c\x00\x00\x1c\x00\x00\x00\xc4\x01\x00\x00\x50\x41\x52\x31',
         #     #     ''
         #     # ],
         # },
         # 'Avro' : {
         #     'data_sample' : [
-        #         '\x4f\x62\x6a\x01\x04\x16\x61\x76\x72\x6f\x2e\x73\x63\x68\x65\x6d\x61\x82\x03\x7b\x22\x74\x79\x70\x65\x22\x3a\x22\x72\x65\x63\x6f\x72\x64\x22\x2c\x22\x6e\x61\x6d\x65\x22\x3a\x22\x72\x6f\x77\x22\x2c\x22\x66\x69\x65\x6c\x64\x73\x22\x3a\x5b\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x69\x64\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x6c\x6f\x6e\x67\x22\x7d\x2c\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x62\x6c\x6f\x63\x6b\x4e\x6f\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x69\x6e\x74\x22\x7d\x2c\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x76\x61\x6c\x31\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x73\x74\x72\x69\x6e\x67\x22\x7d\x2c\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x76\x61\x6c\x32\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x66\x6c\x6f\x61\x74\x22\x7d\x2c\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x76\x61\x6c\x33\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x69\x6e\x74\x22\x7d\x5d\x7d\x14\x61\x76\x72\x6f\x2e\x63\x6f\x64\x65\x63\x08\x6e\x75\x6c\x6c\x00\x8d\x1f\xf2\x17\x71\xa4\x2e\xe4\xc9\x0a\x23\x67\x12\xaa\xc6\xc0\x02\x14\x00\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x8d\x1f\xf2\x17\x71\xa4\x2e\xe4\xc9\x0a\x23\x67\x12\xaa\xc6\xc0',
-        #         '\x4f\x62\x6a\x01\x04\x16\x61\x76\x72\x6f\x2e\x73\x63\x68\x65\x6d\x61\x82\x03\x7b\x22\x74\x79\x70\x65\x22\x3a\x22\x72\x65\x63\x6f\x72\x64\x22\x2c\x22\x6e\x61\x6d\x65\x22\x3a\x22\x72\x6f\x77\x22\x2c\x22\x66\x69\x65\x6c\x64\x73\x22\x3a\x5b\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x69\x64\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x6c\x6f\x6e\x67\x22\x7d\x2c\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x62\x6c\x6f\x63\x6b\x4e\x6f\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x69\x6e\x74\x22\x7d\x2c\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x76\x61\x6c\x31\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x73\x74\x72\x69\x6e\x67\x22\x7d\x2c\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x76\x61\x6c\x32\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x66\x6c\x6f\x61\x74\x22\x7d\x2c\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x76\x61\x6c\x33\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x69\x6e\x74\x22\x7d\x5d\x7d\x14\x61\x76\x72\x6f\x2e\x63\x6f\x64\x65\x63\x08\x6e\x75\x6c\x6c\x00\xeb\x9d\x51\x82\xf2\x11\x3d\x0b\xc5\x92\x97\xb2\x07\x6d\x72\x5a\x1e\xac\x02\x02\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x04\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x06\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x08\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x0a\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x0c\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x0e\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x10\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x12\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x14\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x16\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x18\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x1a\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x1c\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x1e\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\xeb\x9d\x51\x82\xf2\x11\x3d\x0b\xc5\x92\x97\xb2\x07\x6d\x72\x5a',
-        #         '\x4f\x62\x6a\x01\x04\x16\x61\x76\x72\x6f\x2e\x73\x63\x68\x65\x6d\x61\x82\x03\x7b\x22\x74\x79\x70\x65\x22\x3a\x22\x72\x65\x63\x6f\x72\x64\x22\x2c\x22\x6e\x61\x6d\x65\x22\x3a\x22\x72\x6f\x77\x22\x2c\x22\x66\x69\x65\x6c\x64\x73\x22\x3a\x5b\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x69\x64\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x6c\x6f\x6e\x67\x22\x7d\x2c\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x62\x6c\x6f\x63\x6b\x4e\x6f\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x69\x6e\x74\x22\x7d\x2c\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x76\x61\x6c\x31\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x73\x74\x72\x69\x6e\x67\x22\x7d\x2c\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x76\x61\x6c\x32\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x66\x6c\x6f\x61\x74\x22\x7d\x2c\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x76\x61\x6c\x33\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x69\x6e\x74\x22\x7d\x5d\x7d\x14\x61\x76\x72\x6f\x2e\x63\x6f\x64\x65\x63\x08\x6e\x75\x6c\x6c\x00\x73\x65\x4f\x7c\xd9\x33\xe1\x18\xdd\x30\xe8\x22\x2a\x58\x20\x6f\x02\x14\x00\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x73\x65\x4f\x7c\xd9\x33\xe1\x18\xdd\x30\xe8\x22\x2a\x58\x20\x6f',
+        #         b'\x4f\x62\x6a\x01\x04\x16\x61\x76\x72\x6f\x2e\x73\x63\x68\x65\x6d\x61\x82\x03\x7b\x22\x74\x79\x70\x65\x22\x3a\x22\x72\x65\x63\x6f\x72\x64\x22\x2c\x22\x6e\x61\x6d\x65\x22\x3a\x22\x72\x6f\x77\x22\x2c\x22\x66\x69\x65\x6c\x64\x73\x22\x3a\x5b\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x69\x64\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x6c\x6f\x6e\x67\x22\x7d\x2c\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x62\x6c\x6f\x63\x6b\x4e\x6f\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x69\x6e\x74\x22\x7d\x2c\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x76\x61\x6c\x31\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x73\x74\x72\x69\x6e\x67\x22\x7d\x2c\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x76\x61\x6c\x32\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x66\x6c\x6f\x61\x74\x22\x7d\x2c\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x76\x61\x6c\x33\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x69\x6e\x74\x22\x7d\x5d\x7d\x14\x61\x76\x72\x6f\x2e\x63\x6f\x64\x65\x63\x08\x6e\x75\x6c\x6c\x00\x8d\x1f\xf2\x17\x71\xa4\x2e\xe4\xc9\x0a\x23\x67\x12\xaa\xc6\xc0\x02\x14\x00\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x8d\x1f\xf2\x17\x71\xa4\x2e\xe4\xc9\x0a\x23\x67\x12\xaa\xc6\xc0',
+        #         b'\x4f\x62\x6a\x01\x04\x16\x61\x76\x72\x6f\x2e\x73\x63\x68\x65\x6d\x61\x82\x03\x7b\x22\x74\x79\x70\x65\x22\x3a\x22\x72\x65\x63\x6f\x72\x64\x22\x2c\x22\x6e\x61\x6d\x65\x22\x3a\x22\x72\x6f\x77\x22\x2c\x22\x66\x69\x65\x6c\x64\x73\x22\x3a\x5b\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x69\x64\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x6c\x6f\x6e\x67\x22\x7d\x2c\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x62\x6c\x6f\x63\x6b\x4e\x6f\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x69\x6e\x74\x22\x7d\x2c\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x76\x61\x6c\x31\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x73\x74\x72\x69\x6e\x67\x22\x7d\x2c\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x76\x61\x6c\x32\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x66\x6c\x6f\x61\x74\x22\x7d\x2c\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x76\x61\x6c\x33\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x69\x6e\x74\x22\x7d\x5d\x7d\x14\x61\x76\x72\x6f\x2e\x63\x6f\x64\x65\x63\x08\x6e\x75\x6c\x6c\x00\xeb\x9d\x51\x82\xf2\x11\x3d\x0b\xc5\x92\x97\xb2\x07\x6d\x72\x5a\x1e\xac\x02\x02\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x04\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x06\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x08\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x0a\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x0c\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x0e\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x10\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x12\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x14\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x16\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x18\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x1a\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x1c\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x1e\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\xeb\x9d\x51\x82\xf2\x11\x3d\x0b\xc5\x92\x97\xb2\x07\x6d\x72\x5a',
+        #         b'\x4f\x62\x6a\x01\x04\x16\x61\x76\x72\x6f\x2e\x73\x63\x68\x65\x6d\x61\x82\x03\x7b\x22\x74\x79\x70\x65\x22\x3a\x22\x72\x65\x63\x6f\x72\x64\x22\x2c\x22\x6e\x61\x6d\x65\x22\x3a\x22\x72\x6f\x77\x22\x2c\x22\x66\x69\x65\x6c\x64\x73\x22\x3a\x5b\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x69\x64\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x6c\x6f\x6e\x67\x22\x7d\x2c\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x62\x6c\x6f\x63\x6b\x4e\x6f\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x69\x6e\x74\x22\x7d\x2c\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x76\x61\x6c\x31\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x73\x74\x72\x69\x6e\x67\x22\x7d\x2c\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x76\x61\x6c\x32\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x66\x6c\x6f\x61\x74\x22\x7d\x2c\x7b\x22\x6e\x61\x6d\x65\x22\x3a\x22\x76\x61\x6c\x33\x22\x2c\x22\x74\x79\x70\x65\x22\x3a\x22\x69\x6e\x74\x22\x7d\x5d\x7d\x14\x61\x76\x72\x6f\x2e\x63\x6f\x64\x65\x63\x08\x6e\x75\x6c\x6c\x00\x73\x65\x4f\x7c\xd9\x33\xe1\x18\xdd\x30\xe8\x22\x2a\x58\x20\x6f\x02\x14\x00\x00\x04\x41\x4d\x00\x00\x00\x3f\x02\x73\x65\x4f\x7c\xd9\x33\xe1\x18\xdd\x30\xe8\x22\x2a\x58\x20\x6f',
         #     ],
         # },
         'AvroConfluent': {
             'data_sample': [
                 avro_confluent_message(cluster.schema_registry_client,
-                                       {'id': 0L, 'blockNo': 0, 'val1': unicode('AM'), 'val2': 0.5, "val3": 1}),
+                                       {'id': 0, 'blockNo': 0, 'val1': str('AM'), 'val2': 0.5, "val3": 1}),
 
-                ''.join(map(lambda id: avro_confluent_message(cluster.schema_registry_client,
-                                                              {'id': id, 'blockNo': 0, 'val1': unicode('AM'),
-                                                               'val2': 0.5, "val3": 1}), range(1, 16))),
+                b''.join([avro_confluent_message(cluster.schema_registry_client,
+                                                              {'id': id, 'blockNo': 0, 'val1': str('AM'),
+                                                               'val2': 0.5, "val3": 1}) for id in range(1, 16)]),
 
                 avro_confluent_message(cluster.schema_registry_client,
-                                       {'id': 0L, 'blockNo': 0, 'val1': unicode('AM'), 'val2': 0.5, "val3": 1}),
+                                       {'id': 0, 'blockNo': 0, 'val1': str('AM'), 'val2': 0.5, "val3": 1}),
             ],
             'extra_settings': ", format_avro_schema_registry_url='http://{}:{}'".format(
                 cluster.schema_registry_host,
@@ -479,8 +478,8 @@ def test_kafka_formats(kafka_cluster):
         # },
     }
 
-    for format_name, format_opts in all_formats.items():
-        print('Set up {}'.format(format_name))
+    for format_name, format_opts in list(all_formats.items()):
+        print(('Set up {}'.format(format_name)))
         topic_name = 'format_tests_{}'.format(format_name)
         data_sample = format_opts['data_sample']
         data_prefix = []
@@ -513,8 +512,8 @@ def test_kafka_formats(kafka_cluster):
 
     time.sleep(12)
 
-    for format_name, format_opts in all_formats.items():
-        print('Checking {}'.format(format_name))
+    for format_name, format_opts in list(all_formats.items()):
+        print(('Checking {}'.format(format_name)))
         topic_name = 'format_tests_{}'.format(format_name)
         # shift offsets by 1 if format supports empty value
         offsets = [1, 2, 3] if format_opts.get('supports_empty_value', False) else [0, 1, 2]
@@ -588,7 +587,7 @@ def kafka_cluster():
         global kafka_id
         cluster.start()
         kafka_id = instance.cluster.kafka_docker_id
-        print("kafka_id is {}".format(kafka_id))
+        print(("kafka_id is {}".format(kafka_id)))
         yield cluster
 
     finally:
@@ -638,7 +637,7 @@ def test_kafka_settings_old_syntax(kafka_cluster):
     kafka_check_result(result, True)
 
     members = describe_consumer_group('old')
-    assert members[0]['client_id'] == u'ClickHouse-instance-test-kafka'
+    assert members[0]['client_id'] == 'ClickHouse-instance-test-kafka'
     # text_desc = kafka_cluster.exec_in_container(kafka_cluster.get_container_id('kafka1'),"kafka-consumer-groups --bootstrap-server localhost:9092 --describe --members --group old --verbose"))
 
 
@@ -679,7 +678,7 @@ def test_kafka_settings_new_syntax(kafka_cluster):
     kafka_check_result(result, True)
 
     members = describe_consumer_group('new')
-    assert members[0]['client_id'] == u'instance test 1234'
+    assert members[0]['client_id'] == 'instance test 1234'
 
 
 @pytest.mark.timeout(180)
@@ -1124,7 +1123,7 @@ def test_kafka_flush_on_big_message(kafka_cluster):
     while not received:
         try:
             offsets = client.list_consumer_group_offsets('flush')
-            for topic, offset in offsets.items():
+            for topic, offset in list(offsets.items()):
                 if topic.topic == 'flush' and offset.offset == kafka_messages:
                     received = True
                     break
@@ -1407,19 +1406,19 @@ def test_kafka_virtual_columns2(kafka_cluster):
         SELECT value, _key, _topic, _partition, _offset, toUnixTimestamp(_timestamp), toUnixTimestamp64Milli(_timestamp_ms), _headers.name, _headers.value FROM test.kafka;
         ''')
 
-    producer = KafkaProducer(bootstrap_servers="localhost:9092")
+    producer = KafkaProducer(bootstrap_servers="localhost:9092", value_serializer=producer_serializer, key_serializer=producer_serializer)
 
     producer.send(topic='virt2_0', value=json.dumps({'value': 1}), partition=0, key='k1', timestamp_ms=1577836801001,
                   headers=[('content-encoding', b'base64')])
     producer.send(topic='virt2_0', value=json.dumps({'value': 2}), partition=0, key='k2', timestamp_ms=1577836802002,
-                  headers=[('empty_value', ''), ('', 'empty name'), ('', ''), ('repetition', '1'), ('repetition', '2')])
+                  headers=[('empty_value', b''), ('', b'empty name'), ('', b''), ('repetition', b'1'), ('repetition', b'2')])
     producer.flush()
     time.sleep(1)
 
     producer.send(topic='virt2_0', value=json.dumps({'value': 3}), partition=1, key='k3', timestamp_ms=1577836803003,
-                  headers=[('b', 'b'), ('a', 'a')])
+                  headers=[('b', b'b'), ('a', b'a')])
     producer.send(topic='virt2_0', value=json.dumps({'value': 4}), partition=1, key='k4', timestamp_ms=1577836804004,
-                  headers=[('a', 'a'), ('b', 'b')])
+                  headers=[('a', b'a'), ('b', b'b')])
     producer.flush()
     time.sleep(1)
 
@@ -1436,8 +1435,8 @@ def test_kafka_virtual_columns2(kafka_cluster):
 
     members = describe_consumer_group('virt2')
     # pprint.pprint(members)
-    members[0]['client_id'] = u'ClickHouse-instance-test-kafka-0'
-    members[1]['client_id'] = u'ClickHouse-instance-test-kafka-1'
+    members[0]['client_id'] = 'ClickHouse-instance-test-kafka-0'
+    members[1]['client_id'] = 'ClickHouse-instance-test-kafka-1'
 
     result = instance.query("SELECT * FROM test.view ORDER BY value", ignore_error=True)
 
@@ -1717,7 +1716,7 @@ def produce():
 
     for consumer_index in range(NUMBER_OF_CONSURRENT_CONSUMERS):
         table_name = 'kafka_consumer{}'.format(consumer_index)
-        print("Setting up {}".format(table_name))
+        print(("Setting up {}".format(table_name)))
 
         instance.query('''
             DROP TABLE IF EXISTS test.{0};
@@ -1744,14 +1743,14 @@ def produce():
         # kafka_cluster.open_bash_shell('instance')
         while int(
                 instance.query("SELECT count() FROM test.destination WHERE _consumed_by='{}'".format(table_name))) == 0:
-            print("Waiting for test.kafka_consumer{} to start consume".format(consumer_index))
+            print(("Waiting for test.kafka_consumer{} to start consume".format(consumer_index)))
             time.sleep(1)
 
     cancel.set()
 
     # I leave last one working by intent (to finish consuming after all rebalances)
     for consumer_index in range(NUMBER_OF_CONSURRENT_CONSUMERS - 1):
-        print("Dropping test.kafka_consumer{}".format(consumer_index))
+        print(("Dropping test.kafka_consumer{}".format(consumer_index)))
         instance.query('DROP TABLE IF EXISTS test.kafka_consumer{}'.format(consumer_index))
         while int(instance.query(
                 "SELECT count() FROM system.tables WHERE database='test' AND name='kafka_consumer{}'".format(
@@ -1766,9 +1765,9 @@ def produce():
         if messages_consumed >= msg_index[0]:
             break
         time.sleep(1)
-        print("Waiting for finishing consuming (have {}, should be {})".format(messages_consumed, msg_index[0]))
+        print(("Waiting for finishing consuming (have {}, should be {})".format(messages_consumed, msg_index[0])))
 
-    print(instance.query('SELECT count(), uniqExact(key), max(key) + 1 FROM test.destination'))
+    print((instance.query('SELECT count(), uniqExact(key), max(key) + 1 FROM test.destination')))
 
     # Some queries to debug...
     # SELECT * FROM test.destination where key in (SELECT key FROM test.destination group by key having count() <> 1)
@@ -1793,7 +1792,7 @@ def produce():
     result = int(instance.query('SELECT count() == uniqExact(key) FROM test.destination'))
 
     for consumer_index in range(NUMBER_OF_CONSURRENT_CONSUMERS):
-        print("kafka_consumer{}".format(consumer_index))
+        print(("kafka_consumer{}".format(consumer_index)))
         table_name = 'kafka_consumer{}'.format(consumer_index)
         instance.query('''
             DROP TABLE IF EXISTS test.{0};
@@ -2253,5 +2252,5 @@ def test_kafka_csv_with_thread_per_consumer(kafka_cluster):
 
 if __name__ == '__main__':
     cluster.start()
-    raw_input("Cluster created, press any key to destroy...")
+    input("Cluster created, press any key to destroy...")
     cluster.shutdown()
diff --git a/tests/integration/test_storage_kerberized_kafka/test.py b/tests/integration/test_storage_kerberized_kafka/test.py
index ec23d3409779..59fb043b5468 100644
--- a/tests/integration/test_storage_kerberized_kafka/test.py
+++ b/tests/integration/test_storage_kerberized_kafka/test.py
@@ -56,8 +56,10 @@ def wait_kafka_is_available(max_retries=50):
             time.sleep(1)
 
 
+def producer_serializer(x):
+    return x.encode() if isinstance(x, str) else x
 def kafka_produce(topic, messages, timestamp=None):
-    producer = KafkaProducer(bootstrap_servers="localhost:9093")
+    producer = KafkaProducer(bootstrap_servers="localhost:9093", value_serializer=producer_serializer)
     for message in messages:
         producer.send(topic=topic, value=message, timestamp_ms=timestamp)
         producer.flush()
@@ -142,5 +144,5 @@ def test_kafka_json_as_string_no_kdc(kafka_cluster):
 
 if __name__ == '__main__':
     cluster.start()
-    raw_input("Cluster created, press any key to destroy...")
+    input("Cluster created, press any key to destroy...")
     cluster.shutdown()
diff --git a/tests/integration/test_storage_mysql/test.py b/tests/integration/test_storage_mysql/test.py
index 83ef1e6c86a2..87033381e2cb 100644
--- a/tests/integration/test_storage_mysql/test.py
+++ b/tests/integration/test_storage_mysql/test.py
@@ -179,6 +179,6 @@ def create_mysql_table(conn, tableName):
 
 if __name__ == '__main__':
     with contextmanager(started_cluster)() as cluster:
-        for name, instance in cluster.instances.items():
-            print name, instance.ip_address
-        raw_input("Cluster created, press any key to destroy...")
+        for name, instance in list(cluster.instances.items()):
+            print(name, instance.ip_address)
+        input("Cluster created, press any key to destroy...")
diff --git a/tests/integration/test_storage_rabbitmq/test.py b/tests/integration/test_storage_rabbitmq/test.py
index 4d892eaa72c1..ab44d0ebea0c 100644
--- a/tests/integration/test_storage_rabbitmq/test.py
+++ b/tests/integration/test_storage_rabbitmq/test.py
@@ -13,7 +13,7 @@
 from helpers.cluster import ClickHouseCluster
 from helpers.test_tools import TSV
 
-import rabbitmq_pb2
+from . import rabbitmq_pb2
 
 cluster = ClickHouseCluster(__file__)
 instance = cluster.add_instance('instance',
@@ -103,7 +103,7 @@ def rabbitmq_cluster():
         global rabbitmq_id
         cluster.start()
         rabbitmq_id = instance.cluster.rabbitmq_docker_id
-        print("rabbitmq_id is {}".format(rabbitmq_id))
+        print(("rabbitmq_id is {}".format(rabbitmq_id)))
         instance.query('CREATE DATABASE test')
 
         yield cluster
@@ -957,7 +957,7 @@ def test_rabbitmq_direct_exchange(rabbitmq_cluster):
 
     num_tables = 5
     for consumer_id in range(num_tables):
-        print("Setting up table {}".format(consumer_id))
+        print(("Setting up table {}".format(consumer_id)))
         instance.query('''
             DROP TABLE IF EXISTS test.direct_exchange_{0};
             DROP TABLE IF EXISTS test.direct_exchange_{0}_mv;
@@ -1030,7 +1030,7 @@ def test_rabbitmq_fanout_exchange(rabbitmq_cluster):
 
     num_tables = 5
     for consumer_id in range(num_tables):
-        print("Setting up table {}".format(consumer_id))
+        print(("Setting up table {}".format(consumer_id)))
         instance.query('''
             DROP TABLE IF EXISTS test.fanout_exchange_{0};
             DROP TABLE IF EXISTS test.fanout_exchange_{0}_mv;
@@ -1097,7 +1097,7 @@ def test_rabbitmq_topic_exchange(rabbitmq_cluster):
 
     num_tables = 5
     for consumer_id in range(num_tables):
-        print("Setting up table {}".format(consumer_id))
+        print(("Setting up table {}".format(consumer_id)))
         instance.query('''
             DROP TABLE IF EXISTS test.topic_exchange_{0};
             DROP TABLE IF EXISTS test.topic_exchange_{0}_mv;
@@ -1116,7 +1116,7 @@ def test_rabbitmq_topic_exchange(rabbitmq_cluster):
         '''.format(consumer_id))
 
     for consumer_id in range(num_tables):
-        print("Setting up table {}".format(num_tables + consumer_id))
+        print(("Setting up table {}".format(num_tables + consumer_id)))
         instance.query('''
             DROP TABLE IF EXISTS test.topic_exchange_{0};
             DROP TABLE IF EXISTS test.topic_exchange_{0}_mv;
@@ -1195,7 +1195,7 @@ def test_rabbitmq_hash_exchange(rabbitmq_cluster):
     num_tables = 4
     for consumer_id in range(num_tables):
         table_name = 'rabbitmq_consumer{}'.format(consumer_id)
-        print("Setting up {}".format(table_name))
+        print(("Setting up {}".format(table_name)))
         instance.query('''
             DROP TABLE IF EXISTS test.{0};
             DROP TABLE IF EXISTS test.{0}_mv;
@@ -1353,7 +1353,7 @@ def test_rabbitmq_headers_exchange(rabbitmq_cluster):
 
     num_tables_to_receive = 2
     for consumer_id in range(num_tables_to_receive):
-        print("Setting up table {}".format(consumer_id))
+        print(("Setting up table {}".format(consumer_id)))
         instance.query('''
             DROP TABLE IF EXISTS test.headers_exchange_{0};
             DROP TABLE IF EXISTS test.headers_exchange_{0}_mv;
@@ -1372,7 +1372,7 @@ def test_rabbitmq_headers_exchange(rabbitmq_cluster):
 
     num_tables_to_ignore = 2
     for consumer_id in range(num_tables_to_ignore):
-        print("Setting up table {}".format(consumer_id + num_tables_to_receive))
+        print(("Setting up table {}".format(consumer_id + num_tables_to_receive)))
         instance.query('''
             DROP TABLE IF EXISTS test.headers_exchange_{0};
             DROP TABLE IF EXISTS test.headers_exchange_{0}_mv;
@@ -1570,7 +1570,7 @@ def test_rabbitmq_many_consumers_to_each_queue(rabbitmq_cluster):
 
     num_tables = 4
     for table_id in range(num_tables):
-        print("Setting up table {}".format(table_id))
+        print(("Setting up table {}".format(table_id)))
         instance.query('''
             DROP TABLE IF EXISTS test.many_consumers_{0};
             DROP TABLE IF EXISTS test.many_consumers_{0}_mv;
@@ -1864,5 +1864,5 @@ def produce():
 
 if __name__ == '__main__':
     cluster.start()
-    raw_input("Cluster created, press any key to destroy...")
+    input("Cluster created, press any key to destroy...")
     cluster.shutdown()
diff --git a/tests/integration/test_storage_s3/s3_mock/mock_s3.py b/tests/integration/test_storage_s3/s3_mock/mock_s3.py
index 5b422f6a73a5..d76fe4ac36df 100644
--- a/tests/integration/test_storage_s3/s3_mock/mock_s3.py
+++ b/tests/integration/test_storage_s3/s3_mock/mock_s3.py
@@ -11,7 +11,7 @@ def infinite_redirect(_path):
 @route('/<_bucket>/<_path>')
 def server(_bucket, _path):
     for name in request.headers:
-        if name == 'Authorization' and request.headers[name] == u'Bearer TOKEN':
+        if name == 'Authorization' and request.headers[name] == 'Bearer TOKEN':
             return '1, 2, 3'
     abort(403)
 
diff --git a/tests/integration/test_storage_s3/test.py b/tests/integration/test_storage_s3/test.py
index f752e72c6779..42dbeda47170 100644
--- a/tests/integration/test_storage_s3/test.py
+++ b/tests/integration/test_storage_s3/test.py
@@ -2,8 +2,8 @@
 import json
 import logging
 import os
+import io
 import random
-import StringIO
 import threading
 import time
 
@@ -61,18 +61,20 @@ def prepare_s3_bucket(cluster):
 
 
 def put_s3_file_content(cluster, bucket, filename, data):
-    buf = StringIO.StringIO(data)
+    buf = io.BytesIO(data)
     cluster.minio_client.put_object(bucket, filename, buf, len(data))
 
 
 # Returns content of given S3 file as string.
-def get_s3_file_content(cluster, bucket, filename):
+def get_s3_file_content(cluster, bucket, filename, decode=True):
     # type: (ClickHouseCluster, str) -> str
 
     data = cluster.minio_client.get_object(bucket, filename)
-    data_str = ""
+    data_str = b""
     for chunk in data.stream():
         data_str += chunk
+    if decode:
+        return data_str.decode()
     return data_str
 
 
@@ -231,7 +233,7 @@ def test_multipart_put(cluster, maybe_auth, positive):
     one_line_length = 6  # 3 digits, 2 commas, 1 line separator.
 
     # Generate data having size more than one part
-    int_data = [[1, 2, 3] for i in range(csv_size_bytes / one_line_length)]
+    int_data = [[1, 2, 3] for i in range(csv_size_bytes // one_line_length)]
     csv_data = "".join(["{},{},{}
".format(x, y, z) for x, y, z in int_data])
 
     assert len(csv_data) > min_part_size_bytes
@@ -377,9 +379,9 @@ def test_storage_s3_get_gzip(cluster):
         "Norman Ortega,33",
         ""
     ]
-    buf = StringIO.StringIO()
+    buf = io.BytesIO()
     compressed = gzip.GzipFile(fileobj=buf, mode="wb")
-    compressed.write("
".join(data))
+    compressed.write(("
".join(data)).encode())
     compressed.close()
     put_s3_file_content(cluster, bucket, filename, buf.getvalue())
 
@@ -459,9 +461,9 @@ def test_storage_s3_put_gzip(cluster):
 
         run_query(instance, "SELECT sum(id) FROM {}".format(name)).splitlines() == ["708"]
 
-        buf = StringIO.StringIO(get_s3_file_content(cluster, bucket, filename))
+        buf = io.BytesIO(get_s3_file_content(cluster, bucket, filename, decode=False))
         f = gzip.GzipFile(fileobj=buf, mode="rb")
-        uncompressed_content = f.read()
+        uncompressed_content = f.read().decode()
         assert sum([ int(i.split(',')[1]) for i in uncompressed_content.splitlines() ]) == 708
     finally:
         run_query(instance, "DROP TABLE {}".format(name))
diff --git a/tests/integration/test_system_queries/test.py b/tests/integration/test_system_queries/test.py
index 18a164da805d..7f5bce97805f 100644
--- a/tests/integration/test_system_queries/test.py
+++ b/tests/integration/test_system_queries/test.py
@@ -26,9 +26,6 @@ def started_cluster():
         instance = cluster.instances['ch1']
         instance.query('CREATE DATABASE dictionaries ENGINE = Dictionary')
         instance.query('CREATE TABLE dictionary_source (id UInt64, value UInt8) ENGINE = Memory')
-        print instance.query('SELECT * FROM system.dictionaries FORMAT Vertical')
-        print "Started ", instance.ip_address
-
         yield cluster
 
     finally:
@@ -136,6 +133,6 @@ def test_SYSTEM_FLUSH_LOGS(started_cluster):
 
 if __name__ == '__main__':
     with contextmanager(started_cluster)() as cluster:
-        for name, instance in cluster.instances.items():
-            print name, instance.ip_address
-        raw_input("Cluster created, press any key to destroy...")
+        for name, instance in list(cluster.instances.items()):
+            print(name, instance.ip_address)
+        input("Cluster created, press any key to destroy...")
diff --git a/tests/integration/test_ttl_move/test.py b/tests/integration/test_ttl_move/test.py
index 377ee0e5d754..751d15b8313c 100644
--- a/tests/integration/test_ttl_move/test.py
+++ b/tests/integration/test_ttl_move/test.py
@@ -37,14 +37,6 @@ def started_cluster():
         cluster.shutdown()
 
 
-def get_random_string(length):
-    symbols = bytes(string.ascii_uppercase + string.digits)
-    result_list = bytearray([0]) * length
-    for i in range(length):
-        result_list[i] = random.choice(symbols)
-    return str(result_list)
-
-
 def get_used_disks_for_table(node, table_name, partition=None):
     if partition is None:
         suffix = ""
@@ -150,8 +142,8 @@ def test_inserts_to_disk_work(started_cluster, name, engine, positive):
 
         data = []  # 10MB in total
         for i in range(10):
-            data.append(("'{}'".format(get_random_string(1024 * 1024)), "toDateTime({})".format(
-                time.time() - 1 if i > 0 or positive else time.time() + 300)))  # 1MB row
+            data.append(("randomPrintableASCII(1024*1024)", "toDateTime({})".format(
+                time.time() - 1 if i > 0 or positive else time.time() + 300)))
 
         node1.query("INSERT INTO {} (s1, d1) VALUES {}".format(name, ",".join(["(" + ",".join(x) + ")" for x in data])))
         used_disks = get_used_disks_for_table(node1, name)
@@ -199,7 +191,7 @@ def test_moves_work_after_storage_policy_change(started_cluster, name, engine):
 
         data = []  # 10MB in total
         for i in range(10):
-            data.append(("'{}'".format(get_random_string(1024 * 1024)), "toDateTime({})".format(time_1)))  # 1MB row
+            data.append(("randomPrintableASCII(1024*1024)", "toDateTime({})".format(time_1)))
 
         node1.query("INSERT INTO {} (s1, d1) VALUES {}".format(name, ",".join(["(" + ",".join(x) + ")" for x in data])))
         used_disks = get_used_disks_for_table(node1, name)
@@ -247,8 +239,8 @@ def test_moves_to_disk_work(started_cluster, name, engine, positive):
 
         data = []  # 10MB in total
         for i in range(10):
-            data.append(("'{}'".format(get_random_string(1024 * 1024)),
-                         "toDateTime({})".format(time_1 if i > 0 or positive else time_2)))  # 1MB row
+            data.append(("randomPrintableASCII(1024*1024)",
+                         "toDateTime({})".format(time_1 if i > 0 or positive else time_2)))
 
         node1.query("INSERT INTO {} (s1, d1) VALUES {}".format(name, ",".join(["(" + ",".join(x) + ")" for x in data])))
         used_disks = get_used_disks_for_table(node1, name)
@@ -295,7 +287,7 @@ def test_moves_to_volume_work(started_cluster, name, engine):
             data = []  # 10MB in total
             for i in range(5):
                 data.append(
-                    (str(p), "'{}'".format(get_random_string(1024 * 1024)), "toDateTime({})".format(time_1)))  # 1MB row
+                    (str(p), "randomPrintableASCII(1024*1024)", "toDateTime({})".format(time_1)))
 
             node1.query(
                 "INSERT INTO {} (p1, s1, d1) VALUES {}".format(name, ",".join(["(" + ",".join(x) + ")" for x in data])))
@@ -342,8 +334,8 @@ def test_inserts_to_volume_work(started_cluster, name, engine, positive):
         for p in range(2):
             data = []  # 20MB in total
             for i in range(10):
-                data.append((str(p), "'{}'".format(get_random_string(1024 * 1024)), "toDateTime({})".format(
-                    time.time() - 1 if i > 0 or positive else time.time() + 300)))  # 1MB row
+                data.append((str(p), "randomPrintableASCII(1024*1024)", "toDateTime({})".format(
+                    time.time() - 1 if i > 0 or positive else time.time() + 300)))
 
             node1.query(
                 "INSERT INTO {} (p1, s1, d1) VALUES {}".format(name, ",".join(["(" + ",".join(x) + ")" for x in data])))
@@ -376,9 +368,9 @@ def test_moves_to_disk_eventually_work(started_cluster, name, engine):
 
         data = []  # 35MB in total
         for i in range(35):
-            data.append(get_random_string(1024 * 1024))  # 1MB row
+            data.append("randomPrintableASCII(1024*1024)")
 
-        node1.query("INSERT INTO {} VALUES {}".format(name_temp, ",".join(["('" + x + "')" for x in data])))
+        node1.query("INSERT INTO {} VALUES {}".format(name_temp, ",".join(["(" + x + ")" for x in data])))
         used_disks = get_used_disks_for_table(node1, name_temp)
         assert set(used_disks) == {"jbod2"}
 
@@ -395,7 +387,7 @@ def test_moves_to_disk_eventually_work(started_cluster, name, engine):
         data = []  # 10MB in total
         for i in range(10):
             data.append(
-                ("'{}'".format(get_random_string(1024 * 1024)), "toDateTime({})".format(time.time() - 1)))  # 1MB row
+                ("randomPrintableASCII(1024*1024)", "toDateTime({})".format(time.time() - 1)))
 
         node1.query("INSERT INTO {} (s1, d1) VALUES {}".format(name, ",".join(["(" + ",".join(x) + ")" for x in data])))
         used_disks = get_used_disks_for_table(node1, name)
@@ -431,8 +423,7 @@ def test_replicated_download_ttl_info(started_cluster):
 
         node1.query("SYSTEM STOP MOVES {}".format(name))
 
-        node2.query("INSERT INTO {} (s1, d1) VALUES ('{}', toDateTime({}))".format(name, get_random_string(1024 * 1024),
-                                                                                   time.time() - 100))
+        node2.query("INSERT INTO {} (s1, d1) VALUES (randomPrintableASCII(1024*1024), toDateTime({}))".format(name, time.time() - 100))
 
         assert set(get_used_disks_for_table(node2, name)) == {"external"}
         time.sleep(1)
@@ -482,8 +473,8 @@ def test_merges_to_disk_work(started_cluster, name, engine, positive):
         for _ in range(2):
             data = []  # 16MB in total
             for i in range(8):
-                data.append(("'{}'".format(get_random_string(1024 * 1024)),
-                             "toDateTime({})".format(time_1 if i > 0 or positive else time_2)))  # 1MB row
+                data.append(("randomPrintableASCII(1024*1024)",
+                             "toDateTime({})".format(time_1 if i > 0 or positive else time_2)))
 
             node1.query(
                 "INSERT INTO {} (s1, d1) VALUES {}".format(name, ",".join(["(" + ",".join(x) + ")" for x in data])))
@@ -530,9 +521,9 @@ def test_merges_with_full_disk_work(started_cluster, name, engine):
 
         data = []  # 35MB in total
         for i in range(35):
-            data.append(get_random_string(1024 * 1024))  # 1MB row
+            data.append("randomPrintableASCII(1024*1024)")
 
-        node1.query("INSERT INTO {} VALUES {}".format(name_temp, ",".join(["('" + x + "')" for x in data])))
+        node1.query("INSERT INTO {} VALUES {}".format(name_temp, ",".join(["(" + x + ")" for x in data])))
         used_disks = get_used_disks_for_table(node1, name_temp)
         assert set(used_disks) == {"jbod2"}
 
@@ -555,7 +546,7 @@ def test_merges_with_full_disk_work(started_cluster, name, engine):
         for _ in range(2):
             data = []  # 12MB in total
             for i in range(6):
-                data.append(("'{}'".format(get_random_string(1024 * 1024)), "toDateTime({})".format(time_1)))  # 1MB row
+                data.append(("randomPrintableASCII(1024*1024)", "toDateTime({})".format(time_1)))  # 1MB row
             node1.query(
                 "INSERT INTO {} (s1, d1) VALUES {}".format(name, ",".join(["(" + ",".join(x) + ")" for x in data])))
 
@@ -612,7 +603,7 @@ def test_moves_after_merges_work(started_cluster, name, engine, positive):
         for _ in range(2):
             data = []  # 14MB in total
             for i in range(7):
-                data.append(("'{}'".format(get_random_string(1024 * 1024)),
+                data.append(("randomPrintableASCII(1024*1024)",
                              "toDateTime({})".format(time_1 if i > 0 or positive else time_2)))  # 1MB row
 
             node1.query(
@@ -674,7 +665,7 @@ def test_ttls_do_not_work_after_alter(started_cluster, name, engine, positive, b
         data = []  # 10MB in total
         for i in range(10):
             data.append(
-                ("'{}'".format(get_random_string(1024 * 1024)), "toDateTime({})".format(time.time() - 1)))  # 1MB row
+                ("randomPrintableASCII(1024*1024)", "toDateTime({})".format(time.time() - 1)))  # 1MB row
         node1.query("INSERT INTO {} (s1, d1) VALUES {}".format(name, ",".join(["(" + ",".join(x) + ")" for x in data])))
 
         used_disks = get_used_disks_for_table(node1, name)
@@ -706,7 +697,7 @@ def test_materialize_ttl_in_partition(started_cluster, name, engine):
 
         data = []  # 5MB in total
         for i in range(5):
-            data.append((str(i), "'{}'".format(get_random_string(1024 * 1024)),
+            data.append((str(i), "randomPrintableASCII(1024*1024)",
                          "toDateTime({})".format(time.time() - 1)))  # 1MB row
         node1.query(
             "INSERT INTO {} (p1, s1, d1) VALUES {}".format(name, ",".join(["(" + ",".join(x) + ")" for x in data])))
@@ -808,9 +799,8 @@ def test_alter_multiple_ttls(started_cluster, name, engine, positive):
             now = time.time()
             for i in range(2):
                 p1 = p
-                s1 = get_random_string(1024 * 1024)  # 1MB
                 d1 = now - 1 if i > 0 or positive else now + 300
-                data.append("({}, '{}', toDateTime({}))".format(p1, s1, d1))
+                data.append("({}, randomPrintableASCII(1024*1024), toDateTime({}))".format(p1, d1))
             node1.query("INSERT INTO {name} (p1, s1, d1) VALUES {values}".format(name=name, values=",".join(data)))
 
         used_disks = get_used_disks_for_table(node1, name)
@@ -970,7 +960,7 @@ def test_double_move_while_select(started_cluster, name, positive):
         """.format(name=name))
 
         node1.query(
-            "INSERT INTO {name} VALUES (1, '{string}')".format(name=name, string=get_random_string(10 * 1024 * 1024)))
+            "INSERT INTO {name} VALUES (1, randomPrintableASCII(10*1024*1024))".format(name=name))
 
         parts = node1.query(
             "SELECT name FROM system.parts WHERE table = '{name}' AND active = 1".format(name=name)).splitlines()
@@ -991,11 +981,11 @@ def long_select():
 
         # Fill jbod1 to force ClickHouse to make move of partition 1 to external.
         node1.query(
-            "INSERT INTO {name} VALUES (2, '{string}')".format(name=name, string=get_random_string(9 * 1024 * 1024)))
+            "INSERT INTO {name} VALUES (2, randomPrintableASCII(9*1024*1024))".format(name=name))
         node1.query(
-            "INSERT INTO {name} VALUES (3, '{string}')".format(name=name, string=get_random_string(9 * 1024 * 1024)))
+            "INSERT INTO {name} VALUES (3, randomPrintableASCII(9*1024*1024))".format(name=name))
         node1.query(
-            "INSERT INTO {name} VALUES (4, '{string}')".format(name=name, string=get_random_string(9 * 1024 * 1024)))
+            "INSERT INTO {name} VALUES (4, randomPrintableASCII(9*1024*1024))".format(name=name))
 
         time.sleep(1)
 
@@ -1059,9 +1049,8 @@ def optimize_table(num):
             data = []  # 6MB in total
             now = time.time()
             for i in range(2):
-                s1 = get_random_string(1024 * 1024)  # 1MB
                 d1 = now - 1 if positive else now + 300
-                data.append("('{}', toDateTime({}))".format(s1, d1))
+                data.append("(randomPrintableASCII(1024*1024), toDateTime({}))".format(d1))
             values = ",".join(data)
             node1.query("INSERT INTO {name} (s1, d1) VALUES {values}".format(name=name, values=values))
 
@@ -1126,8 +1115,7 @@ def test_disabled_ttl_move_on_insert(started_cluster, name, dest_type, engine):
 
         data = []  # 10MB in total
         for i in range(10):
-            data.append(("'{}'".format(get_random_string(1024 * 1024)), "toDateTime({})".format(
-                time.time() - 1)))  # 1MB row
+            data.append(("randomPrintableASCII(1024*1024)", "toDateTime({})".format(time.time() - 1)))
 
         node1.query("INSERT INTO {} (s1, d1) VALUES {}".format(name, ",".join(["(" + ",".join(x) + ")" for x in data])))
 
diff --git a/tests/integration/test_ttl_replicated/test.py b/tests/integration/test_ttl_replicated/test.py
index 13fb779a6e69..cbf13c202209 100644
--- a/tests/integration/test_ttl_replicated/test.py
+++ b/tests/integration/test_ttl_replicated/test.py
@@ -18,7 +18,7 @@ def started_cluster():
         yield cluster
 
     except Exception as ex:
-        print ex
+        print(ex)
 
     finally:
         cluster.shutdown()
diff --git a/tests/integration/test_user_ip_restrictions/test.py b/tests/integration/test_user_ip_restrictions/test.py
index 1f28fbde069f..a7344fd1a450 100644
--- a/tests/integration/test_user_ip_restrictions/test.py
+++ b/tests/integration/test_user_ip_restrictions/test.py
@@ -63,7 +63,7 @@ def test_ipv4(setup_cluster):
     except AssertionError:
         raise
     except Exception as ex:
-        print ex
+        print(ex)
 
 
 def test_ipv6(setup_cluster):
@@ -72,7 +72,7 @@ def test_ipv6(setup_cluster):
             ["bash", "-c", "/usr/bin/clickhouse client --host 2001:3984:3989::1:1000 --query 'select 1'"],
             privileged=True, user='root')
     except Exception as ex:
-        print ex
+        print(ex)
         assert False, "allowed client with 2001:3984:3989:0:0:0:1:1111 cannot connect to server with allowed mask '2001:3984:3989:0:0:0:0:0/112'"
 
     try:
@@ -90,4 +90,4 @@ def test_ipv6(setup_cluster):
     except AssertionError:
         raise
     except Exception as ex:
-        print ex
+        print(ex)
diff --git a/tests/integration/test_user_zero_database_access/test_user_zero_database_access.py b/tests/integration/test_user_zero_database_access/test_user_zero_database_access.py
index c5ea7ed60a0b..dd3789cde571 100644
--- a/tests/integration/test_user_zero_database_access/test_user_zero_database_access.py
+++ b/tests/integration/test_user_zero_database_access/test_user_zero_database_access.py
@@ -24,7 +24,7 @@ def test_user_zero_database_access(start_cluster):
     except AssertionError:
         raise
     except Exception as ex:
-        print ex
+        print(ex)
 
     try:
         node.exec_in_container(
@@ -47,7 +47,7 @@ def test_user_zero_database_access(start_cluster):
     except AssertionError:
         raise
     except Exception as ex:
-        print ex
+        print(ex)
 
     try:
         node.exec_in_container(
@@ -57,7 +57,7 @@ def test_user_zero_database_access(start_cluster):
     except AssertionError:
         raise
     except Exception as ex:
-        print ex
+        print(ex)
 
     try:
         node.exec_in_container(
diff --git a/tests/integration/test_zookeeper_config/test.py b/tests/integration/test_zookeeper_config/test.py
index 9bc206d8da49..eb5ab2da98f3 100644
--- a/tests/integration/test_zookeeper_config/test.py
+++ b/tests/integration/test_zookeeper_config/test.py
@@ -1,4 +1,4 @@
-from __future__ import print_function
+
 
 import time
 from os import path as p, unlink
@@ -147,7 +147,7 @@ def test_secure_connection():
 
     cluster = ClickHouseCluster(__file__, zookeeper_config_path='configs/zookeeper_config_with_ssl.xml')
 
-    docker_compose = NamedTemporaryFile(delete=False)
+    docker_compose = NamedTemporaryFile(mode='w+', delete=False)
 
     docker_compose.write(
         "version: '2.3'
services:
" +
diff --git a/tests/perf_drafts/accurate_comparisons/accurate_comparisons.sh b/tests/perf_drafts/accurate_comparisons/accurate_comparisons.sh
index 2cd040cec632..cfd73b5b942e 100755
--- a/tests/perf_drafts/accurate_comparisons/accurate_comparisons.sh
+++ b/tests/perf_drafts/accurate_comparisons/accurate_comparisons.sh
@@ -8,7 +8,7 @@ clickhouse-client -q "INSERT INTO test.comparisons SELECT toInt64(rand64()) + nu
 function test_cmp {
     echo -n "$1 : "
     echo "SELECT count() FROM test.comparisons WHERE ($1)" | clickhouse-benchmark --max_threads=1 -i 20 -d 0 --json test.json 1>&2 2>/dev/null
-    python2 -c "import json; print '%.3f' % float(json.load(open('test.json'))['query_time_percentiles']['0'])"
+    python3 -c "import json; print '%.3f' % float(json.load(open('test.json'))['query_time_percentiles']['0'])"
     rm test.json
 }
 
diff --git a/tests/queries/0_stateless/00386_long_in_pk.python b/tests/queries/0_stateless/00386_long_in_pk.python
index f189233d2997..ab5fc50d8e34 100644
--- a/tests/queries/0_stateless/00386_long_in_pk.python
+++ b/tests/queries/0_stateless/00386_long_in_pk.python
@@ -1,4 +1,4 @@
-#!/usr/bin/env python
+#!/usr/bin/env python3
 
 def gen_queries():
     create_template = 'create table tab_00386 (a Int8, b String, c Tuple(Int8), d Tuple(Tuple(Int8)), e Tuple(Int8, String), f Tuple(Tuple(Int8, String))) engine = MergeTree order by ({}) partition by {}'
@@ -45,9 +45,9 @@ def main():
     for q in gen_queries():
         resp = requests.post(url, data=q)
         if resp.status_code != 200 or resp.text.strip() not in ('1', ''):
-            print 'Query:', q
-            print 'Code:', resp.status_code
-            print resp.text
+            print('Query:', q)
+            print('Code:', resp.status_code)
+            print(resp.text)
             break
 
 if __name__ == "__main__":
diff --git a/tests/queries/0_stateless/00386_long_in_pk.sh b/tests/queries/0_stateless/00386_long_in_pk.sh
index 414a3dce32d3..8cad8f93a13d 100755
--- a/tests/queries/0_stateless/00386_long_in_pk.sh
+++ b/tests/queries/0_stateless/00386_long_in_pk.sh
@@ -5,5 +5,5 @@ CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 
 # We should have correct env vars from shell_config.sh to run this test
 
-python "$CURDIR"/00386_long_in_pk.python
+python3 "$CURDIR"/00386_long_in_pk.python
 
diff --git a/tests/queries/0_stateless/00411_long_accurate_number_comparison.python b/tests/queries/0_stateless/00411_long_accurate_number_comparison.python
index 47c5d7f3d5b8..3c8a8f2ea25d 100644
--- a/tests/queries/0_stateless/00411_long_accurate_number_comparison.python
+++ b/tests/queries/0_stateless/00411_long_accurate_number_comparison.python
@@ -1,9 +1,9 @@
-#!/usr/bin/env python
-from __future__ import print_function
-import os, itertools, urllib, urllib2, sys
+#!/usr/bin/env python3
+
+import os, itertools, urllib.request, urllib.parse, urllib.error, urllib.request, urllib.error, urllib.parse, sys
 
 def get_ch_answer(query):
-    return urllib.urlopen(os.environ.get('CLICKHOUSE_URL', 'http://localhost:' + os.environ.get('CLICKHOUSE_PORT_HTTP', '8123') ), data=query).read()
+    return urllib.request.urlopen(os.environ.get('CLICKHOUSE_URL', 'http://localhost:' + os.environ.get('CLICKHOUSE_PORT_HTTP', '8123') ), data=query.encode()).read().decode()
 
 def check_answers(query, answer):
     ch_answer = get_ch_answer(query)
@@ -83,9 +83,9 @@ def test_pair(v1, v2):
     answers += a
 
     if TEST_WITH_CASTING:
-        for t1 in TYPES.iterkeys():
+        for t1 in TYPES.keys():
             if inside_range(v1, t1):
-                for t2 in TYPES.iterkeys():
+                for t2 in TYPES.keys():
                     if inside_range(v2, t2):
                         q, a = test_operators(v1, v2, 'to{}({})'.format(t1, v1), 'to{}({})'.format(t2, v2))
                         query += ', ' + q
@@ -108,7 +108,7 @@ def test_float_pair(i, f):
     answers += a
 
     if TEST_WITH_CASTING:
-        for t1 in TYPES.iterkeys():
+        for t1 in TYPES.keys():
             if inside_range(i, t1):
                 q, a = test_operators(i, f, 'to{}({})'.format(t1, i), f_str)
                 query += ', ' + q
@@ -127,9 +127,9 @@ def main():
     num_int_tests = len(list(itertools.combinations(VALUES, 2)))
 
     num_parts = 4
-    for part in xrange(0, num_parts):
+    for part in range(0, num_parts):
         if 'int' + str(part + 1) in sys.argv[1:]:
-            for (v1, v2) in itertools.islice(itertools.combinations(VALUES, 2), part * num_int_tests / num_parts, (part + 1) * num_int_tests / num_parts):
+            for (v1, v2) in itertools.islice(itertools.combinations(VALUES, 2), part * num_int_tests // num_parts, (part + 1) * num_int_tests // num_parts):
                 q, a = test_pair(v1, v2)
                 if GENERATE_TEST_FILES:
                     sql_file.write(q + ";
")
diff --git a/tests/queries/0_stateless/00411_long_accurate_number_comparison_float.sh b/tests/queries/0_stateless/00411_long_accurate_number_comparison_float.sh
index 50a6cd386aee..17d0c7564e36 100755
--- a/tests/queries/0_stateless/00411_long_accurate_number_comparison_float.sh
+++ b/tests/queries/0_stateless/00411_long_accurate_number_comparison_float.sh
@@ -5,4 +5,4 @@ CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 
 # We should have correct env vars from shell_config.sh to run this test
 
-python "$CURDIR"/00411_long_accurate_number_comparison.python float
+python3 "$CURDIR"/00411_long_accurate_number_comparison.python float
diff --git a/tests/queries/0_stateless/00411_long_accurate_number_comparison_int1.sh b/tests/queries/0_stateless/00411_long_accurate_number_comparison_int1.sh
index 8aba65d89116..43d9d550ddf8 100755
--- a/tests/queries/0_stateless/00411_long_accurate_number_comparison_int1.sh
+++ b/tests/queries/0_stateless/00411_long_accurate_number_comparison_int1.sh
@@ -5,4 +5,4 @@ CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 
 # We should have correct env vars from shell_config.sh to run this test
 
-python "$CURDIR"/00411_long_accurate_number_comparison.python int1
+python3 "$CURDIR"/00411_long_accurate_number_comparison.python int1
diff --git a/tests/queries/0_stateless/00411_long_accurate_number_comparison_int2.sh b/tests/queries/0_stateless/00411_long_accurate_number_comparison_int2.sh
index 93001184144d..34aaf9ef7edf 100755
--- a/tests/queries/0_stateless/00411_long_accurate_number_comparison_int2.sh
+++ b/tests/queries/0_stateless/00411_long_accurate_number_comparison_int2.sh
@@ -5,4 +5,4 @@ CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 
 # We should have correct env vars from shell_config.sh to run this test
 
-python "$CURDIR"/00411_long_accurate_number_comparison.python int2
+python3 "$CURDIR"/00411_long_accurate_number_comparison.python int2
diff --git a/tests/queries/0_stateless/00411_long_accurate_number_comparison_int3.sh b/tests/queries/0_stateless/00411_long_accurate_number_comparison_int3.sh
index 08ef31863b51..139792944ee6 100755
--- a/tests/queries/0_stateless/00411_long_accurate_number_comparison_int3.sh
+++ b/tests/queries/0_stateless/00411_long_accurate_number_comparison_int3.sh
@@ -5,4 +5,4 @@ CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 
 # We should have correct env vars from shell_config.sh to run this test
 
-python "$CURDIR"/00411_long_accurate_number_comparison.python int3
+python3 "$CURDIR"/00411_long_accurate_number_comparison.python int3
diff --git a/tests/queries/0_stateless/00411_long_accurate_number_comparison_int4.sh b/tests/queries/0_stateless/00411_long_accurate_number_comparison_int4.sh
index a268066725b3..f57099e77cab 100755
--- a/tests/queries/0_stateless/00411_long_accurate_number_comparison_int4.sh
+++ b/tests/queries/0_stateless/00411_long_accurate_number_comparison_int4.sh
@@ -5,4 +5,4 @@ CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 
 # We should have correct env vars from shell_config.sh to run this test
 
-python "$CURDIR"/00411_long_accurate_number_comparison.python int4
+python3 "$CURDIR"/00411_long_accurate_number_comparison.python int4
diff --git a/tests/queries/0_stateless/00565_enum_order.sh b/tests/queries/0_stateless/00565_enum_order.sh
index d7d06b49108e..2851bcaaca26 100755
--- a/tests/queries/0_stateless/00565_enum_order.sh
+++ b/tests/queries/0_stateless/00565_enum_order.sh
@@ -42,7 +42,7 @@ QUERY='INSERT INTO "test_log"("date", "datetime", "path", "gtid", "query_serial"
     "new_fields"."is_null", "record_source_type", "record_source_timestamp", "deleted") FORMAT TabSeparated'
 QUERY="$(tr -d '
' <<<"$QUERY")"
 echo "$QUERY"
-URL=$(python -c 'print "'"${CLICKHOUSE_URL}"'&query=" + __import__("urllib").quote('"'''$QUERY'''"')')
+URL=$(python3 -c 'import urllib.parse; print("'"${CLICKHOUSE_URL}"'&query=" + urllib.parse.quote('"'''$QUERY'''"'))')
 
 set +e
 for _ in 1 2 3; do
diff --git a/tests/queries/0_stateless/00612_http_max_query_size.sh b/tests/queries/0_stateless/00612_http_max_query_size.sh
index a50155edab05..78ae4eba1dc5 100755
--- a/tests/queries/0_stateless/00612_http_max_query_size.sh
+++ b/tests/queries/0_stateless/00612_http_max_query_size.sh
@@ -28,20 +28,20 @@ if not url.startswith('http'):
 q = 'select sum(number) from (select * from system.numbers limit 10000000) where number = 0'
 
 def gen_data(q):
-    yield q
-    yield ''.join([' '] * (1024 - len(q)))
+    yield q.encode()
+    yield (''.join([' '] * (1024 - len(q)))).encode()
 
     pattern = ''' or toString(number) = '{}'
'''
 
     for i in range(1, 4 * 1024):
-        yield pattern.format(str(i).zfill(1024 - len(pattern) + 2))
+        yield pattern.format(str(i).zfill(1024 - len(pattern) + 2)).encode()
 
 s = requests.Session()
 resp = s.post(url + '&max_query_size={}'.format(1 << 21), timeout=1, data=gen_data(q), stream=True,
               headers = {'Connection': 'close'})
 
 for line in resp.iter_lines():
-    print line
-" | python | grep -o "Max query size exceeded"
+    print(line)
+" | python3 | grep -o "Max query size exceeded"
 echo -
 
diff --git a/tests/queries/0_stateless/00646_url_engine.python b/tests/queries/0_stateless/00646_url_engine.python
index c03ce51c9a9f..6a70fac21f30 100644
--- a/tests/queries/0_stateless/00646_url_engine.python
+++ b/tests/queries/0_stateless/00646_url_engine.python
@@ -1,14 +1,21 @@
-#!/usr/bin/env python
-from __future__ import print_function
+#!/usr/bin/env python3
+
+import socket
 import csv
 import sys
-import time
 import tempfile
 import threading
-import os, urllib
+import os
+import traceback
+import urllib.request
 import subprocess
 from io import StringIO
-from BaseHTTPServer import BaseHTTPRequestHandler, HTTPServer
+from http.server import BaseHTTPRequestHandler, HTTPServer
+
+def get_local_port(host):
+    with socket.socket() as fd:
+        fd.bind((host, 0))
+        return fd.getsockname()[1]
 
 CLICKHOUSE_HOST = os.environ.get('CLICKHOUSE_HOST', '127.0.0.1')
 CLICKHOUSE_PORT_HTTP = os.environ.get('CLICKHOUSE_PORT_HTTP', '8123')
@@ -21,7 +28,7 @@ CLICKHOUSE_PORT_HTTP = os.environ.get('CLICKHOUSE_PORT_HTTP', '8123')
 
 # IP-address of this host accessible from outside world.
 HTTP_SERVER_HOST = subprocess.check_output(['hostname', '-i']).decode('utf-8').strip()
-HTTP_SERVER_PORT = 55123
+HTTP_SERVER_PORT = get_local_port(HTTP_SERVER_HOST)
 
 # IP address and port of the HTTP server started from this script.
 HTTP_SERVER_ADDRESS = (HTTP_SERVER_HOST, HTTP_SERVER_PORT)
@@ -30,7 +37,7 @@ CSV_DATA = os.path.join(tempfile._get_default_tempdir(), next(tempfile._get_cand
 
 def get_ch_answer(query):
     url = os.environ.get('CLICKHOUSE_URL', 'http://{host}:{port}'.format(host=CLICKHOUSE_HOST, port=CLICKHOUSE_PORT_HTTP))
-    return urllib.urlopen(url, data=query).read()
+    return urllib.request.urlopen(url, data=query.encode()).read().decode()
 
 def check_answers(query, answer):
     ch_answer = get_ch_answer(query)
@@ -51,7 +58,7 @@ class CSVHTTPServer(BaseHTTPRequestHandler):
         with open(CSV_DATA, 'r') as fl:
             reader = csv.reader(fl, delimiter=',')
             for row in reader:
-                self.wfile.write(', '.join(row) + '
')
+                self.wfile.write((', '.join(row) + '
').encode())
         return
 
     def read_chunk(self):
@@ -77,14 +84,13 @@ class CSVHTTPServer(BaseHTTPRequestHandler):
             if not chunk:
                 break
             data += chunk
-        text = ""
         with StringIO(data) as fl:
             reader = csv.reader(fl, delimiter=',')
             with open(CSV_DATA, 'a') as d:
                 for row in reader:
                     d.write(','.join(row) + '
')
         self._set_headers()
-        self.wfile.write("ok")
+        self.wfile.write(b"ok")
 
     def log_message(self, format, *args):
         return
@@ -93,7 +99,7 @@ def start_server(requests_amount):
     httpd = HTTPServer(HTTP_SERVER_ADDRESS, CSVHTTPServer)
 
     def real_func():
-        for i in xrange(requests_amount):
+        for i in range(requests_amount):
             httpd.handle_request()
 
     t = threading.Thread(target=real_func)
@@ -113,7 +119,7 @@ def test_select(table_name="", schema="str String,numuint UInt32,numint Int32,do
         get_ch_answer("drop table if exists {}".format(table_name))
         get_ch_answer("create table {} ({}) engine=URL('{}', 'CSV')".format(table_name, schema, HTTP_SERVER_URL_STR))
 
-    for i in xrange(len(requests)):
+    for i in range(len(requests)):
         tbl = table_name
         if not tbl:
             tbl = "url('{addr}', 'CSV', '{schema}')".format(addr=HTTP_SERVER_URL_STR, schema=schema)
@@ -137,7 +143,7 @@ def test_insert(table_name="", schema="str String,numuint UInt32,numint Int32,do
         get_ch_answer(req.format(tbl=tbl))
 
 
-    for i in xrange(len(requests_select)):
+    for i in range(len(requests_select)):
         tbl = table_name
         if not tbl:
             tbl = "url('{addr}', 'CSV', '{schema}')".format(addr=HTTP_SERVER_URL_STR, schema=schema)
@@ -161,7 +167,7 @@ def main():
     ]
 
     select_requests = {
-        "select distinct numuint from {tbl} order by numuint": '
'.join([str(i) for i in xrange(11)]),
+        "select distinct numuint from {tbl} order by numuint": '
'.join([str(i) for i in range(11)]),
         "select count(*) from {tbl}": '12',
         'select double, count(*) from {tbl} group by double': "7.7\t2
9.9\t10"
     }
@@ -169,27 +175,24 @@ def main():
     t = start_server(len(select_only_requests) * 2 + (len(insert_requests) + len(select_requests)) * 2)
     t.start()
     # test table with url engine
-    test_select(table_name="test_table_select", requests=select_only_requests.keys(), answers=select_only_requests.values(), test_data=test_data)
+    test_select(table_name="test_table_select", requests=list(select_only_requests.keys()), answers=list(select_only_requests.values()), test_data=test_data)
     # test table function url
-    test_select(requests=select_only_requests.keys(), answers=select_only_requests.values(), test_data=test_data)
+    test_select(requests=list(select_only_requests.keys()), answers=list(select_only_requests.values()), test_data=test_data)
     #test insert into table with url engine
-    test_insert(table_name="test_table_insert", requests_insert=insert_requests, requests_select=select_requests.keys(), answers=select_requests.values())
+    test_insert(table_name="test_table_insert", requests_insert=insert_requests, requests_select=list(select_requests.keys()), answers=list(select_requests.values()))
     #test insert into table function url
-    test_insert(requests_insert=insert_requests, requests_select=select_requests.keys(), answers=select_requests.values())
+    test_insert(requests_insert=insert_requests, requests_select=list(select_requests.keys()), answers=list(select_requests.values()))
     t.join()
     print("PASSED")
 
 
 if __name__ == "__main__":
-    exception_text = ''
-    for i in range(1, 5):
-        try:
-            main()
-            break
-        except Exception as ex:
-            exception_text = str(ex)
-            time.sleep(0.1)
-
-    if exception_text:
-        print("Exception: {}".format(exception_text), file=sys.stderr)
+    try:
+        main()
+    except Exception as ex:
+        exc_type, exc_value, exc_traceback = sys.exc_info()
+        traceback.print_tb(exc_traceback, file=sys.stderr)
+        print(ex, file=sys.stderr)
+        sys.stderr.flush()
+
         os._exit(1)
diff --git a/tests/queries/0_stateless/00646_url_engine.sh b/tests/queries/0_stateless/00646_url_engine.sh
index ee2e2521cf8d..bf20e0c1222d 100755
--- a/tests/queries/0_stateless/00646_url_engine.sh
+++ b/tests/queries/0_stateless/00646_url_engine.sh
@@ -5,4 +5,4 @@ CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 
 # We should have correct env vars from shell_config.sh to run this test
 
-python "$CURDIR"/00646_url_engine.python
+python3 "$CURDIR"/00646_url_engine.python
diff --git a/tests/queries/0_stateless/00921_datetime64_compatibility.python b/tests/queries/0_stateless/00921_datetime64_compatibility.python
index 54630755f055..bf0ae8a72ac6 100755
--- a/tests/queries/0_stateless/00921_datetime64_compatibility.python
+++ b/tests/queries/0_stateless/00921_datetime64_compatibility.python
@@ -1,4 +1,4 @@
-#!/usr/bin/env python
+#!/usr/bin/env python3
 # encoding: utf-8
 
 import re
@@ -88,8 +88,7 @@ formatDateTime(N, '%C %d %D %e %F %H %I %j %m %M %p %R %S %T %u %V %w %y %Y %%')
 
 # Expanded later to cartesian product of all arguments.
 # NOTE: {N} to be turned into N after str.format() for keys (format string), but not for list of values!
-extra_ops =\
-[
+extra_ops = [
     # With same type:
     (
         ['N {op} N'],
@@ -161,37 +160,35 @@ extra_ops =\
 
 # Expand extra_ops here
 for funcs, args in extra_ops:
-    args_keys = args.keys()
-    for args_vals in itertools.product(*args.values()):
+    args_keys = list(args.keys())
+    for args_vals in itertools.product(*list(args.values())):
         for func in funcs:
-            result_func = func.format(**dict(zip(args_keys, args_vals)))
+            result_func = func.format(**dict(list(zip(args_keys, args_vals))))
             FUNCTIONS.append(result_func)
 
 # filter out empty lines and commented out lines
 COMMENTED_OUT_LINE_RE = re.compile(r"^\s*#")
-FUNCTIONS = list(filter(lambda f: len(f) != 0 and COMMENTED_OUT_LINE_RE.match(f) == None, FUNCTIONS))
+FUNCTIONS = list([f for f in FUNCTIONS if len(f) != 0 and COMMENTED_OUT_LINE_RE.match(f) == None])
 TYPES = ['D', 'DT', 'DT64']
 
-if sys.version_info[0] > 2:
-    escape_string_codec = 'unicode_escape'
-else:
-    escape_string_codec = 'string-escape'
-
 def escape_string(s):
-    return s.encode(escape_string_codec).decode('utf-8')
+    if sys.version_info[0] > 2:
+        return s.encode('unicode_escape').decode('utf-8').replace("'", "\\'")
+    else:
+        return s.encode('string-escape').decode('utf-8')
 
 
 def execute_functions_for_types(functions, types):
     # TODO: use string.Template here to allow lines that do not contain type, like: SELECT CAST(toDateTime64(1234567890), 'DateTime64')
     for func in functions:
-        print("""SELECT 'SELECT {func}';""".format(func=escape_string(func)))
+        print(("""SELECT 'SELECT {func}';""".format(func=escape_string(func))))
         for dt in types:
             prologue = "\
 WITH \
 toDateTime64('2019-09-16 19:20:11.234', 3, 'Europe/Minsk') as DT64, \
 toDateTime('2019-09-16 19:20:11', 'Europe/Minsk') as DT, \
 toDate('2019-09-16') as D, {X} as N".format(X=dt)
-            print("""{prologue} SELECT toTypeName(r), {func} as r FORMAT CSV;""".format(prologue=prologue, func=func))
+            print(("""{prologue} SELECT toTypeName(r), {func} as r FORMAT CSV;""".format(prologue=prologue, func=func)))
         print("""SELECT '------------------------------------------';""")
 
 def main():
@@ -210,22 +207,22 @@ def main():
     types = TYPES
 
     if args.functions_re:
-        functions = list(filter(lambda f : args.functions_re.search(f), functions))
+        functions = list([f for f in functions if args.functions_re.search(f)])
         if len(functions) == 0:
             print("functions list is empty")
             return -1
 
     if args.types_re:
-        types = list(filter(lambda t : args.types_re.match(t), types))
+        types = list([t for t in types if args.types_re.match(t)])
         if len(types) == 0:
             print("types list is empty")
             return -1
 
     if args.list_functions:
-        print("
".join(functions))
+        print(("
".join(functions)))
         return 0
 
     execute_functions_for_types(functions, types)
 
 if __name__ == '__main__':
-    exit(main())
\ No newline at end of file
+    exit(main())
diff --git a/tests/queries/0_stateless/00921_datetime64_compatibility.reference b/tests/queries/0_stateless/00921_datetime64_compatibility.reference
index 079469c8c2d8..1a909c8c754d 100644
--- a/tests/queries/0_stateless/00921_datetime64_compatibility.reference
+++ b/tests/queries/0_stateless/00921_datetime64_compatibility.reference
@@ -430,6 +430,36 @@ Code: 43: Illegal types DateTime('Europe/Minsk') and Date of arguments of functi
 
 Code: 43: Illegal types DateTime('Europe/Minsk') and DateTime64(3, 'Europe/Minsk') of arguments of function minus.
 ------------------------------------------
+SELECT N - D
+"Int32",0
+
+Code: 43: Illegal types DateTime('Europe/Minsk') and Date of arguments of function minus.
+
+Code: 43: Illegal types DateTime64(3, 'Europe/Minsk') and Date of arguments of function minus.
+------------------------------------------
+SELECT D - N
+"Int32",0
+
+Code: 43: Illegal types Date and DateTime('Europe/Minsk') of arguments of function minus.
+
+Code: 43: Illegal types Date and DateTime64(3, 'Europe/Minsk') of arguments of function minus.
+------------------------------------------
+SELECT N - DT64
+
+Code: 43: Illegal types Date and DateTime64(3, 'Europe/Minsk') of arguments of function minus.
+
+Code: 43: Illegal types DateTime('Europe/Minsk') and DateTime64(3, 'Europe/Minsk') of arguments of function minus.
+
+Code: 43: Illegal types DateTime64(3, 'Europe/Minsk') and DateTime64(3, 'Europe/Minsk') of arguments of function minus.
+------------------------------------------
+SELECT DT64 - N
+
+Code: 43: Illegal types DateTime64(3, 'Europe/Minsk') and Date of arguments of function minus.
+
+Code: 43: Illegal types DateTime64(3, 'Europe/Minsk') and DateTime('Europe/Minsk') of arguments of function minus.
+
+Code: 43: Illegal types DateTime64(3, 'Europe/Minsk') and DateTime64(3, 'Europe/Minsk') of arguments of function minus.
+------------------------------------------
 SELECT N != DT
 "UInt8",1
 "UInt8",0
@@ -440,89 +470,65 @@ SELECT DT != N
 "UInt8",0
 "UInt8",1
 ------------------------------------------
-SELECT N == DT
+SELECT N != D
 "UInt8",0
 "UInt8",1
-"UInt8",0
+"UInt8",1
 ------------------------------------------
-SELECT DT == N
+SELECT D != N
 "UInt8",0
 "UInt8",1
-"UInt8",0
-------------------------------------------
-SELECT N <  DT
 "UInt8",1
-"UInt8",0
-"UInt8",0
 ------------------------------------------
-SELECT DT <  N
-"UInt8",0
-"UInt8",0
+SELECT N != DT64
+"UInt8",1
 "UInt8",1
+"UInt8",0
 ------------------------------------------
-SELECT N <= DT
+SELECT DT64 != N
 "UInt8",1
 "UInt8",1
 "UInt8",0
 ------------------------------------------
-SELECT DT <= N
+SELECT N == DT
 "UInt8",0
 "UInt8",1
-"UInt8",1
-------------------------------------------
-SELECT N >  DT
 "UInt8",0
+------------------------------------------
+SELECT DT == N
 "UInt8",0
 "UInt8",1
+"UInt8",0
 ------------------------------------------
-SELECT DT >  N
+SELECT N == D
 "UInt8",1
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT N >= DT
-"UInt8",0
-"UInt8",1
-"UInt8",1
-------------------------------------------
-SELECT DT >= N
-"UInt8",1
+SELECT D == N
 "UInt8",1
 "UInt8",0
+"UInt8",0
 ------------------------------------------
-SELECT N - D
-"Int32",0
-
-Code: 43: Illegal types DateTime('Europe/Minsk') and Date of arguments of function minus.
-
-Code: 43: Illegal types DateTime64(3, 'Europe/Minsk') and Date of arguments of function minus.
-------------------------------------------
-SELECT D - N
-"Int32",0
-
-Code: 43: Illegal types Date and DateTime('Europe/Minsk') of arguments of function minus.
-
-Code: 43: Illegal types Date and DateTime64(3, 'Europe/Minsk') of arguments of function minus.
-------------------------------------------
-SELECT N != D
+SELECT N == DT64
+"UInt8",0
 "UInt8",0
-"UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT D != N
+SELECT DT64 == N
+"UInt8",0
 "UInt8",0
-"UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT N == D
+SELECT N <  DT
 "UInt8",1
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT D == N
-"UInt8",1
+SELECT DT <  N
 "UInt8",0
 "UInt8",0
+"UInt8",1
 ------------------------------------------
 SELECT N <  D
 "UInt8",0
@@ -534,100 +540,94 @@ SELECT D <  N
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT N <= D
+SELECT N <  DT64
 "UInt8",1
+"UInt8",1
+"UInt8",0
+------------------------------------------
+SELECT DT64 <  N
+"UInt8",0
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT D <= N
-"UInt8",1
+SELECT N <= DT
 "UInt8",1
 "UInt8",1
+"UInt8",0
 ------------------------------------------
-SELECT N >  D
+SELECT DT <= N
 "UInt8",0
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT D >  N
-"UInt8",0
+SELECT N <= D
+"UInt8",1
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT N >= D
+SELECT D <= N
 "UInt8",1
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT D >= N
+SELECT N <= DT64
 "UInt8",1
-"UInt8",0
-"UInt8",0
-------------------------------------------
-SELECT N - DT64
-
-Code: 43: Illegal types Date and DateTime64(3, 'Europe/Minsk') of arguments of function minus.
-
-Code: 43: Illegal types DateTime('Europe/Minsk') and DateTime64(3, 'Europe/Minsk') of arguments of function minus.
-
-Code: 43: Illegal types DateTime64(3, 'Europe/Minsk') and DateTime64(3, 'Europe/Minsk') of arguments of function minus.
-------------------------------------------
-SELECT DT64 - N
-
-Code: 43: Illegal types DateTime64(3, 'Europe/Minsk') and Date of arguments of function minus.
-
-Code: 43: Illegal types DateTime64(3, 'Europe/Minsk') and DateTime('Europe/Minsk') of arguments of function minus.
-
-Code: 43: Illegal types DateTime64(3, 'Europe/Minsk') and DateTime64(3, 'Europe/Minsk') of arguments of function minus.
-------------------------------------------
-SELECT N != DT64
 "UInt8",1
 "UInt8",1
-"UInt8",0
 ------------------------------------------
-SELECT DT64 != N
-"UInt8",1
-"UInt8",1
+SELECT DT64 <= N
 "UInt8",0
+"UInt8",0
+"UInt8",1
 ------------------------------------------
-SELECT N == DT64
+SELECT N >  DT
 "UInt8",0
 "UInt8",0
 "UInt8",1
 ------------------------------------------
-SELECT DT64 == N
+SELECT DT >  N
+"UInt8",1
 "UInt8",0
 "UInt8",0
-"UInt8",1
 ------------------------------------------
-SELECT N <  DT64
+SELECT N >  D
+"UInt8",0
 "UInt8",1
 "UInt8",1
+------------------------------------------
+SELECT D >  N
+"UInt8",0
+"UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT DT64 <  N
+SELECT N >  DT64
 "UInt8",0
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT N <= DT64
-"UInt8",1
+SELECT DT64 >  N
 "UInt8",1
 "UInt8",1
-------------------------------------------
-SELECT DT64 <= N
 "UInt8",0
+------------------------------------------
+SELECT N >= DT
 "UInt8",0
 "UInt8",1
+"UInt8",1
 ------------------------------------------
-SELECT N >  DT64
-"UInt8",0
-"UInt8",0
+SELECT DT >= N
+"UInt8",1
+"UInt8",1
 "UInt8",0
 ------------------------------------------
-SELECT DT64 >  N
+SELECT N >= D
+"UInt8",1
 "UInt8",1
 "UInt8",1
+------------------------------------------
+SELECT D >= N
+"UInt8",1
+"UInt8",0
 "UInt8",0
 ------------------------------------------
 SELECT N >= DT64
@@ -650,6 +650,76 @@ SELECT toUInt8(1) +  N
 "DateTime('Europe/Minsk')","2019-09-16 19:20:12"
 "DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:12.234"
 ------------------------------------------
+SELECT N +  toInt8(-1)
+"Date","2019-09-15"
+"DateTime('Europe/Minsk')","2019-09-16 19:20:10"
+"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:10.234"
+------------------------------------------
+SELECT toInt8(-1) +  N
+"Date","2019-09-15"
+"DateTime('Europe/Minsk')","2019-09-16 19:20:10"
+"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:10.234"
+------------------------------------------
+SELECT N +  toUInt16(1)
+"Date","2019-09-17"
+"DateTime('Europe/Minsk')","2019-09-16 19:20:12"
+"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:12.234"
+------------------------------------------
+SELECT toUInt16(1) +  N
+"Date","2019-09-17"
+"DateTime('Europe/Minsk')","2019-09-16 19:20:12"
+"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:12.234"
+------------------------------------------
+SELECT N +  toInt16(-1)
+"Date","2019-09-15"
+"DateTime('Europe/Minsk')","2019-09-16 19:20:10"
+"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:10.234"
+------------------------------------------
+SELECT toInt16(-1) +  N
+"Date","2019-09-15"
+"DateTime('Europe/Minsk')","2019-09-16 19:20:10"
+"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:10.234"
+------------------------------------------
+SELECT N +  toUInt32(1)
+"Date","2019-09-17"
+"DateTime('Europe/Minsk')","2019-09-16 19:20:12"
+"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:12.234"
+------------------------------------------
+SELECT toUInt32(1) +  N
+"Date","2019-09-17"
+"DateTime('Europe/Minsk')","2019-09-16 19:20:12"
+"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:12.234"
+------------------------------------------
+SELECT N +  toInt32(-1)
+"Date","2019-09-15"
+"DateTime('Europe/Minsk')","2019-09-16 19:20:10"
+"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:10.234"
+------------------------------------------
+SELECT toInt32(-1) +  N
+"Date","2019-09-15"
+"DateTime('Europe/Minsk')","2019-09-16 19:20:10"
+"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:10.234"
+------------------------------------------
+SELECT N +  toUInt64(1)
+"Date","2019-09-17"
+"DateTime('Europe/Minsk')","2019-09-16 19:20:12"
+"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:12.234"
+------------------------------------------
+SELECT toUInt64(1) +  N
+"Date","2019-09-17"
+"DateTime('Europe/Minsk')","2019-09-16 19:20:12"
+"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:12.234"
+------------------------------------------
+SELECT N +  toInt64(-1)
+"Date","2019-09-15"
+"DateTime('Europe/Minsk')","2019-09-16 19:20:10"
+"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:10.234"
+------------------------------------------
+SELECT toInt64(-1) +  N
+"Date","2019-09-15"
+"DateTime('Europe/Minsk')","2019-09-16 19:20:10"
+"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:10.234"
+------------------------------------------
 SELECT N -  toUInt8(1)
 "Date","2019-09-15"
 "DateTime('Europe/Minsk')","2019-09-16 19:20:10"
@@ -663,94 +733,90 @@ Code: 43: Wrong order of arguments for function minus: argument of type Interval
 
 Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
 ------------------------------------------
-SELECT N == toUInt8(1)
-
-Code: 43: Illegal types of arguments (Date, UInt8) of function equals.
-"UInt8",0
-"UInt8",0
-------------------------------------------
-SELECT toUInt8(1) == N
-
-Code: 43: Illegal types of arguments (UInt8, Date) of function equals.
-"UInt8",0
-"UInt8",0
+SELECT N -  toInt8(-1)
+"Date","2019-09-17"
+"DateTime('Europe/Minsk')","2019-09-16 19:20:12"
+"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:12.234"
 ------------------------------------------
-SELECT N != toUInt8(1)
+SELECT toInt8(-1) -  N
 
-Code: 43: Illegal types of arguments (Date, UInt8) of function notEquals.
-"UInt8",1
-"UInt8",1
-------------------------------------------
-SELECT toUInt8(1) != N
+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
 
-Code: 43: Illegal types of arguments (UInt8, Date) of function notEquals.
-"UInt8",1
-"UInt8",1
-------------------------------------------
-SELECT N <  toUInt8(1)
+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
 
-Code: 43: Illegal types of arguments (Date, UInt8) of function less.
-"UInt8",0
-"UInt8",0
+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
 ------------------------------------------
-SELECT toUInt8(1) <  N
-
-Code: 43: Illegal types of arguments (UInt8, Date) of function less.
-"UInt8",1
-"UInt8",1
+SELECT N -  toUInt16(1)
+"Date","2019-09-15"
+"DateTime('Europe/Minsk')","2019-09-16 19:20:10"
+"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:10.234"
 ------------------------------------------
-SELECT N <= toUInt8(1)
+SELECT toUInt16(1) -  N
 
-Code: 43: Illegal types of arguments (Date, UInt8) of function lessOrEquals.
-"UInt8",0
-"UInt8",0
-------------------------------------------
-SELECT toUInt8(1) <= N
+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
 
-Code: 43: Illegal types of arguments (UInt8, Date) of function lessOrEquals.
-"UInt8",1
-"UInt8",1
-------------------------------------------
-SELECT N >  toUInt8(1)
+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
 
-Code: 43: Illegal types of arguments (Date, UInt8) of function greater.
-"UInt8",1
-"UInt8",1
+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
 ------------------------------------------
-SELECT toUInt8(1) >  N
-
-Code: 43: Illegal types of arguments (UInt8, Date) of function greater.
-"UInt8",0
-"UInt8",0
+SELECT N -  toInt16(-1)
+"Date","2019-09-17"
+"DateTime('Europe/Minsk')","2019-09-16 19:20:12"
+"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:12.234"
 ------------------------------------------
-SELECT N >= toUInt8(1)
+SELECT toInt16(-1) -  N
 
-Code: 43: Illegal types of arguments (Date, UInt8) of function greaterOrEquals.
-"UInt8",1
-"UInt8",1
-------------------------------------------
-SELECT toUInt8(1) >= N
+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
 
-Code: 43: Illegal types of arguments (UInt8, Date) of function greaterOrEquals.
-"UInt8",0
-"UInt8",0
+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
+
+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
 ------------------------------------------
-SELECT N +  toInt8(-1)
+SELECT N -  toUInt32(1)
 "Date","2019-09-15"
 "DateTime('Europe/Minsk')","2019-09-16 19:20:10"
 "DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:10.234"
 ------------------------------------------
-SELECT toInt8(-1) +  N
+SELECT toUInt32(1) -  N
+
+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
+
+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
+
+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
+------------------------------------------
+SELECT N -  toInt32(-1)
+"Date","2019-09-17"
+"DateTime('Europe/Minsk')","2019-09-16 19:20:12"
+"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:12.234"
+------------------------------------------
+SELECT toInt32(-1) -  N
+
+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
+
+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
+
+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
+------------------------------------------
+SELECT N -  toUInt64(1)
 "Date","2019-09-15"
 "DateTime('Europe/Minsk')","2019-09-16 19:20:10"
 "DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:10.234"
 ------------------------------------------
-SELECT N -  toInt8(-1)
+SELECT toUInt64(1) -  N
+
+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
+
+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
+
+Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
+------------------------------------------
+SELECT N -  toInt64(-1)
 "Date","2019-09-17"
 "DateTime('Europe/Minsk')","2019-09-16 19:20:12"
 "DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:12.234"
 ------------------------------------------
-SELECT toInt8(-1) -  N
+SELECT toInt64(-1) -  N
 
 Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
 
@@ -758,6 +824,18 @@ Code: 43: Wrong order of arguments for function minus: argument of type Interval
 
 Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
 ------------------------------------------
+SELECT N == toUInt8(1)
+
+Code: 43: Illegal types of arguments (Date, UInt8) of function equals.
+"UInt8",0
+"UInt8",0
+------------------------------------------
+SELECT toUInt8(1) == N
+
+Code: 43: Illegal types of arguments (UInt8, Date) of function equals.
+"UInt8",0
+"UInt8",0
+------------------------------------------
 SELECT N == toInt8(-1)
 
 Code: 43: Illegal types of arguments (Date, Int8) of function equals.
@@ -770,196 +848,114 @@ Code: 43: Illegal types of arguments (Int8, Date) of function equals.
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT N != toInt8(-1)
-
-Code: 43: Illegal types of arguments (Date, Int8) of function notEquals.
-"UInt8",1
-"UInt8",1
-------------------------------------------
-SELECT toInt8(-1) != N
+SELECT N == toUInt16(1)
 
-Code: 43: Illegal types of arguments (Int8, Date) of function notEquals.
-"UInt8",1
-"UInt8",1
+Code: 43: Illegal types of arguments (Date, UInt16) of function equals.
+"UInt8",0
+"UInt8",0
 ------------------------------------------
-SELECT N <  toInt8(-1)
+SELECT toUInt16(1) == N
 
-Code: 43: Illegal types of arguments (Date, Int8) of function less.
+Code: 43: Illegal types of arguments (UInt16, Date) of function equals.
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT toInt8(-1) <  N
+SELECT N == toInt16(-1)
 
-Code: 43: Illegal types of arguments (Int8, Date) of function less.
-"UInt8",1
-"UInt8",1
+Code: 43: Illegal types of arguments (Date, Int16) of function equals.
+"UInt8",0
+"UInt8",0
 ------------------------------------------
-SELECT N <= toInt8(-1)
+SELECT toInt16(-1) == N
 
-Code: 43: Illegal types of arguments (Date, Int8) of function lessOrEquals.
+Code: 43: Illegal types of arguments (Int16, Date) of function equals.
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT toInt8(-1) <= N
+SELECT N == toUInt32(1)
 
-Code: 43: Illegal types of arguments (Int8, Date) of function lessOrEquals.
-"UInt8",1
-"UInt8",1
+Code: 43: Illegal types of arguments (Date, UInt32) of function equals.
+"UInt8",0
+"UInt8",0
 ------------------------------------------
-SELECT N >  toInt8(-1)
+SELECT toUInt32(1) == N
 
-Code: 43: Illegal types of arguments (Date, Int8) of function greater.
-"UInt8",1
-"UInt8",1
+Code: 43: Illegal types of arguments (UInt32, Date) of function equals.
+"UInt8",0
+"UInt8",0
 ------------------------------------------
-SELECT toInt8(-1) >  N
+SELECT N == toInt32(-1)
 
-Code: 43: Illegal types of arguments (Int8, Date) of function greater.
+Code: 43: Illegal types of arguments (Date, Int32) of function equals.
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT N >= toInt8(-1)
+SELECT toInt32(-1) == N
 
-Code: 43: Illegal types of arguments (Date, Int8) of function greaterOrEquals.
-"UInt8",1
-"UInt8",1
+Code: 43: Illegal types of arguments (Int32, Date) of function equals.
+"UInt8",0
+"UInt8",0
 ------------------------------------------
-SELECT toInt8(-1) >= N
+SELECT N == toUInt64(1)
 
-Code: 43: Illegal types of arguments (Int8, Date) of function greaterOrEquals.
+Code: 43: Illegal types of arguments (Date, UInt64) of function equals.
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT N +  toUInt16(1)
-"Date","2019-09-17"
-"DateTime('Europe/Minsk')","2019-09-16 19:20:12"
-"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:12.234"
-------------------------------------------
-SELECT toUInt16(1) +  N
-"Date","2019-09-17"
-"DateTime('Europe/Minsk')","2019-09-16 19:20:12"
-"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:12.234"
-------------------------------------------
-SELECT N -  toUInt16(1)
-"Date","2019-09-15"
-"DateTime('Europe/Minsk')","2019-09-16 19:20:10"
-"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:10.234"
-------------------------------------------
-SELECT toUInt16(1) -  N
-
-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
-
-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
+SELECT toUInt64(1) == N
 
-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
+Code: 43: Illegal types of arguments (UInt64, Date) of function equals.
+"UInt8",0
+"UInt8",0
 ------------------------------------------
-SELECT N == toUInt16(1)
+SELECT N == toInt64(-1)
 
-Code: 43: Illegal types of arguments (Date, UInt16) of function equals.
+Code: 43: Illegal types of arguments (Date, Int64) of function equals.
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT toUInt16(1) == N
+SELECT toInt64(-1) == N
 
-Code: 43: Illegal types of arguments (UInt16, Date) of function equals.
+Code: 43: Illegal types of arguments (Int64, Date) of function equals.
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT N != toUInt16(1)
+SELECT N != toUInt8(1)
 
-Code: 43: Illegal types of arguments (Date, UInt16) of function notEquals.
+Code: 43: Illegal types of arguments (Date, UInt8) of function notEquals.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT toUInt16(1) != N
+SELECT toUInt8(1) != N
 
-Code: 43: Illegal types of arguments (UInt16, Date) of function notEquals.
+Code: 43: Illegal types of arguments (UInt8, Date) of function notEquals.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT N <  toUInt16(1)
-
-Code: 43: Illegal types of arguments (Date, UInt16) of function less.
-"UInt8",0
-"UInt8",0
-------------------------------------------
-SELECT toUInt16(1) <  N
+SELECT N != toInt8(-1)
 
-Code: 43: Illegal types of arguments (UInt16, Date) of function less.
+Code: 43: Illegal types of arguments (Date, Int8) of function notEquals.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT N <= toUInt16(1)
-
-Code: 43: Illegal types of arguments (Date, UInt16) of function lessOrEquals.
-"UInt8",0
-"UInt8",0
-------------------------------------------
-SELECT toUInt16(1) <= N
+SELECT toInt8(-1) != N
 
-Code: 43: Illegal types of arguments (UInt16, Date) of function lessOrEquals.
+Code: 43: Illegal types of arguments (Int8, Date) of function notEquals.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT N >  toUInt16(1)
+SELECT N != toUInt16(1)
 
-Code: 43: Illegal types of arguments (Date, UInt16) of function greater.
+Code: 43: Illegal types of arguments (Date, UInt16) of function notEquals.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT toUInt16(1) >  N
-
-Code: 43: Illegal types of arguments (UInt16, Date) of function greater.
-"UInt8",0
-"UInt8",0
-------------------------------------------
-SELECT N >= toUInt16(1)
+SELECT toUInt16(1) != N
 
-Code: 43: Illegal types of arguments (Date, UInt16) of function greaterOrEquals.
+Code: 43: Illegal types of arguments (UInt16, Date) of function notEquals.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT toUInt16(1) >= N
-
-Code: 43: Illegal types of arguments (UInt16, Date) of function greaterOrEquals.
-"UInt8",0
-"UInt8",0
-------------------------------------------
-SELECT N +  toInt16(-1)
-"Date","2019-09-15"
-"DateTime('Europe/Minsk')","2019-09-16 19:20:10"
-"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:10.234"
-------------------------------------------
-SELECT toInt16(-1) +  N
-"Date","2019-09-15"
-"DateTime('Europe/Minsk')","2019-09-16 19:20:10"
-"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:10.234"
-------------------------------------------
-SELECT N -  toInt16(-1)
-"Date","2019-09-17"
-"DateTime('Europe/Minsk')","2019-09-16 19:20:12"
-"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:12.234"
-------------------------------------------
-SELECT toInt16(-1) -  N
-
-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
-
-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
-
-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
-------------------------------------------
-SELECT N == toInt16(-1)
-
-Code: 43: Illegal types of arguments (Date, Int16) of function equals.
-"UInt8",0
-"UInt8",0
-------------------------------------------
-SELECT toInt16(-1) == N
-
-Code: 43: Illegal types of arguments (Int16, Date) of function equals.
-"UInt8",0
-"UInt8",0
-------------------------------------------
 SELECT N != toInt16(-1)
 
 Code: 43: Illegal types of arguments (Date, Int16) of function notEquals.
@@ -972,98 +968,99 @@ Code: 43: Illegal types of arguments (Int16, Date) of function notEquals.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT N <  toInt16(-1)
+SELECT N != toUInt32(1)
 
-Code: 43: Illegal types of arguments (Date, Int16) of function less.
-"UInt8",0
-"UInt8",0
+Code: 43: Illegal types of arguments (Date, UInt32) of function notEquals.
+"UInt8",1
+"UInt8",1
 ------------------------------------------
-SELECT toInt16(-1) <  N
+SELECT toUInt32(1) != N
 
-Code: 43: Illegal types of arguments (Int16, Date) of function less.
+Code: 43: Illegal types of arguments (UInt32, Date) of function notEquals.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT N <= toInt16(-1)
+SELECT N != toInt32(-1)
 
-Code: 43: Illegal types of arguments (Date, Int16) of function lessOrEquals.
-"UInt8",0
-"UInt8",0
+Code: 43: Illegal types of arguments (Date, Int32) of function notEquals.
+"UInt8",1
+"UInt8",1
 ------------------------------------------
-SELECT toInt16(-1) <= N
+SELECT toInt32(-1) != N
 
-Code: 43: Illegal types of arguments (Int16, Date) of function lessOrEquals.
+Code: 43: Illegal types of arguments (Int32, Date) of function notEquals.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT N >  toInt16(-1)
+SELECT N != toUInt64(1)
 
-Code: 43: Illegal types of arguments (Date, Int16) of function greater.
+Code: 43: Illegal types of arguments (Date, UInt64) of function notEquals.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT toInt16(-1) >  N
+SELECT toUInt64(1) != N
 
-Code: 43: Illegal types of arguments (Int16, Date) of function greater.
-"UInt8",0
-"UInt8",0
+Code: 43: Illegal types of arguments (UInt64, Date) of function notEquals.
+"UInt8",1
+"UInt8",1
 ------------------------------------------
-SELECT N >= toInt16(-1)
+SELECT N != toInt64(-1)
 
-Code: 43: Illegal types of arguments (Date, Int16) of function greaterOrEquals.
+Code: 43: Illegal types of arguments (Date, Int64) of function notEquals.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT toInt16(-1) >= N
+SELECT toInt64(-1) != N
 
-Code: 43: Illegal types of arguments (Int16, Date) of function greaterOrEquals.
+Code: 43: Illegal types of arguments (Int64, Date) of function notEquals.
+"UInt8",1
+"UInt8",1
+------------------------------------------
+SELECT N <  toUInt8(1)
+
+Code: 43: Illegal types of arguments (Date, UInt8) of function less.
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT N +  toUInt32(1)
-"Date","2019-09-17"
-"DateTime('Europe/Minsk')","2019-09-16 19:20:12"
-"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:12.234"
-------------------------------------------
-SELECT toUInt32(1) +  N
-"Date","2019-09-17"
-"DateTime('Europe/Minsk')","2019-09-16 19:20:12"
-"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:12.234"
-------------------------------------------
-SELECT N -  toUInt32(1)
-"Date","2019-09-15"
-"DateTime('Europe/Minsk')","2019-09-16 19:20:10"
-"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:10.234"
-------------------------------------------
-SELECT toUInt32(1) -  N
-
-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
-
-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
+SELECT toUInt8(1) <  N
 
-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
+Code: 43: Illegal types of arguments (UInt8, Date) of function less.
+"UInt8",1
+"UInt8",1
 ------------------------------------------
-SELECT N == toUInt32(1)
+SELECT N <  toInt8(-1)
 
-Code: 43: Illegal types of arguments (Date, UInt32) of function equals.
+Code: 43: Illegal types of arguments (Date, Int8) of function less.
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT toUInt32(1) == N
+SELECT toInt8(-1) <  N
 
-Code: 43: Illegal types of arguments (UInt32, Date) of function equals.
+Code: 43: Illegal types of arguments (Int8, Date) of function less.
+"UInt8",1
+"UInt8",1
+------------------------------------------
+SELECT N <  toUInt16(1)
+
+Code: 43: Illegal types of arguments (Date, UInt16) of function less.
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT N != toUInt32(1)
+SELECT toUInt16(1) <  N
 
-Code: 43: Illegal types of arguments (Date, UInt32) of function notEquals.
+Code: 43: Illegal types of arguments (UInt16, Date) of function less.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT toUInt32(1) != N
+SELECT N <  toInt16(-1)
 
-Code: 43: Illegal types of arguments (UInt32, Date) of function notEquals.
+Code: 43: Illegal types of arguments (Date, Int16) of function less.
+"UInt8",0
+"UInt8",0
+------------------------------------------
+SELECT toInt16(-1) <  N
+
+Code: 43: Illegal types of arguments (Int16, Date) of function less.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
@@ -1079,98 +1076,99 @@ Code: 43: Illegal types of arguments (UInt32, Date) of function less.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT N <= toUInt32(1)
+SELECT N <  toInt32(-1)
 
-Code: 43: Illegal types of arguments (Date, UInt32) of function lessOrEquals.
+Code: 43: Illegal types of arguments (Date, Int32) of function less.
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT toUInt32(1) <= N
+SELECT toInt32(-1) <  N
 
-Code: 43: Illegal types of arguments (UInt32, Date) of function lessOrEquals.
+Code: 43: Illegal types of arguments (Int32, Date) of function less.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT N >  toUInt32(1)
+SELECT N <  toUInt64(1)
 
-Code: 43: Illegal types of arguments (Date, UInt32) of function greater.
+Code: 43: Illegal types of arguments (Date, UInt64) of function less.
+"UInt8",0
+"UInt8",0
+------------------------------------------
+SELECT toUInt64(1) <  N
+
+Code: 43: Illegal types of arguments (UInt64, Date) of function less.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT toUInt32(1) >  N
+SELECT N <  toInt64(-1)
 
-Code: 43: Illegal types of arguments (UInt32, Date) of function greater.
+Code: 43: Illegal types of arguments (Date, Int64) of function less.
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT N >= toUInt32(1)
+SELECT toInt64(-1) <  N
 
-Code: 43: Illegal types of arguments (Date, UInt32) of function greaterOrEquals.
+Code: 43: Illegal types of arguments (Int64, Date) of function less.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT toUInt32(1) >= N
+SELECT N <= toUInt8(1)
 
-Code: 43: Illegal types of arguments (UInt32, Date) of function greaterOrEquals.
+Code: 43: Illegal types of arguments (Date, UInt8) of function lessOrEquals.
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT N +  toInt32(-1)
-"Date","2019-09-15"
-"DateTime('Europe/Minsk')","2019-09-16 19:20:10"
-"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:10.234"
-------------------------------------------
-SELECT toInt32(-1) +  N
-"Date","2019-09-15"
-"DateTime('Europe/Minsk')","2019-09-16 19:20:10"
-"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:10.234"
-------------------------------------------
-SELECT N -  toInt32(-1)
-"Date","2019-09-17"
-"DateTime('Europe/Minsk')","2019-09-16 19:20:12"
-"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:12.234"
-------------------------------------------
-SELECT toInt32(-1) -  N
-
-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
-
-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
+SELECT toUInt8(1) <= N
 
-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
+Code: 43: Illegal types of arguments (UInt8, Date) of function lessOrEquals.
+"UInt8",1
+"UInt8",1
 ------------------------------------------
-SELECT N == toInt32(-1)
+SELECT N <= toInt8(-1)
 
-Code: 43: Illegal types of arguments (Date, Int32) of function equals.
+Code: 43: Illegal types of arguments (Date, Int8) of function lessOrEquals.
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT toInt32(-1) == N
+SELECT toInt8(-1) <= N
 
-Code: 43: Illegal types of arguments (Int32, Date) of function equals.
+Code: 43: Illegal types of arguments (Int8, Date) of function lessOrEquals.
+"UInt8",1
+"UInt8",1
+------------------------------------------
+SELECT N <= toUInt16(1)
+
+Code: 43: Illegal types of arguments (Date, UInt16) of function lessOrEquals.
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT N != toInt32(-1)
+SELECT toUInt16(1) <= N
 
-Code: 43: Illegal types of arguments (Date, Int32) of function notEquals.
+Code: 43: Illegal types of arguments (UInt16, Date) of function lessOrEquals.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT toInt32(-1) != N
+SELECT N <= toInt16(-1)
 
-Code: 43: Illegal types of arguments (Int32, Date) of function notEquals.
+Code: 43: Illegal types of arguments (Date, Int16) of function lessOrEquals.
+"UInt8",0
+"UInt8",0
+------------------------------------------
+SELECT toInt16(-1) <= N
+
+Code: 43: Illegal types of arguments (Int16, Date) of function lessOrEquals.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT N <  toInt32(-1)
+SELECT N <= toUInt32(1)
 
-Code: 43: Illegal types of arguments (Date, Int32) of function less.
+Code: 43: Illegal types of arguments (Date, UInt32) of function lessOrEquals.
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT toInt32(-1) <  N
+SELECT toUInt32(1) <= N
 
-Code: 43: Illegal types of arguments (Int32, Date) of function less.
+Code: 43: Illegal types of arguments (UInt32, Date) of function lessOrEquals.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
@@ -1186,101 +1184,102 @@ Code: 43: Illegal types of arguments (Int32, Date) of function lessOrEquals.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT N >  toInt32(-1)
-
-Code: 43: Illegal types of arguments (Date, Int32) of function greater.
-"UInt8",1
-"UInt8",1
-------------------------------------------
-SELECT toInt32(-1) >  N
+SELECT N <= toUInt64(1)
 
-Code: 43: Illegal types of arguments (Int32, Date) of function greater.
+Code: 43: Illegal types of arguments (Date, UInt64) of function lessOrEquals.
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT N >= toInt32(-1)
+SELECT toUInt64(1) <= N
 
-Code: 43: Illegal types of arguments (Date, Int32) of function greaterOrEquals.
+Code: 43: Illegal types of arguments (UInt64, Date) of function lessOrEquals.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT toInt32(-1) >= N
+SELECT N <= toInt64(-1)
 
-Code: 43: Illegal types of arguments (Int32, Date) of function greaterOrEquals.
+Code: 43: Illegal types of arguments (Date, Int64) of function lessOrEquals.
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT N +  toUInt64(1)
-"Date","2019-09-17"
-"DateTime('Europe/Minsk')","2019-09-16 19:20:12"
-"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:12.234"
-------------------------------------------
-SELECT toUInt64(1) +  N
-"Date","2019-09-17"
-"DateTime('Europe/Minsk')","2019-09-16 19:20:12"
-"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:12.234"
-------------------------------------------
-SELECT N -  toUInt64(1)
-"Date","2019-09-15"
-"DateTime('Europe/Minsk')","2019-09-16 19:20:10"
-"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:10.234"
-------------------------------------------
-SELECT toUInt64(1) -  N
-
-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
+SELECT toInt64(-1) <= N
 
-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
+Code: 43: Illegal types of arguments (Int64, Date) of function lessOrEquals.
+"UInt8",1
+"UInt8",1
+------------------------------------------
+SELECT N >  toUInt8(1)
 
-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
+Code: 43: Illegal types of arguments (Date, UInt8) of function greater.
+"UInt8",1
+"UInt8",1
 ------------------------------------------
-SELECT N == toUInt64(1)
+SELECT toUInt8(1) >  N
 
-Code: 43: Illegal types of arguments (Date, UInt64) of function equals.
+Code: 43: Illegal types of arguments (UInt8, Date) of function greater.
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT toUInt64(1) == N
+SELECT N >  toInt8(-1)
 
-Code: 43: Illegal types of arguments (UInt64, Date) of function equals.
+Code: 43: Illegal types of arguments (Date, Int8) of function greater.
+"UInt8",1
+"UInt8",1
+------------------------------------------
+SELECT toInt8(-1) >  N
+
+Code: 43: Illegal types of arguments (Int8, Date) of function greater.
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT N != toUInt64(1)
+SELECT N >  toUInt16(1)
 
-Code: 43: Illegal types of arguments (Date, UInt64) of function notEquals.
+Code: 43: Illegal types of arguments (Date, UInt16) of function greater.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT toUInt64(1) != N
+SELECT toUInt16(1) >  N
 
-Code: 43: Illegal types of arguments (UInt64, Date) of function notEquals.
+Code: 43: Illegal types of arguments (UInt16, Date) of function greater.
+"UInt8",0
+"UInt8",0
+------------------------------------------
+SELECT N >  toInt16(-1)
+
+Code: 43: Illegal types of arguments (Date, Int16) of function greater.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT N <  toUInt64(1)
+SELECT toInt16(-1) >  N
 
-Code: 43: Illegal types of arguments (Date, UInt64) of function less.
+Code: 43: Illegal types of arguments (Int16, Date) of function greater.
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT toUInt64(1) <  N
+SELECT N >  toUInt32(1)
 
-Code: 43: Illegal types of arguments (UInt64, Date) of function less.
+Code: 43: Illegal types of arguments (Date, UInt32) of function greater.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT N <= toUInt64(1)
+SELECT toUInt32(1) >  N
 
-Code: 43: Illegal types of arguments (Date, UInt64) of function lessOrEquals.
+Code: 43: Illegal types of arguments (UInt32, Date) of function greater.
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT toUInt64(1) <= N
+SELECT N >  toInt32(-1)
 
-Code: 43: Illegal types of arguments (UInt64, Date) of function lessOrEquals.
+Code: 43: Illegal types of arguments (Date, Int32) of function greater.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
+SELECT toInt32(-1) >  N
+
+Code: 43: Illegal types of arguments (Int32, Date) of function greater.
+"UInt8",0
+"UInt8",0
+------------------------------------------
 SELECT N >  toUInt64(1)
 
 Code: 43: Illegal types of arguments (Date, UInt64) of function greater.
@@ -1293,98 +1292,99 @@ Code: 43: Illegal types of arguments (UInt64, Date) of function greater.
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT N >= toUInt64(1)
+SELECT N >  toInt64(-1)
 
-Code: 43: Illegal types of arguments (Date, UInt64) of function greaterOrEquals.
+Code: 43: Illegal types of arguments (Date, Int64) of function greater.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT toUInt64(1) >= N
+SELECT toInt64(-1) >  N
 
-Code: 43: Illegal types of arguments (UInt64, Date) of function greaterOrEquals.
+Code: 43: Illegal types of arguments (Int64, Date) of function greater.
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT N +  toInt64(-1)
-"Date","2019-09-15"
-"DateTime('Europe/Minsk')","2019-09-16 19:20:10"
-"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:10.234"
-------------------------------------------
-SELECT toInt64(-1) +  N
-"Date","2019-09-15"
-"DateTime('Europe/Minsk')","2019-09-16 19:20:10"
-"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:10.234"
-------------------------------------------
-SELECT N -  toInt64(-1)
-"Date","2019-09-17"
-"DateTime('Europe/Minsk')","2019-09-16 19:20:12"
-"DateTime64(3, 'Europe/Minsk')","2019-09-16 19:20:12.234"
-------------------------------------------
-SELECT toInt64(-1) -  N
-
-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
-
-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
+SELECT N >= toUInt8(1)
 
-Code: 43: Wrong order of arguments for function minus: argument of type Interval cannot be first..
+Code: 43: Illegal types of arguments (Date, UInt8) of function greaterOrEquals.
+"UInt8",1
+"UInt8",1
 ------------------------------------------
-SELECT N == toInt64(-1)
+SELECT toUInt8(1) >= N
 
-Code: 43: Illegal types of arguments (Date, Int64) of function equals.
+Code: 43: Illegal types of arguments (UInt8, Date) of function greaterOrEquals.
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT toInt64(-1) == N
+SELECT N >= toInt8(-1)
 
-Code: 43: Illegal types of arguments (Int64, Date) of function equals.
+Code: 43: Illegal types of arguments (Date, Int8) of function greaterOrEquals.
+"UInt8",1
+"UInt8",1
+------------------------------------------
+SELECT toInt8(-1) >= N
+
+Code: 43: Illegal types of arguments (Int8, Date) of function greaterOrEquals.
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT N != toInt64(-1)
+SELECT N >= toUInt16(1)
 
-Code: 43: Illegal types of arguments (Date, Int64) of function notEquals.
+Code: 43: Illegal types of arguments (Date, UInt16) of function greaterOrEquals.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT toInt64(-1) != N
+SELECT toUInt16(1) >= N
 
-Code: 43: Illegal types of arguments (Int64, Date) of function notEquals.
+Code: 43: Illegal types of arguments (UInt16, Date) of function greaterOrEquals.
+"UInt8",0
+"UInt8",0
+------------------------------------------
+SELECT N >= toInt16(-1)
+
+Code: 43: Illegal types of arguments (Date, Int16) of function greaterOrEquals.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT N <  toInt64(-1)
+SELECT toInt16(-1) >= N
 
-Code: 43: Illegal types of arguments (Date, Int64) of function less.
+Code: 43: Illegal types of arguments (Int16, Date) of function greaterOrEquals.
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT toInt64(-1) <  N
+SELECT N >= toUInt32(1)
 
-Code: 43: Illegal types of arguments (Int64, Date) of function less.
+Code: 43: Illegal types of arguments (Date, UInt32) of function greaterOrEquals.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT N <= toInt64(-1)
+SELECT toUInt32(1) >= N
 
-Code: 43: Illegal types of arguments (Date, Int64) of function lessOrEquals.
+Code: 43: Illegal types of arguments (UInt32, Date) of function greaterOrEquals.
 "UInt8",0
 "UInt8",0
 ------------------------------------------
-SELECT toInt64(-1) <= N
+SELECT N >= toInt32(-1)
 
-Code: 43: Illegal types of arguments (Int64, Date) of function lessOrEquals.
+Code: 43: Illegal types of arguments (Date, Int32) of function greaterOrEquals.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT N >  toInt64(-1)
+SELECT toInt32(-1) >= N
 
-Code: 43: Illegal types of arguments (Date, Int64) of function greater.
+Code: 43: Illegal types of arguments (Int32, Date) of function greaterOrEquals.
+"UInt8",0
+"UInt8",0
+------------------------------------------
+SELECT N >= toUInt64(1)
+
+Code: 43: Illegal types of arguments (Date, UInt64) of function greaterOrEquals.
 "UInt8",1
 "UInt8",1
 ------------------------------------------
-SELECT toInt64(-1) >  N
+SELECT toUInt64(1) >= N
 
-Code: 43: Illegal types of arguments (Int64, Date) of function greater.
+Code: 43: Illegal types of arguments (UInt64, Date) of function greaterOrEquals.
 "UInt8",0
 "UInt8",0
 ------------------------------------------
diff --git a/tests/queries/0_stateless/00960_live_view_watch_events_live.py b/tests/queries/0_stateless/00960_live_view_watch_events_live.py
index 3349175dee8b..780c31f20cad 100755
--- a/tests/queries/0_stateless/00960_live_view_watch_events_live.py
+++ b/tests/queries/0_stateless/00960_live_view_watch_events_live.py
@@ -1,4 +1,4 @@
-#!/usr/bin/env python
+#!/usr/bin/env python3
 import os
 import sys
 import signal
diff --git a/tests/queries/0_stateless/00962_temporary_live_view_watch_live.py b/tests/queries/0_stateless/00962_temporary_live_view_watch_live.py
index c6a5251fbeeb..073c8c88e2be 100755
--- a/tests/queries/0_stateless/00962_temporary_live_view_watch_live.py
+++ b/tests/queries/0_stateless/00962_temporary_live_view_watch_live.py
@@ -1,4 +1,4 @@
-#!/usr/bin/env python
+#!/usr/bin/env python3
 import os
 import sys
 import signal
diff --git a/tests/queries/0_stateless/00963_temporary_live_view_watch_live_timeout.py.disabled b/tests/queries/0_stateless/00963_temporary_live_view_watch_live_timeout.py.disabled
index 525e70221564..cfd218d5983b 100755
--- a/tests/queries/0_stateless/00963_temporary_live_view_watch_live_timeout.py.disabled
+++ b/tests/queries/0_stateless/00963_temporary_live_view_watch_live_timeout.py.disabled
@@ -1,4 +1,4 @@
-#!/usr/bin/env python
+#!/usr/bin/env python3
 import os
 import sys
 import signal
diff --git a/tests/queries/0_stateless/00964_live_view_watch_events_heartbeat.py b/tests/queries/0_stateless/00964_live_view_watch_events_heartbeat.py
index 794d04a429cc..03b598fe46f4 100755
--- a/tests/queries/0_stateless/00964_live_view_watch_events_heartbeat.py
+++ b/tests/queries/0_stateless/00964_live_view_watch_events_heartbeat.py
@@ -1,4 +1,4 @@
-#!/usr/bin/env python
+#!/usr/bin/env python3
 import os
 import sys
 import signal
diff --git a/tests/queries/0_stateless/00965_live_view_watch_heartbeat.py b/tests/queries/0_stateless/00965_live_view_watch_heartbeat.py
index 1d557f09f4d6..15c4e7636344 100755
--- a/tests/queries/0_stateless/00965_live_view_watch_heartbeat.py
+++ b/tests/queries/0_stateless/00965_live_view_watch_heartbeat.py
@@ -1,4 +1,4 @@
-#!/usr/bin/env python
+#!/usr/bin/env python3
 import os
 import sys
 import signal
diff --git a/tests/queries/0_stateless/00966_live_view_watch_events_http.py b/tests/queries/0_stateless/00966_live_view_watch_events_http.py
index 72ab3ea88181..3d407ec56026 100755
--- a/tests/queries/0_stateless/00966_live_view_watch_events_http.py
+++ b/tests/queries/0_stateless/00966_live_view_watch_events_http.py
@@ -1,4 +1,4 @@
-#!/usr/bin/env python
+#!/usr/bin/env python3
 import os
 import sys
 
diff --git a/tests/queries/0_stateless/00967_live_view_watch_http.py b/tests/queries/0_stateless/00967_live_view_watch_http.py
index e2f33971c3d9..d26bb5402e76 100755
--- a/tests/queries/0_stateless/00967_live_view_watch_http.py
+++ b/tests/queries/0_stateless/00967_live_view_watch_http.py
@@ -1,4 +1,4 @@
-#!/usr/bin/env python
+#!/usr/bin/env python3
 import os
 import sys
 
diff --git a/tests/queries/0_stateless/00970_live_view_watch_events_http_heartbeat.py b/tests/queries/0_stateless/00970_live_view_watch_events_http_heartbeat.py
index 8435cdc147a9..76e5cdbe88de 100755
--- a/tests/queries/0_stateless/00970_live_view_watch_events_http_heartbeat.py
+++ b/tests/queries/0_stateless/00970_live_view_watch_events_http_heartbeat.py
@@ -1,4 +1,4 @@
-#!/usr/bin/env python
+#!/usr/bin/env python3
 import os
 import sys
 
diff --git a/tests/queries/0_stateless/00971_live_view_watch_http_heartbeat.py b/tests/queries/0_stateless/00971_live_view_watch_http_heartbeat.py
index 2317d705efed..5da36ab2d5f6 100755
--- a/tests/queries/0_stateless/00971_live_view_watch_http_heartbeat.py
+++ b/tests/queries/0_stateless/00971_live_view_watch_http_heartbeat.py
@@ -1,4 +1,4 @@
-#!/usr/bin/env python
+#!/usr/bin/env python3
 import os
 import sys
 
diff --git a/tests/queries/0_stateless/00979_live_view_watch_continuous_aggregates.py b/tests/queries/0_stateless/00979_live_view_watch_continuous_aggregates.py
index 3a67226da80a..7924aa15d0ca 100755
--- a/tests/queries/0_stateless/00979_live_view_watch_continuous_aggregates.py
+++ b/tests/queries/0_stateless/00979_live_view_watch_continuous_aggregates.py
@@ -1,4 +1,4 @@
-#!/usr/bin/env python
+#!/usr/bin/env python3
 import os
 import sys
 import signal
diff --git a/tests/queries/0_stateless/00979_live_view_watch_live.py b/tests/queries/0_stateless/00979_live_view_watch_live.py
index 04ca070c9699..2fc70352dbfd 100755
--- a/tests/queries/0_stateless/00979_live_view_watch_live.py
+++ b/tests/queries/0_stateless/00979_live_view_watch_live.py
@@ -1,4 +1,4 @@
-#!/usr/bin/env python
+#!/usr/bin/env python3
 import os
 import sys
 import signal
diff --git a/tests/queries/0_stateless/00979_live_view_watch_live_moving_avg.py b/tests/queries/0_stateless/00979_live_view_watch_live_moving_avg.py
index ccc824c4d208..54f9ef694d6e 100755
--- a/tests/queries/0_stateless/00979_live_view_watch_live_moving_avg.py
+++ b/tests/queries/0_stateless/00979_live_view_watch_live_moving_avg.py
@@ -1,4 +1,4 @@
-#!/usr/bin/env python
+#!/usr/bin/env python3
 import os
 import sys
 import signal
diff --git a/tests/queries/0_stateless/00979_live_view_watch_live_with_subquery.py b/tests/queries/0_stateless/00979_live_view_watch_live_with_subquery.py
index 809b8b0342ad..2918bed82e81 100755
--- a/tests/queries/0_stateless/00979_live_view_watch_live_with_subquery.py
+++ b/tests/queries/0_stateless/00979_live_view_watch_live_with_subquery.py
@@ -1,4 +1,4 @@
-#!/usr/bin/env python
+#!/usr/bin/env python3
 import os
 import sys
 import signal
diff --git a/tests/queries/0_stateless/00990_hasToken.python b/tests/queries/0_stateless/00990_hasToken.python
index cd2a284655f8..7d3775adc9da 100755
--- a/tests/queries/0_stateless/00990_hasToken.python
+++ b/tests/queries/0_stateless/00990_hasToken.python
@@ -1,4 +1,4 @@
-#!/usr/bin/env python
+#!/usr/bin/env python3
 # encoding: utf-8
 
 import re
@@ -126,7 +126,7 @@ def create_cases(case_sensitive_func, case_insensitive_func, table_row_template,
 def main():
 
     def query(x):
-        print x
+        print(x)
 
     CONST_QUERY = Template("""SELECT ${func}('${haystack}', '${needle}'), ' expecting ', ${match};""")
     TABLE_QUERY = Template("""WITH '${needle}' as n
diff --git a/tests/queries/0_stateless/00990_hasToken.sh b/tests/queries/0_stateless/00990_hasToken.sh
index 0b88ac0007f0..4b42a570e994 100755
--- a/tests/queries/0_stateless/00990_hasToken.sh
+++ b/tests/queries/0_stateless/00990_hasToken.sh
@@ -5,4 +5,4 @@ CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 
 # We should have correct env vars from shell_config.sh to run this test
 
-python "$CURDIR"/00990_hasToken.python | ${CLICKHOUSE_CLIENT} --max_query_size 1048576 -nm
+python3 "$CURDIR"/00990_hasToken.python | ${CLICKHOUSE_CLIENT} --max_query_size 1048576 -nm
diff --git a/tests/queries/0_stateless/00991_live_view_watch_event_live.python b/tests/queries/0_stateless/00991_live_view_watch_event_live.python
index 782671cdfaf7..901d388ec011 100644
--- a/tests/queries/0_stateless/00991_live_view_watch_event_live.python
+++ b/tests/queries/0_stateless/00991_live_view_watch_event_live.python
@@ -1,8 +1,8 @@
-#!/usr/bin/env python
+#!/usr/bin/env python3
 
 import subprocess
 import threading
-import Queue as queue
+import queue as queue
 import os
 import sys
 import signal
diff --git a/tests/queries/0_stateless/00991_live_view_watch_event_live.sh.disabled b/tests/queries/0_stateless/00991_live_view_watch_event_live.sh.disabled
index 10e4e98b2e36..0548d24a80b4 100755
--- a/tests/queries/0_stateless/00991_live_view_watch_event_live.sh.disabled
+++ b/tests/queries/0_stateless/00991_live_view_watch_event_live.sh.disabled
@@ -3,4 +3,4 @@
 CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 . $CURDIR/../shell_config.sh
 
-python $CURDIR/00991_live_view_watch_event_live.python
+python3 $CURDIR/00991_live_view_watch_event_live.python
diff --git a/tests/queries/0_stateless/00991_live_view_watch_http.python b/tests/queries/0_stateless/00991_live_view_watch_http.python
index 938547ca0cb1..d5a1e6e8ed99 100755
--- a/tests/queries/0_stateless/00991_live_view_watch_http.python
+++ b/tests/queries/0_stateless/00991_live_view_watch_http.python
@@ -1,8 +1,8 @@
-#!/usr/bin/env python
+#!/usr/bin/env python3
 
 import subprocess
 import threading
-import Queue as queue
+import queue as queue
 import os
 import sys
 
diff --git a/tests/queries/0_stateless/00991_live_view_watch_http.sh.disabled b/tests/queries/0_stateless/00991_live_view_watch_http.sh.disabled
index 88cce77f5954..d441ab94473f 100755
--- a/tests/queries/0_stateless/00991_live_view_watch_http.sh.disabled
+++ b/tests/queries/0_stateless/00991_live_view_watch_http.sh.disabled
@@ -3,4 +3,4 @@
 CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 . $CURDIR/../shell_config.sh
 
-python $CURDIR/00991_live_view_watch_http.python
+python3 $CURDIR/00991_live_view_watch_http.python
diff --git a/tests/queries/0_stateless/00991_temporary_live_view_watch_events_heartbeat.python b/tests/queries/0_stateless/00991_temporary_live_view_watch_events_heartbeat.python
index 3fd3b38be16f..8ddb1a1ea81a 100644
--- a/tests/queries/0_stateless/00991_temporary_live_view_watch_events_heartbeat.python
+++ b/tests/queries/0_stateless/00991_temporary_live_view_watch_events_heartbeat.python
@@ -1,8 +1,8 @@
-#!/usr/bin/env python
+#!/usr/bin/env python3
 
 import subprocess
 import threading
-import Queue as queue
+import queue as queue
 import os
 import sys
 import signal
diff --git a/tests/queries/0_stateless/00991_temporary_live_view_watch_events_heartbeat.sh.disabled b/tests/queries/0_stateless/00991_temporary_live_view_watch_events_heartbeat.sh.disabled
index f7aa13d52b33..ebe492fafcef 100755
--- a/tests/queries/0_stateless/00991_temporary_live_view_watch_events_heartbeat.sh.disabled
+++ b/tests/queries/0_stateless/00991_temporary_live_view_watch_events_heartbeat.sh.disabled
@@ -3,4 +3,4 @@
 CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 . $CURDIR/../shell_config.sh
 
-python $CURDIR/00991_temporary_live_view_watch_events_heartbeat.python
+python3 $CURDIR/00991_temporary_live_view_watch_events_heartbeat.python
diff --git a/tests/queries/0_stateless/00991_temporary_live_view_watch_live.python b/tests/queries/0_stateless/00991_temporary_live_view_watch_live.python
index a0a1fae0188c..a417cdf29376 100644
--- a/tests/queries/0_stateless/00991_temporary_live_view_watch_live.python
+++ b/tests/queries/0_stateless/00991_temporary_live_view_watch_live.python
@@ -1,8 +1,8 @@
-#!/usr/bin/env python
+#!/usr/bin/env python3
 
 import subprocess
 import threading
-import Queue as queue
+import queue as queue
 import os
 import sys
 import signal
diff --git a/tests/queries/0_stateless/00991_temporary_live_view_watch_live.sh.disabled b/tests/queries/0_stateless/00991_temporary_live_view_watch_live.sh.disabled
index 4d01d1c3a8e9..91efff53abec 100755
--- a/tests/queries/0_stateless/00991_temporary_live_view_watch_live.sh.disabled
+++ b/tests/queries/0_stateless/00991_temporary_live_view_watch_live.sh.disabled
@@ -3,4 +3,4 @@
 CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 . $CURDIR/../shell_config.sh
 
-python $CURDIR/00991_temporary_live_view_watch_live.python
+python3 $CURDIR/00991_temporary_live_view_watch_live.python
diff --git a/tests/queries/0_stateless/01246_insert_into_watch_live_view.py b/tests/queries/0_stateless/01246_insert_into_watch_live_view.py
index 7f65a7135d55..0f7c6965b7b8 100755
--- a/tests/queries/0_stateless/01246_insert_into_watch_live_view.py
+++ b/tests/queries/0_stateless/01246_insert_into_watch_live_view.py
@@ -1,4 +1,4 @@
-#!/usr/bin/env python
+#!/usr/bin/env python3
 import os
 import sys
 import time
diff --git a/tests/queries/0_stateless/helpers/httpclient.py b/tests/queries/0_stateless/helpers/httpclient.py
index a42fad2cbc34..6fb6edff1422 100644
--- a/tests/queries/0_stateless/helpers/httpclient.py
+++ b/tests/queries/0_stateless/helpers/httpclient.py
@@ -8,7 +8,7 @@
 import httpexpect
 
 def client(request, name='', log=None):
-    client = httpexpect.spawn({'host':'localhost','port':8123}, request)
+    client = httpexpect.spawn({'host':'localhost','port':8123,'timeout':1}, request)
     client.logger(log, prefix=name)
     client.timeout(20)
     return client
diff --git a/tests/queries/0_stateless/helpers/httpechoserver.py b/tests/queries/0_stateless/helpers/httpechoserver.py
index 94f94d07f67b..a1176c5e72d5 100644
--- a/tests/queries/0_stateless/helpers/httpechoserver.py
+++ b/tests/queries/0_stateless/helpers/httpechoserver.py
@@ -1,12 +1,12 @@
-#!/usr/bin/env python
-from __future__ import print_function
+#!/usr/bin/env python3
+
 import sys
 import os
 import time
 import subprocess
 import threading
 from io import StringIO, SEEK_END
-from BaseHTTPServer import BaseHTTPRequestHandler, HTTPServer
+from http.server import BaseHTTPRequestHandler, HTTPServer
 
 CLICKHOUSE_HOST = os.environ.get('CLICKHOUSE_HOST', '127.0.0.1')
 CLICKHOUSE_PORT_HTTP = os.environ.get('CLICKHOUSE_PORT_HTTP', '8123')
@@ -72,7 +72,7 @@ def start_server(requests_amount, test_data="Hello,2,-2,7.7
World,2,-5,8.8"):
     httpd = HTTPServer(HTTP_SERVER_ADDRESS, EchoCSVHTTPServer)
 
     def real_func():
-        for i in xrange(requests_amount):
+        for i in range(requests_amount):
             httpd.handle_request()
 
     t = threading.Thread(target=real_func)
diff --git a/tests/queries/0_stateless/helpers/httpexpect.py b/tests/queries/0_stateless/helpers/httpexpect.py
index e440dafce4e5..788e57499a87 100644
--- a/tests/queries/0_stateless/helpers/httpexpect.py
+++ b/tests/queries/0_stateless/helpers/httpexpect.py
@@ -13,7 +13,7 @@
 # limitations under the License.
 import os
 import sys
-import httplib
+import http.client
 
 CURDIR = os.path.dirname(os.path.realpath(__file__))
 sys.path.insert(0, CURDIR)
@@ -21,7 +21,7 @@
 import uexpect
 
 from threading import Thread, Event
-from Queue import Queue, Empty
+from queue import Queue, Empty
 
 class IO(uexpect.IO):
     def __init__(self, connection, response, queue, reader):
@@ -45,15 +45,15 @@ def reader(response, queue, kill_event):
         try:
             if kill_event.is_set():
                 break
-            data = response.read(1)
+            data = response.read(1).decode()
             queue.put(data)
-        except Exception, e:
+        except Exception as e:
             if kill_event.is_set():
                 break
             raise
 
 def spawn(connection, request):
-    connection = httplib.HTTPConnection(**connection)
+    connection = http.client.HTTPConnection(**connection)
     connection.request(**request)
     response = connection.getresponse()
 
@@ -66,8 +66,8 @@ def spawn(connection, request):
     return IO(connection, response, queue, reader={'thread':thread, 'kill_event':reader_kill_event})
 
 if __name__ == '__main__':
-    with http({'host':'localhost','port':8123},{'method':'GET', 'url':'?query=SELECT%201'}) as client:
+    with spawn({'host':'localhost','port':8123},{'method':'GET', 'url':'?query=SELECT%201'}) as client:
         client.logger(sys.stdout)
         client.timeout(2)
-        print client.response.status, client.response.reason
+        print(client.response.status, client.response.reason)
         client.expect('1
')
diff --git a/tests/queries/0_stateless/helpers/uexpect.py b/tests/queries/0_stateless/helpers/uexpect.py
index b71dd2f81a0d..7a633facc95f 100644
--- a/tests/queries/0_stateless/helpers/uexpect.py
+++ b/tests/queries/0_stateless/helpers/uexpect.py
@@ -19,7 +19,7 @@
 
 from threading import Thread, Event
 from subprocess import Popen
-from Queue import Queue, Empty
+from queue import Queue, Empty
 
 class TimeoutError(Exception):
     def __init__(self, timeout):
@@ -117,7 +117,7 @@ def send(self, data, eol=None):
         return self.write(data + eol)
 
     def write(self, data):
-        return os.write(self.master, data)
+        return os.write(self.master, data.encode())
 
     def expect(self, pattern, timeout=None, escape=False):
         self.match = None
@@ -198,7 +198,7 @@ def spawn(command):
 def reader(process, out, queue, kill_event):
     while True:
         try:
-            data = os.read(out, 65536)
+            data = os.read(out, 65536).decode(errors='replace')
             queue.put(data)
         except:
             if kill_event.is_set():
diff --git a/tests/queries/conftest.py b/tests/queries/conftest.py
index e0f47f63451d..85b7250af0c3 100644
--- a/tests/queries/conftest.py
+++ b/tests/queries/conftest.py
@@ -4,7 +4,7 @@
 import sys
 import tempfile
 
-from server import ServerThread
+from .server import ServerThread
 
 
 def pytest_addoption(parser):
@@ -44,9 +44,9 @@ def standalone_server(bin_prefix, tmp_path):
 
     if wait_result is not None:
         with open(os.path.join(server.log_dir, 'server', 'stdout.txt'), 'r') as f:
-            print >> sys.stderr, f.read()
+            print(f.read(), file=sys.stderr)
         with open(os.path.join(server.log_dir, 'server', 'stderr.txt'), 'r') as f:
-            print >> sys.stderr, f.read()
+            print(f.read(), file=sys.stderr)
         pytest.fail('Server died unexpectedly with code {code}'.format(code=server._proc.returncode), pytrace=False)
 
     yield server
diff --git a/tests/queries/query_test.py b/tests/queries/query_test.py
index e31a8ded2652..bac38d0334e0 100644
--- a/tests/queries/query_test.py
+++ b/tests/queries/query_test.py
@@ -14,11 +14,11 @@ def run_client(bin_prefix, port, query, reference, replace_map={}):
     result, error = client.communicate(query)
     assert client.returncode is not None, "Client should exit after processing all queries"
 
-    for old, new in replace_map.iteritems():
+    for old, new in replace_map.items():
         result = result.replace(old, new)
 
     if client.returncode != 0:
-        print >> sys.stderr, error
+        print(error, file=sys.stderr)
         pytest.fail('Client died unexpectedly with code {code}'.format(code=client.returncode), pytrace=False)
     elif result != reference:
         pytest.fail("Query output doesn't match reference:{eol}{diff}".format(
diff --git a/tests/queries/server.py b/tests/queries/server.py
index 31f92281f973..cb0755db6aec 100644
--- a/tests/queries/server.py
+++ b/tests/queries/server.py
@@ -56,7 +56,7 @@ def run(self):
 
         while retries:
             self._choose_ports_and_args()
-            print 'Start clickhouse-server with args:', self._args
+            print('Start clickhouse-server with args:', self._args)
             self._proc = subprocess.Popen([self._bin] + self._args, shell=False, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
 
             while self._proc.poll() is None:
@@ -64,11 +64,11 @@ def run(self):
                     time.sleep(ServerThread.DEFAULT_SERVER_DELAY)
                     s = socket.create_connection(('localhost', self.tcp_port), ServerThread.DEFAULT_CONNECTION_TIMEOUT)
                     s.sendall('G')  # trigger expected "bad" HELLO response
-                    print 'Successful server response:', s.recv(1024)  # FIXME: read whole buffered response
+                    print('Successful server response:', s.recv(1024))  # FIXME: read whole buffered response
                     s.shutdown(socket.SHUT_RDWR)
                     s.close()
                 except Exception as e:
-                    print >> sys.stderr, 'Failed to connect to server:', e
+                    print('Failed to connect to server:', e, file=sys.stderr)
                     continue
                 else:
                     break
@@ -76,8 +76,8 @@ def run(self):
             # If process has died then try to fetch output before releasing lock
             if self._proc.returncode is not None:
                 stdout, stderr = self._proc.communicate()
-                print >> sys.stderr, stdout
-                print >> sys.stderr, stderr
+                print(stdout, file=sys.stderr)
+                print(stderr, file=sys.stderr)
 
             if self._proc.returncode == 70:  # Address already in use
                 retries -= 1
@@ -101,7 +101,7 @@ def stop(self):
         if self._proc.returncode is None:
             self._proc.terminate()
         self.join()
-        print 'Stop clickhouse-server'
+        print('Stop clickhouse-server')
 
 
 ServerThread.DEFAULT_SERVER_CONFIG = \
diff --git a/tests/queries/shell_config.sh b/tests/queries/shell_config.sh
index 8c66d79b5b1a..1fe199be48f1 100644
--- a/tests/queries/shell_config.sh
+++ b/tests/queries/shell_config.sh
@@ -73,5 +73,5 @@ function clickhouse_client_removed_host_parameter()
 {
     # removing only `--host=value` and `--host value` (removing '-hvalue' feels to dangerous) with python regex.
     # bash regex magic is arcane, but version dependant and weak; sed or awk are not really portable.
-    $(echo "$CLICKHOUSE_CLIENT"  | python -c "import sys, re; print re.sub('--host(\s+|=)[^\s]+', '', sys.stdin.read())") "$@"
+    $(echo "$CLICKHOUSE_CLIENT"  | python3 -c "import sys, re; print(re.sub('--host(\s+|=)[^\s]+', '', sys.stdin.read()))") "$@"
 }
diff --git a/tests/testflows/helpers/cluster.py b/tests/testflows/helpers/cluster.py
index 8288e700e3b5..8fda8ac43d87 100644
--- a/tests/testflows/helpers/cluster.py
+++ b/tests/testflows/helpers/cluster.py
@@ -210,7 +210,7 @@ def __exit__(self, type, value, traceback):
                 self.down()
         finally:
             with self.lock:
-                for shell in self._bash.values():
+                for shell in list(self._bash.values()):
                     shell.__exit__(type, value, traceback)
 
     def node(self, name):
diff --git a/tests/testflows/ldap/tests/common.py b/tests/testflows/ldap/tests/common.py
index eb21923e9309..c065576c9d44 100644
--- a/tests/testflows/ldap/tests/common.py
+++ b/tests/testflows/ldap/tests/common.py
@@ -129,9 +129,9 @@ def create_ldap_servers_config_content(servers, config_d_dir="/etc/clickhouse-se
     xml_servers = root.find("ldap_servers")
     xml_servers.append(xmltree.Comment(text=f"LDAP servers {uid}"))
 
-    for _name, server in servers.items():
+    for _name, server in list(servers.items()):
         xml_server = xmltree.Element(_name)
-        for key, value in server.items():
+        for key, value in list(server.items()):
             xml_append(xml_server, key, value)
         xml_servers.append(xml_server)
 
@@ -288,7 +288,7 @@ def add_user_to_ldap(cn, userpassword, givenname=None, homedirectory=None, sn=No
     }
 
     lines = []
-    for key, value in user.items():
+    for key, value in list(user.items()):
         if key.startswith("_"):
             continue
         elif key == "objectclass":
diff --git a/tests/testflows/rbac/tests/privileges/insert.py b/tests/testflows/rbac/tests/privileges/insert.py
index 5cb78c6a8a57..ad0ba90c8e35 100755
--- a/tests/testflows/rbac/tests/privileges/insert.py
+++ b/tests/testflows/rbac/tests/privileges/insert.py
@@ -65,9 +65,9 @@ def role(node, role):
 
 def input_output_equality_check(node, input_columns, input_data):
     data_list = [x.strip("'") for x in input_data.split(",")]
-    input_dict = dict(zip(input_columns.split(","), data_list))
+    input_dict = dict(list(zip(input_columns.split(","), data_list)))
     output_dict = json.loads(node.query(f"select {input_columns} from merge_tree format JSONEachRow").output)
-    output_dict = {k:str(v) for (k,v) in output_dict.items()}
+    output_dict = {k:str(v) for (k,v) in list(output_dict.items())}
     return input_dict == output_dict
 
 @TestScenario
@@ -509,7 +509,7 @@ def revoke_privilege_from_role_via_role_with_grant_option(self, table_type, node
     RQ_SRS_006_RBAC_Privileges_Insert("1.0"),
 )
 @Examples("table_type", [
-    (table_type, Requirements(requirement)) for table_type, requirement in table_requirements.items()
+    (table_type, Requirements(requirement)) for table_type, requirement in list(table_requirements.items())
 ])
 @Name("insert")
 def feature(self, table_type, node="clickhouse1"):
diff --git a/tests/testflows/rbac/tests/privileges/select.py b/tests/testflows/rbac/tests/privileges/select.py
index e74a63614d59..a2d3092f1c3c 100644
--- a/tests/testflows/rbac/tests/privileges/select.py
+++ b/tests/testflows/rbac/tests/privileges/select.py
@@ -477,7 +477,7 @@ def revoke_privilege_from_role_via_role_with_grant_option(self, table_type, node
     RQ_SRS_006_RBAC_Privileges_Select("1.0"),
 )
 @Examples("table_type", [
-    (table_type, Requirements(requirement)) for table_type, requirement in table_requirements.items()
+    (table_type, Requirements(requirement)) for table_type, requirement in list(table_requirements.items())
 ])
 @Name("select")
 def feature(self, table_type, node="clickhouse1"):
diff --git a/tests/testflows/runner b/tests/testflows/runner
index 6522c8f47f73..0acc3a25945f 100755
--- a/tests/testflows/runner
+++ b/tests/testflows/runner
@@ -1,4 +1,4 @@
-#!/usr/bin/env python
+#!/usr/bin/env python3
 #-*- coding: utf-8 -*-
 import subprocess
 import os
@@ -117,6 +117,6 @@ if __name__ == "__main__":
         command=args.command
     )
 
-    print("Running testflows container as: '" + cmd + "'.")
+    print(("Running testflows container as: '" + cmd + "'."))
     # testflows return non zero error code on failed tests
     subprocess.call(cmd, shell=True)
diff --git a/utils/test_history/test-history b/utils/test_history/test-history
index dca62625c9f3..fdd6c36e9dc4 100755
--- a/utils/test_history/test-history
+++ b/utils/test_history/test-history
@@ -1,8 +1,8 @@
-#!/usr/bin/env python
+#!/usr/bin/env python3
 # -*- coding: utf-8 -*-
 
 # Note: should work with python 2 and 3
-from __future__ import print_function
+
 from github import Github
 import datetime
 import tabulate
@@ -31,7 +31,7 @@ def _filter_statuses(statuses):
     filt = {}
     for status in sorted(statuses, key=lambda x: x.updated_at):
         filt[status.context] = status
-    return filt.values()
+    return list(filt.values())
 
 
 def get_filtered_statuses(commit):
@@ -76,7 +76,7 @@ if __name__ == "__main__":
     all_data = []
     for num, commit in enumerate(commits):
         commit_sha, commit_modified, check_results = process_one_commit(commit)
-        mapped_keys = [key for key in check_results.keys() if args.substr in key]
+        mapped_keys = [key for key in list(check_results.keys()) if args.substr in key]
         if len(mapped_keys) > len(longest_header):
             longest_header = mapped_keys
         all_data.append((commit_modified, commit_sha, check_results))
diff --git a/utils/upload_test_results/upload_test_results b/utils/upload_test_results/upload_test_results
index 058a73d80812..5916d0d85e86 100755
--- a/utils/upload_test_results/upload_test_results
+++ b/utils/upload_test_results/upload_test_results
@@ -1,4 +1,4 @@
-#!/usr/bin/env python
+#!/usr/bin/env python3
 import requests
 import argparse
 
@@ -96,7 +96,7 @@ def upload_request(sha, pr, file, q_type, user, password, ca_cert, host, db):
             'X-ClickHouse-Key': password,
         }
 
-        print query;
+        print(query);
 
         res = requests.post(
             url,
@@ -121,7 +121,7 @@ if __name__ == "__main__":
 
     args = parser.parse_args()
 
-    print(upload_request(args.sha, args.pr, args.file, args.type, args.user, args.password, args.ca_cert, args.host, args.db))
+    print((upload_request(args.sha, args.pr, args.file, args.type, args.user, args.password, args.ca_cert, args.host, args.db)))
 
 
 
