You will be provided with a partial code base and an issue statement explaining a problem to resolve.

<issue>
Invalid number of rows in Chunk column UInt8 position 0: 
**Describe what's wrong**

Null sub column doesn't work.

**Does it reproduce on recent release?**

Yes.


**How to reproduce**

Clickhouse version 21.8.5.7
Compact part.
Nullable(String) column

All values in that column are non nullable

```
SELECT some_column_name.`null`
FROM default.xxx_test_4
LIMIT 8182, 10



┌───some_column_name.null─┐
│                       0 │
│                       0 │
│                       0 │
│                       0 │
│                       0 │
│                       0 │
│                       0 │
│                       0 │
│                       0 │
│                       0 │
└─────────────────────────┘

10 rows in set. Elapsed: 0.003 sec. Processed 8.19 thousand rows, 8.19 KB (2.46 million rows/s., 2.46 MB/s.)

SELECT some_column_name.`null`
FROM default.xxx_test_4
LIMIT 8183, 10

Query id: 57433167-6bcf-4e67-8a0e-89a7c4640062


0 rows in set. Elapsed: 0.003 sec.

Received exception from server (version 21.8.5):
Code: 49. DB::Exception: Received from localhost:9000. DB::Exception: Invalid number of rows in Chunk column UInt8 position 0: expected 11508, got 3316: While executing MergeTree.


SELECT isNotNull(some_column_name)
FROM default.xxx_test_4
LIMIT 8183, 10
SETTINGS optimize_functions_to_subcolumns = 0

┌───isNotNull(some_column_name)─┐
│                             1 │
│                             1 │
│                             1 │
│                             1 │
│                             1 │
│                             1 │
│                             1 │
│                             1 │
│                             1 │
│                             1 │
└───────────────────────────────┘

10 rows in set. Elapsed: 0.002 sec. Processed 11.51 thousand rows, 287.70 KB (4.81 million rows/s., 120.15 MB/s.)


SELECT isNotNull(some_column_name)
FROM default.xxx_test_4
LIMIT 8183, 10
SETTINGS optimize_functions_to_subcolumns = 1

0 rows in set. Elapsed: 0.003 sec.

Received exception from server (version 21.8.5):
Code: 49. DB::Exception: Received from localhost:9000. DB::Exception: Invalid number of rows in Chunk column UInt8 position 0: expected 11508, got 3316: While executing MergeTree.
```

11508-3316=8192

**Expected behavior**

Query works.

**Error message and/or stacktrace**

```
0. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, bool) @ 0x8f9a2ba in /usr/bin/clickhouse
1. DB::Chunk::checkNumRowsIsConsistent() @ 0x11012245 in /usr/bin/clickhouse
2. DB::MergeTreeBaseSelectProcessor::readFromPartImpl() @ 0x112689d0 in /usr/bin/clickhouse
3. DB::MergeTreeBaseSelectProcessor::readFromPart() @ 0x1126916d in /usr/bin/clickhouse
4. DB::MergeTreeBaseSelectProcessor::generate() @ 0x11267cab in /usr/bin/clickhouse
5. DB::ISource::tryGenerate() @ 0x1101a335 in /usr/bin/clickhouse
6. DB::ISource::work() @ 0x11019f1a in /usr/bin/clickhouse
7. DB::SourceWithProgress::work() @ 0x111eb0ca in /usr/bin/clickhouse
8. ? @ 0x110549dd in /usr/bin/clickhouse
9. DB::PipelineExecutor::executeStepImpl(unsigned long, unsigned long, std::__1::atomic<bool>*) @ 0x11051571 in /usr/bin/clickhouse
10. DB::PipelineExecutor::executeImpl(unsigned long) @ 0x1104f5af in /usr/bin/clickhouse
11. DB::PipelineExecutor::execute(unsigned long) @ 0x1104f38d in /usr/bin/clickhouse
12. ? @ 0x1105c61f in /usr/bin/clickhouse
13. ThreadPoolImpl<std::__1::thread>::worker(std::__1::__list_iterator<std::__1::thread, void*>) @ 0x8fdaf3f in /usr/bin/clickhouse
14. ? @ 0x8fde823 in /usr/bin/clickhouse
15. start_thread @ 0x9609 in /usr/lib/x86_64-linux-gnu/libpthread-2.31.so
16. __clone @ 0x122293 in /usr/lib/x86_64-linux-gnu/libc-2.31.so
```
    
**Additional context**

Related to https://github.com/ClickHouse/ClickHouse/issues/20218
</issue>

I need you to solve the provided issue by generating a code fix that can be applied directly to the repository

Respond below:
