{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 35973,
  "instance_id": "ClickHouse__ClickHouse-35973",
  "issue_numbers": [
    "35153"
  ],
  "base_commit": "c675f73a8366548f09adb4971f7759c38d617d5c",
  "patch": "diff --git a/src/Storages/Kafka/StorageKafka.cpp b/src/Storages/Kafka/StorageKafka.cpp\nindex 4c7465d587d1..127911c9f609 100644\n--- a/src/Storages/Kafka/StorageKafka.cpp\n+++ b/src/Storages/Kafka/StorageKafka.cpp\n@@ -661,9 +661,14 @@ bool StorageKafka::streamToViews()\n     // We can't cancel during copyData, as it's not aware of commits and other kafka-related stuff.\n     // It will be cancelled on underlying layer (kafka buffer)\n \n-    size_t rows = 0;\n+    std::atomic_size_t rows = 0;\n     {\n         block_io.pipeline.complete(std::move(pipe));\n+\n+        // we need to read all consumers in parallel (sequential read may lead to situation\n+        // when some of consumers are not used, and will break some Kafka consumer invariants)\n+        block_io.pipeline.setNumThreads(stream_count);\n+\n         block_io.pipeline.setProgressCallback([&](const Progress & progress) { rows += progress.read_rows.load(); });\n         CompletedPipelineExecutor executor(block_io.pipeline);\n         executor.execute();\n",
  "test_patch": "diff --git a/tests/integration/test_storage_kafka/test.py b/tests/integration/test_storage_kafka/test.py\nindex e451e15a5d6e..a27b5a134e49 100644\n--- a/tests/integration/test_storage_kafka/test.py\n+++ b/tests/integration/test_storage_kafka/test.py\n@@ -1135,6 +1135,76 @@ def test_kafka_consumer_hang2(kafka_cluster):\n     kafka_delete_topic(admin_client, topic_name)\n \n \n+# sequential read from different consumers leads to breaking lot of kafka invariants\n+# (first consumer will get all partitions initially, and may have problems in doing polls every 60 sec)\n+def test_kafka_read_consumers_in_parallel(kafka_cluster):\n+    admin_client = KafkaAdminClient(\n+        bootstrap_servers=\"localhost:{}\".format(kafka_cluster.kafka_port)\n+    )\n+\n+    topic_name = \"read_consumers_in_parallel\"\n+    kafka_create_topic(admin_client, topic_name, num_partitions=8)\n+\n+    cancel = threading.Event()\n+\n+    def produce():\n+        while not cancel.is_set():\n+            messages = []\n+            for _ in range(100):\n+                messages.append(json.dumps({\"key\": 0, \"value\": 0}))\n+            kafka_produce(kafka_cluster, \"read_consumers_in_parallel\", messages)\n+            time.sleep(1)\n+\n+    kafka_thread = threading.Thread(target=produce)\n+    kafka_thread.start()\n+\n+    # when we have more than 1 consumer in a single table,\n+    # and kafka_thread_per_consumer=0\n+    # all the consumers should be read in parallel, not in sequence.\n+    # then reading in parallel 8 consumers with 1 seconds kafka_poll_timeout_ms and less than 1 sec limit\n+    # we should have exactly 1 poll per consumer (i.e. 8 polls) every 1 seconds (from different threads)\n+    # in case parallel consuming is not working we will have only 1 poll every 1 seconds (from the same thread).\n+    instance.query(\n+        f\"\"\"\n+        DROP TABLE IF EXISTS test.kafka;\n+        DROP TABLE IF EXISTS test.view;\n+        DROP TABLE IF EXISTS test.consumer;\n+\n+        CREATE TABLE test.kafka (key UInt64, value UInt64)\n+            ENGINE = Kafka\n+            SETTINGS kafka_broker_list = 'kafka1:19092',\n+                     kafka_topic_list = '{topic_name}',\n+                     kafka_group_name = '{topic_name}',\n+                     kafka_format = 'JSONEachRow',\n+                     kafka_num_consumers = 8,\n+                     kafka_thread_per_consumer = 0,\n+                     kafka_poll_timeout_ms = 1000,\n+                     kafka_flush_interval_ms = 999;\n+        CREATE TABLE test.view (key UInt64, value UInt64) ENGINE = Memory();\n+        CREATE MATERIALIZED VIEW test.consumer TO test.view AS SELECT * FROM test.kafka;\n+        \"\"\"\n+    )\n+\n+    instance.wait_for_log_line(\n+        \"kafka.*Polled batch of [0-9]+.*read_consumers_in_parallel\",\n+        repetitions=64,\n+        look_behind_lines=100,\n+        timeout=30,  # we should get 64 polls in ~8 seconds, but when read sequentially it will take more than 64 sec\n+    )\n+\n+    cancel.set()\n+    kafka_thread.join()\n+\n+    instance.query(\n+        \"\"\"\n+        DROP TABLE test.consumer;\n+        DROP TABLE test.view;\n+        DROP TABLE test.kafka;\n+    \"\"\"\n+    )\n+    kafka_delete_topic(admin_client, topic_name)\n+\n+\n def test_kafka_csv_with_delimiter(kafka_cluster):\n     messages = []\n     for i in range(50):\n",
  "problem_statement": "kafka_num_consumers setting doesn't work without kafka_thread_per_consumer\nI have Kafka engine table, MV and destination MT table.\r\nKafka table create query:\r\n```\r\nCREATE TABLE abc.Kafka_TestSource (...) \r\nENGINE = Kafka \r\nSETTINGS kafka_broker_list = '...'\r\n, format_avro_schema_registry_url = '...'\r\n, kafka_topic_list = '...'\r\n, kafka_group_name = 'Test_KafkaToCH'\r\n, kafka_format = 'AvroConfluent'\r\n, kafka_num_consumers = 1\r\n, kafka_thread_per_consumer = 0\r\n```\r\n\r\nDue to Grafana consumer group stats dashboard it reads the topic with average speed ~11k records per second.\r\nI recreate Kafka table with `kafka_num_consumers = 9` (kafka topic has 9 partitions) and it still reads with the same speed ~11k rps, **system.metrics** also shows that only 1 pool is being used:\r\n```\r\nSELECT\r\n    m.metric,\r\n    m.value\r\nFROM system.metrics AS m\r\nWHERE m.metric LIKE 'Background%'\r\n\r\nQuery id: 831a9285-e91b-45a4-8a1b-6b536d6860fe\r\n\r\n\u250c\u2500metric\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500value\u2500\u2510\r\n\u2502 BackgroundMergesAndMutationsPoolTask    \u2502     4 \u2502\r\n\u2502 BackgroundFetchesPoolTask               \u2502     0 \u2502\r\n\u2502 BackgroundCommonPoolTask                \u2502     0 \u2502\r\n\u2502 BackgroundMovePoolTask                  \u2502     0 \u2502\r\n\u2502 BackgroundSchedulePoolTask              \u2502     0 \u2502\r\n\u2502 BackgroundBufferFlushSchedulePoolTask   \u2502     0 \u2502\r\n\u2502 BackgroundDistributedSchedulePoolTask   \u2502     0 \u2502\r\n\u2502 BackgroundMessageBrokerSchedulePoolTask \u2502     1 \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n```\r\n\r\nIf I set `kafka_thread_per_consumer = 1` then **BackgroundMessageBrokerSchedulePoolTask** in **system.metrics** raises up to 9 and read speed in Grafana raises up to 100 records per second:\r\n![pic](https://github.com/sokolov-alexey/pics/blob/main/ch_kafka.PNG?raw=true)\r\n1. `kafka_num_consumers = 1, kafka_thread_per_consumer = 0`\r\n2. `kafka_num_consumers = 9, kafka_thread_per_consumer = 0`\r\n3. `kafka_num_consumers = 9, kafka_thread_per_consumer = 1`\r\n\r\nWhy `kafka_num_consumers` doesn't work without `kafka_thread_per_consumer`?\r\n\r\nClickHouse 21.11.4.14.\n",
  "hints_text": "> Why kafka_num_consumers doesn't work without kafka_thread_per_consumer?\r\n\r\nit works. \r\n\r\nOne flushing thread started (you see it in BackgroundMessageBrokerSchedulePoolTask). It reads from 9 consumers simultaneously (BTW every consumer = several librdkafka threads). \r\n\r\nSo with `kafka_thread_per_consumer = 0` you can have linearized inserts to a target table, while reads/parses happen from 9 different streams. \r\n\r\nWith `kafka_thread_per_consumer = 1` every stream flushes data by it's own. So several simulanious / parallel inserts can happen at the same time (i.e. no linearability).\r\n\r\nP.S. picture / attachement is missing\n@filimonov thanks for notice, I repaired the attached screenshot.\r\n\r\nWhy are you talking about 3 consumers if I use either 1 or 9 in kafka table settings? Is it a default value for some streaming setting or just for example?\r\n\r\nI wonder if increasing `kafka_num_consumers` from 1 to 9 (1 and 2 intervals on the screenshot) doesn't affect stream flushing speed at all. Shouldn't it affect stream flushing speed regardless linearized or parallel mode?\r\n\n> Why are you talking about 3 consumers if I use either 1 or 9 in kafka table settings? \r\n\r\njust misread, sorry. (will edit the original message to avoid confusions by readers).\r\n\r\n> I wonder if increasing kafka_num_consumers from 1 to 9 (1 and 2 intervals on the screenshot) doesn't affect stream flushing speed at all. Shouldn't it affect stream flushing speed regardless linearized or parallel mode?\r\n\r\nThat means the bottleneck is not the consume speed by a flush speed.\r\n\r\nBTW having 9 consumers - may be quite expensive thing: they are not 'for free', every consumer = several threads (one per broker + a couple of service threads), and some buffers.  \n@filimonov could you please remove \"question answered\" then?\r\n\r\n> That means the bottleneck is not the consume speed by a flush speed.\r\n\r\nIt is a new server (another one handles ~3 billion records per day inserted by an application), and the only Kafka table on it. Don't think if it can't handle one more Kafka consumer.\r\nSeems more like a bug or a setting - not like bottleneck. This bottleneck effect affects only single Kafka table. I've tried to create 3 more Kafka engines with 1 consumer each - all of them flush streams with same speed ~11k rps. And all of them don't respond to `kafka_num_consumers` changes.\n> @filimonov could you please remove \"question answered\" then?\r\n\r\nwhat is still unclear for you? Just use `kafka_thread_per_consumer = 1` if you ok to do flushes in parallel. \r\n\r\n>  I've tried to create 3 more Kafka engines with 1 consumer each - all of them flush streams with same speed ~11k rps. And all of them don't respond to kafka_num_consumers changes.\r\n\r\nWhen you create 3 tables with engine=Kafka and a single consumer it gives the same behaviour as single kafka table with num_consumers = 3 and kafka_thread_per_consumer = 1\nIt seems like after https://github.com/ClickHouse/ClickHouse/pull/29491 it flushes consumers sequentially.",
  "created_at": "2022-04-05T19:59:16Z",
  "modified_files": [
    "src/Storages/Kafka/StorageKafka.cpp"
  ],
  "modified_test_files": [
    "tests/integration/test_storage_kafka/test.py"
  ]
}