diff --git a/tests/config/macros.xml b/tests/config/macros.xml
index 1f86f5f9efdd..97c3065471f7 100644
--- a/tests/config/macros.xml
+++ b/tests/config/macros.xml
@@ -1,5 +1,7 @@
 <yandex>
     <macros>
         <test>Hello, world!</test>
+        <shard>s1</shard>
+        <replica>r1</replica>
     </macros>
 </yandex>
diff --git a/tests/integration/test_cluster_copier/test.py b/tests/integration/test_cluster_copier/test.py
index 9c2bcc22ef7b..983cac596dce 100644
--- a/tests/integration/test_cluster_copier/test.py
+++ b/tests/integration/test_cluster_copier/test.py
@@ -78,7 +78,7 @@ def start(self):
 
         for cluster_num in ["0", "1"]:
             ddl_check_query(instance, "DROP DATABASE IF EXISTS default ON CLUSTER cluster{}".format(cluster_num))
-            ddl_check_query(instance, "CREATE DATABASE IF NOT EXISTS default ON CLUSTER cluster{}".format(cluster_num))
+            ddl_check_query(instance, "CREATE DATABASE IF NOT EXISTS default ON CLUSTER cluster{} ENGINE=Ordinary".format(cluster_num))
 
         ddl_check_query(instance, "CREATE TABLE hits ON CLUSTER cluster0 (d UInt64, d1 UInt64 MATERIALIZED d+1) " +
                                   "ENGINE=ReplicatedMergeTree('/clickhouse/tables/cluster_{cluster}/{shard}/hits', '{replica}') " +
@@ -115,7 +115,7 @@ def start(self):
 
         for cluster_num in ["0", "1"]:
             ddl_check_query(instance, "DROP DATABASE IF EXISTS default ON CLUSTER cluster{}".format(cluster_num))
-            ddl_check_query(instance, "CREATE DATABASE IF NOT EXISTS default ON CLUSTER cluster{}".format(cluster_num))
+            ddl_check_query(instance, "CREATE DATABASE IF NOT EXISTS default ON CLUSTER cluster{} ENGINE=Ordinary".format(cluster_num))
 
         ddl_check_query(instance, "CREATE TABLE a ON CLUSTER cluster0 (date Date, d UInt64, d1 UInt64 ALIAS d+1) ENGINE=ReplicatedMergeTree('/clickhouse/tables/cluster_{cluster}/{shard}/a', '{replica}', date, intHash64(d), (date, intHash64(d)), 8192)")
         ddl_check_query(instance, "CREATE TABLE a_all ON CLUSTER cluster0 (date Date, d UInt64) ENGINE=Distributed(cluster0, default, a, d)")
diff --git a/tests/integration/test_cluster_copier/trivial_test.py b/tests/integration/test_cluster_copier/trivial_test.py
index c0966f77deb7..70c66653cb27 100644
--- a/tests/integration/test_cluster_copier/trivial_test.py
+++ b/tests/integration/test_cluster_copier/trivial_test.py
@@ -62,7 +62,7 @@ def start(self):
 
         for node in [source, destination]:
             node.query("DROP DATABASE IF EXISTS default")
-            node.query("CREATE DATABASE IF NOT EXISTS default")
+            node.query("CREATE DATABASE IF NOT EXISTS default ENGINE=Ordinary")
 
         source.query("CREATE TABLE trivial (d UInt64, d1 UInt64 MATERIALIZED d+1) "
                      "ENGINE=ReplicatedMergeTree('/clickhouse/tables/source_trivial_cluster/1/trivial', '1') "
@@ -181,4 +181,4 @@ def test_trivial_copy_with_move_fault(started_cluster, use_sample_offset):
     with contextmanager(started_cluster)() as cluster:
         for name, instance in cluster.instances.items():
             print name, instance.ip_address
-        raw_input("Cluster created, press any key to destroy...")
\ No newline at end of file
+        raw_input("Cluster created, press any key to destroy...")
diff --git a/tests/integration/test_distributed_ddl/cluster.py b/tests/integration/test_distributed_ddl/cluster.py
index 280713815861..082a76cd88d7 100644
--- a/tests/integration/test_distributed_ddl/cluster.py
+++ b/tests/integration/test_distributed_ddl/cluster.py
@@ -68,8 +68,8 @@ def check_all_hosts_successfully_executed(self, tsv_content, num_hosts=None):
         assert len(set(codes)) == 1, "
" + tsv_content
         assert codes[0] == "0", "
" + tsv_content
 
-    def ddl_check_query(self, instance, query, num_hosts=None):
-        contents = instance.query(query)
+    def ddl_check_query(self, instance, query, num_hosts=None, settings=None):
+        contents = instance.query(query, settings=settings)
         self.check_all_hosts_successfully_executed(contents, num_hosts)
         return contents
 
diff --git a/tests/integration/test_distributed_ddl/test.py b/tests/integration/test_distributed_ddl/test.py
index 8ef6f1892c52..f5dbe0ef8d29 100755
--- a/tests/integration/test_distributed_ddl/test.py
+++ b/tests/integration/test_distributed_ddl/test.py
@@ -295,6 +295,22 @@ def test_socket_timeout(test_cluster):
     for i in range(0, 100):
         instance.query("select hostName() as host, count() from cluster('cluster', 'system', 'settings') group by host")
 
+def test_replicated_without_arguments(test_cluster):
+    rules = test_cluster.pm_random_drops.pop_rules()
+    instance = test_cluster.instances['ch1']
+    test_cluster.ddl_check_query(instance, "CREATE DATABASE test_atomic ON CLUSTER cluster ENGINE=Atomic",
+                                 settings={'show_table_uuid_in_table_create_query_if_not_nil': 1})
+    test_cluster.ddl_check_query(instance, "CREATE TABLE test_atomic.rmt ON CLUSTER cluster (n UInt64, s String) ENGINE=ReplicatedMergeTree ORDER BY n",
+                                 settings={'show_table_uuid_in_table_create_query_if_not_nil': 1})
+    test_cluster.ddl_check_query(instance, "DROP TABLE test_atomic.rmt ON CLUSTER cluster")
+    test_cluster.ddl_check_query(instance, "CREATE TABLE test_atomic.rmt ON CLUSTER cluster (n UInt64, s String) ENGINE=ReplicatedMergeTree ORDER BY n",
+                                 settings={'show_table_uuid_in_table_create_query_if_not_nil': 1})
+    test_cluster.ddl_check_query(instance, "RENAME TABLE test_atomic.rmt TO test_atomic.rmt_renamed ON CLUSTER cluster")
+    test_cluster.ddl_check_query(instance, "CREATE TABLE test_atomic.rmt ON CLUSTER cluster (n UInt64, s String) ENGINE=ReplicatedMergeTree ORDER BY n",
+                                 settings={'show_table_uuid_in_table_create_query_if_not_nil': 1})
+    test_cluster.ddl_check_query(instance, "EXCHANGE TABLES test_atomic.rmt AND test_atomic.rmt_renamed ON CLUSTER cluster")
+    test_cluster.pm_random_drops.push_rules(rules)
+
 if __name__ == '__main__':
     with contextmanager(test_cluster)() as ctx_cluster:
        for name, instance in ctx_cluster.instances.items():
diff --git a/tests/integration/test_ttl_move/test.py b/tests/integration/test_ttl_move/test.py
index 1894f88029ed..eedcb01ee3aa 100644
--- a/tests/integration/test_ttl_move/test.py
+++ b/tests/integration/test_ttl_move/test.py
@@ -97,7 +97,7 @@ def get_command(x, policy):
         with pytest.raises(QueryRuntimeException):
             node1.query(get_command("TTL d1 TO DISK 'unknown'", "small_jbod_with_external"))
 
-        node1.query("DROP TABLE IF EXISTS {}".format(name))
+        node1.query("DROP TABLE IF EXISTS {} NO DELAY".format(name))
 
         if alter:
             node1.query(get_command(None, "small_jbod_with_external"))
@@ -105,7 +105,7 @@ def get_command(x, policy):
         with pytest.raises(QueryRuntimeException):
             node1.query(get_command("TTL d1 TO VOLUME 'unknown'", "small_jbod_with_external"))
 
-        node1.query("DROP TABLE IF EXISTS {}".format(name))
+        node1.query("DROP TABLE IF EXISTS {} NO DELAY".format(name))
 
         if alter:
             node1.query(get_command(None, "only_jbod2"))
@@ -113,7 +113,7 @@ def get_command(x, policy):
         with pytest.raises(QueryRuntimeException):
             node1.query(get_command("TTL d1 TO DISK 'jbod1'", "only_jbod2"))
 
-        node1.query("DROP TABLE IF EXISTS {}".format(name))
+        node1.query("DROP TABLE IF EXISTS {} NO DELAY".format(name))
 
         if alter:
             node1.query(get_command(None, "only_jbod2"))
@@ -122,7 +122,7 @@ def get_command(x, policy):
             node1.query(get_command("TTL d1 TO VOLUME 'external'", "only_jbod2"))
 
     finally:
-        node1.query("DROP TABLE IF EXISTS {}".format(name))
+        node1.query("DROP TABLE IF EXISTS {} NO DELAY".format(name))
 
 
 @pytest.mark.parametrize("name,engine,positive", [
@@ -155,7 +155,7 @@ def test_inserts_to_disk_work(started_cluster, name, engine, positive):
 
     finally:
         try:
-            node1.query("DROP TABLE IF EXISTS {}".format(name))
+            node1.query("DROP TABLE IF EXISTS {} NO DELAY".format(name))
         except:
             pass
 
@@ -204,7 +204,7 @@ def test_moves_work_after_storage_policy_change(started_cluster, name, engine):
         assert node1.query("SELECT count() FROM {name}".format(name=name)).strip() == "10"
 
     finally:
-        node1.query("DROP TABLE IF EXISTS {}".format(name))
+        node1.query("DROP TABLE IF EXISTS {} NO DELAY".format(name))
 
 
 @pytest.mark.parametrize("name,engine,positive", [
@@ -250,7 +250,7 @@ def test_moves_to_disk_work(started_cluster, name, engine, positive):
         assert node1.query("SELECT count() FROM {name}".format(name=name)).strip() == "10"
 
     finally:
-        node1.query("DROP TABLE IF EXISTS {}".format(name))
+        node1.query("DROP TABLE IF EXISTS {} NO DELAY".format(name))
 
 
 @pytest.mark.parametrize("name,engine", [
@@ -296,7 +296,7 @@ def test_moves_to_volume_work(started_cluster, name, engine):
         assert node1.query("SELECT count() FROM {name}".format(name=name)).strip() == "10"
 
     finally:
-        node1.query("DROP TABLE IF EXISTS {}".format(name))
+        node1.query("DROP TABLE IF EXISTS {} NO DELAY".format(name))
 
 
 @pytest.mark.parametrize("name,engine,positive", [
@@ -334,7 +334,7 @@ def test_inserts_to_volume_work(started_cluster, name, engine, positive):
         assert node1.query("SELECT count() FROM {name}".format(name=name)).strip() == "20"
 
     finally:
-        node1.query("DROP TABLE IF EXISTS {}".format(name))
+        node1.query("DROP TABLE IF EXISTS {} NO DELAY".format(name))
 
 
 @pytest.mark.parametrize("name,engine", [
@@ -379,7 +379,7 @@ def test_moves_to_disk_eventually_work(started_cluster, name, engine):
         used_disks = get_used_disks_for_table(node1, name)
         assert set(used_disks) == {"jbod1"}
 
-        node1.query("DROP TABLE {}".format(name_temp))
+        node1.query("DROP TABLE {} NO DELAY".format(name_temp))
 
         time.sleep(2)
         used_disks = get_used_disks_for_table(node1, name)
@@ -388,8 +388,8 @@ def test_moves_to_disk_eventually_work(started_cluster, name, engine):
         assert node1.query("SELECT count() FROM {name}".format(name=name)).strip() == "10"
 
     finally:
-        node1.query("DROP TABLE IF EXISTS {}".format(name_temp))
-        node1.query("DROP TABLE IF EXISTS {}".format(name))
+        node1.query("DROP TABLE IF EXISTS {} NO DELAY".format(name_temp))
+        node1.query("DROP TABLE IF EXISTS {} NO DELAY".format(name))
 
 
 def test_replicated_download_ttl_info(started_cluster):
@@ -420,7 +420,7 @@ def test_replicated_download_ttl_info(started_cluster):
     finally:
         for node in (node1, node2):
             try:
-                node.query("DROP TABLE IF EXISTS {}".format(name))
+                node.query("DROP TABLE IF EXISTS {} NO DELAY".format(name))
             except:
                 continue
 
@@ -479,7 +479,7 @@ def test_merges_to_disk_work(started_cluster, name, engine, positive):
         assert node1.query("SELECT count() FROM {name}".format(name=name)).strip() == "16"
 
     finally:
-        node1.query("DROP TABLE IF EXISTS {}".format(name))
+        node1.query("DROP TABLE IF EXISTS {} NO DELAY".format(name))
 
 
 @pytest.mark.parametrize("name,engine", [
@@ -544,8 +544,8 @@ def test_merges_with_full_disk_work(started_cluster, name, engine):
         assert node1.query("SELECT count() FROM {name}".format(name=name)).strip() == "12"
 
     finally:
-        node1.query("DROP TABLE IF EXISTS {}".format(name_temp))
-        node1.query("DROP TABLE IF EXISTS {}".format(name))
+        node1.query("DROP TABLE IF EXISTS {} NO DELAY".format(name_temp))
+        node1.query("DROP TABLE IF EXISTS {} NO DELAY".format(name))
 
 
 @pytest.mark.parametrize("name,engine,positive", [
@@ -597,7 +597,7 @@ def test_moves_after_merges_work(started_cluster, name, engine, positive):
         assert node1.query("SELECT count() FROM {name}".format(name=name)).strip() == "14"
 
     finally:
-        node1.query("DROP TABLE IF EXISTS {}".format(name))
+        node1.query("DROP TABLE IF EXISTS {} NO DELAY".format(name))
 
 
 @pytest.mark.parametrize("name,engine,positive,bar", [
@@ -640,7 +640,7 @@ def test_ttls_do_not_work_after_alter(started_cluster, name, engine, positive, b
         assert node1.query("SELECT count() FROM {name}".format(name=name)).strip() == "10"
 
     finally:
-        node1.query("DROP TABLE IF EXISTS {}".format(name))
+        node1.query("DROP TABLE IF EXISTS {} NO DELAY".format(name))
 
 
 @pytest.mark.parametrize("name,engine", [
@@ -702,7 +702,7 @@ def test_materialize_ttl_in_partition(started_cluster, name, engine):
         assert node1.query("SELECT count() FROM {name}".format(name=name)).strip() == str(len(data))
 
     finally:
-        node1.query("DROP TABLE IF EXISTS {}".format(name))
+        node1.query("DROP TABLE IF EXISTS {} NO DELAY".format(name))
 
 
 @pytest.mark.parametrize("name,engine,positive", [
@@ -799,7 +799,7 @@ def test_alter_multiple_ttls(started_cluster, name, engine, positive):
             assert rows_count == 3
 
     finally:
-        node1.query("DROP TABLE IF EXISTS {name}".format(name=name))
+        node1.query("DROP TABLE IF EXISTS {name} NO DELAY".format(name=name))
 
 
 @pytest.mark.parametrize("name,engine", [
@@ -897,7 +897,7 @@ def optimize_table(num):
         assert node1.query("SELECT 1") == "1
"
         assert node1.query("SELECT COUNT() FROM {}".format(name)) == "500
"
     finally:
-        node1.query("DROP TABLE IF EXISTS {name}".format(name=name))
+        node1.query("DROP TABLE IF EXISTS {name} NO DELAY".format(name=name))
 
 @pytest.mark.skip(reason="Flacky test")
 @pytest.mark.parametrize("name,positive", [
@@ -950,7 +950,7 @@ def long_select():
         assert node1.query("SELECT n FROM {name} ORDER BY n".format(name=name)).splitlines() == ["1", "2", "3", "4"]
 
     finally:
-        node1.query("DROP TABLE IF EXISTS {name}".format(name=name))
+        node1.query("DROP TABLE IF EXISTS {name} NO DELAY".format(name=name))
 
 
 @pytest.mark.parametrize("name,engine,positive", [
@@ -1040,4 +1040,4 @@ def optimize_table(num):
             assert node1.query("SELECT count() FROM {name}".format(name=name)) == "6
"
 
     finally:
-        node1.query("DROP TABLE IF EXISTS {name}".format(name=name))
+        node1.query("DROP TABLE IF EXISTS {name} NO DELAY".format(name=name))
diff --git a/tests/queries/0_stateless/01045_dictionaries_restrictions.sql b/tests/queries/0_stateless/01045_dictionaries_restrictions.sql
index 67a1d76e95b2..909e2fe8ad41 100644
--- a/tests/queries/0_stateless/01045_dictionaries_restrictions.sql
+++ b/tests/queries/0_stateless/01045_dictionaries_restrictions.sql
@@ -1,6 +1,6 @@
 DROP DATABASE IF EXISTS dictdb;
 
-CREATE DATABASE dictdb ENGINE=Ordinary;
+CREATE DATABASE dictdb;
 
 CREATE DICTIONARY dictdb.restricted_dict (
   key UInt64,
diff --git a/tests/queries/0_stateless/01107_atomic_db_detach_attach.sh b/tests/queries/0_stateless/01107_atomic_db_detach_attach.sh
index 59fe28ae244f..18d74a1817cf 100755
--- a/tests/queries/0_stateless/01107_atomic_db_detach_attach.sh
+++ b/tests/queries/0_stateless/01107_atomic_db_detach_attach.sh
@@ -18,7 +18,7 @@ wait
 $CLICKHOUSE_CLIENT -q "ATTACH TABLE test_01107.mt"
 $CLICKHOUSE_CLIENT -q "SELECT count(n), sum(n) FROM test_01107.mt"
 $CLICKHOUSE_CLIENT -q "DETACH DATABASE test_01107"
-$CLICKHOUSE_CLIENT --allow_experimental_database_atomic=1 -q "ATTACH DATABASE test_01107 ENGINE=Atomic"
+$CLICKHOUSE_CLIENT --allow_experimental_database_atomic=1 -q "ATTACH DATABASE test_01107"
 $CLICKHOUSE_CLIENT -q "SELECT count(n), sum(n) FROM test_01107.mt"
 
 $CLICKHOUSE_CLIENT -q "INSERT INTO test_01107.mt SELECT number + sleepEachRow(1) FROM numbers(5)" && echo "end" &
diff --git a/tests/queries/0_stateless/01114_database_atomic.reference b/tests/queries/0_stateless/01114_database_atomic.reference
index dece5bd9b8bf..7980819f9af4 100644
--- a/tests/queries/0_stateless/01114_database_atomic.reference
+++ b/tests/queries/0_stateless/01114_database_atomic.reference
@@ -1,9 +1,9 @@
 CREATE DATABASE test_01114_1
ENGINE = Atomic
 CREATE DATABASE test_01114_2
ENGINE = Atomic
 CREATE DATABASE test_01114_3
ENGINE = Ordinary
-test_01114_1	Atomic	store	metadata	test_01114_1
-test_01114_2	Atomic	store	metadata	test_01114_2
-test_01114_3	Ordinary	test_01114_3	metadata	test_01114_3
+test_01114_1	Atomic	store	00001114-1000-4000-8000-000000000001	1
+test_01114_2	Atomic	store	00001114-1000-4000-8000-000000000002	1
+test_01114_3	Ordinary	test_01114_3	test_01114_3	1
 20
 100
 CREATE TABLE test_01114_2.mt UUID \'00001114-0000-4000-8000-000000000002\'
(
    `n` UInt64
)
ENGINE = MergeTree()
PARTITION BY n % 5
ORDER BY tuple()
SETTINGS index_granularity = 8192
diff --git a/tests/queries/0_stateless/01114_database_atomic.sh b/tests/queries/0_stateless/01114_database_atomic.sh
index 0a56f551252f..c7862bf5314a 100755
--- a/tests/queries/0_stateless/01114_database_atomic.sh
+++ b/tests/queries/0_stateless/01114_database_atomic.sh
@@ -12,10 +12,17 @@ $CLICKHOUSE_CLIENT --allow_experimental_database_atomic=1 -q "CREATE DATABASE te
 $CLICKHOUSE_CLIENT --default_database_engine=Atomic --allow_experimental_database_atomic=1 -q "CREATE DATABASE test_01114_2"
 $CLICKHOUSE_CLIENT --default_database_engine=Ordinary -q "CREATE DATABASE test_01114_3"
 
-$CLICKHOUSE_CLIENT -q "SHOW CREATE DATABASE test_01114_1"
-$CLICKHOUSE_CLIENT -q "SHOW CREATE DATABASE test_01114_2"
+$CLICKHOUSE_CLIENT --show_table_uuid_in_table_create_query_if_not_nil=0 -q "SHOW CREATE DATABASE test_01114_1"
+$CLICKHOUSE_CLIENT --show_table_uuid_in_table_create_query_if_not_nil=0 -q "SHOW CREATE DATABASE test_01114_2"
 $CLICKHOUSE_CLIENT -q "SHOW CREATE DATABASE test_01114_3"
-$CLICKHOUSE_CLIENT -q "SELECT name, engine, splitByChar('/', data_path)[-2], splitByChar('/', metadata_path)[-3], splitByChar('/', metadata_path)[-2] FROM system.databases WHERE name LIKE 'test_01114_%'"
+
+uuid_db_1=`$CLICKHOUSE_CLIENT -q "SELECT uuid FROM system.databases WHERE name='test_01114_1'"`
+uuid_db_2=`$CLICKHOUSE_CLIENT -q "SELECT uuid FROM system.databases WHERE name='test_01114_2'"`
+$CLICKHOUSE_CLIENT -q "SELECT name,
+                              engine,
+                              splitByChar('/', data_path)[-2],
+                              splitByChar('/', metadata_path)[-2] as uuid_path, ((splitByChar('/', metadata_path)[-3] as metadata) = substr(uuid_path, 1, 3)) OR metadata='metadata'
+                              FROM system.databases WHERE name LIKE 'test_01114_%'" | sed "s/$uuid_db_1/00001114-1000-4000-8000-000000000001/g" | sed "s/$uuid_db_2/00001114-1000-4000-8000-000000000002/g"
 
 $CLICKHOUSE_CLIENT -q "CREATE TABLE test_01114_1.mt_tmp (n UInt64) ENGINE=MergeTree() ORDER BY tuple()"
 $CLICKHOUSE_CLIENT -q "INSERT INTO test_01114_1.mt_tmp SELECT * FROM numbers(100)"
diff --git a/tests/queries/0_stateless/01191_rename_dictionary.reference b/tests/queries/0_stateless/01191_rename_dictionary.reference
new file mode 100644
index 000000000000..7b6ac0526888
--- /dev/null
+++ b/tests/queries/0_stateless/01191_rename_dictionary.reference
@@ -0,0 +1,11 @@
+dict	NOT_LOADED
+_	Memory
+dict	Dictionary
+dict1	NOT_LOADED
+_	Memory
+dict1	Dictionary
+test
+dict2	LOADED
+_	Memory
+dict2	Dictionary
+test
diff --git a/tests/queries/0_stateless/01191_rename_dictionary.sql b/tests/queries/0_stateless/01191_rename_dictionary.sql
new file mode 100644
index 000000000000..1a2440ee28bc
--- /dev/null
+++ b/tests/queries/0_stateless/01191_rename_dictionary.sql
@@ -0,0 +1,34 @@
+DROP DATABASE IF EXISTS test_01191;
+CREATE DATABASE test_01191 ENGINE=Atomic;
+
+CREATE TABLE test_01191._ (n UInt64, s String) ENGINE = Memory();
+
+CREATE DICTIONARY test_01191.dict (n UInt64, s String)
+PRIMARY KEY n
+LAYOUT(DIRECT())
+SOURCE(CLICKHOUSE(HOST 'localhost' PORT 9000 USER 'default' TABLE '_' DB 'test_01191'));
+
+INSERT INTO test_01191._ VALUES (42, 'test');
+
+SELECT name, status FROM system.dictionaries WHERE database='test_01191';
+SELECT name, engine FROM system.tables WHERE database='test_01191' ORDER BY name;
+
+RENAME DICTIONARY test_01191.table TO test_01191.table1; -- {serverError 80}
+EXCHANGE TABLES test_01191.table AND test_01191.dict; -- {serverError 48}
+EXCHANGE TABLES test_01191.dict AND test_01191.table; -- {serverError 80}
+RENAME TABLE test_01191.dict TO test_01191.dict1; -- {serverError 80}
+RENAME DICTIONARY test_01191.dict TO default.dict1; -- {serverError 48}
+
+RENAME DICTIONARY test_01191.dict TO test_01191.dict1;
+
+SELECT name, status FROM system.dictionaries WHERE database='test_01191';
+SELECT name, engine FROM system.tables WHERE database='test_01191' ORDER BY name;
+SELECT dictGet(test_01191.dict1, 's', toUInt64(42));
+
+RENAME DICTIONARY test_01191.dict1 TO test_01191.dict2;
+
+SELECT name, status FROM system.dictionaries WHERE database='test_01191';
+SELECT name, engine FROM system.tables WHERE database='test_01191' ORDER BY name;
+SELECT dictGet(test_01191.dict2, 's', toUInt64(42));
+
+DROP DATABASE test_01191;
diff --git a/tests/queries/0_stateless/01192_rename_database.reference b/tests/queries/0_stateless/01192_rename_database.reference
new file mode 100644
index 000000000000..13f2a780e0bc
--- /dev/null
+++ b/tests/queries/0_stateless/01192_rename_database.reference
@@ -0,0 +1,29 @@
+ok
+CREATE DATABASE test_01192 UUID \'00001192-0000-4000-8000-000000000001\'
ENGINE = Atomic
+Atomic	store	00001192-0000-4000-8000-000000000001	00001192-0000-4000-8000-000000000001
+ok
+ok
+renamed
+inserted
+CREATE DATABASE test_01192_renamed UUID \'00001192-0000-4000-8000-000000000001\'
ENGINE = Atomic
+Atomic	store	00001192-0000-4000-8000-000000000001	00001192-0000-4000-8000-000000000001
+CREATE DATABASE test_01192_renamed
ENGINE = Atomic
+10	45
+inserted
+renamed
+10	45
+10	45
+ok
+CREATE DICTIONARY test_01192_atomic.dict UUID \'00001192-0000-4000-8000-000000000002\'
(
    `n` UInt64,
    `_part` String DEFAULT \'no\'
)
PRIMARY KEY n
SOURCE(CLICKHOUSE(HOST \'localhost\' PORT 9000 USER \'default\' TABLE \'mt\' DB \'test_01192\'))
LAYOUT(DIRECT())
+test_01192_atomic	dict	NOT_LOADED	00001192-0000-4000-8000-000000000002
+no
+ok
+renamed
+inserted
+20	190
+10	45
+10	45
+test_01192	dict	LOADED	00001192-0000-4000-8000-000000000002
+all_1_1_0
+all_2_2_0
+test_01192	dict	LOADED	00001192-0000-4000-8000-000000000002
diff --git a/tests/queries/0_stateless/01192_rename_database.sh b/tests/queries/0_stateless/01192_rename_database.sh
new file mode 100755
index 000000000000..3d4223d09d5e
--- /dev/null
+++ b/tests/queries/0_stateless/01192_rename_database.sh
@@ -0,0 +1,81 @@
+#!/usr/bin/env bash
+
+CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
+. $CURDIR/../shell_config.sh
+
+
+# 1. init
+$CLICKHOUSE_CLIENT -q "DROP DATABASE IF EXISTS test_01192"
+$CLICKHOUSE_CLIENT -q "DROP DATABASE IF EXISTS test_01192_renamed"
+$CLICKHOUSE_CLIENT -q "DROP DATABASE IF EXISTS test_01192_atomic"
+
+$CLICKHOUSE_CLIENT --default_database_engine=Ordinary -q "CREATE DATABASE test_01192 UUID '00001192-0000-4000-8000-000000000001'" 2>&1| grep -F "does not support" > /dev/null && echo "ok"
+$CLICKHOUSE_CLIENT --allow_experimental_database_atomic=1 --default_database_engine=Atomic -q "CREATE DATABASE test_01192 UUID '00001192-0000-4000-8000-000000000001'"
+
+# 2. check metadata
+$CLICKHOUSE_CLIENT --show_table_uuid_in_table_create_query_if_not_nil=1 -q "SHOW CREATE DATABASE test_01192"
+$CLICKHOUSE_CLIENT -q "SELECT engine, splitByChar('/', data_path)[-2], uuid, splitByChar('/', metadata_path)[-2] FROM system.databases WHERE name='test_01192'"
+
+# 3. check RENAME don't wait for INSERT
+$CLICKHOUSE_CLIENT -q "CREATE TABLE test_01192.mt (n UInt64) ENGINE=MergeTree ORDER BY n"
+$CLICKHOUSE_CLIENT -q "INSERT INTO test_01192.mt SELECT number + sleepEachRow(1.5) FROM numbers(10)" && echo "inserted" &
+sleep 1
+
+$CLICKHOUSE_CLIENT -q "RENAME DATABASE test_01192 TO default" 2>&1| grep -F "already exists" > /dev/null && echo "ok"
+$CLICKHOUSE_CLIENT -q "RENAME DATABASE test_01192_notexisting TO test_01192_renamed" 2>&1| grep -F "doesn't exist" > /dev/null && echo "ok"
+$CLICKHOUSE_CLIENT -q "RENAME DATABASE test_01192 TO test_01192_renamed" && echo "renamed"
+wait
+
+# 4. check metadata after RENAME
+$CLICKHOUSE_CLIENT --show_table_uuid_in_table_create_query_if_not_nil=1 -q "SHOW CREATE DATABASE test_01192_renamed"
+$CLICKHOUSE_CLIENT -q "SELECT engine, splitByChar('/', data_path)[-2], uuid, splitByChar('/', metadata_path)[-2] FROM system.databases WHERE name='test_01192_renamed'"
+$CLICKHOUSE_CLIENT -q "SHOW CREATE DATABASE test_01192_renamed"
+$CLICKHOUSE_CLIENT -q "SELECT count(n), sum(n) FROM test_01192_renamed.mt"
+
+# 5. check moving tables from Ordinary to Atomic (can be used to "alter" database engine)
+$CLICKHOUSE_CLIENT --default_database_engine=Ordinary -q "CREATE DATABASE test_01192"
+$CLICKHOUSE_CLIENT -q "CREATE TABLE test_01192.mt AS test_01192_renamed.mt ENGINE=MergeTree ORDER BY n"
+$CLICKHOUSE_CLIENT -q "CREATE TABLE test_01192.rmt AS test_01192_renamed.mt ENGINE=ReplicatedMergeTree('/test/01192/', '1') ORDER BY n"
+$CLICKHOUSE_CLIENT -q "CREATE MATERIALIZED VIEW test_01192.mv TO test_01192.rmt AS SELECT * FROM test_01192.mt"
+
+$CLICKHOUSE_CLIENT -q "INSERT INTO test_01192.mt SELECT number FROM numbers(10)" && echo "inserted"
+
+$CLICKHOUSE_CLIENT --allow_experimental_database_atomic=1 --default_database_engine=Atomic -q "CREATE DATABASE test_01192_atomic"
+$CLICKHOUSE_CLIENT -q "DROP DATABASE test_01192_renamed"
+# it's blocking
+$CLICKHOUSE_CLIENT -q "RENAME TABLE test_01192.mt TO test_01192_atomic.mt, test_01192.rmt TO test_01192_atomic.rmt, test_01192.mv TO test_01192_atomic.mv" && echo "renamed"
+
+# 6. check data after RENAME
+$CLICKHOUSE_CLIENT -q "SELECT count(n), sum(n) FROM test_01192_atomic.mt"
+$CLICKHOUSE_CLIENT -q "SELECT count(n), sum(n) FROM test_01192_atomic.rmt"
+$CLICKHOUSE_CLIENT -q "SELECT count(n), sum(n) FROM test_01192_atomic.mv" 2>&1| grep -F "doesn't exist" > /dev/null && echo "ok"
+
+# 7. create dictionary and check it
+$CLICKHOUSE_CLIENT -q "CREATE TABLE test_01192.mt (n UInt64, _part String) ENGINE=Memory" # mock
+$CLICKHOUSE_CLIENT -q "CREATE DICTIONARY test_01192_atomic.dict UUID '00001192-0000-4000-8000-000000000002' (n UInt64, _part String DEFAULT 'no') PRIMARY KEY n LAYOUT(DIRECT()) SOURCE(CLICKHOUSE(HOST 'localhost' PORT 9000 USER 'default' TABLE 'mt' DB 'test_01192'))"
+$CLICKHOUSE_CLIENT --show_table_uuid_in_table_create_query_if_not_nil=1 -q "SHOW CREATE DICTIONARY test_01192_atomic.dict"
+$CLICKHOUSE_CLIENT -q "SELECT database, name, status, origin FROM system.dictionaries WHERE uuid='00001192-0000-4000-8000-000000000002'"
+$CLICKHOUSE_CLIENT -q "SELECT dictGet('test_01192_atomic.dict', '_part', toUInt64(1))"
+
+# 8. check RENAME don't wait for INSERT
+$CLICKHOUSE_CLIENT -q "INSERT INTO test_01192_atomic.mt SELECT number + sleepEachRow(1) + 10 FROM numbers(10)" && echo "inserted" &
+sleep 1
+
+$CLICKHOUSE_CLIENT -q "RENAME DATABASE test_01192 TO test_01192_renamed" 2>&1| grep -F "not supported" > /dev/null && echo "ok"
+$CLICKHOUSE_CLIENT -q "DROP DATABASE test_01192"
+$CLICKHOUSE_CLIENT -q "RENAME DATABASE test_01192_atomic TO test_01192" && echo "renamed"
+wait
+
+# 9. check data after RENAME
+$CLICKHOUSE_CLIENT -q "SELECT count(n), sum(n) FROM test_01192.mt"
+$CLICKHOUSE_CLIENT -q "SELECT count(n), sum(n) FROM test_01192.rmt"
+$CLICKHOUSE_CLIENT -q "SELECT count(n), sum(n) FROM test_01192.mv"
+$CLICKHOUSE_CLIENT -q "SELECT database, name, status, origin FROM system.dictionaries WHERE uuid='00001192-0000-4000-8000-000000000002'"
+$CLICKHOUSE_CLIENT -q "SELECT dictGet('test_01192.dict', '_part', toUInt64(1))"
+$CLICKHOUSE_CLIENT -q "SYSTEM RELOAD DICTIONARY test_01192.dict"
+$CLICKHOUSE_CLIENT -q "SELECT dictGet('test_01192.dict', '_part', toUInt64(10))"
+$CLICKHOUSE_CLIENT -q "SELECT database, name, status, origin FROM system.dictionaries WHERE uuid='00001192-0000-4000-8000-000000000002'"
+
+$CLICKHOUSE_CLIENT -q "DROP DATABASE test_01192"
+
+$CLICKHOUSE_CLIENT -q "SELECT database, name, status, origin FROM system.dictionaries WHERE uuid='00001192-0000-4000-8000-000000000002'" # 0 rows
diff --git a/tests/queries/0_stateless/01193_metadata_loading.sh b/tests/queries/0_stateless/01193_metadata_loading.sh
index 38da0fbd92df..c16726209a38 100755
--- a/tests/queries/0_stateless/01193_metadata_loading.sh
+++ b/tests/queries/0_stateless/01193_metadata_loading.sh
@@ -41,12 +41,10 @@ wait
 $CLICKHOUSE_CLIENT -q "CREATE TABLE $db.table_merge (i UInt64, d Date, s String, n Nested(i UInt8, f Float32)) ENGINE=Merge('$db', '^table_')"
 $CLICKHOUSE_CLIENT -q "SELECT count() * $count_multiplier, i, d, s, n.i, n.f FROM $db.table_merge GROUP BY i, d, s, n.i, n.f ORDER BY i"
 
-db_engine=$($CLICKHOUSE_CLIENT -q "SELECT engine FROM system.databases WHERE name='$db'")
-
 $CLICKHOUSE_CLIENT -q "DETACH DATABASE $db"
 
 # get real time, grep seconds, remove point, remove leading zeros
-elapsed_ms=$({ time $CLICKHOUSE_CLIENT -q "ATTACH DATABASE $db ENGINE=$db_engine"; } 2>&1 | grep real | grep -Po "0m\K[0-9\.]*" | tr -d '.' | sed "s/^0*//")
+elapsed_ms=$({ time $CLICKHOUSE_CLIENT -q "ATTACH DATABASE $db"; } 2>&1 | grep real | grep -Po "0m\K[0-9\.]*" | tr -d '.' | sed "s/^0*//")
 $CLICKHOUSE_CLIENT -q "SELECT '01193_metadata_loading', $elapsed_ms FORMAT Null" # it will be printed to server log
 
 if [[ $elapsed_ms -le $max_time_ms ]]; then echo ok; fi
diff --git a/tests/queries/0_stateless/01254_dict_load_after_detach_attach.sql b/tests/queries/0_stateless/01254_dict_load_after_detach_attach.sql
index ed419f1857a3..5a5f694d28f5 100644
--- a/tests/queries/0_stateless/01254_dict_load_after_detach_attach.sql
+++ b/tests/queries/0_stateless/01254_dict_load_after_detach_attach.sql
@@ -1,5 +1,5 @@
 DROP DATABASE IF EXISTS dict_db_01254;
-CREATE DATABASE dict_db_01254 ENGINE=Ordinary;
+CREATE DATABASE dict_db_01254;
 
 CREATE TABLE dict_db_01254.dict_data (key UInt64, val UInt64) Engine=Memory();
 CREATE DICTIONARY dict_db_01254.dict
@@ -13,7 +13,7 @@ LIFETIME(MIN 0 MAX 0)
 LAYOUT(FLAT());
 
 DETACH DATABASE dict_db_01254;
-ATTACH DATABASE dict_db_01254 ENGINE=Ordinary;
+ATTACH DATABASE dict_db_01254;
 
 SELECT query_count, status FROM system.dictionaries WHERE database = 'dict_db_01254' AND name = 'dict';
 SYSTEM RELOAD DICTIONARY dict_db_01254.dict;
diff --git a/tests/queries/0_stateless/01376_GROUP_BY_injective_elimination_dictGet.sql b/tests/queries/0_stateless/01376_GROUP_BY_injective_elimination_dictGet.sql
index 1c7a4d16f054..5982864bd978 100644
--- a/tests/queries/0_stateless/01376_GROUP_BY_injective_elimination_dictGet.sql
+++ b/tests/queries/0_stateless/01376_GROUP_BY_injective_elimination_dictGet.sql
@@ -7,7 +7,7 @@ DROP TABLE IF EXISTS dictdb_01376.table_for_dict;
 DROP DICTIONARY IF EXISTS dictdb_01376.dict_exists;
 DROP DATABASE IF EXISTS dictdb_01376;
 
-CREATE DATABASE dictdb_01376 ENGINE = Ordinary;
+CREATE DATABASE dictdb_01376;
 
 CREATE TABLE dictdb_01376.table_for_dict
 (
diff --git a/tests/queries/0_stateless/01378_alter_rename_with_ttl_zookeeper.sql b/tests/queries/0_stateless/01378_alter_rename_with_ttl_zookeeper.sql
index 98f295383800..0cd6feb9da15 100644
--- a/tests/queries/0_stateless/01378_alter_rename_with_ttl_zookeeper.sql
+++ b/tests/queries/0_stateless/01378_alter_rename_with_ttl_zookeeper.sql
@@ -5,7 +5,7 @@ CREATE TABLE table_rename_with_ttl
   date1 Date,
   value1 String
 )
-ENGINE = ReplicatedMergeTree('/clickhouse/test/table_rename_with_ttl', '1')
+ENGINE = ReplicatedMergeTree('/clickhouse/test/table_rename_with_ttl_01378', '1')
 ORDER BY tuple();
 
 INSERT INTO table_rename_with_ttl SELECT toDate('2018-10-01') + number % 3, toString(number) from numbers(9);
diff --git a/tests/queries/0_stateless/arcadia_skip_list.txt b/tests/queries/0_stateless/arcadia_skip_list.txt
index ea2944c25ccd..0c3ce88b439f 100644
--- a/tests/queries/0_stateless/arcadia_skip_list.txt
+++ b/tests/queries/0_stateless/arcadia_skip_list.txt
@@ -87,6 +87,7 @@
 01125_dict_ddl_cannot_add_column
 01129_dict_get_join_lose_constness
 01138_join_on_distributed_and_tmp
+01191_rename_dictionary
 01200_mutations_memory_consumption
 01211_optimize_skip_unused_shards_type_mismatch
 01213_optimize_skip_unused_shards_DISTINCT
diff --git a/tests/queries/skip_list.json b/tests/queries/skip_list.json
index 955c67b0b960..c40da4c8e50a 100644
--- a/tests/queries/skip_list.json
+++ b/tests/queries/skip_list.json
@@ -107,8 +107,9 @@
         "00992_system_parts_race_condition_zookeeper",
         "01320_create_sync_race_condition",
         "01305_replica_create_drop_zookeeper",
-        "01193_metadata_loading",
-        "01130_in_memory_parts_partitons"
+        "01130_in_memory_parts_partitons",
+        "01225_show_create_table_from_dictionary",
+        "01224_no_superfluous_dict_reload"
     ],
     "polymorphic-parts": [
         "avx",
