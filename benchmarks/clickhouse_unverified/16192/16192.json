{
  "repo": "ClickHouse/ClickHouse",
  "pull_number": 16192,
  "instance_id": "ClickHouse__ClickHouse-16192",
  "issue_numbers": [
    "16076"
  ],
  "base_commit": "ed8fe9c3acb91b8495fc30fddcaa134e6aa5079a",
  "patch": "diff --git a/programs/local/LocalServer.cpp b/programs/local/LocalServer.cpp\nindex 41da477152c6..2d019f813675 100644\n--- a/programs/local/LocalServer.cpp\n+++ b/programs/local/LocalServer.cpp\n@@ -57,8 +57,8 @@ LocalServer::LocalServer() = default;\n \n LocalServer::~LocalServer()\n {\n-    if (context)\n-        context->shutdown(); /// required for properly exception handling\n+    if (global_context)\n+        global_context->shutdown(); /// required for properly exception handling\n }\n \n \n@@ -95,9 +95,9 @@ void LocalServer::initialize(Poco::Util::Application & self)\n     }\n }\n \n-void LocalServer::applyCmdSettings()\n+void LocalServer::applyCmdSettings(Context & context)\n {\n-    context->applySettingsChanges(cmd_settings.changes());\n+    context.applySettingsChanges(cmd_settings.changes());\n }\n \n /// If path is specified and not empty, will try to setup server environment and load existing metadata\n@@ -151,8 +151,12 @@ void LocalServer::tryInitPath()\n     if (path.back() != '/')\n         path += '/';\n \n-    context->setPath(path);\n-    context->setUserFilesPath(\"\"); // user's files are everywhere\n+    global_context->setPath(path);\n+\n+    global_context->setTemporaryStorage(path + \"tmp\");\n+    global_context->setFlagsPath(path + \"flags\");\n+\n+    global_context->setUserFilesPath(\"\"); // user's files are everywhere\n }\n \n \n@@ -186,9 +190,9 @@ try\n     }\n \n     shared_context = Context::createShared();\n-    context = std::make_unique<Context>(Context::createGlobal(shared_context.get()));\n-    context->makeGlobalContext();\n-    context->setApplicationType(Context::ApplicationType::LOCAL);\n+    global_context = std::make_unique<Context>(Context::createGlobal(shared_context.get()));\n+    global_context->makeGlobalContext();\n+    global_context->setApplicationType(Context::ApplicationType::LOCAL);\n     tryInitPath();\n \n     std::optional<StatusFile> status;\n@@ -210,32 +214,32 @@ try\n \n     /// Maybe useless\n     if (config().has(\"macros\"))\n-        context->setMacros(std::make_unique<Macros>(config(), \"macros\", log));\n+        global_context->setMacros(std::make_unique<Macros>(config(), \"macros\", log));\n \n     /// Skip networking\n \n     /// Sets external authenticators config (LDAP).\n-    context->setExternalAuthenticatorsConfig(config());\n+    global_context->setExternalAuthenticatorsConfig(config());\n \n     setupUsers();\n \n     /// Limit on total number of concurrently executing queries.\n     /// There is no need for concurrent queries, override max_concurrent_queries.\n-    context->getProcessList().setMaxSize(0);\n+    global_context->getProcessList().setMaxSize(0);\n \n     /// Size of cache for uncompressed blocks. Zero means disabled.\n     size_t uncompressed_cache_size = config().getUInt64(\"uncompressed_cache_size\", 0);\n     if (uncompressed_cache_size)\n-        context->setUncompressedCache(uncompressed_cache_size);\n+        global_context->setUncompressedCache(uncompressed_cache_size);\n \n     /// Size of cache for marks (index of MergeTree family of tables). It is necessary.\n     /// Specify default value for mark_cache_size explicitly!\n     size_t mark_cache_size = config().getUInt64(\"mark_cache_size\", 5368709120);\n     if (mark_cache_size)\n-        context->setMarkCache(mark_cache_size);\n+        global_context->setMarkCache(mark_cache_size);\n \n     /// Load global settings from default_profile and system_profile.\n-    context->setDefaultProfiles(config());\n+    global_context->setDefaultProfiles(config());\n \n     /** Init dummy default DB\n       * NOTE: We force using isolated default database to avoid conflicts with default database from server environment\n@@ -243,34 +247,34 @@ try\n       *  if such tables will not be dropped, clickhouse-server will not be able to load them due to security reasons.\n       */\n     std::string default_database = config().getString(\"default_database\", \"_local\");\n-    DatabaseCatalog::instance().attachDatabase(default_database, std::make_shared<DatabaseMemory>(default_database, *context));\n-    context->setCurrentDatabase(default_database);\n-    applyCmdOptions();\n+    DatabaseCatalog::instance().attachDatabase(default_database, std::make_shared<DatabaseMemory>(default_database, *global_context));\n+    global_context->setCurrentDatabase(default_database);\n+    applyCmdOptions(*global_context);\n \n-    String path = context->getPath();\n+    String path = global_context->getPath();\n     if (!path.empty())\n     {\n         /// Lock path directory before read\n-        status.emplace(context->getPath() + \"status\", StatusFile::write_full_info);\n+        status.emplace(global_context->getPath() + \"status\", StatusFile::write_full_info);\n \n         LOG_DEBUG(log, \"Loading metadata from {}\", path);\n         Poco::File(path + \"data/\").createDirectories();\n         Poco::File(path + \"metadata/\").createDirectories();\n-        loadMetadataSystem(*context);\n-        attachSystemTables(*context);\n-        loadMetadata(*context);\n+        loadMetadataSystem(*global_context);\n+        attachSystemTables(*global_context);\n+        loadMetadata(*global_context);\n         DatabaseCatalog::instance().loadDatabases();\n         LOG_DEBUG(log, \"Loaded metadata.\");\n     }\n     else\n     {\n-        attachSystemTables(*context);\n+        attachSystemTables(*global_context);\n     }\n \n     processQueries();\n \n-    context->shutdown();\n-    context.reset();\n+    global_context->shutdown();\n+    global_context.reset();\n \n     status.reset();\n     cleanup();\n@@ -323,7 +327,7 @@ void LocalServer::processQueries()\n     String initial_create_query = getInitialCreateTableQuery();\n     String queries_str = initial_create_query + config().getRawString(\"query\");\n \n-    const auto & settings = context->getSettingsRef();\n+    const auto & settings = global_context->getSettingsRef();\n \n     std::vector<String> queries;\n     auto parse_res = splitMultipartQuery(queries_str, queries, settings.max_query_size, settings.max_parser_depth);\n@@ -331,15 +335,19 @@ void LocalServer::processQueries()\n     if (!parse_res.second)\n         throw Exception(\"Cannot parse and execute the following part of query: \" + String(parse_res.first), ErrorCodes::SYNTAX_ERROR);\n \n-    context->makeSessionContext();\n-    context->makeQueryContext();\n+    /// we can't mutate global global_context (can lead to races, as it was already passed to some background threads)\n+    /// so we can't reuse it safely as a query context and need a copy here\n+    auto context = Context(*global_context);\n+\n+    context.makeSessionContext();\n+    context.makeQueryContext();\n \n-    context->setUser(\"default\", \"\", Poco::Net::SocketAddress{});\n-    context->setCurrentQueryId(\"\");\n-    applyCmdSettings();\n+    context.setUser(\"default\", \"\", Poco::Net::SocketAddress{});\n+    context.setCurrentQueryId(\"\");\n+    applyCmdSettings(context);\n \n     /// Use the same query_id (and thread group) for all queries\n-    CurrentThread::QueryScope query_scope_holder(*context);\n+    CurrentThread::QueryScope query_scope_holder(context);\n \n     bool echo_queries = config().hasOption(\"echo\") || config().hasOption(\"verbose\");\n     std::exception_ptr exception;\n@@ -358,7 +366,7 @@ void LocalServer::processQueries()\n \n         try\n         {\n-            executeQuery(read_buf, write_buf, /* allow_into_outfile = */ true, *context, {});\n+            executeQuery(read_buf, write_buf, /* allow_into_outfile = */ true, context, {});\n         }\n         catch (...)\n         {\n@@ -423,7 +431,7 @@ void LocalServer::setupUsers()\n     }\n \n     if (users_config)\n-        context->setUsersConfig(users_config);\n+        global_context->setUsersConfig(users_config);\n     else\n         throw Exception(\"Can't load config for users\", ErrorCodes::CANNOT_LOAD_CONFIG);\n }\n@@ -577,10 +585,10 @@ void LocalServer::init(int argc, char ** argv)\n     argsToConfig(arguments, config(), 100);\n }\n \n-void LocalServer::applyCmdOptions()\n+void LocalServer::applyCmdOptions(Context & context)\n {\n-    context->setDefaultFormat(config().getString(\"output-format\", config().getString(\"format\", \"TSV\")));\n-    applyCmdSettings();\n+    context.setDefaultFormat(config().getString(\"output-format\", config().getString(\"format\", \"TSV\")));\n+    applyCmdSettings(context);\n }\n \n }\ndiff --git a/programs/local/LocalServer.h b/programs/local/LocalServer.h\nindex a89087543695..02778bd86cbe 100644\n--- a/programs/local/LocalServer.h\n+++ b/programs/local/LocalServer.h\n@@ -36,15 +36,15 @@ class LocalServer : public Poco::Util::Application, public Loggers\n     std::string getInitialCreateTableQuery();\n \n     void tryInitPath();\n-    void applyCmdOptions();\n-    void applyCmdSettings();\n+    void applyCmdOptions(Context & context);\n+    void applyCmdSettings(Context & context);\n     void processQueries();\n     void setupUsers();\n     void cleanup();\n \n protected:\n     SharedContextHolder shared_context;\n-    std::unique_ptr<Context> context;\n+    std::unique_ptr<Context> global_context;\n \n     /// Settings specified via command line args\n     Settings cmd_settings;\n",
  "test_patch": "diff --git a/tests/queries/0_stateless/01527_clickhouse_local_optimize.reference b/tests/queries/0_stateless/01527_clickhouse_local_optimize.reference\nnew file mode 100644\nindex 000000000000..e69de29bb2d1\ndiff --git a/tests/queries/0_stateless/01527_clickhouse_local_optimize.sh b/tests/queries/0_stateless/01527_clickhouse_local_optimize.sh\nnew file mode 100755\nindex 000000000000..bbbdf9c65d6c\n--- /dev/null\n+++ b/tests/queries/0_stateless/01527_clickhouse_local_optimize.sh\n@@ -0,0 +1,13 @@\n+#!/usr/bin/env bash\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+. \"$CURDIR\"/../shell_config.sh\n+\n+WORKING_FOLDER_01527=\"${CLICKHOUSE_TMP}/01527_clickhouse_local_optimize\"\n+rm -rf \"${WORKING_FOLDER_01527}\"\n+mkdir -p \"${WORKING_FOLDER_01527}\"\n+\n+# OPTIMIZE was crashing due to lack of temporary volume in local\n+${CLICKHOUSE_LOCAL} --query \"drop database if exists d; create database d; create table d.t engine MergeTree order by a as select 1 a; optimize table d.t final\" -- --path=\"${WORKING_FOLDER_01527}\"\n+\n+rm -rf \"${WORKING_FOLDER_01527}\"\ndiff --git a/tests/queries/0_stateless/01528_clickhouse_local_prepare_parts.reference b/tests/queries/0_stateless/01528_clickhouse_local_prepare_parts.reference\nnew file mode 100644\nindex 000000000000..64a56d9b949e\n--- /dev/null\n+++ b/tests/queries/0_stateless/01528_clickhouse_local_prepare_parts.reference\n@@ -0,0 +1,19 @@\n+Option 1. Prepare parts from from table with Engine=File defined in metadata, read from an arbitrary path\n+1\t2020-01-01\tString\n+2\t2020-02-02\tAnother string\n+3\t2020-03-03\tOne more string\n+4\t2020-01-02\tString for first partition\n+Option 2. Prepare parts from from table with Engine=File defined in metadata, read from stdin (pipe)\n+11\t2020-01-01\tString\n+12\t2020-02-02\tAnother string\n+13\t2020-03-03\tOne more string\n+14\t2020-01-02\tString for first partition\n+Option 3. Prepare parts from from table with Engine=File defined via command line, read from stdin (pipe)\n+21\t2020-01-01\tString\n+22\t2020-02-02\tAnother string\n+23\t2020-03-03\tOne more string\n+24\t2020-01-02\tString for first partition\n+Possibility to run optimize on prepared parts before sending parts to server\n+202001\t1\n+202002\t1\n+202003\t1\ndiff --git a/tests/queries/0_stateless/01528_clickhouse_local_prepare_parts.sh b/tests/queries/0_stateless/01528_clickhouse_local_prepare_parts.sh\nnew file mode 100755\nindex 000000000000..9b09edfe27ae\n--- /dev/null\n+++ b/tests/queries/0_stateless/01528_clickhouse_local_prepare_parts.sh\n@@ -0,0 +1,83 @@\n+#!/usr/bin/env bash\n+\n+CURDIR=$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\n+. \"$CURDIR\"/../shell_config.sh\n+\n+WORKING_FOLDER_01528=\"${CLICKHOUSE_TMP}/01528_clickhouse_local_prepare_parts\"\n+rm -rf \"${WORKING_FOLDER_01528}\"\n+\n+mkdir -p \"${WORKING_FOLDER_01528}/metadata/local\"\n+\n+## Checks scenario of preparing parts offline by clickhouse-local\n+\n+## that is the metadata for the table we want to fill\n+## schema should match the schema of the table from server\n+## (the easiest way is just to copy it from the server)\n+cat <<EOF > \"${WORKING_FOLDER_01528}/metadata/local/test.sql\"\n+ATTACH TABLE local.test (id UInt64, d Date, s String) Engine=MergeTree ORDER BY id PARTITION BY toYYYYMM(d);\n+EOF\n+\n+#################\n+\n+echo \"Option 1. Prepare parts from from table with Engine=File defined in metadata, read from an arbitrary path\"\n+\n+## Source file:\n+cat <<EOF > \"${WORKING_FOLDER_01528}/data.csv\"\n+1,2020-01-01,\"String\"\n+2,2020-02-02,\"Another string\"\n+3,2020-03-03,\"One more string\"\n+4,2020-01-02,\"String for first partition\"\n+EOF\n+\n+## metadata written into file\n+cat <<EOF > \"${WORKING_FOLDER_01528}/metadata/local/data_csv.sql\"\n+ATTACH TABLE local.data_csv (id UInt64, d Date, s String) Engine=File(CSV, '${WORKING_FOLDER_01528}/data.csv');\n+EOF\n+\n+## feed the table\n+${CLICKHOUSE_LOCAL} --query \"INSERT INTO local.test SELECT * FROM local.data_csv;\" -- --path=\"${WORKING_FOLDER_01528}\"\n+\n+## check the parts were created\n+${CLICKHOUSE_LOCAL} --query \"SELECT * FROM local.test WHERE id < 10 ORDER BY id;\" -- --path=\"${WORKING_FOLDER_01528}\"\n+\n+#################\n+\n+echo \"Option 2. Prepare parts from from table with Engine=File defined in metadata, read from stdin (pipe)\"\n+\n+cat <<EOF > \"${WORKING_FOLDER_01528}/metadata/local/stdin.sql\"\n+ATTACH TABLE local.stdin (id UInt64, d Date, s String) Engine=File(CSV, stdin);\n+EOF\n+\n+cat <<EOF | ${CLICKHOUSE_LOCAL} --query \"INSERT INTO local.test SELECT * FROM local.stdin;\" -- --path=\"${WORKING_FOLDER_01528}\"\n+11,2020-01-01,\"String\"\n+12,2020-02-02,\"Another string\"\n+13,2020-03-03,\"One more string\"\n+14,2020-01-02,\"String for first partition\"\n+EOF\n+\n+${CLICKHOUSE_LOCAL} --query \"SELECT * FROM local.test WHERE id BETWEEN 10 AND 19 ORDER BY id;\" -- --path=\"${WORKING_FOLDER_01528}\"\n+\n+#################\n+\n+echo \"Option 3. Prepare parts from from table with Engine=File defined via command line, read from stdin (pipe)\"\n+\n+cat <<EOF | ${CLICKHOUSE_LOCAL} --query \"INSERT INTO local.test SELECT * FROM table;\" -S \"id UInt64, d Date, s String\" --input-format=CSV -- --path=\"${WORKING_FOLDER_01528}\"\n+21,2020-01-01,\"String\"\n+22,2020-02-02,\"Another string\"\n+23,2020-03-03,\"One more string\"\n+24,2020-01-02,\"String for first partition\"\n+EOF\n+\n+${CLICKHOUSE_LOCAL} --query \"SELECT * FROM local.test WHERE id BETWEEN 20 AND 29 ORDER BY id;\" -- --path=\"${WORKING_FOLDER_01528}\"\n+\n+#################\n+\n+echo \"Possibility to run optimize on prepared parts before sending parts to server\"\n+\n+${CLICKHOUSE_LOCAL} --query \"OPTIMIZE TABLE local.test FINAL;\" -- --path=\"${WORKING_FOLDER_01528}\"\n+\n+# ensure we have one part per partition\n+${CLICKHOUSE_LOCAL} --query \"SELECT toYYYYMM(d) m, uniqExact(_part) FROM local.test GROUP BY m ORDER BY m\" -- --path=\"${WORKING_FOLDER_01528}\"\n+\n+# cleanup\n+rm -rf \"${WORKING_FOLDER_01528}\"\n",
  "problem_statement": "clickhouse-local can crash due to lack of TemporaryVolume\nI've tried to run optimize using clickhouse-local :) \r\n```\r\n#0  __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:50\r\n#1  0x00007fb333cf3859 in __GI_abort () at abort.c:79\r\n#2  0x0000000010e89c1c in Poco::SignalHandler::handleSignal (sig=11) at ../contrib/poco/Foundation/src/SignalHandler.cpp:94\r\n#3  <signal handler called>\r\n#4  DB::IVolume::getDisk (this=0x0) at ../src/Disks/IVolume.h:63\r\n#5  DB::MergeTreeDataMergerMutator::mergePartsToTemporaryPart (this=<optimized out>, future_part=..., metadata_snapshot=..., merge_entry=..., time_of_merge=<optimized out>, context=..., \r\n    space_reservation=..., deduplicate=<optimized out>) at ../src/Storages/MergeTree/MergeTreeDataMergerMutator.cpp:719\r\n#6  0x000000000e0f07d9 in DB::StorageMergeTree::merge (this=<optimized out>, aggressive=<optimized out>, partition_id=..., final=<optimized out>, deduplicate=<optimized out>, \r\n    out_disable_reason=<optimized out>) at ../src/Storages/StorageMergeTree.cpp:746\r\n#7  0x000000000e0f54fc in DB::StorageMergeTree::optimize (this=0x7fb33362f700, partition=..., final=<optimized out>, deduplicate=<optimized out>, context=...)\r\n    at ../src/Storages/StorageMergeTree.cpp:1032\r\n#8  0x000000000dbdd824 in DB::InterpreterOptimizeQuery::execute (this=0x7fb332e983e0) at ../src/Interpreters/InterpreterOptimizeQuery.cpp:30\r\n#9  0x000000000dee5908 in DB::executeQueryImpl (begin=<optimized out>, end=<optimized out>, context=..., internal=<optimized out>, stage=<optimized out>, has_query_tail=<optimized out>, \r\n    istr=<optimized out>) at ../src/Interpreters/executeQuery.cpp:422\r\n#10 0x000000000dee85a9 in DB::executeQuery(DB::ReadBuffer&, DB::WriteBuffer&, bool, DB::Context&, std::__1::function<void (std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)>) (istr=..., ostr=..., allow_into_outfile=false, context=..., set_result_details=...)\r\n    at ../src/Interpreters/executeQuery.cpp:796\r\n#11 0x0000000007c71ed0 in DB::LocalServer::processQueries (this=<optimized out>) at ../programs/local/LocalServer.cpp:361\r\n#12 0x0000000007c6fee3 in DB::LocalServer::main (this=0x7fff1f995348) at ../programs/local/LocalServer.cpp:270\r\n#13 0x0000000010d7b513 in Poco::Util::Application::run (this=0x7fff1f995348) at ../contrib/poco/Util/src/Application.cpp:334\r\n#14 0x0000000007c75a8b in mainEntryClickHouseLocal (argc=8, argv=0x7fb332ee7680) at ../programs/local/LocalServer.cpp:597\r\n#15 0x0000000007b87cbd in main (argc_=<optimized out>, argv_=<optimized out>) at ../programs/main.cpp:400\r\n```\r\n\r\nSo it's from this line: \r\nhttps://github.com/ClickHouse/ClickHouse/blob/38c7132c0f580547a72e3cc1fa18a091abf46221/src/Storages/MergeTree/MergeTreeDataMergerMutator.cpp#L719\r\n(getTemporaryVolume is nullptr)\r\n\r\nIntroduced https://github.com/ClickHouse/ClickHouse/pull/8750\r\n\n",
  "hints_text": ">Introduced #8750\r\n\r\nActually it has been introduced in #11931",
  "created_at": "2020-10-20T16:00:58Z",
  "modified_files": [
    "programs/local/LocalServer.cpp",
    "programs/local/LocalServer.h"
  ],
  "modified_test_files": [
    "b/tests/queries/0_stateless/01527_clickhouse_local_optimize.sh",
    "b/tests/queries/0_stateless/01528_clickhouse_local_prepare_parts.reference",
    "b/tests/queries/0_stateless/01528_clickhouse_local_prepare_parts.sh"
  ]
}