{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 3980,
  "instance_id": "dragonflydb__dragonfly-3980",
  "issue_numbers": [
    "3973"
  ],
  "base_commit": "132ffe0920ae60df973287c2e3a4ef1d0136d420",
  "patch": "diff --git a/src/core/dense_set.cc b/src/core/dense_set.cc\nindex f19215dd26d6..c4be03b24429 100644\n--- a/src/core/dense_set.cc\n+++ b/src/core/dense_set.cc\n@@ -47,14 +47,16 @@ DenseSet::IteratorBase::IteratorBase(const DenseSet* owner, bool is_end)\n }\n \n void DenseSet::IteratorBase::SetExpiryTime(uint32_t ttl_sec) {\n+  DensePtr* ptr = curr_entry_->IsLink() ? curr_entry_->AsLink() : curr_entry_;\n+  void* src = ptr->GetObject();\n   if (!HasExpiry()) {\n-    auto src = curr_entry_->GetObject();\n     void* new_obj = owner_->ObjectClone(src, false, true);\n-    curr_entry_->SetObject(new_obj);\n+    ptr->SetObject(new_obj);\n     curr_entry_->SetTtl(true);\n     owner_->ObjDelete(src, false);\n+    src = new_obj;\n   }\n-  owner_->ObjUpdateExpireTime(curr_entry_->GetObject(), ttl_sec);\n+  owner_->ObjUpdateExpireTime(src, ttl_sec);\n }\n \n void DenseSet::IteratorBase::Advance() {\ndiff --git a/src/core/dense_set.h b/src/core/dense_set.h\nindex ec00dc4d97e3..c4e791a6cd23 100644\n--- a/src/core/dense_set.h\n+++ b/src/core/dense_set.h\n@@ -130,6 +130,7 @@ class DenseSet {\n \n     // Sets pointer but preserves tagging info\n     void SetObject(void* obj) {\n+      assert(IsObject());\n       ptr_ = (void*)((uptr() & kTagMask) | (uintptr_t(obj) & ~kTagMask));\n     }\n \n",
  "test_patch": "diff --git a/src/core/string_map_test.cc b/src/core/string_map_test.cc\nindex e59efc1a8be8..3feaef03d4d1 100644\n--- a/src/core/string_map_test.cc\n+++ b/src/core/string_map_test.cc\n@@ -146,6 +146,28 @@ TEST_F(StringMapTest, SetFieldExpireNoHasExpiry) {\n   EXPECT_EQ(k.ExpiryTime(), 1);\n }\n \n+TEST_F(StringMapTest, Bug3973) {\n+  for (unsigned i = 0; i < 8; i++) {\n+    EXPECT_TRUE(sm_->AddOrUpdate(to_string(i), \"val\"));\n+  }\n+  for (unsigned i = 0; i < 8; i++) {\n+    auto k = sm_->Find(to_string(i));\n+    ASSERT_FALSE(k.HasExpiry());\n+    k.SetExpiryTime(1);\n+    EXPECT_EQ(k.ExpiryTime(), 1);\n+  }\n+  for (unsigned i = 100; i < 1000; i++) {\n+    EXPECT_TRUE(sm_->AddOrUpdate(to_string(i), \"val\"));\n+  }\n+\n+  // make sure the first 8 keys have expiry set\n+  for (unsigned i = 0; i < 8; i++) {\n+    auto k = sm_->Find(to_string(i));\n+    ASSERT_TRUE(k.HasExpiry());\n+    EXPECT_EQ(k.ExpiryTime(), 1);\n+  }\n+}\n+\n unsigned total_wasted_memory = 0;\n \n TEST_F(StringMapTest, ReallocIfNeeded) {\n",
  "problem_statement": "Segfault on calls to HEXPIRE\n**Describe the bug**\r\nThere seems to be some sort of race condition in v.1.24.0 where if one calls `HEXPIRE` on fields using the same key in parallell, we get a segfault. I've provided some code that triggers it in 100% of the cases I've tried. However, there might be random variables at play, that I haven't obvserved, so please do try a few runs if it doesn't happen right away.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n0. Run Dragonflydb locally on port 6379\r\n1. Generate some stable ids\r\n```\r\nfor run in {1..100}; do touch $(uuidgen); done;\r\n```\r\n2. Insert some values\r\n```\r\nls | xargs -P 8 -I{} sh -c 'echo \"HSET abc {} 1\" | nc -c localhost 6379'\r\n```\r\n3. HEXPIRE these elements in parallell\r\n```\r\nls | xargs -P 8 -I{} sh -c 'echo \"HEXPIRE abc 10 FIELDS 1 {}\" | nc -c localhost 6379'\r\n```\r\n4. At step 3 a similar error to this should occur serverside:\r\n```\r\n*** SIGSEGV received at time=1729702103 on cpu 12 ***\r\nPC: @     0x5e996c28e944  (unknown)  dfly::SdsUpdateExpireTime()\r\n```\r\nEDIT: You might need to substitute `nc -c` with `nc -q0` or `nc -w0` depending on your distribution.\r\n\r\n**Expected behavior**\r\nEven if there's parallell calls (especially when we're not operating on the same underlying field), I wouldn't expect there to be a segfault.\r\n\r\n**Environment (please complete the following information):**\r\n - OS: I think this is irrellevant. Happens on both Ubuntu, offical docker, and arch.\r\n - Kernel: # Command: I think this is irrellevant. Happens on both Ubuntu, offical docker, and arch.\r\n - Containerized?: Yes, docker.\r\n - Dragonfly Version: v1.24.0\r\n\r\n**Additional context**\r\nI wrote the code for `HEXPIRE`, so I regret not being able to debug this. But I think one would need to know more about the inner workings than I do. It seems like an  `sds` ends up in an invalid state / gets deleted somehow, and then gets acted upon.\r\n\n",
  "hints_text": "A small correction: It seems like the parallell part of this is not 100% needed.\r\nE.g. I'm able to make it fail without parallellization on my system:\r\n``` ls | xargs -P 1 -I{} sh -c 'echo \"HEXPIRE abc 10 FIELDS 1 {}\" | nc -c localhost 6379'```\r\n\r\nBut, the targeting of the same key, is very important it seems. If I create 100 separate keys, with the same value, it seems to run without any problem at all.\r\nE.g.\r\n```ls | xargs -P 8 -I{} sh -c 'echo \"HEXPIRE {} 10 FIELDS 1 abc\" | nc -q0 localhost 6379'```",
  "created_at": "2024-10-24T08:01:10Z",
  "modified_files": [
    "src/core/dense_set.cc",
    "src/core/dense_set.h"
  ],
  "modified_test_files": [
    "src/core/string_map_test.cc"
  ]
}