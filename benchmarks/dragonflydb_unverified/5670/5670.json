{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 5670,
  "instance_id": "dragonflydb__dragonfly-5670",
  "issue_numbers": [
    "5635",
    "5653"
  ],
  "base_commit": "940b2bbe5d2b72bef959494145993b8bb04a7f35",
  "patch": "diff --git a/src/server/json_family.cc b/src/server/json_family.cc\nindex a3774a882efd..5f14e9239945 100644\n--- a/src/server/json_family.cc\n+++ b/src/server/json_family.cc\n@@ -505,6 +505,8 @@ OpStatus SetFullJson(const OpArgs& op_args, string_view key, string_view json_st\n     return OpStatus::INVALID_JSON;\n   }\n \n+  op_args.GetDbSlice().RemoveExpire(op_args.db_cntx.db_index, it_res->it);\n+\n   if (JsonEnconding() == kEncodingJsonFlat) {\n     flexbuffers::Builder fbb;\n     json::FromJsonType(*parsed_json, &fbb);\n",
  "test_patch": "diff --git a/src/server/json_family_test.cc b/src/server/json_family_test.cc\nindex b7252f194069..3f0705a2c483 100644\n--- a/src/server/json_family_test.cc\n+++ b/src/server/json_family_test.cc\n@@ -3226,4 +3226,17 @@ TEST_F(JsonFamilyTest, JsonKeysWithDots) {\n   EXPECT_THAT(resp, \"[\\\"some_value\\\"]\");\n }\n \n+TEST_F(JsonFamilyTest, JsonSetDeleteExpiryOfExistingKey) {\n+  auto resp = Run(\"SET key foo EX 1000\");\n+  ASSERT_THAT(resp, \"OK\");\n+  resp = Run(\"JSON.SET key $ {}\");\n+  ASSERT_THAT(resp, \"OK\");\n+  resp = Run(\"TTL key\");\n+  ASSERT_THAT(resp, IntArg(-1));\n+  resp = Run(\"EXPIRE key 100\");\n+  ASSERT_THAT(resp, IntArg(1));\n+  resp = Run(\"TTL key\");\n+  EXPECT_THAT(resp.GetInt(), 100);\n+}\n+\n }  // namespace dfly\n",
  "problem_statement": "chore: more pipeline latency coverage (#5632)\nPartially covers #5630\r\n\r\nAdd `pipeline_dispatch_flush_duration_seconds` metrics that bridge the gap between pipeline_commands_duration_seconds and cmd_squash_hop_duration_seconds + pipeline_queue_wait_duration_seconds.\r\n\r\nIn summary,\r\npipeline_commands_duration_seconds roughly equals to `dragonfly_cmd_squash_hop_duration_seconds + cmd_squash_hop_duration_seconds + pipeline_queue_wait_duration_seconds`.\r\n\r\nAlso update the local dashboard.\r\nFinally, cause AsyncFiber to wait for 20usec to give the I/O fiber the opportunity to read more data so that the pipeline will be larger.\r\n\r\n<!--\r\n**Commits Must Be Signed and Your PR title must conform to the conventional commit spec**\r\n  * See: https://github.com/dragonflydb/dragonfly/blob/main/CONTRIBUTING.md\r\n  * Please follow the section on `pre-commit hooks`, a linter will validate before you push\r\n\r\n  Example PR Title: <type>(<scope>)!: <description>\r\n\r\n  * `type` = bug, chore, feat, fix, docs, build, style, refactor, perf, test\r\n  * `!` = OPTIONAL: signals a breaking change\r\n  * `scope` = Optional when `type` is \"chore\" or \"docs\"\r\n  * `description` = short description of the change\r\n\r\nExamples:\r\n\r\n  * chore(examples): Clarify `docker` usage #120\r\n  * docs(readme): Fix Example Links #121\r\n  * feat(ingest)!: Add new ingest #122\r\n  * fix(ingest): Refactor for loop to list comprehension #123\r\n-->\nDragonfly Crash After Changing Record Type to JSON and Setting TTL\n**Describe the bug**\nDragonfly crashes when attempting to set a TTL on a key after its data type has been changed from a string to a JSON object. \n\n**To Reproduce**\nSteps to reproduce the behavior:\n1. Start Dragonfly:`docker run --rm -p 6379:6379 --ulimit memlock=-1  docker.dragonflydb.io/dragonflydb/dragonfly:latest`\n2. Connect to Dragonfly: `redis-cli`\n3. Execute the following Redis commands in sequence:\n```\nSET test foo EX 100    # Set 'test' as a string with a 100-second TTL\nJSON.SET test $ '{}'   # Change 'test' to a JSON object\nEXPIRE test 100        # Attempt to set a 100-second TTL (CRASH OCCURS HERE)\n```\nError Logs:\n```\nI20250811 12:26:02.859664     1 init.cc:127] dragonfly running in opt mode.\nI20250811 12:26:02.859730     1 dfly_main.cc:757] Starting dragonfly df-v1.32.0-960ddf41c41ce27d5c038856957b4d740629f94b\n                   .--::--.                   \n   :+*=:          =@@@@@@@@=          :+*+:   \n  %@@@@@@%*=.     =@@@@@@@@-     .=*%@@@@@@#  \n  @@@@@@@@@@@@#+-. .%@@@@#. .-+#@@@@@@@@@@@%  \n  -@@@@@@@@@@@@@@@@*:#@@#:*@@@@@@@@@@@@@@@@-  \n    :+*********####-%@%%@%-####********++.    \n   .%@@@@@@@@@@@@@%:@@@@@@:@@@@@@@@@@@@@@%    \n   .@@@@@@@@%*+-:   =@@@@=  .:-+*%@@@@@@@%.   \n     =*+-:           ###*          .:-+*=     \n                     %@@%                     \n                     *@@*                     \n                     +@@=                     \n                     :##:                     \n                     :@@:                     \n                      @@                      \n                      ..                      \n* Logs will be written to the first available of the following paths:\n/tmp/dragonfly.*\n./dragonfly.*\n* For the available flags type dragonfly [--help | --helpfull]\n* Documentation can be found at: https://www.dragonflydb.io/docs\nI20250811 12:26:02.859808     1 dfly_main.cc:799] maxmemory has not been specified. Deciding myself....\nI20250811 12:26:02.859820     1 dfly_main.cc:808] Found 7.29GiB available memory. Setting maxmemory to 5.83GiB\nW20250811 12:26:02.859839     1 dfly_main.cc:380] Weird error 1 switching to epoll\nI20250811 12:26:02.860366     1 proactor_pool.cc:149] Running 4 io threads\nI20250811 12:26:02.862628     1 server_family.cc:1073] Host OS: Linux 6.8.0-50-generic aarch64 with 4 threads\nI20250811 12:26:02.862906     1 snapshot_storage.cc:186] Load snapshot: Searching for snapshot in directory: \"/data\"\nW20250811 12:26:02.862937     1 server_family.cc:1173] Load snapshot: No snapshot found\nI20250811 12:26:02.875483    12 listener_interface.cc:102] sock[11] AcceptServer - listening on 0.0.0.0:6379\nF20250811 12:27:01.479359    14 db_slice.cc:948] Check failed: db.expire.Insert(main_it->first.AsRef(), ExpirePeriod(delta)).second \n*** Check failure stack trace: ***\n    @     0xc304ad11ee2c  google::LogMessage::SendToLog()\n    @     0xc304ad117d10  google::LogMessage::Flush()\n    @     0xc304ad11964c  google::LogMessageFatal::~LogMessageFatal()\n    @     0xc304acb91d54  dfly::DbSlice::AddExpire()\n    @     0xc304acb9c84c  dfly::DbSlice::UpdateExpire()\n    @     0xc304ac560da4  dfly::(anonymous namespace)::OpExpire()\n    @     0xc304ac56116c  _ZN4absl12lts_2025051219functional_internal12InvokeObjectIZN4dfly13GenericFamily6ExpireENS0_4SpanIKSt17basic_string_viewIcSt11char_traitsIcEEEERKNS3_14CommandContextEEUlPNS3_11TransactionEPNS3_11EngineShardEE_NSF_14RunnableResultEJSG_SI_EEET0_NS1_7VoidPtrEDpNS1_8ForwardTIT1_E4typeE\n    @     0xc304acbd01c8  dfly::Transaction::RunCallback()\n    @     0xc304acbd09b0  dfly::Transaction::ScheduleInShard()\n    @     0xc304acbd29a8  dfly::Transaction::ScheduleBatchInShard()\n    @     0xc304acd7e3c0  util::fb2::FiberQueue::Run()\n    @     0xc304acc222fc  _ZN5boost7context6detail11fiber_entryINS1_12fiber_recordINS0_5fiberEN4util3fb219FixedStackAllocatorEZNS6_6detail15WorkerFiberImplIZN4dfly9TaskQueue5StartESt17basic_string_viewIcSt11char_traitsIcEEEUlvE_JEEC4IS7_EESF_NS6_13FiberPriorityERKNS0_12preallocatedEOT_OSG_EUlOS4_E_EEEEvNS1_10transfer_tE\n    @     0xc304ace43dec  make_fcontext\n*** SIGABRT received at time=1754915221 on cpu 3 ***\nPC: @     0xfc42d172f1f0  (unknown)  (unknown)\n    @     0xc304ad177784        464  absl::lts_20250512::AbslFailureSignalHandler()\n    @     0xfc42d19ac8f8       4960  (unknown)\n    @     0xfc42d16ea67c        208  gsignal\n    @     0xfc42d16d7130         32  abort\n    @     0xc304ad1248ec        336  google::DumpStackTraceAndExit()\n    @     0xc304ad11830c        192  google::LogMessage::Fail()\n    @     0xc304ad11ee2c         16  google::LogMessage::SendToLog()\n    @     0xc304ad117d10        208  google::LogMessage::Flush()\n    @     0xc304ad11964c         80  google::LogMessageFatal::~LogMessageFatal()\n    @     0xc304acb91d54         16  dfly::DbSlice::AddExpire()\n    @     0xc304acb9c84c        256  dfly::DbSlice::UpdateExpire()\n    @     0xc304ac560da4        192  dfly::(anonymous namespace)::OpExpire()\n    @     0xc304ac56116c        496  absl::lts_20250512::functional_internal::InvokeObject<>()\n    @     0xc304acbd01c8         96  dfly::Transaction::RunCallback()\n    @     0xc304acbd09b0        288  dfly::Transaction::ScheduleInShard()\n    @     0xc304acbd29a8        592  dfly::Transaction::ScheduleBatchInShard()\n    @     0xc304acd7e3c0         96  util::fb2::FiberQueue::Run()\n    @     0xc304acc222fc        304  boost::context::detail::fiber_entry<>()\n[failure_signal_handler.cc : 377] RAW: Signal 5 raised at PC=0xfc42d16d71ec while already in AbslFailureSignalHandler()\n*** SIGTRAP received at time=1754915221 on cpu 3 ***\nPC: @     0xfc42d16d71ec  (unknown)  abort\n    @     0xc304ad177784        464  absl::lts_20250512::AbslFailureSignalHandler()\n    @     0xfc42d19ac8f8       4960  (unknown)\n    @     0xc304ad1248ec        336  google::DumpStackTraceAndExit()\n    @     0xc304ad11830c        192  google::LogMessage::Fail()\n    @     0xc304ad11ee2c         16  google::LogMessage::SendToLog()\n    @     0xc304ad117d10        208  google::LogMessage::Flush()\n    @     0xc304ad11964c         80  google::LogMessageFatal::~LogMessageFatal()\n    @     0xc304acb91d54         16  dfly::DbSlice::AddExpire()\n    @     0xc304acb9c84c        256  dfly::DbSlice::UpdateExpire()\n    @     0xc304ac560da4        192  dfly::(anonymous namespace)::OpExpire()\n    @     0xc304ac56116c        496  absl::lts_20250512::functional_internal::InvokeObject<>()\n    @     0xc304acbd01c8         96  dfly::Transaction::RunCallback()\n    @     0xc304acbd09b0        288  dfly::Transaction::ScheduleInShard()\n    @     0xc304acbd29a8        592  dfly::Transaction::ScheduleBatchInShard()\n    @     0xc304acd7e3c0         96  util::fb2::FiberQueue::Run()\n    @     0xc304acc222fc        304  boost::context::detail::fiber_entry<>()\n```\n\nExpected Behavior:\n\nThe EXPIRE test 100 command should successfully set a TTL of 100 seconds for the test key, even after its data type has been changed to JSON.\n\nActual Behavior:\n\nDragonfly crashes after executing the EXPIRE test 100 command, following the sequence of commands outlined above.\n\n\n**Environment (please complete the following information):**\n - OS: Linux / Darwin (Production / Local Development)\n - Containerized?: Kubernetes / Docker\n - Dragonfly Version: v1.31.2, also occurs with latest version v1.32.0\n\n\n**Additional context**\nThe issue does not occur when changing a record from JSON to a string and then setting the TTL. \nThe following sequence works without error:\n```\nJSON.SET test $ '{}'    # Set 'test' as a JSON object\nEXPIRE test 100         # Set a 100-second TTL\nSET test foo EX 100     # Change 'test' to a string with a 100-second TTL (No crash)\n```\n",
  "hints_text": "\nthanks for reporting this.\nWe tried to work around this bug by creating a little script that\n\n1. removes the TTL from the key\n2. writes the JSON data\n3. sets a new TTL\n\nwhich prevents DragonflyDB from crashing. Unfortunately, this leads to other error messages being logged every now and then:\n\n```\nE20250812 14:22:39.636881    11 compact_object.cc:62] Can't decrease 0 from 8288\nE20250812 14:23:46.887369    11 compact_object.cc:62] Can't decrease 18446744073709512352 from -21376\nE20250812 14:24:38.970415    12 compact_object.cc:62] Can't decrease 0 from 304\nE20250812 14:25:53.620461    12 compact_object.cc:62] Can't decrease 6192 from 14992\nE20250812 14:26:55.948788    12 compact_object.cc:62] Can't decrease 0 from 27088\nE20250812 14:27:53.609599    11 compact_object.cc:62] Can't decrease 18446744073709550128 from 20576\nE20250812 14:28:51.110918    12 compact_object.cc:62] Can't decrease 18446744073709550736 from 10960\nE20250812 14:29:42.571484    12 compact_object.cc:62] Can't decrease 0 from 31808\nE20250812 14:30:38.522343    12 compact_object.cc:62] Can't decrease 18446744073709511552 from -11696\nE20250812 14:31:40.226853    12 compact_object.cc:62] Can't decrease 18446744073709535680 from 6720\nE20250812 14:32:26.454803    11 compact_object.cc:62] Can't decrease 18446744073709544832 from 27232\nE20250812 14:33:27.215487    12 compact_object.cc:62] Can't decrease 0 from 5568\nE20250812 14:34:33.114913    12 compact_object.cc:62] Can't decrease 4192 from 10672\n```\n\nThis is the aforementioned script:\n\n```lua\nredis.call(\"PERSIST\", KEYS[1])\nlocal status = redis.call(\"JSON.SET\", KEYS[1], \"$\", ARGV[1])\nredis.call(\"EXPIRE\", KEYS[1], ARGV[2])\n\nreturn status\n```\n\nYou can run these two Ruby scripts in parallel to reproduce the log messages:\n\n```ruby\n#!/usr/bin/env ruby\nrequire 'json'\nrequire 'redis'\n\nredis = Redis.new(host: 'localhost', port: 6379)\n\nloop do\n  key = \"foo:#{rand(1..100)}\"\n\n  obj = {}\n  rand(1..100).times { |i| obj[\"key#{i+1}\"] = \"x\" * rand(10..1000) }\n\n  redis.call('SET', key, JSON.generate(obj), \"EX\", 60)\n  puts \"SET #{key}\"\n\n  sleep(rand(0.1..1.0))\nend\n```\n\n```ruby\n#!/usr/bin/env ruby\nrequire 'json'\nrequire 'redis'\n\nredis = Redis.new(host: 'localhost', port: 6379)\n\nloop do\n  key = \"foo:#{rand(1..100)}\"\n\n  obj = {}\n  rand(1..100).times { |i| obj[\"key#{i+1}\"] = \"x\" * rand(10..1000) }\n\n  redis.call('EVALSHA', '217a040c06cc8447588c817623eaf8fb39798ad5', 1, key, JSON.generate(obj), 60)\n  puts \"JSON.SET #{key}\"\n\n  sleep(rand(0.1..1.0))\nend\n```\n\nWe have no clue what the log message is telling us. Should we be worried about it or can it be ignored?\n\nEdit: While writing this, I figured that we could simply delete the key instead of persisting it. This way the error log does not show up. Might still be interesting for you to know.\nThanks @rey1128 for reporting and @brushmate for providing work around. We have analyzed problem and will discuss internally what needs to be done so it can be used smoothly.  \nAlso, we need to test this case:\n```\nset test foo ex <some small time>\njson.set test $ '{}\n<wait until the expiration time has passed>\n```\nMaybe we will still remove test key.",
  "created_at": "2025-08-13T09:38:33Z",
  "modified_files": [
    "src/server/json_family.cc"
  ],
  "modified_test_files": [
    "src/server/json_family_test.cc"
  ]
}