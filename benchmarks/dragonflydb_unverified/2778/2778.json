{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 2778,
  "instance_id": "dragonflydb__dragonfly-2778",
  "issue_numbers": [
    "2773"
  ],
  "base_commit": "3ec43afd309c0a9345760534663aec2e03bc96e3",
  "patch": "diff --git a/src/server/dflycmd.cc b/src/server/dflycmd.cc\nindex efefbff705e0..9fa7f26f28e6 100644\n--- a/src/server/dflycmd.cc\n+++ b/src/server/dflycmd.cc\n@@ -503,7 +503,8 @@ OpStatus DflyCmd::StartStableSyncInThread(FlowInfo* flow, Context* cntx, EngineS\n \n   if (shard != nullptr) {\n     flow->streamer.reset(new JournalStreamer(sf_->journal(), cntx));\n-    flow->streamer->Start(flow->conn->socket());\n+    bool send_lsn = flow->version >= DflyVersion::VER4;\n+    flow->streamer->Start(flow->conn->socket(), send_lsn);\n   }\n \n   // Register cleanup.\ndiff --git a/src/server/journal/journal.cc b/src/server/journal/journal.cc\nindex 09cd66839c9d..91425ebdcd33 100644\n--- a/src/server/journal/journal.cc\n+++ b/src/server/journal/journal.cc\n@@ -86,6 +86,11 @@ LSN Journal::GetLsn() const {\n void Journal::RecordEntry(TxId txid, Op opcode, DbIndex dbid, unsigned shard_cnt,\n                           std::optional<SlotId> slot, Entry::Payload payload, bool await) {\n   journal_slice.AddLogRecord(Entry{txid, opcode, dbid, shard_cnt, slot, std::move(payload)}, await);\n+  time_t now = time(nullptr);\n+  if (now - last_lsn_joural_time_ > 2) {\n+    journal_slice.AddLogRecord(Entry{txid, journal::Op::LSN, 0, 0, nullopt, {}}, await);\n+    last_lsn_joural_time_ = now;\n+  }\n }\n \n }  // namespace journal\ndiff --git a/src/server/journal/journal.h b/src/server/journal/journal.h\nindex 43edb1992a4e..0ffec04e33ae 100644\n--- a/src/server/journal/journal.h\n+++ b/src/server/journal/journal.h\n@@ -39,6 +39,7 @@ class Journal {\n \n  private:\n   mutable util::fb2::Mutex state_mu_;\n+  time_t last_lsn_joural_time_ = 0;\n };\n \n }  // namespace journal\ndiff --git a/src/server/journal/journal_slice.cc b/src/server/journal/journal_slice.cc\nindex f7c068f4613b..6c1e6bd2d730 100644\n--- a/src/server/journal/journal_slice.cc\n+++ b/src/server/journal/journal_slice.cc\n@@ -142,7 +142,7 @@ std::string_view JournalSlice::GetEntry(LSN lsn) const {\n   return (*ring_buffer_)[lsn - start].data;\n }\n \n-void JournalSlice::AddLogRecord(const Entry& entry, bool await) {\n+void JournalSlice::AddLogRecord(Entry&& entry, bool await) {\n   optional<FiberAtomicGuard> guard;\n   if (!await) {\n     guard.emplace();  // Guard is non-movable/copyable, so we must use emplace()\n@@ -166,6 +166,7 @@ void JournalSlice::AddLogRecord(const Entry& entry, bool await) {\n     item->opcode = entry.opcode;\n     item->lsn = lsn_++;\n     item->slot = entry.slot;\n+    entry.lsn = lsn_;\n \n     io::BufSink buf_sink{&ring_serialize_buf_};\n     JournalWriter writer{&buf_sink};\ndiff --git a/src/server/journal/journal_slice.h b/src/server/journal/journal_slice.h\nindex 2752eb463c56..e5414bc6ede0 100644\n--- a/src/server/journal/journal_slice.h\n+++ b/src/server/journal/journal_slice.h\n@@ -37,7 +37,7 @@ class JournalSlice {\n     return slice_index_ != UINT32_MAX;\n   }\n \n-  void AddLogRecord(const Entry& entry, bool await);\n+  void AddLogRecord(Entry&& entry, bool await);\n \n   // Register a callback that will be called every time a new entry is\n   // added to the journal.\ndiff --git a/src/server/journal/serializer.cc b/src/server/journal/serializer.cc\nindex 9130de7ba50b..e21162a31910 100644\n--- a/src/server/journal/serializer.cc\n+++ b/src/server/journal/serializer.cc\n@@ -75,6 +75,8 @@ void JournalWriter::Write(const journal::Entry& entry) {\n   switch (entry.opcode) {\n     case journal::Op::SELECT:\n       return Write(entry.dbid);\n+    case journal::Op::LSN:\n+      return Write(entry.lsn);\n     case journal::Op::PING:\n       return;\n     case journal::Op::COMMAND:\n@@ -199,6 +201,11 @@ io::Result<journal::ParsedEntry> JournalReader::ReadEntry() {\n     return entry;\n   }\n \n+  if (opcode == journal::Op::LSN) {\n+    SET_OR_UNEXPECT(ReadUInt<uint64_t>(), entry.lsn);\n+    return entry;\n+  }\n+\n   SET_OR_UNEXPECT(ReadUInt<uint64_t>(), entry.txid);\n   SET_OR_UNEXPECT(ReadUInt<uint32_t>(), entry.shard_cnt);\n \ndiff --git a/src/server/journal/serializer.h b/src/server/journal/serializer.h\nindex 09ce227c0ad3..4d832a2349d9 100644\n--- a/src/server/journal/serializer.h\n+++ b/src/server/journal/serializer.h\n@@ -22,9 +22,9 @@ class JournalWriter {\n \n   // Write single entry to sink.\n   void Write(const journal::Entry& entry);\n+  void Write(uint64_t v);  // Write packed unsigned integer.\n \n  private:\n-  void Write(uint64_t v);           // Write packed unsigned integer.\n   void Write(std::string_view sv);  // Write string.\n \n   template <typename C>  // CmdArgList or ArgSlice.\ndiff --git a/src/server/journal/streamer.cc b/src/server/journal/streamer.cc\nindex d35706246461..8cce4a1e7514 100644\n--- a/src/server/journal/streamer.cc\n+++ b/src/server/journal/streamer.cc\n@@ -11,22 +11,26 @@\n namespace dfly {\n using namespace util;\n \n-void JournalStreamer::Start(io::Sink* dest) {\n+void JournalStreamer::Start(io::Sink* dest, bool send_lsn) {\n   using namespace journal;\n   write_fb_ = fb2::Fiber(\"journal_stream\", &JournalStreamer::WriterFb, this, dest);\n-  journal_cb_id_ = journal_->RegisterOnChange([this](const JournalItem& item, bool allow_await) {\n-    if (!ShouldWrite(item)) {\n-      return;\n-    }\n+  journal_cb_id_ =\n+      journal_->RegisterOnChange([this, send_lsn](const JournalItem& item, bool allow_await) {\n+        if (!ShouldWrite(item)) {\n+          return;\n+        }\n+        if (item.opcode == Op::LSN && !send_lsn) {\n+          return;\n+        }\n \n-    if (item.opcode == Op::NOOP) {\n-      // No record to write, just await if data was written so consumer will read the data.\n-      return AwaitIfWritten();\n-    }\n+        if (item.opcode == Op::NOOP) {\n+          // No record to write, just await if data was written so consumer will read the data.\n+          return AwaitIfWritten();\n+        }\n \n-    Write(io::Buffer(item.data));\n-    NotifyWritten(allow_await);\n-  });\n+        Write(io::Buffer(item.data));\n+        NotifyWritten(allow_await);\n+      });\n }\n \n void JournalStreamer::Cancel() {\n@@ -55,12 +59,12 @@ RestoreStreamer::RestoreStreamer(DbSlice* slice, SlotSet slots, journal::Journal\n   DCHECK(slice != nullptr);\n }\n \n-void RestoreStreamer::Start(io::Sink* dest) {\n+void RestoreStreamer::Start(io::Sink* dest, bool send_lsn) {\n   VLOG(2) << \"RestoreStreamer start\";\n   auto db_cb = absl::bind_front(&RestoreStreamer::OnDbChange, this);\n   snapshot_version_ = db_slice_->RegisterOnChange(std::move(db_cb));\n \n-  JournalStreamer::Start(dest);\n+  JournalStreamer::Start(dest, send_lsn);\n \n   PrimeTable::Cursor cursor;\n   uint64_t last_yield = 0;\ndiff --git a/src/server/journal/streamer.h b/src/server/journal/streamer.h\nindex 611f62501918..9a4c29f6d464 100644\n--- a/src/server/journal/streamer.h\n+++ b/src/server/journal/streamer.h\n@@ -25,7 +25,7 @@ class JournalStreamer : protected BufferedStreamerBase {\n   JournalStreamer(JournalStreamer&& other) = delete;\n \n   // Register journal listener and start writer in fiber.\n-  virtual void Start(io::Sink* dest);\n+  virtual void Start(io::Sink* dest, bool send_lsn);\n \n   // Must be called on context cancellation for unblocking\n   // and manual cleanup.\n@@ -40,7 +40,6 @@ class JournalStreamer : protected BufferedStreamerBase {\n     return true;\n   }\n \n- private:\n   Context* cntx_;\n \n   uint32_t journal_cb_id_{0};\n@@ -56,7 +55,7 @@ class RestoreStreamer : public JournalStreamer {\n   RestoreStreamer(DbSlice* slice, SlotSet slots, journal::Journal* journal, Context* cntx);\n   ~RestoreStreamer() override;\n \n-  void Start(io::Sink* dest) override;\n+  void Start(io::Sink* dest, bool send_lsn = false) override;\n   // Cancel() must be called if Start() is called\n   void Cancel() override;\n \ndiff --git a/src/server/journal/tx_executor.cc b/src/server/journal/tx_executor.cc\nindex fd0a63903032..24ff4d27ef16 100644\n--- a/src/server/journal/tx_executor.cc\n+++ b/src/server/journal/tx_executor.cc\n@@ -54,8 +54,10 @@ void TransactionData::AddEntry(journal::ParsedEntry&& entry) {\n   opcode = entry.opcode;\n \n   switch (entry.opcode) {\n-    case journal::Op::PING:\n+    case journal::Op::LSN:\n+      lsn = entry.lsn;\n       return;\n+    case journal::Op::PING:\n     case journal::Op::FIN:\n       return;\n     case journal::Op::EXPIRED:\n@@ -107,13 +109,25 @@ std::optional<TransactionData> TransactionReader::NextTxData(JournalReader* read\n       cntx->ReportError(res.error());\n       return std::nullopt;\n     }\n+    if (lsn_.has_value()) {\n+      ++*lsn_;\n+    }\n \n     // Check if journal command can be executed right away.\n     // Expiration checks lock on master, so it never conflicts with running multi transactions.\n     if (res->opcode == journal::Op::EXPIRED || res->opcode == journal::Op::COMMAND ||\n         res->opcode == journal::Op::PING || res->opcode == journal::Op::FIN ||\n-        (res->opcode == journal::Op::MULTI_COMMAND && !accumulate_multi_))\n-      return TransactionData::FromSingle(std::move(res.value()));\n+        res->opcode == journal::Op::LSN ||\n+        (res->opcode == journal::Op::MULTI_COMMAND && !accumulate_multi_)) {\n+      TransactionData tx_data = TransactionData::FromSingle(std::move(res.value()));\n+      if (lsn_.has_value() && tx_data.opcode == journal::Op::LSN) {\n+        DCHECK_NE(tx_data.lsn, 0u);\n+        LOG_IF_EVERY_N(WARNING, tx_data.lsn != *lsn_, 1000)\n+            << \"master lsn:\" << tx_data.lsn << \" replica lsn\" << *lsn_;\n+        DCHECK_EQ(tx_data.lsn, *lsn_);\n+      }\n+      return tx_data;\n+    }\n \n     // Otherwise, continue building multi command.\n     DCHECK(res->opcode == journal::Op::MULTI_COMMAND || res->opcode == journal::Op::EXEC);\ndiff --git a/src/server/journal/tx_executor.h b/src/server/journal/tx_executor.h\nindex 8599f552a2cc..4c4d99985f52 100644\n--- a/src/server/journal/tx_executor.h\n+++ b/src/server/journal/tx_executor.h\n@@ -51,13 +51,15 @@ struct TransactionData {\n   absl::InlinedVector<journal::ParsedEntry::CmdData, 1> commands{0};\n   uint32_t journal_rec_count{0};  // Count number of source entries to check offset.\n   journal::Op opcode = journal::Op::NOOP;\n+  uint64_t lsn = 0;\n };\n \n // Utility for reading TransactionData from a journal reader.\n // The journal stream can contain interleaved data for multiple multi transactions,\n // expiries and out of order executed transactions that need to be grouped on the replica side.\n struct TransactionReader {\n-  TransactionReader(bool accumulate_multi) : accumulate_multi_(accumulate_multi) {\n+  TransactionReader(bool accumulate_multi, std::optional<uint64_t> lsn = std::nullopt)\n+      : accumulate_multi_(accumulate_multi), lsn_(lsn) {\n   }\n   std::optional<TransactionData> NextTxData(JournalReader* reader, Context* cntx);\n \n@@ -65,6 +67,7 @@ struct TransactionReader {\n   // Stores ongoing multi transaction data.\n   absl::flat_hash_map<TxId, TransactionData> current_;\n   bool accumulate_multi_ = false;\n+  std::optional<uint64_t> lsn_ = 0;\n };\n \n }  // namespace dfly\ndiff --git a/src/server/journal/types.h b/src/server/journal/types.h\nindex 82677a62ccc5..ddd301f4f77a 100644\n--- a/src/server/journal/types.h\n+++ b/src/server/journal/types.h\n@@ -22,7 +22,8 @@ enum class Op : uint8_t {\n   MULTI_COMMAND = 11,\n   EXEC = 12,\n   PING = 13,\n-  FIN = 14\n+  FIN = 14,\n+  LSN = 15\n };\n \n struct EntryBase {\n@@ -31,6 +32,7 @@ struct EntryBase {\n   DbIndex dbid;\n   uint32_t shard_cnt;\n   std::optional<SlotId> slot;\n+  LSN lsn{0};\n };\n \n // This struct represents a single journal entry.\n@@ -49,12 +51,12 @@ struct Entry : public EntryBase {\n   }\n \n   Entry(journal::Op opcode, DbIndex dbid, std::optional<SlotId> slot_id)\n-      : EntryBase{0, opcode, dbid, 0, slot_id}, payload{} {\n+      : EntryBase{0, opcode, dbid, 0, slot_id, 0} {\n   }\n \n   Entry(TxId txid, journal::Op opcode, DbIndex dbid, uint32_t shard_cnt,\n         std::optional<SlotId> slot_id)\n-      : EntryBase{txid, opcode, dbid, shard_cnt, slot_id}, payload{} {\n+      : EntryBase{txid, opcode, dbid, shard_cnt, slot_id, 0} {\n   }\n \n   bool HasPayload() const {\ndiff --git a/src/server/replica.cc b/src/server/replica.cc\nindex 969ab46b1e4e..efa22b16c939 100644\n--- a/src/server/replica.cc\n+++ b/src/server/replica.cc\n@@ -812,7 +812,7 @@ void DflyShardReplica::StableSyncDflyReadFb(Context* cntx) {\n   io::PrefixSource ps{prefix, Sock()};\n \n   JournalReader reader{&ps, 0};\n-  TransactionReader tx_reader{use_multi_shard_exe_sync_};\n+  TransactionReader tx_reader{use_multi_shard_exe_sync_, journal_rec_executed_};\n \n   if (master_context_.version > DflyVersion::VER0) {\n     acks_fb_ = fb2::Fiber(\"shard_acks\", &DflyShardReplica::StableSyncDflyAcksFb, this, cntx);\n@@ -830,8 +830,9 @@ void DflyShardReplica::StableSyncDflyReadFb(Context* cntx) {\n       break;\n \n     last_io_time_ = Proactor()->GetMonotonicTimeNs();\n-\n-    if (tx_data->opcode == journal::Op::PING) {\n+    if (tx_data->opcode == journal::Op::LSN) {\n+      journal_rec_executed_.fetch_add(1, std::memory_order_relaxed);\n+    } else if (tx_data->opcode == journal::Op::PING) {\n       force_ping_ = true;\n       journal_rec_executed_.fetch_add(1, std::memory_order_relaxed);\n     } else if (tx_data->opcode == journal::Op::EXEC) {\ndiff --git a/src/server/snapshot.cc b/src/server/snapshot.cc\nindex 81460971f919..b120e5516a77 100644\n--- a/src/server/snapshot.cc\n+++ b/src/server/snapshot.cc\n@@ -331,7 +331,8 @@ void SliceSnapshot::OnDbChange(DbIndex db_index, const DbSlice::ChangeReq& req)\n void SliceSnapshot::OnJournalEntry(const journal::JournalItem& item, bool await) {\n   // We ignore EXEC and NOOP entries because we they have no meaning during\n   // the LOAD phase on replica.\n-  if (item.opcode == journal::Op::NOOP || item.opcode == journal::Op::EXEC)\n+  if (item.opcode == journal::Op::NOOP || item.opcode == journal::Op::EXEC ||\n+      item.opcode == journal::Op::LSN)\n     return;\n \n   serializer_->WriteJournalEntry(item.data);\ndiff --git a/src/server/transaction.cc b/src/server/transaction.cc\nindex 5458974a363d..36578ff7dbcb 100644\n--- a/src/server/transaction.cc\n+++ b/src/server/transaction.cc\n@@ -696,7 +696,7 @@ void Transaction::RunCallback(EngineShard* shard) {\n     coordinator_state_ &= ~COORD_CONCLUDING;  // safe because single shard\n   }\n \n-  // Log to jounrnal only once the command finished running\n+  // Log to journal only once the command finished running\n   if ((coordinator_state_ & COORD_CONCLUDING) || (multi_ && multi_->concluding))\n     LogAutoJournalOnShard(shard, result);\n }\ndiff --git a/src/server/version.h b/src/server/version.h\nindex fbf4e9af5625..f5f8ea6ff83d 100644\n--- a/src/server/version.h\n+++ b/src/server/version.h\n@@ -33,8 +33,11 @@ enum class DflyVersion {\n   // ACL with user replication\n   VER3,\n \n+  // - Periodic lag checks from master to replica\n+  VER4,\n+\n   // Always points to the latest version\n-  CURRENT_VER = VER3,\n+  CURRENT_VER = VER4,\n };\n \n }  // namespace dfly\n",
  "test_patch": "diff --git a/tests/dragonfly/replication_test.py b/tests/dragonfly/replication_test.py\nindex 7b5f8e91a998..4f8829272681 100644\n--- a/tests/dragonfly/replication_test.py\n+++ b/tests/dragonfly/replication_test.py\n@@ -136,7 +136,6 @@ async def check_all_replicas_finished(c_replicas, c_master, timeout=20):\n         if not waiting_for:\n             return\n         await asyncio.sleep(0.2)\n-\n         m_offset = await c_master.execute_command(\"DFLY REPLICAOFFSET\")\n         finished_list = await asyncio.gather(\n             *(check_replica_finished_exec(c, m_offset) for c in waiting_for)\n@@ -1655,7 +1654,6 @@ async def test_network_disconnect(df_local_factory, df_seeder_factory):\n \n     master.stop()\n     replica.stop()\n-    assert replica.is_in_logs(\"partial sync finished in\")\n \n \n async def test_network_disconnect_active_stream(df_local_factory, df_seeder_factory):\n@@ -1698,7 +1696,6 @@ async def test_network_disconnect_active_stream(df_local_factory, df_seeder_fact\n \n     master.stop()\n     replica.stop()\n-    assert replica.is_in_logs(\"partial sync finished in\")\n \n \n async def test_network_disconnect_small_buffer(df_local_factory, df_seeder_factory):\n@@ -2147,6 +2144,7 @@ async def test_replica_reconnect(df_local_factory, break_conn):\n         assert await c_master.execute_command(\"get k\") == None\n         assert await c_replica.execute_command(\"get k\") == None\n         assert await c_master.execute_command(\"set k 6789\")\n+        await check_all_replicas_finished([c_replica], c_master)\n         assert await c_replica.execute_command(\"get k\") == \"6789\"\n         assert not await is_replicaiton_conn_down(c_replica)\n \n",
  "problem_statement": "Add master Lag check in replica side to check if replica is out of sync\nCreate new DflyVersion - VER4\r\nSend periodic pings from master to replica \r\nif replica version is >= VER4 Add master journal lsn to ping opcode sent from master to replica\r\nOn replica side check journal lsn is equal to journal_rec_executed , if not print warning and DCHECK\r\n\r\n\n",
  "hints_text": "",
  "created_at": "2024-03-26T21:26:38Z",
  "modified_files": [
    "src/server/dflycmd.cc",
    "src/server/journal/journal.cc",
    "src/server/journal/journal.h",
    "src/server/journal/journal_slice.cc",
    "src/server/journal/journal_slice.h",
    "src/server/journal/serializer.cc",
    "src/server/journal/serializer.h",
    "src/server/journal/streamer.cc",
    "src/server/journal/streamer.h",
    "src/server/journal/tx_executor.cc",
    "src/server/journal/tx_executor.h",
    "src/server/journal/types.h",
    "src/server/replica.cc",
    "src/server/snapshot.cc",
    "src/server/transaction.cc",
    "src/server/version.h"
  ],
  "modified_test_files": [
    "tests/dragonfly/replication_test.py"
  ]
}