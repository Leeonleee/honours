diff --git a/tests/dragonfly/replication_test.py b/tests/dragonfly/replication_test.py
index 27fa6725854f..27cccccf500f 100644
--- a/tests/dragonfly/replication_test.py
+++ b/tests/dragonfly/replication_test.py
@@ -3387,3 +3387,56 @@ async def get_keys():
         moved_saved = extract_int_after_prefix("moved_saved ", line)
         logging.debug(f"Moved saves {moved_saved}")
         assert moved_saved > 0
+
+
+@dfly_args({"proactor_threads": 1})
+async def test_big_strings(df_factory):
+    master = df_factory.create(
+        proactor_threads=1, serialization_max_chunk_size=1, vmodule="snapshot=1"
+    )
+    replica = df_factory.create(proactor_threads=1)
+
+    df_factory.start_all([master, replica])
+    c_master = master.client()
+    c_replica = replica.client()
+
+    # 500kb
+    value_size = 500_000
+
+    async def get_memory(client, field):
+        info = await client.info("memory")
+        return info[field]
+
+    capacity = await get_memory(c_master, "prime_capacity")
+
+    seeder = DebugPopulateSeeder(
+        key_target=int(capacity * 0.8),
+        data_size=value_size,
+        collection_size=1,
+        variance=1,
+        samples=1,
+        types=["STRING"],
+    )
+    await seeder.run(c_master)
+
+    # sanity
+    capacity = await get_memory(c_master, "prime_capacity")
+    assert capacity < 8000
+
+    await c_replica.execute_command(f"REPLICAOF localhost {master.port}")
+    await wait_for_replicas_state(c_replica)
+
+    # Check if replica data is consistent
+    replica_data = await DebugPopulateSeeder.capture(c_replica)
+    master_data = await DebugPopulateSeeder.capture(c_master)
+    assert master_data == replica_data
+
+    replica.stop()
+    master.stop()
+
+    lines = master.find_in_logs("Serialization peak bytes: ")
+    assert len(lines) == 1
+    # We test the serializtion path of command execution
+    line = lines[0]
+    peak_bytes = extract_int_after_prefix("Serialization peak bytes: ", line)
+    assert peak_bytes < value_size
