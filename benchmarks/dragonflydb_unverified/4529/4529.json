{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 4529,
  "instance_id": "dragonflydb__dragonfly-4529",
  "issue_numbers": [
    "4517"
  ],
  "base_commit": "21d63e8cf7b8cd45d9e07067f43f5375b38a250e",
  "patch": "diff --git a/src/facade/conn_context.h b/src/facade/conn_context.h\nindex d4e777010ea1..38133e391d47 100644\n--- a/src/facade/conn_context.h\n+++ b/src/facade/conn_context.h\n@@ -7,6 +7,7 @@\n #include <absl/container/flat_hash_set.h>\n \n #include <memory>\n+#include <string_view>\n \n #include \"core/heap_size.h\"\n #include \"facade/acl_commands_def.h\"\n@@ -34,6 +35,10 @@ class ConnectionContext {\n \n   virtual size_t UsedMemory() const;\n \n+  // Noop.\n+  virtual void Unsubscribe(std::string_view channel) {\n+  }\n+\n   // connection state / properties.\n   bool conn_closing : 1;\n   bool req_auth : 1;\ndiff --git a/src/facade/dragonfly_connection.cc b/src/facade/dragonfly_connection.cc\nindex 4e416c2888ff..6fda573fb425 100644\n--- a/src/facade/dragonfly_connection.cc\n+++ b/src/facade/dragonfly_connection.cc\n@@ -494,6 +494,17 @@ void Connection::AsyncOperations::operator()(const AclUpdateMessage& msg) {\n \n void Connection::AsyncOperations::operator()(const PubMessage& pub_msg) {\n   RedisReplyBuilder* rbuilder = (RedisReplyBuilder*)builder;\n+\n+  if (pub_msg.should_unsubscribe) {\n+    rbuilder->StartCollection(3, RedisReplyBuilder::CollectionType::PUSH);\n+    rbuilder->SendBulkString(\"unsubscribe\");\n+    rbuilder->SendBulkString(pub_msg.channel);\n+    rbuilder->SendLong(0);\n+    auto* cntx = self->cntx();\n+    cntx->Unsubscribe(pub_msg.channel);\n+    return;\n+  }\n+\n   unsigned i = 0;\n   array<string_view, 4> arr;\n   if (pub_msg.pattern.empty()) {\n@@ -502,8 +513,10 @@ void Connection::AsyncOperations::operator()(const PubMessage& pub_msg) {\n     arr[i++] = \"pmessage\";\n     arr[i++] = pub_msg.pattern;\n   }\n+\n   arr[i++] = pub_msg.channel;\n   arr[i++] = pub_msg.message;\n+\n   rbuilder->SendBulkStrArr(absl::Span<string_view>{arr.data(), i},\n                            RedisReplyBuilder::CollectionType::PUSH);\n }\ndiff --git a/src/facade/dragonfly_connection.h b/src/facade/dragonfly_connection.h\nindex 75fecd67fc92..a264722e1098 100644\n--- a/src/facade/dragonfly_connection.h\n+++ b/src/facade/dragonfly_connection.h\n@@ -75,6 +75,7 @@ class Connection : public util::Connection {\n     std::string pattern{};              // non-empty for pattern subscriber\n     std::shared_ptr<char[]> buf;        // stores channel name and message\n     std::string_view channel, message;  // channel and message parts from buf\n+    bool should_unsubscribe = false;    // unsubscribe from channel after sending the message\n   };\n \n   // Pipeline message, accumulated Redis command to be executed.\ndiff --git a/src/server/channel_store.cc b/src/server/channel_store.cc\nindex 2a1770898c6e..6c4373b3fa32 100644\n--- a/src/server/channel_store.cc\n+++ b/src/server/channel_store.cc\n@@ -8,6 +8,8 @@\n \n #include \"base/logging.h\"\n #include \"core/glob_matcher.h\"\n+#include \"server/cluster/slot_set.h\"\n+#include \"server/cluster_support.h\"\n #include \"server/engine_shard_set.h\"\n #include \"server/server_state.h\"\n \n@@ -17,7 +19,7 @@ using namespace std;\n namespace {\n \n // Build functor for sending messages to connection\n-auto BuildSender(string_view channel, facade::ArgRange messages) {\n+auto BuildSender(string_view channel, facade::ArgRange messages, bool unsubscribe = false) {\n   absl::FixedArray<string_view, 1> views(messages.Size());\n   size_t messages_size = accumulate(messages.begin(), messages.end(), 0,\n                                     [](int sum, string_view str) { return sum + str.size(); });\n@@ -34,11 +36,12 @@ auto BuildSender(string_view channel, facade::ArgRange messages) {\n     }\n   }\n \n-  return [channel, buf = std::move(buf), views = std::move(views)](facade::Connection* conn,\n-                                                                   string pattern) {\n+  return [channel, buf = std::move(buf), views = std::move(views), unsubscribe](\n+             facade::Connection* conn, string pattern) {\n     string_view channel_view{buf.get(), channel.size()};\n-    for (std::string_view message_view : views)\n-      conn->SendPubMessageAsync({std::move(pattern), buf, channel_view, message_view});\n+    for (std::string_view message_view : views) {\n+      conn->SendPubMessageAsync({std::move(pattern), buf, channel_view, message_view, unsubscribe});\n+    }\n   };\n }\n \n@@ -144,7 +147,6 @@ unsigned ChannelStore::SendMessages(std::string_view channel, facade::ArgRange m\n     auto it = lower_bound(subscribers_ptr->begin(), subscribers_ptr->end(), idx,\n                           ChannelStore::Subscriber::ByThreadId);\n     while (it != subscribers_ptr->end() && it->Thread() == idx) {\n-      // if ptr->cntx() is null, a connection might have closed or be in the process of closing\n       if (auto* ptr = it->Get(); ptr && ptr->cntx() != nullptr)\n         send(ptr, it->pattern);\n       it++;\n@@ -196,6 +198,45 @@ size_t ChannelStore::PatternCount() const {\n   return patterns_->size();\n }\n \n+void ChannelStore::UnsubscribeAfterClusterSlotMigration(const cluster::SlotSet& deleted_slots) {\n+  if (deleted_slots.Empty()) {\n+    return;\n+  }\n+\n+  const uint32_t tid = util::ProactorBase::me()->GetPoolIndex();\n+  ChannelStoreUpdater csu(false, false, nullptr, tid);\n+\n+  for (const auto& [channel, _] : *channels_) {\n+    auto channel_slot = KeySlot(channel);\n+    if (deleted_slots.Contains(channel_slot)) {\n+      csu.Record(channel);\n+    }\n+  }\n+\n+  csu.ApplyAndUnsubscribe();\n+}\n+\n+void ChannelStore::UnsubscribeConnectionsFromDeletedSlots(const ChannelsSubMap& sub_map,\n+                                                          uint32_t idx) {\n+  const bool should_unsubscribe = true;\n+  for (const auto& [channel, subscribers] : sub_map) {\n+    // ignored by pub sub handler because should_unsubscribe is true\n+    std::string msg = \"__ignore__\";\n+    auto send = BuildSender(channel, {facade::ArgSlice{msg}}, should_unsubscribe);\n+\n+    auto it = lower_bound(subscribers.begin(), subscribers.end(), idx,\n+                          ChannelStore::Subscriber::ByThreadId);\n+    while (it != subscribers.end() && it->Thread() == idx) {\n+      // if ptr->cntx() is null, a connection might have closed or be in the process of closing\n+      if (auto* ptr = it->Get(); ptr && ptr->cntx() != nullptr) {\n+        DCHECK(it->pattern.empty());\n+        send(ptr, it->pattern);\n+      }\n+      ++it;\n+    }\n+  }\n+}\n+\n ChannelStoreUpdater::ChannelStoreUpdater(bool pattern, bool to_add, ConnectionContext* cntx,\n                                          uint32_t thread_id)\n     : pattern_{pattern}, to_add_{to_add}, cntx_{cntx}, thread_id_{thread_id} {\n@@ -295,4 +336,61 @@ void ChannelStoreUpdater::Apply() {\n     delete ptr;\n }\n \n+void ChannelStoreUpdater::ApplyAndUnsubscribe() {\n+  DCHECK(to_add_ == false);\n+  DCHECK(pattern_ == false);\n+  DCHECK(cntx_ == nullptr);\n+\n+  if (ops_.empty()) {\n+    return;\n+  }\n+\n+  // Wait for other updates to finish, lock the control block and update store pointer.\n+  auto& cb = ChannelStore::control_block;\n+  cb.update_mu.lock();\n+  auto* store = cb.most_recent.load(memory_order_relaxed);\n+\n+  // Deep copy, we will remove channels\n+  auto* target = new ChannelStore::ChannelMap{*store->channels_};\n+\n+  for (auto key : ops_) {\n+    auto it = target->find(key);\n+    freelist_.push_back(it->second.Get());\n+    target->erase(it);\n+    continue;\n+  }\n+\n+  // Prepare replacement.\n+  auto* replacement = new ChannelStore{target, store->patterns_};\n+\n+  // Update control block and unlock it.\n+  cb.most_recent.store(replacement, memory_order_relaxed);\n+  cb.update_mu.unlock();\n+\n+  // FetchSubscribers is not thead safe so we need to fetch here before we do the hop below.\n+  // Bonus points because now we compute subscribers only once.\n+  absl::flat_hash_map<std::string_view, std::vector<ChannelStore::Subscriber>> subs;\n+  for (auto channel : ops_) {\n+    auto channel_subs = ServerState::tlocal()->channel_store()->FetchSubscribers(channel);\n+    DCHECK(!subs.contains(channel));\n+    subs[channel] = std::move(channel_subs);\n+  }\n+  // Update thread local references. Readers fetch subscribers via FetchSubscribers,\n+  // which runs without preemption, and store references to them in self container Subscriber\n+  // structs. This means that any point on the other thread is safe to update the channel store.\n+  // Regardless of whether we need to replace, we dispatch to make sure all\n+  // queued SubscribeMaps in the freelist are no longer in use.\n+  shard_set->pool()->AwaitFiberOnAll([&subs](unsigned idx, util::ProactorBase*) {\n+    ServerState::tlocal()->UnsubscribeSlotsAndUpdateChannelStore(\n+        subs, ChannelStore::control_block.most_recent.load(memory_order_relaxed));\n+  });\n+\n+  // Delete previous map and channel store.\n+  delete store->channels_;\n+  delete store;\n+\n+  for (auto ptr : freelist_)\n+    delete ptr;\n+}\n+\n }  // namespace dfly\ndiff --git a/src/server/channel_store.h b/src/server/channel_store.h\nindex 2a67606c5244..4ae9d7f4e532 100644\n--- a/src/server/channel_store.h\n+++ b/src/server/channel_store.h\n@@ -14,6 +14,10 @@ namespace dfly {\n \n class ChannelStoreUpdater;\n \n+namespace cluster {\n+class SlotSet;\n+}\n+\n // ChannelStore manages PUB/SUB subscriptions.\n //\n // Updates are carried out via RCU (read-copy-update). Each thread stores a pointer to ChannelStore\n@@ -61,8 +65,15 @@ class ChannelStore {\n   std::vector<Subscriber> FetchSubscribers(std::string_view channel) const;\n \n   std::vector<std::string> ListChannels(const std::string_view pattern) const;\n+\n   size_t PatternCount() const;\n \n+  void UnsubscribeAfterClusterSlotMigration(const cluster::SlotSet& deleted_slots);\n+\n+  using ChannelsSubMap =\n+      absl::flat_hash_map<std::string_view, std::vector<ChannelStore::Subscriber>>;\n+  void UnsubscribeConnectionsFromDeletedSlots(const ChannelsSubMap& sub_map, uint32_t idx);\n+\n   // Destroy current instance and delete it.\n   static void Destroy();\n \n@@ -128,6 +139,12 @@ class ChannelStoreUpdater {\n   void Record(std::string_view key);\n   void Apply();\n \n+  // Used for cluster when slots migrate. We need to:\n+  // 1. Remove the channel from the copy.\n+  // 2. Unsuscribe all the connections from each channel.\n+  // 3. Update the control block pointer.\n+  void ApplyAndUnsubscribe();\n+\n  private:\n   using ChannelMap = ChannelStore::ChannelMap;\n \ndiff --git a/src/server/cluster/cluster_family.cc b/src/server/cluster/cluster_family.cc\nindex 241b63cdebff..890200a2ae99 100644\n--- a/src/server/cluster/cluster_family.cc\n+++ b/src/server/cluster/cluster_family.cc\n@@ -15,6 +15,7 @@\n #include \"facade/dragonfly_connection.h\"\n #include \"facade/error.h\"\n #include \"server/acl/acl_commands_def.h\"\n+#include \"server/channel_store.h\"\n #include \"server/command_registry.h\"\n #include \"server/conn_context.h\"\n #include \"server/dflycmd.h\"\n@@ -506,6 +507,10 @@ void DeleteSlots(const SlotRanges& slots_ranges) {\n     namespaces->GetDefaultNamespace().GetDbSlice(shard->shard_id()).FlushSlots(slots_ranges);\n   };\n   shard_set->pool()->AwaitFiberOnAll(std::move(cb));\n+\n+  auto* channel_store = ServerState::tlocal()->channel_store();\n+  auto deleted = SlotSet(slots_ranges);\n+  channel_store->UnsubscribeAfterClusterSlotMigration(deleted);\n }\n \n void WriteFlushSlotsToJournal(const SlotRanges& slot_ranges) {\ndiff --git a/src/server/conn_context.cc b/src/server/conn_context.cc\nindex 034d0292a7ab..9ffa535733ca 100644\n--- a/src/server/conn_context.cc\n+++ b/src/server/conn_context.cc\n@@ -223,6 +223,18 @@ size_t ConnectionContext::UsedMemory() const {\n   return facade::ConnectionContext::UsedMemory() + dfly::HeapSize(conn_state);\n }\n \n+void ConnectionContext::Unsubscribe(std::string_view channel) {\n+  auto* sinfo = conn_state.subscribe_info.get();\n+  DCHECK(sinfo);\n+  auto erased = sinfo->channels.erase(channel);\n+  DCHECK(erased);\n+  if (sinfo->IsEmpty()) {\n+    conn_state.subscribe_info.reset();\n+    DCHECK_GE(subscriptions, 1u);\n+    --subscriptions;\n+  }\n+}\n+\n vector<unsigned> ConnectionContext::ChangeSubscriptions(CmdArgList channels, bool pattern,\n                                                         bool to_add, bool to_reply) {\n   vector<unsigned> result(to_reply ? channels.size() : 0, 0);\ndiff --git a/src/server/conn_context.h b/src/server/conn_context.h\nindex db5f76f2dde2..c276455ea5b5 100644\n--- a/src/server/conn_context.h\n+++ b/src/server/conn_context.h\n@@ -304,6 +304,8 @@ class ConnectionContext : public facade::ConnectionContext {\n \n   size_t UsedMemory() const override;\n \n+  virtual void Unsubscribe(std::string_view channel) override;\n+\n   // Whether this connection is a connection from a replica to its master.\n   // This flag is true only on replica side, where we need to setup a special ConnectionContext\n   // instance that helps applying commands coming from master.\ndiff --git a/src/server/server_state.cc b/src/server/server_state.cc\nindex 11554d66598a..433bf98a0c65 100644\n--- a/src/server/server_state.cc\n+++ b/src/server/server_state.cc\n@@ -16,6 +16,7 @@ extern \"C\" {\n #include \"base/logging.h\"\n #include \"facade/conn_context.h\"\n #include \"facade/dragonfly_connection.h\"\n+#include \"server/channel_store.h\"\n #include \"server/journal/journal.h\"\n #include \"util/listener_interface.h\"\n \n@@ -261,8 +262,8 @@ void ServerState::ConnectionsWatcherFb(util::ListenerInterface* main) {\n         is_replica = dfly_conn->cntx()->replica_conn;\n       }\n \n-      if ((phase == Phase::READ_SOCKET || dfly_conn->IsSending()) &&\n-          !is_replica && dfly_conn->idle_time() > timeout) {\n+      if ((phase == Phase::READ_SOCKET || dfly_conn->IsSending()) && !is_replica &&\n+          dfly_conn->idle_time() > timeout) {\n         conn_refs.push_back(dfly_conn->Borrow());\n       }\n     };\n@@ -285,4 +286,10 @@ void ServerState::ConnectionsWatcherFb(util::ListenerInterface* main) {\n   }\n }\n \n+void ServerState::UnsubscribeSlotsAndUpdateChannelStore(const ChannelStore::ChannelsSubMap& sub_map,\n+                                                        ChannelStore* replacement) {\n+  channel_store_->UnsubscribeConnectionsFromDeletedSlots(sub_map, thread_index_);\n+  channel_store_ = replacement;\n+}\n+\n }  // end of namespace dfly\ndiff --git a/src/server/server_state.h b/src/server/server_state.h\nindex 6d77e759d08b..ae977f6b2252 100644\n--- a/src/server/server_state.h\n+++ b/src/server/server_state.h\n@@ -12,6 +12,7 @@\n #include \"core/interpreter.h\"\n #include \"server/acl/acl_log.h\"\n #include \"server/acl/user_registry.h\"\n+#include \"server/channel_store.h\"\n #include \"server/common.h\"\n #include \"server/script_mgr.h\"\n #include \"server/slowlog.h\"\n@@ -260,6 +261,9 @@ class ServerState {  // public struct - to allow initialization.\n     channel_store_ = replacement;\n   }\n \n+  void UnsubscribeSlotsAndUpdateChannelStore(const ChannelStore::ChannelsSubMap& sub_map,\n+                                             ChannelStore* replacement);\n+\n   bool ShouldLogSlowCmd(unsigned latency_usec) const;\n \n   Stats stats;\n",
  "test_patch": "diff --git a/tests/dragonfly/cluster_test.py b/tests/dragonfly/cluster_test.py\nindex a6d8f3e92130..4813e0bc47da 100644\n--- a/tests/dragonfly/cluster_test.py\n+++ b/tests/dragonfly/cluster_test.py\n@@ -2980,3 +2980,51 @@ async def test_cluster_sharded_pub_sub(df_factory: DflyInstanceFactory):\n     await c_nodes[0].execute_command(\"SPUBLISH kostas new_message\")\n     message = consumer.get_sharded_message(target_node=node_a)\n     assert message == {\"type\": \"unsubscribe\", \"pattern\": None, \"channel\": b\"kostas\", \"data\": 0}\n+\n+\n+@dfly_args({\"proactor_threads\": 2, \"cluster_mode\": \"yes\"})\n+async def test_cluster_sharded_pub_sub_migration(df_factory: DflyInstanceFactory):\n+    instances = [df_factory.create(port=next(next_port)) for i in range(2)]\n+    df_factory.start_all(instances)\n+\n+    c_nodes = [instance.client() for instance in instances]\n+\n+    nodes = [(await create_node_info(instance)) for instance in instances]\n+    nodes[0].slots = [(0, 16383)]\n+    nodes[1].slots = []\n+\n+    await push_config(json.dumps(generate_config(nodes)), [node.client for node in nodes])\n+\n+    # Setup producer and consumer\n+    node_a = ClusterNode(\"localhost\", instances[0].port)\n+    node_b = ClusterNode(\"localhost\", instances[1].port)\n+\n+    consumer_client = RedisCluster(startup_nodes=[node_a, node_b])\n+    consumer = consumer_client.pubsub()\n+    consumer.ssubscribe(\"kostas\")\n+\n+    # Push new config\n+    nodes[0].migrations.append(\n+        MigrationInfo(\"127.0.0.1\", nodes[1].instance.port, [(0, 16383)], nodes[1].id)\n+    )\n+    await push_config(json.dumps(generate_config(nodes)), [node.client for node in nodes])\n+\n+    await wait_for_status(nodes[0].client, nodes[1].id, \"FINISHED\")\n+\n+    nodes[0].migrations = []\n+    nodes[0].slots = []\n+    nodes[1].slots = [(0, 16383)]\n+    logging.debug(\"remove finished migrations\")\n+    await push_config(json.dumps(generate_config(nodes)), [node.client for node in nodes])\n+\n+    # channel name kostas crc is at slot 2883 which is part of the second now.\n+    with pytest.raises(redis.exceptions.ResponseError) as moved_error:\n+        await c_nodes[0].execute_command(\"SSUBSCRIBE kostas\")\n+\n+    assert str(moved_error.value) == f\"MOVED 2833 127.0.0.1:{instances[1].port}\"\n+\n+    # Consume subscription message result from above\n+    message = consumer.get_sharded_message(target_node=node_a)\n+    assert message == {\"type\": \"subscribe\", \"pattern\": None, \"channel\": b\"kostas\", \"data\": 1}\n+    message = consumer.get_sharded_message(target_node=node_a)\n+    assert message == {\"type\": \"unsubscribe\", \"pattern\": None, \"channel\": b\"kostas\", \"data\": 0}\n",
  "problem_statement": "Evict subscribed sharded pub/sub on cluster migrations\nUpon slot migration, the node that owns the slots for channels in sharded pub/sub commands continues to process normally incoming pub/sub commands. Upon completion, the node evicts the connected clients to that given slot, returns a MOVED error for the client to redirect the connection.\n\nThere is no state associated with pub/sub that needs to be transferred during slot migration. After the migration completes, clients need to redirect their pub/sub commands to the newly migrated node.\n",
  "hints_text": "",
  "created_at": "2025-01-29T20:18:43Z",
  "modified_files": [
    "src/facade/conn_context.h",
    "src/facade/dragonfly_connection.cc",
    "src/facade/dragonfly_connection.h",
    "src/server/channel_store.cc",
    "src/server/channel_store.h",
    "src/server/cluster/cluster_family.cc",
    "src/server/conn_context.cc",
    "src/server/conn_context.h",
    "src/server/server_state.cc",
    "src/server/server_state.h"
  ],
  "modified_test_files": [
    "tests/dragonfly/cluster_test.py"
  ]
}