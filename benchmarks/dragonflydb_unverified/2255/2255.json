{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 2255,
  "instance_id": "dragonflydb__dragonfly-2255",
  "issue_numbers": [
    "2168",
    "1480"
  ],
  "base_commit": "4cce3b4a01c4ab19c2a0dd44d4159198bb9e38f7",
  "patch": "diff --git a/src/facade/conn_context.h b/src/facade/conn_context.h\nindex 05ef8b024e4a..49a0d466389f 100644\n--- a/src/facade/conn_context.h\n+++ b/src/facade/conn_context.h\n@@ -100,6 +100,7 @@ class ConnectionContext {\n   bool sync_dispatch : 1;     // whether this connection is amid a sync dispatch\n   bool journal_emulated : 1;  // whether it is used to dispatch journal commands\n   bool paused : 1;            // whether this connection is paused due to CLIENT PAUSE\n+  bool blocked;  // whether it's blocked on blocking commands like BLPOP, needs to be addressable\n \n   // How many async subscription sources are active: monitor and/or pubsub - at most 2.\n   uint8_t subscriptions;\ndiff --git a/src/facade/dragonfly_connection.cc b/src/facade/dragonfly_connection.cc\nindex c2df33088cb9..9ead4e8cdde1 100644\n--- a/src/facade/dragonfly_connection.cc\n+++ b/src/facade/dragonfly_connection.cc\n@@ -1048,6 +1048,12 @@ std::string Connection::DebugInfo() const {\n   absl::StrAppend(&info, \"dispatch_queue:pipelined=\", pending_pipeline_cmd_cnt_, \", \");\n   absl::StrAppend(&info, \"dispatch_queue:intrusive=\", intrusive_front, \", \");\n \n+  absl::StrAppend(&info, \"state=\");\n+  if (cc_->paused)\n+    absl::StrAppend(&info, \"p\");\n+  if (cc_->blocked)\n+    absl::StrAppend(&info, \"b\");\n+\n   absl::StrAppend(&info, \"}\");\n   return info;\n }\n@@ -1225,13 +1231,16 @@ void Connection::SendAclUpdateAsync(AclUpdateMessage msg) {\n   SendAsync({make_unique<AclUpdateMessage>(std::move(msg))});\n }\n \n-void Connection::SendCheckpoint(fb2::BlockingCounter bc, bool ignore_paused) {\n+void Connection::SendCheckpoint(fb2::BlockingCounter bc, bool ignore_paused, bool ignore_blocked) {\n   if (!IsCurrentlyDispatching())\n     return;\n \n   if (cc_->paused && ignore_paused)\n     return;\n \n+  if (cc_->blocked && ignore_blocked)\n+    return;\n+\n   VLOG(1) << \"Sent checkpoint to \" << DebugInfo();\n \n   bc.Add(1);\ndiff --git a/src/facade/dragonfly_connection.h b/src/facade/dragonfly_connection.h\nindex 4d502e57ed80..75233ddec4c4 100644\n--- a/src/facade/dragonfly_connection.h\n+++ b/src/facade/dragonfly_connection.h\n@@ -195,8 +195,9 @@ class Connection : public util::Connection {\n   void SendAclUpdateAsync(AclUpdateMessage msg);\n \n   // If any dispatch is currently in progress, increment counter and send checkpoint message to\n-  // decrement it once finished. It ignore_paused is true, paused dispatches are ignored.\n-  void SendCheckpoint(util::fb2::BlockingCounter bc, bool ignore_paused = false);\n+  // decrement it once finished.\n+  void SendCheckpoint(util::fb2::BlockingCounter bc, bool ignore_paused = false,\n+                      bool ignore_blocked = false);\n \n   // Must be called before sending pubsub messages to ensure the threads pipeline queue limit is not\n   // reached. Blocks until free space is available. Controlled with `pipeline_queue_limit` flag.\ndiff --git a/src/facade/dragonfly_listener.cc b/src/facade/dragonfly_listener.cc\nindex f51cfc23b4fd..d239ad536b82 100644\n--- a/src/facade/dragonfly_listener.cc\n+++ b/src/facade/dragonfly_listener.cc\n@@ -374,10 +374,12 @@ ProactorBase* Listener::PickConnectionProactor(util::FiberSocketBase* sock) {\n }\n \n DispatchTracker::DispatchTracker(absl::Span<facade::Listener* const> listeners,\n-                                 facade::Connection* issuer, bool ignore_paused)\n+                                 facade::Connection* issuer, bool ignore_paused,\n+                                 bool ignore_blocked)\n     : listeners_{listeners.begin(), listeners.end()},\n       issuer_{issuer},\n-      ignore_paused_{ignore_paused} {\n+      ignore_paused_{ignore_paused},\n+      ignore_blocked_{ignore_blocked} {\n }\n \n void DispatchTracker::TrackOnThread() {\n@@ -396,7 +398,7 @@ void DispatchTracker::TrackAll() {\n \n void DispatchTracker::Handle(unsigned thread_index, util::Connection* conn) {\n   if (auto* fconn = static_cast<facade::Connection*>(conn); fconn != issuer_)\n-    fconn->SendCheckpoint(bc_, ignore_paused_);\n+    fconn->SendCheckpoint(bc_, ignore_paused_, ignore_blocked_);\n }\n \n }  // namespace facade\ndiff --git a/src/facade/dragonfly_listener.h b/src/facade/dragonfly_listener.h\nindex 163fa435f2ed..e6cc751d1abd 100644\n--- a/src/facade/dragonfly_listener.h\n+++ b/src/facade/dragonfly_listener.h\n@@ -89,7 +89,7 @@ class Listener : public util::ListenerInterface {\n class DispatchTracker {\n  public:\n   DispatchTracker(absl::Span<facade::Listener* const>, facade::Connection* issuer = nullptr,\n-                  bool ignore_paused = false);\n+                  bool ignore_paused = false, bool ignore_blocked = false);\n \n   void TrackAll();       // Track busy connection on all threads\n   void TrackOnThread();  // Track busy connections on current thread\n@@ -105,6 +105,7 @@ class DispatchTracker {\n   facade::Connection* issuer_;\n   util::fb2::BlockingCounter bc_{0};\n   bool ignore_paused_;\n+  bool ignore_blocked_;\n };\n \n }  // namespace facade\ndiff --git a/src/facade/facade.cc b/src/facade/facade.cc\nindex b4c98e547213..0999439e8a31 100644\n--- a/src/facade/facade.cc\n+++ b/src/facade/facade.cc\n@@ -134,6 +134,7 @@ ConnectionContext::ConnectionContext(::io::Sink* stream, Connection* owner) : ow\n   sync_dispatch = false;\n   journal_emulated = false;\n   paused = false;\n+  blocked = false;\n \n   subscriptions = 0;\n }\ndiff --git a/src/facade/op_status.h b/src/facade/op_status.h\nindex f96fdba7c964..183b7da5401b 100644\n--- a/src/facade/op_status.h\n+++ b/src/facade/op_status.h\n@@ -13,6 +13,7 @@ enum class OpStatus : uint16_t {\n   OK,\n   KEY_EXISTS,\n   KEY_NOTFOUND,\n+  KEY_MOVED,\n   SKIPPED,\n   INVALID_VALUE,\n   OUT_OF_RANGE,\ndiff --git a/src/server/cluster/cluster_config.cc b/src/server/cluster/cluster_config.cc\nindex fd897bdde325..50dfd0f91bc8 100644\n--- a/src/server/cluster/cluster_config.cc\n+++ b/src/server/cluster/cluster_config.cc\n@@ -311,6 +311,10 @@ bool ClusterConfig::IsMySlot(SlotId id) const {\n   return my_slots_.test(id);\n }\n \n+bool ClusterConfig::IsMySlot(std::string_view key) const {\n+  return IsMySlot(KeySlot(key));\n+}\n+\n ClusterConfig::Node ClusterConfig::GetMasterNodeForSlot(SlotId id) const {\n   CHECK_LT(id, my_slots_.size()) << \"Requesting a non-existing slot id \" << id;\n \ndiff --git a/src/server/cluster/cluster_config.h b/src/server/cluster/cluster_config.h\nindex 542ac18bfa50..87b55286cd1b 100644\n--- a/src/server/cluster/cluster_config.h\n+++ b/src/server/cluster/cluster_config.h\n@@ -65,6 +65,7 @@ class ClusterConfig {\n \n   // If key is in my slots ownership return true\n   bool IsMySlot(SlotId id) const;\n+  bool IsMySlot(std::string_view key) const;\n \n   // Returns the master configured for `id`.\n   Node GetMasterNodeForSlot(SlotId id) const;\ndiff --git a/src/server/cluster/cluster_family.cc b/src/server/cluster/cluster_family.cc\nindex 5ebb119efee8..db6b357f15c2 100644\n--- a/src/server/cluster/cluster_family.cc\n+++ b/src/server/cluster/cluster_family.cc\n@@ -514,11 +514,21 @@ void ClusterFamily::DflyClusterConfig(CmdArgList args, ConnectionContext* cntx)\n     before = tl_cluster_config->GetOwnedSlots();\n   }\n \n-  DispatchTracker tracker{server_family_->GetListeners(), cntx->conn()};\n-  auto cb = [&tracker, &new_config](util::ProactorBase* pb) {\n+  // Ignore blocked commands because we filter them with CancelBlockingOnThread\n+  DispatchTracker tracker{server_family_->GetListeners(), cntx->conn(), false /* ignore paused */,\n+                          true /* ignore blocked */};\n+\n+  auto blocking_filter = [&new_config](ArgSlice keys) {\n+    bool moved = any_of(keys.begin(), keys.end(), [&](auto k) { return !new_config->IsMySlot(k); });\n+    return moved ? OpStatus::KEY_MOVED : OpStatus::OK;\n+  };\n+\n+  auto cb = [this, &tracker, &new_config, blocking_filter](util::ProactorBase* pb) {\n+    server_family_->CancelBlockingOnThread(blocking_filter);\n     tl_cluster_config = new_config;\n     tracker.TrackOnThread();\n   };\n+\n   server_family_->service().proactor_pool().AwaitFiberOnAll(std::move(cb));\n   DCHECK(tl_cluster_config != nullptr);\n \ndiff --git a/src/server/conn_context.cc b/src/server/conn_context.cc\nindex fa97ee50dfe5..ba2ae77ece43 100644\n--- a/src/server/conn_context.cc\n+++ b/src/server/conn_context.cc\n@@ -117,12 +117,6 @@ void ConnectionContext::ChangeMonitor(bool start) {\n   EnableMonitoring(start);\n }\n \n-void ConnectionContext::CancelBlocking() {\n-  if (transaction) {\n-    transaction->CancelBlocking();\n-  }\n-}\n-\n vector<unsigned> ChangeSubscriptions(bool pattern, CmdArgList args, bool to_add, bool to_reply,\n                                      ConnectionContext* conn) {\n   vector<unsigned> result(to_reply ? args.size() : 0, 0);\ndiff --git a/src/server/conn_context.h b/src/server/conn_context.h\nindex a27d842e1669..837684e4e177 100644\n--- a/src/server/conn_context.h\n+++ b/src/server/conn_context.h\n@@ -147,8 +147,6 @@ struct ConnectionState {\n   // For get op - we use it as a mask of MCGetMask values.\n   uint32_t memcache_flag = 0;\n \n-  bool is_blocking = false;  // whether this connection is blocking on a command\n-\n   ExecInfo exec_info;\n   ReplicationInfo replication_info;\n \n@@ -186,7 +184,6 @@ class ConnectionContext : public facade::ConnectionContext {\n   void UnsubscribeAll(bool to_reply);\n   void PUnsubscribeAll(bool to_reply);\n   void ChangeMonitor(bool start);  // either start or stop monitor on a given connection\n-  void CancelBlocking();           // Cancel an ongoing blocking transaction if there is one.\n \n   size_t UsedMemory() const override;\n \ndiff --git a/src/server/container_utils.cc b/src/server/container_utils.cc\nindex 463258009664..aa3901c42e8e 100644\n--- a/src/server/container_utils.cc\n+++ b/src/server/container_utils.cc\n@@ -238,7 +238,8 @@ OpResult<ShardFFResult> FindFirstNonEmptyKey(Transaction* trans, int req_obj_typ\n }\n \n OpResult<string> RunCbOnFirstNonEmptyBlocking(Transaction* trans, int req_obj_type,\n-                                              BlockingResultCb func, unsigned limit_ms) {\n+                                              BlockingResultCb func, unsigned limit_ms,\n+                                              bool* block_flag) {\n   trans->Schedule();\n \n   string result_key;\n@@ -281,9 +282,12 @@ OpResult<string> RunCbOnFirstNonEmptyBlocking(Transaction* trans, int req_obj_ty\n \n   auto wcb = [](Transaction* t, EngineShard* shard) { return t->GetShardArgs(shard->shard_id()); };\n \n-  bool wait_succeeded = trans->WaitOnWatch(limit_tp, std::move(wcb));\n-  if (!wait_succeeded)\n-    return OpStatus::TIMED_OUT;\n+  *block_flag = true;\n+  auto status = trans->WaitOnWatch(limit_tp, std::move(wcb));\n+  *block_flag = false;\n+\n+  if (status != OpStatus::OK)\n+    return status;\n \n   auto cb = [&](Transaction* t, EngineShard* shard) {\n     if (auto wake_key = t->GetWakeKey(shard->shard_id()); wake_key) {\ndiff --git a/src/server/container_utils.h b/src/server/container_utils.h\nindex d359895d6fb9..dfce2b16610e 100644\n--- a/src/server/container_utils.h\n+++ b/src/server/container_utils.h\n@@ -95,8 +95,10 @@ using BlockingResultCb =\n // Block until a any key of the transaction becomes non-empty and executes the callback.\n // If multiple keys are non-empty when this function is called, the callback is executed\n // immediately with the first key listed in the tx arguments.\n+// The block flag is set to true while the transaction is blocking.\n OpResult<std::string> RunCbOnFirstNonEmptyBlocking(Transaction* trans, int req_obj_type,\n-                                                   BlockingResultCb cb, unsigned limit_ms);\n+                                                   BlockingResultCb cb, unsigned limit_ms,\n+                                                   bool* block_flag);\n \n };  // namespace container_utils\n \ndiff --git a/src/server/dflycmd.cc b/src/server/dflycmd.cc\nindex 77eeabb07984..e5af8137fde6 100644\n--- a/src/server/dflycmd.cc\n+++ b/src/server/dflycmd.cc\n@@ -421,12 +421,13 @@ void DflyCmd::TakeOver(CmdArgList args, ConnectionContext* cntx) {\n   absl::Time start = absl::Now();\n   AggregateStatus status;\n \n-  sf_->CancelBlockingCommands();\n-\n   // We need to await for all dispatches to finish: Otherwise a transaction might be scheduled\n   // after this function exits but before the actual shutdown.\n   facade::DispatchTracker tracker{sf_->GetListeners(), cntx->conn()};\n-  tracker.TrackAll();\n+  shard_set->pool()->Await([&](unsigned index, auto* pb) {\n+    sf_->CancelBlockingOnThread();\n+    tracker.TrackOnThread();\n+  });\n \n   if (!tracker.Wait(timeout_dur)) {\n     LOG(WARNING) << \"Couldn't wait for commands to finish dispatching. \" << timeout_dur;\ndiff --git a/src/server/list_family.cc b/src/server/list_family.cc\nindex 2255fd5fc4dd..dd38bb816569 100644\n--- a/src/server/list_family.cc\n+++ b/src/server/list_family.cc\n@@ -889,9 +889,8 @@ OpResult<string> BPopPusher::RunSingle(Transaction* t, time_point tp) {\n   auto wcb = [&](Transaction* t, EngineShard* shard) { return ArgSlice{&this->pop_key_, 1}; };\n \n   // Block\n-  bool wait_succeeded = t->WaitOnWatch(tp, std::move(wcb));\n-  if (!wait_succeeded)\n-    return OpStatus::TIMED_OUT;\n+  if (auto status = t->WaitOnWatch(tp, std::move(wcb)); status != OpStatus::OK)\n+    return status;\n \n   t->Execute(cb_move, true);\n   return op_res;\n@@ -914,9 +913,8 @@ OpResult<string> BPopPusher::RunPair(Transaction* t, time_point tp) {\n   // This allows us to run Transaction::Execute on watched transactions in both shards.\n   auto wcb = [&](Transaction* t, EngineShard* shard) { return ArgSlice{&this->pop_key_, 1}; };\n \n-  bool wait_succeeded = t->WaitOnWatch(tp, std::move(wcb));\n-  if (!wait_succeeded)\n-    return OpStatus::TIMED_OUT;\n+  if (auto status = t->WaitOnWatch(tp, std::move(wcb)); status != OpStatus::OK)\n+    return status;\n \n   return MoveTwoShards(t, pop_key_, push_key_, popdir_, pushdir_, true);\n }\n@@ -1206,10 +1204,9 @@ void ListFamily::BPopGeneric(ListDir dir, CmdArgList args, ConnectionContext* cn\n     popped_value = OpBPop(t, shard, key, dir);\n   };\n \n-  cntx->conn_state.is_blocking = true;\n   OpResult<string> popped_key = container_utils::RunCbOnFirstNonEmptyBlocking(\n-      transaction, OBJ_LIST, std::move(cb), unsigned(timeout * 1000));\n-  cntx->conn_state.is_blocking = false;\n+      transaction, OBJ_LIST, std::move(cb), unsigned(timeout * 1000), &cntx->blocked);\n+\n   auto* rb = static_cast<RedisReplyBuilder*>(cntx->reply_builder());\n   if (popped_key) {\n     DVLOG(1) << \"BPop \" << transaction->DebugId() << \" popped from key \" << popped_key;  // key.\n@@ -1222,8 +1219,12 @@ void ListFamily::BPopGeneric(ListDir dir, CmdArgList args, ConnectionContext* cn\n   switch (popped_key.status()) {\n     case OpStatus::WRONG_TYPE:\n       return rb->SendError(kWrongTypeErr);\n+    case OpStatus::CANCELLED:\n     case OpStatus::TIMED_OUT:\n       return rb->SendNullArray();\n+    case OpStatus::KEY_MOVED:\n+      // TODO: proper error for moved\n+      return rb->SendError(\"-MOVED\");\n     default:\n       LOG(ERROR) << \"Unexpected error \" << popped_key.status();\n   }\ndiff --git a/src/server/main_service.cc b/src/server/main_service.cc\nindex aa560c613cbc..6e1783b6595f 100644\n--- a/src/server/main_service.cc\n+++ b/src/server/main_service.cc\n@@ -1447,7 +1447,8 @@ facade::ConnectionContext* Service::CreateContext(util::FiberSocketBase* peer,\n   // a bit of a hack. I set up breaker callback here for the owner.\n   // Should work though it's confusing to have it here.\n   owner->RegisterBreakHook([res, this](uint32_t) {\n-    res->CancelBlocking();\n+    if (res->transaction)\n+      res->transaction->CancelBlocking(nullptr);\n     this->server_family().BreakOnShutdown();\n   });\n \n@@ -2407,7 +2408,7 @@ string Service::GetContextInfo(facade::ConnectionContext* cntx) {\n   if (server_cntx->conn_state.subscribe_info)\n     buf[index++] = 'P';\n \n-  if (server_cntx->conn_state.is_blocking)\n+  if (server_cntx->blocked)\n     buf[index++] = 'b';\n \n   if (index) {\ndiff --git a/src/server/server_family.cc b/src/server/server_family.cc\nindex 16869165b86f..a1bb75af7958 100644\n--- a/src/server/server_family.cc\n+++ b/src/server/server_family.cc\n@@ -1142,17 +1142,18 @@ void ServerFamily::BreakOnShutdown() {\n   dfly_cmd_->BreakOnShutdown();\n }\n \n-void ServerFamily::CancelBlockingCommands() {\n-  auto cb = [](unsigned thread_index, util::Connection* conn) {\n-    facade::ConnectionContext* fc = static_cast<facade::Connection*>(conn)->cntx();\n-    if (fc) {\n-      ConnectionContext* cntx = static_cast<ConnectionContext*>(fc);\n-      cntx->CancelBlocking();\n+void ServerFamily::CancelBlockingOnThread(std::function<OpStatus(ArgSlice)> status_cb) {\n+  auto cb = [status_cb](unsigned thread_index, util::Connection* conn) {\n+    if (auto fcntx = static_cast<facade::Connection*>(conn)->cntx(); fcntx) {\n+      auto* cntx = static_cast<ConnectionContext*>(fcntx);\n+      if (cntx->transaction && cntx->blocked) {\n+        cntx->transaction->CancelBlocking(status_cb);\n+      }\n     }\n   };\n-  for (auto* listener : listeners_) {\n-    listener->TraverseConnections(cb);\n-  }\n+\n+  for (auto* listener : listeners_)\n+    listener->TraverseConnectionsOnThread(cb);\n }\n \n string GetPassword() {\ndiff --git a/src/server/server_family.h b/src/server/server_family.h\nindex 192869b04aea..211f456ecadf 100644\n--- a/src/server/server_family.h\n+++ b/src/server/server_family.h\n@@ -196,7 +196,7 @@ class ServerFamily {\n \n   void BreakOnShutdown();\n \n-  void CancelBlockingCommands();\n+  void CancelBlockingOnThread(std::function<facade::OpStatus(ArgSlice)> = {});\n \n   // Sets the server to replicate another instance. Does not flush the database beforehand!\n   void Replicate(std::string_view host, std::string_view port);\ndiff --git a/src/server/stream_family.cc b/src/server/stream_family.cc\nindex ccfc29386071..95b0bbe54850 100644\n--- a/src/server/stream_family.cc\n+++ b/src/server/stream_family.cc\n@@ -2823,10 +2823,8 @@ void XReadBlock(ReadOpts opts, ConnectionContext* cntx) {\n   auto tp = (opts.timeout) ? chrono::steady_clock::now() + chrono::milliseconds(opts.timeout)\n                            : Transaction::time_point::max();\n \n-  bool wait_succeeded = cntx->transaction->WaitOnWatch(tp, std::move(wcb));\n-  if (!wait_succeeded) {\n+  if (auto status = cntx->transaction->WaitOnWatch(tp, std::move(wcb)); status != OpStatus::OK)\n     return rb->SendNullArray();\n-  }\n \n   // Resolve the entry in the woken key. Note this must not use OpRead since\n   // only the shard that contains the woken key blocks for the awoken\ndiff --git a/src/server/transaction.cc b/src/server/transaction.cc\nindex bc12987eff77..8cd30b0692ba 100644\n--- a/src/server/transaction.cc\n+++ b/src/server/transaction.cc\n@@ -1144,7 +1144,7 @@ size_t Transaction::ReverseArgIndex(ShardId shard_id, size_t arg_index) const {\n   return reverse_index_[sd.arg_start + arg_index];\n }\n \n-bool Transaction::WaitOnWatch(const time_point& tp, WaitKeysProvider wkeys_provider) {\n+OpStatus Transaction::WaitOnWatch(const time_point& tp, WaitKeysProvider wkeys_provider) {\n   DVLOG(2) << \"WaitOnWatch \" << DebugId();\n   using namespace chrono;\n \n@@ -1165,29 +1165,36 @@ bool Transaction::WaitOnWatch(const time_point& tp, WaitKeysProvider wkeys_provi\n   auto* stats = ServerState::tl_connection_stats();\n   ++stats->num_blocked_clients;\n \n+  if (DCHECK_IS_ON()) {\n+    int64_t ms = -1;\n+    if (tp != time_point::max())\n+      ms = duration_cast<milliseconds>(tp - time_point::clock::now()).count();\n+    DVLOG(1) << \"WaitOnWatch TimeWait for \" << ms << \" ms \" << DebugId();\n+  }\n+\n   cv_status status = cv_status::no_timeout;\n   if (tp == time_point::max()) {\n-    DVLOG(1) << \"WaitOnWatch foreva \" << DebugId();\n     blocking_ec_.await(std::move(wake_cb));\n-    DVLOG(1) << \"WaitOnWatch AfterWait\";\n   } else {\n-    DVLOG(1) << \"WaitOnWatch TimeWait for \"\n-             << duration_cast<milliseconds>(tp - time_point::clock::now()).count() << \" ms \"\n-             << DebugId();\n-\n     status = blocking_ec_.await_until(std::move(wake_cb), tp);\n-\n-    DVLOG(1) << \"WaitOnWatch await_until \" << int(status);\n   }\n \n+  DVLOG(1) << \"WaitOnWatch done \" << int(status) << \" \" << DebugId();\n+\n   --stats->num_blocked_clients;\n \n-  bool is_expired = (coordinator_state_ & COORD_CANCELLED) || status == cv_status::timeout;\n-  if (is_expired)\n+  OpStatus result = OpStatus::OK;\n+  if (status == cv_status::timeout) {\n+    result = OpStatus::TIMED_OUT;\n+  } else if (coordinator_state_ & COORD_CANCELLED) {\n+    result = local_result_;\n+  }\n+\n+  if (result != OpStatus::OK)\n     ExpireBlocking(wkeys_provider);\n \n   coordinator_state_ &= ~COORD_BLOCKED;\n-  return !is_expired;\n+  return result;\n }\n \n // Runs only in the shard thread.\n@@ -1430,11 +1437,26 @@ void Transaction::RunOnceAsCommand(const CommandId* cid, RunnableType cb) {\n   });\n }\n \n-void Transaction::CancelBlocking() {\n-  if (coordinator_state_ & COORD_BLOCKED) {\n-    coordinator_state_ |= COORD_CANCELLED;\n-    blocking_ec_.notify();\n+void Transaction::CancelBlocking(std::function<OpStatus(ArgSlice)> status_cb) {\n+  if ((coordinator_state_ & COORD_BLOCKED) == 0)\n+    return;\n+\n+  OpStatus status = OpStatus::CANCELLED;\n+  if (status_cb) {\n+    vector<string_view> all_keys;\n+    IterateActiveShards([this, &all_keys](PerShardData&, auto i) {\n+      auto shard_keys = GetShardArgs(i);\n+      all_keys.insert(all_keys.end(), shard_keys.begin(), shard_keys.end());\n+    });\n+    status = status_cb(absl::MakeSpan(all_keys));\n   }\n+\n+  if (status == OpStatus::OK)\n+    return;\n+\n+  coordinator_state_ |= COORD_CANCELLED;\n+  local_result_ = status;\n+  blocking_ec_.notify();\n }\n \n OpResult<KeyIndex> DetermineKeys(const CommandId* cid, CmdArgList args) {\ndiff --git a/src/server/transaction.h b/src/server/transaction.h\nindex 64d175e28809..6ff5f75c4ee8 100644\n--- a/src/server/transaction.h\n+++ b/src/server/transaction.h\n@@ -186,7 +186,7 @@ class Transaction {\n   // or b) tp is reached. If tp is time_point::max() then waits indefinitely.\n   // Expects that the transaction had been scheduled before, and uses Execute(.., true) to register.\n   // Returns false if timeout occurred, true if was notified by one of the keys.\n-  bool WaitOnWatch(const time_point& tp, WaitKeysProvider cb);\n+  facade::OpStatus WaitOnWatch(const time_point& tp, WaitKeysProvider cb);\n \n   // Returns true if transaction is awaked, false if it's timed-out and can be removed from the\n   // blocking queue.\n@@ -194,7 +194,7 @@ class Transaction {\n \n   // Cancel all blocking watches. Set COORD_CANCELLED.\n   // Must be called from coordinator thread.\n-  void CancelBlocking();\n+  void CancelBlocking(std::function<OpStatus(ArgSlice)>);\n \n   // In some cases for non auto-journaling commands we want to enable the auto journal flow.\n   void RenableAutoJournal() {\ndiff --git a/src/server/zset_family.cc b/src/server/zset_family.cc\nindex 8c29e2b7dcbf..71f34f7b9177 100644\n--- a/src/server/zset_family.cc\n+++ b/src/server/zset_family.cc\n@@ -1321,15 +1321,14 @@ void BZPopMinMax(CmdArgList args, ConnectionContext* cntx, bool is_max) {\n   VLOG(1) << \"BZPop timeout(\" << timeout << \")\";\n \n   Transaction* transaction = cntx->transaction;\n+\n   OpResult<ScoredArray> popped_array;\n-  cntx->conn_state.is_blocking = true;\n+  auto cb = [is_max, &popped_array](Transaction* t, EngineShard* shard, std::string_view key) {\n+    popped_array = OpBZPop(t, shard, key, is_max);\n+  };\n+\n   OpResult<string> popped_key = container_utils::RunCbOnFirstNonEmptyBlocking(\n-      transaction, OBJ_ZSET,\n-      [is_max, &popped_array](Transaction* t, EngineShard* shard, std::string_view key) {\n-        popped_array = OpBZPop(t, shard, key, is_max);\n-      },\n-      unsigned(timeout * 1000));\n-  cntx->conn_state.is_blocking = false;\n+      transaction, OBJ_ZSET, std::move(cb), unsigned(timeout * 1000), &cntx->blocked);\n \n   auto* rb = static_cast<RedisReplyBuilder*>(cntx->reply_builder());\n   if (popped_key) {\n",
  "test_patch": "diff --git a/src/server/blocking_controller_test.cc b/src/server/blocking_controller_test.cc\nindex 3faa31f091e4..e5839e52beed 100644\n--- a/src/server/blocking_controller_test.cc\n+++ b/src/server/blocking_controller_test.cc\n@@ -88,9 +88,9 @@ TEST_F(BlockingControllerTest, Timeout) {\n   trans_->Schedule();\n   auto cb = [&](Transaction* t, EngineShard* shard) { return trans_->GetShardArgs(0); };\n \n-  bool res = trans_->WaitOnWatch(tp, cb);\n+  facade::OpStatus status = trans_->WaitOnWatch(tp, cb);\n \n-  EXPECT_FALSE(res);\n+  EXPECT_EQ(status, facade::OpStatus::TIMED_OUT);\n   unsigned num_watched = shard_set->Await(\n       0, [&] { return EngineShard::tlocal()->blocking_controller()->NumWatched(0); });\n \ndiff --git a/tests/dragonfly/cluster_test.py b/tests/dragonfly/cluster_test.py\nindex 9692c0554578..d36bdfb958a0 100644\n--- a/tests/dragonfly/cluster_test.py\n+++ b/tests/dragonfly/cluster_test.py\n@@ -1,5 +1,6 @@\n import pytest\n import re\n+import json\n import redis\n from redis import asyncio as aioredis\n import asyncio\n@@ -515,6 +516,50 @@ async def test_cluster_flush_slots_after_config_change(df_local_factory: DflyIns\n     assert await c_replica.execute_command(\"dbsize\") == (100_000 - slot_0_size)\n \n \n+@dfly_args({\"proactor_threads\": 4, \"cluster_mode\": \"yes\", \"admin_port\": 30001})\n+async def test_cluster_blocking_command(df_server):\n+    c_master = df_server.client()\n+    c_master_admin = df_server.admin_client()\n+\n+    config = [\n+        {\n+            \"slot_ranges\": [{\"start\": 0, \"end\": 8000}],\n+            \"master\": {\"id\": await get_node_id(c_master_admin), \"ip\": \"10.0.0.1\", \"port\": 7000},\n+            \"replicas\": [],\n+        },\n+        {\n+            \"slot_ranges\": [{\"start\": 8001, \"end\": 16383}],\n+            \"master\": {\"id\": \"other\", \"ip\": \"10.0.0.2\", \"port\": 7000},\n+            \"replicas\": [],\n+        },\n+    ]\n+\n+    assert (\n+        await c_master_admin.execute_command(\"DFLYCLUSTER\", \"CONFIG\", json.dumps(config))\n+    ) == \"OK\"\n+\n+    assert (await c_master.execute_command(\"CLUSTER\", \"KEYSLOT\", \"keep-local\")) == 3479\n+    assert (await c_master.execute_command(\"CLUSTER\", \"KEYSLOT\", \"remove-key-4\")) == 6103\n+\n+    v1 = asyncio.create_task(c_master.blpop(\"keep-local\", 2))\n+    v2 = asyncio.create_task(c_master.blpop(\"remove-key-4\", 2))\n+\n+    await asyncio.sleep(0.1)\n+\n+    config[0][\"slot_ranges\"][0][\"end\"] = 5000\n+    config[1][\"slot_ranges\"][0][\"start\"] = 5001\n+    assert (\n+        await c_master_admin.execute_command(\"DFLYCLUSTER\", \"CONFIG\", json.dumps(config))\n+    ) == \"OK\"\n+\n+    await c_master.lpush(\"keep-local\", \"WORKS\")\n+\n+    assert (await v1) == (\"keep-local\", \"WORKS\")\n+    with pytest.raises(aioredis.ResponseError) as e_info:\n+        await v2\n+    assert \"MOVED\" in str(e_info.value)\n+\n+\n @dfly_args({\"proactor_threads\": 4, \"cluster_mode\": \"yes\"})\n async def test_cluster_native_client(df_local_factory: DflyInstanceFactory):\n     # Start and configure cluster with 3 masters and 3 replicas\n",
  "problem_statement": "DFLYCLUSTER CONFIG handle blocking commands \nWhen a new config is set to a node and slots where removed from the node slots ownership we need to returned MOVED error to running blocking commands waiting on keys that slots where removed.\nAtomic Cluster Config Set\nToday, there are various races, that could lead to writes losses, when setting cluster config.\r\n\r\n# The Problem\r\nUpon setting a new slot ownership config, master nodes may \u201close\u201d ownership over certain slots. In such a case, all requests to use (both read and write) keys which belong to unowned slots are supposed to receive `MOVED` replies.\r\nA naive (read: current) implementation will simply set the configuration, and any future requests will access the configuration to see the updated slot mapping.\r\nHowever, there could be in-progress requests being handled, which already saw the previous configuration (i.e. they moved passed replying with `MOVED`). If we reply with OK to a write/modify command, we\u2019ll lose that information as it will be unretrievable. Furthermore, it will also be undeletable which can be seen as a memory leak.\r\n\r\n# Proposed Solution\r\n1. We\u2019ll set the config immediately upon receiving it\r\n1. Add 2 per-slot counters: how many `requests_started`, and how many `requests_finished`\r\n1. Before handling any key, we\u2019ll check the cluster config:\r\n    a. If the key does not belong to this node, we\u2019ll reply with `MOVED`\r\n    b. Otherwise, we\u2019ll increment `requests_started`\r\n    c. When the request finishes, we\u2019ll increment `requests_finished`\r\n1. When receiving a set-cluster-config request, we\u2019ll save each thread\u2019s `requests_started`\r\n1. Then we\u2019ll wait for all threads\u2019 `requests_finished` to be at least as big as their saved `requests_started`\r\nAt this point in time all requests that saw the previous config will have already finished running\r\n\r\n# Future Expansion\r\nOur planned slot-migration feature should hook into this solution to determine when the last possible writes to slots are done, end stable sync, and complete taking over the ownership of the slot.\r\n\n",
  "hints_text": "\n",
  "created_at": "2023-12-05T12:09:21Z",
  "modified_files": [
    "src/facade/conn_context.h",
    "src/facade/dragonfly_connection.cc",
    "src/facade/dragonfly_connection.h",
    "src/facade/dragonfly_listener.cc",
    "src/facade/dragonfly_listener.h",
    "src/facade/facade.cc",
    "src/facade/op_status.h",
    "src/server/cluster/cluster_config.cc",
    "src/server/cluster/cluster_config.h",
    "src/server/cluster/cluster_family.cc",
    "src/server/conn_context.cc",
    "src/server/conn_context.h",
    "src/server/container_utils.cc",
    "src/server/container_utils.h",
    "src/server/dflycmd.cc",
    "src/server/list_family.cc",
    "src/server/main_service.cc",
    "src/server/server_family.cc",
    "src/server/server_family.h",
    "src/server/stream_family.cc",
    "src/server/transaction.cc",
    "src/server/transaction.h",
    "src/server/zset_family.cc"
  ],
  "modified_test_files": [
    "src/server/blocking_controller_test.cc",
    "tests/dragonfly/cluster_test.py"
  ]
}