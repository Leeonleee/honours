{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 5069,
  "instance_id": "dragonflydb__dragonfly-5069",
  "issue_numbers": [
    "4926"
  ],
  "base_commit": "3da7e497125cdd9b9c15773fefe5295dc58e6a70",
  "patch": "diff --git a/src/server/CMakeLists.txt b/src/server/CMakeLists.txt\nindex f1e9b6ae0378..27236153d44c 100644\n--- a/src/server/CMakeLists.txt\n+++ b/src/server/CMakeLists.txt\n@@ -118,6 +118,7 @@ cxx_test(zset_family_test dfly_test_lib LABELS DFLY)\n cxx_test(geo_family_test dfly_test_lib LABELS DFLY)\n cxx_test(blocking_controller_test dfly_test_lib LABELS DFLY)\n cxx_test(json_family_test dfly_test_lib LABELS DFLY)\n+cxx_test(json_family_memory_test dfly_test_lib LABELS DFLY)\n cxx_test(journal/journal_test dfly_test_lib LABELS DFLY)\n cxx_test(hll_family_test dfly_test_lib LABELS DFLY)\n cxx_test(bloom_family_test dfly_test_lib LABELS DFLY)\n@@ -131,6 +132,7 @@ if (WITH_ASAN OR WITH_USAN)\n   target_compile_definitions(multi_test PRIVATE SANITIZERS)\n   target_compile_definitions(search_family_test PRIVATE SANITIZERS)\n   target_compile_definitions(json_family_test PRIVATE SANITIZERS)\n+  target_compile_definitions(json_family_memory_test PRIVATE SANITIZERS)\n   target_compile_definitions(dragonfly_test PRIVATE SANITIZERS)\n endif()\n cxx_test(search/aggregator_test dfly_test_lib LABELS DFLY)\n@@ -142,4 +144,5 @@ add_dependencies(check_dfly dragonfly_test json_family_test list_family_test\n                  generic_family_test memcache_parser_test rdb_test journal_test\n                  redis_parser_test stream_family_test string_family_test\n                  bitops_family_test set_family_test zset_family_test geo_family_test\n-                 hll_family_test cluster_config_test cluster_family_test acl_family_test)\n+                 hll_family_test cluster_config_test cluster_family_test acl_family_test\n+                 json_family_memory_test)\ndiff --git a/src/server/json_family.cc b/src/server/json_family.cc\nindex ac9f2271e96a..bee4e64a5b68 100644\n--- a/src/server/json_family.cc\n+++ b/src/server/json_family.cc\n@@ -82,6 +82,80 @@ class JsonMemTracker {\n   size_t start_size_{0};\n };\n \n+/* Helper class which must be initialized before any mutate operations on json.\n+  It will track the memory usage of the json object and update the size in the CompactObj.\n+  It also contains indexes updates, post update operations on the iterator. */\n+class JsonAutoUpdater {\n+ public:\n+  JsonAutoUpdater(const OpArgs& op_args, string_view key, DbSlice::ItAndUpdater it,\n+                  bool update_on_delete = false)\n+      : op_args_(op_args), key_(key), it_(std::move(it)), update_on_delete_(update_on_delete) {\n+    op_args.shard->search_indices()->RemoveDoc(key, op_args.db_cntx, it.it->second);\n+\n+    /* We need to initialize start memory usage after RemoveDoc because internally RemoveDoc has\n+    static cache that can allocate/deallocate memory. Because of this, we will\n+    overestimate/underestimate memory usage for json object. */\n+    start_size_ = GetMemoryUsage();\n+  }\n+\n+  JsonAutoUpdater(const JsonAutoUpdater&) = delete;\n+  JsonAutoUpdater& operator=(const JsonAutoUpdater&) = delete;\n+\n+  JsonAutoUpdater(JsonAutoUpdater&&) = default;\n+  JsonAutoUpdater& operator=(JsonAutoUpdater&&) = delete;\n+\n+  void SetJsonSize() {\n+    set_size_was_called_ = true;\n+\n+    const size_t current = GetMemoryUsage();\n+    int64_t diff = static_cast<int64_t>(current) - static_cast<int64_t>(start_size_);\n+\n+    GetPrimeValue().SetJsonSize(diff);\n+\n+    // Under any flow we must not end up with this special value.\n+    DCHECK(GetPrimeValue().MallocUsed() != 0);\n+  }\n+\n+  ~JsonAutoUpdater() {\n+    if (update_on_delete_ && !set_size_was_called_) {\n+      SetJsonSize();\n+    } else if (!set_size_was_called_) {\n+      LOG(WARNING) << \"JsonAutoUpdater destructor called without SetJsonSize() being called. This \"\n+                      \"may lead to memory tracking issues.\";\n+    }\n+\n+    it_.post_updater.Run();\n+\n+    /* We need to call AddDoc after SetJsonSize because internally AddDoc has static cache that can\n+    allocate/deallocate memory. Because of this, we will overestimate/underestimate memory usage for\n+    json object. */\n+    op_args_.shard->search_indices()->AddDoc(key_, op_args_.db_cntx, GetPrimeValue());\n+  }\n+\n+  PrimeValue& GetPrimeValue() {\n+    return it_.it->second;\n+  }\n+\n+  JsonType* GetJson() {\n+    return GetPrimeValue().GetJson();\n+  }\n+\n+ private:\n+  size_t GetMemoryUsage() const {\n+    return static_cast<MiMemoryResource*>(CompactObj::memory_resource())->used();\n+  }\n+\n+ private:\n+  const OpArgs& op_args_;\n+  string_view key_;\n+  DbSlice::ItAndUpdater it_;\n+\n+  // Used to track the memory usage of the json object\n+  size_t start_size_{0};\n+  bool set_size_was_called_{false};\n+  bool update_on_delete_;\n+};\n+\n template <typename T> using ParseResult = io::Result<T, std::string>;\n \n ParseResult<JsonExpression> ParseJsonPathAsExpression(std::string_view path) {\n@@ -318,28 +392,63 @@ bool JsonAreEquals(const JsonType& lhs, const JsonType& rhs) {\n   }\n }\n \n+/* Converts a JSONPath to a JSONPointer.\n+   E.g. $[a][b][0] -> /a/b/0.\n+   V1 JSONPath is not supported. */\n+std::optional<std::string> ConvertJsonPathToJsonPointer(string_view json_path) {\n+  auto parsed_path = json::ParsePath(json_path);\n+\n+  if (!parsed_path) {\n+    VLOG(2) << \"Error during conversion of JSONPath to JSONPointer: \" << json_path\n+            << \". Invalid JSONPath.\";\n+    return std::nullopt;\n+  }\n+\n+  std::string pointer;\n+  const auto& path = parsed_path.value();\n+  for (const auto& node : path) {\n+    const auto& type = node.type();\n+    if (type == json::SegmentType::IDENTIFIER) {\n+      absl::StrAppend(&pointer, \"/\"sv, node.identifier());\n+    } else if (type == json::SegmentType::INDEX) {\n+      const auto& index = node.index();\n+\n+      if (index.first != index.second) {\n+        VLOG(2) << \"Error during conversion of JSONPath to JSONPointer: \" << json_path\n+                << \". Index range is not supported.\";\n+        return std::nullopt;\n+      }\n+\n+      absl::StrAppend(&pointer, \"/\"sv, node.index().first);\n+    } else {\n+      VLOG(2) << \"Error during conversion of JSONPath to JSONPointer: \" << json_path\n+              << \". Unsupported segment type.\";\n+      return std::nullopt;\n+    }\n+  }\n+\n+  return pointer;\n+}\n+\n // Use this method on the coordinator thread\n std::optional<JsonType> JsonFromString(std::string_view input) {\n   return dfly::JsonFromString(input, PMR_NS::get_default_resource());\n }\n \n-// Use this method on the shard thread\n+/* Use this method on the shard thread\n+\n+   If you do memory tracking, make sure to initialize it before calling this method, and reset the\n+   result before invoking SetJsonSize. Note that even after calling std::move on an optional, it may\n+   still hold the JSON value, which can lead to incorrect memory tracking. */\n std::optional<JsonType> ShardJsonFromString(std::string_view input) {\n   return dfly::JsonFromString(input, CompactObj::memory_resource());\n }\n \n-OpResult<DbSlice::ItAndUpdater> SetJson(const OpArgs& op_args, string_view key,\n-                                        string_view json_str) {\n-  auto& db_slice = op_args.GetDbSlice();\n-\n-  auto op_res = db_slice.AddOrFind(op_args.db_cntx, key);\n-  RETURN_ON_BAD_STATUS(op_res);\n-\n-  auto& res = *op_res;\n-\n-  op_args.shard->search_indices()->RemoveDoc(key, op_args.db_cntx, res.it->second);\n+OpStatus SetFullJson(const OpArgs& op_args, string_view key, string_view json_str) {\n+  auto it_res = op_args.GetDbSlice().AddOrFind(op_args.db_cntx, key);\n+  RETURN_ON_BAD_STATUS(it_res);\n \n-  JsonMemTracker tracker;\n+  JsonAutoUpdater updater(op_args, key, *std::move(it_res));\n \n   std::optional<JsonType> parsed_json = ShardJsonFromString(json_str);\n   if (!parsed_json) {\n@@ -352,15 +461,83 @@ OpResult<DbSlice::ItAndUpdater> SetJson(const OpArgs& op_args, string_view key,\n     json::FromJsonType(*parsed_json, &fbb);\n     fbb.Finish();\n     const auto& buf = fbb.GetBuffer();\n-    res.it->second.SetJson(buf.data(), buf.size());\n+    updater.GetPrimeValue().SetJson(buf.data(), buf.size());\n   } else {\n-    res.it->second.SetJson(std::move(*parsed_json));\n+    updater.GetPrimeValue().SetJson(std::move(*parsed_json));\n   }\n \n-  tracker.SetJsonSize(res.it->second, res.is_new);\n-  op_args.shard->search_indices()->AddDoc(key, op_args.db_cntx, res.it->second);\n+  // We should do reset before setting the size of the json, because\n+  // std::optional still holds the value and it will be deallocated\n+  parsed_json.reset();\n+  updater.SetJsonSize();\n \n-  return std::move(res);\n+  return OpStatus::OK;\n+}\n+\n+/* Sets a partial JSON value at the specified path.\n+   True means that the value was set, false means that the value was not set. */\n+OpResult<bool> SetPartialJson(const OpArgs& op_args, string_view key,\n+                              const WrappedJsonPath& json_path, string_view json_str,\n+                              bool is_nx_condition, bool is_xx_condition) {\n+  auto it_res = op_args.GetDbSlice().FindMutable(op_args.db_cntx, key, OBJ_JSON);\n+  RETURN_ON_BAD_STATUS(it_res);\n+\n+  JsonAutoUpdater updater(op_args, key, *std::move(it_res));\n+\n+  /* This method would use copy for parsed_json and not move!\n+     The reason being, that we are applying this multiple times for each match we found.\n+     So for example if we have an array that this expression will match each entry in it then the\n+     assign here is called N times. */\n+  std::optional<JsonType> parsed_json = ShardJsonFromString(json_str);\n+  if (!parsed_json) {\n+    VLOG(1) << \"got invalid JSON string '\" << json_str << \"' cannot be saved\";\n+    return OpStatus::INVALID_JSON;\n+  }\n+\n+  bool path_exists = false;\n+  bool value_was_set = false;\n+\n+  // If the path exists, this callback will be called\n+  auto mutate_cb = [&](std::optional<std::string_view>, JsonType* val) -> MutateCallbackResult<> {\n+    path_exists = true;\n+    if (!is_nx_condition) {\n+      value_was_set = true;\n+      *val = JsonType(parsed_json.value(),\n+                      std::pmr::polymorphic_allocator<char>{CompactObj::memory_resource()});\n+    }\n+    return {};\n+  };\n+\n+  auto mutate_res = json_path.ExecuteMutateCallback<Nothing>(\n+      updater.GetJson(), mutate_cb, CallbackResultOptions::DefaultMutateOptions());\n+\n+  // Set a new value if the path doesn't exist and the xx condition is not set.\n+  if (mutate_res && !path_exists && !is_xx_condition) {\n+    auto pointer = ConvertJsonPathToJsonPointer(json_path.Path());\n+    if (!pointer) {\n+      return OpStatus::SYNTAX_ERR;\n+    }\n+\n+    std::error_code ec;\n+    jsoncons::jsonpointer::add(*updater.GetJson(), pointer.value(), std::move(parsed_json).value(),\n+                               ec);\n+    if (ec) {\n+      VLOG(1) << \"Failed to add a JSON value to the following path: \" << json_str\n+              << \" with the error: \" << ec.message();\n+      return OpStatus::SYNTAX_ERR;\n+    }\n+\n+    value_was_set = true;\n+  }\n+\n+  if (value_was_set) {\n+    // We should do reset before setting the size of the json, because\n+    // std::optional still holds the value and it will be deallocated\n+    parsed_json.reset();\n+    updater.SetJsonSize();\n+  }\n+\n+  return value_was_set;\n }\n \n size_t NormalizeNegativeIndex(int index, size_t size) {\n@@ -517,44 +694,6 @@ string ConvertToJsonPointer(string_view json_path) {\n   return result;\n }\n \n-/* Converts a JSONPath to a JSONPointer.\n-   E.g. $[a][b][0] -> /a/b/0.\n-   V1 JSONPath is not supported. */\n-std::optional<std::string> ConvertJsonPathToJsonPointer(string_view json_path) {\n-  auto parsed_path = json::ParsePath(json_path);\n-\n-  if (!parsed_path) {\n-    VLOG(2) << \"Error during conversion of JSONPath to JSONPointer: \" << json_path\n-            << \". Invalid JSONPath.\";\n-    return std::nullopt;\n-  }\n-\n-  std::string pointer;\n-  const auto& path = parsed_path.value();\n-  for (const auto& node : path) {\n-    const auto& type = node.type();\n-    if (type == json::SegmentType::IDENTIFIER) {\n-      pointer += '/' + node.identifier();\n-    } else if (type == json::SegmentType::INDEX) {\n-      const auto& index = node.index();\n-\n-      if (index.first != index.second) {\n-        VLOG(2) << \"Error during conversion of JSONPath to JSONPointer: \" << json_path\n-                << \". Index range is not supported.\";\n-        return std::nullopt;\n-      }\n-\n-      pointer += '/' + std::to_string(node.index().first);\n-    } else {\n-      VLOG(2) << \"Error during conversion of JSONPath to JSONPointer: \" << json_path\n-              << \". Unsupported segment type.\";\n-      return std::nullopt;\n-    }\n-  }\n-\n-  return pointer;\n-}\n-\n size_t CountJsonFields(const JsonType& j) {\n   size_t res = 0;\n   json_type type = j.type();\n@@ -1331,68 +1470,14 @@ OpResult<bool> OpSet(const OpArgs& op_args, string_view key, string_view path,\n       }\n     }\n \n-    auto st = SetJson(op_args, key, json_str);\n-    RETURN_ON_BAD_STATUS(st);\n-    return true;\n-  }\n-\n-  // Note that this operation would use copy and not move!\n-  // The reason being, that we are applying this multiple times\n-  // For each match we found. So for example if we have\n-  // an array that this expression will match each entry in it\n-  // then the assign here is called N times, where N == array.size().\n-  bool path_exists = false;\n-  bool operation_result = false;\n-\n-  optional<JsonType> parsed_json = ShardJsonFromString(json_str);\n-  if (!parsed_json) {\n-    VLOG(1) << \"got invalid JSON string '\" << json_str << \"' cannot be saved\";\n-    return OpStatus::INVALID_JSON;\n-  }\n-  const JsonType& new_json = parsed_json.value();\n-\n-  // If the path exists, this callback will be called\n-  auto mutate_cb = [&](std::optional<std::string_view>, JsonType* val) -> MutateCallbackResult<> {\n-    path_exists = true;\n-    if (!is_nx_condition) {\n-      operation_result = true;\n-      *val =\n-          JsonType(new_json, std::pmr::polymorphic_allocator<char>{CompactObj::memory_resource()});\n-    }\n-    return {};\n-  };\n-\n-  // If the path doesn't exist, this callback will be called\n-  auto insert_cb = [&](JsonType* json) {\n-    // Set a new value if the path doesn't exist and the xx condition is not set.\n-    if (!path_exists && !is_xx_condition) {\n-      auto pointer = ConvertJsonPathToJsonPointer(json_path.Path());\n-      if (!pointer) {\n-        return OpStatus::SYNTAX_ERR;\n-      }\n-\n-      std::error_code ec;\n-      jsoncons::jsonpointer::add(*json, pointer.value(), new_json, ec);\n-      if (ec) {\n-        VLOG(1) << \"Failed to add a JSON value to the following path: \" << path\n-                << \" with the error: \" << ec.message();\n-        return OpStatus::SYNTAX_ERR;\n-      }\n-\n-      operation_result = true;\n+    OpStatus result = SetFullJson(op_args, key, json_str);\n+    if (result == OpStatus::OK) {\n+      return true;\n     }\n+    return result;\n+  }\n \n-    return OpStatus::OK;\n-  };\n-\n-  // JsonMutateOperation uses it's own JsonMemTracker. It will work, because updates to already\n-  // existing json keys use copy assign, so we don't really need to account for the memory\n-  // allocated by ShardJsonFromString above since it's not being moved here at all.\n-  auto res = JsonMutateOperation<Nothing>(op_args, key, json_path, std::move(mutate_cb),\n-                                          MutateOperationOptions{std::move(insert_cb)});\n-  RETURN_ON_BAD_STATUS(res);\n-\n-  return operation_result;\n+  return SetPartialJson(op_args, key, json_path, json_str, is_nx_condition, is_xx_condition);\n }\n \n OpResult<bool> OpSet(const OpArgs& op_args, string_view key, string_view path,\n",
  "test_patch": "diff --git a/src/server/json_family_memory_test.cc b/src/server/json_family_memory_test.cc\nnew file mode 100644\nindex 000000000000..e414a3fd9182\n--- /dev/null\n+++ b/src/server/json_family_memory_test.cc\n@@ -0,0 +1,108 @@\n+// Copyright 2025, DragonflyDB authors.  All rights reserved.\n+// See LICENSE for licensing terms.\n+//\n+\n+#include \"base/gtest.h\"\n+#include \"base/logging.h\"\n+#include \"facade/facade_test.h\"\n+#include \"server/command_registry.h\"\n+#include \"server/json_family.h\"\n+#include \"server/test_utils.h\"\n+\n+using namespace testing;\n+using namespace std;\n+using namespace util;\n+\n+ABSL_DECLARE_FLAG(bool, jsonpathv2);\n+\n+namespace dfly {\n+\n+class JsonFamilyMemoryTest : public BaseFamilyTest {\n+ public:\n+  static dfly::MiMemoryResource* GetMemoryResource() {\n+    static thread_local mi_heap_t* heap = mi_heap_new();\n+    static thread_local dfly::MiMemoryResource memory_resource{heap};\n+    return &memory_resource;\n+  }\n+\n+ protected:\n+  auto GetJsonMemoryUsageFromDb(std::string_view key) {\n+    return Run({\"MEMORY\", \"USAGE\", key, \"WITHOUTKEY\"});\n+  }\n+};\n+\n+size_t GetMemoryUsage() {\n+  return static_cast<MiMemoryResource*>(JsonFamilyMemoryTest::GetMemoryResource())->used();\n+}\n+\n+size_t GetJsonMemoryUsageFromString(std::string_view json_str) {\n+  size_t start = GetMemoryUsage();\n+  auto json = dfly::JsonFromString(json_str, JsonFamilyMemoryTest::GetMemoryResource());\n+  if (!json) {\n+    return 0;\n+  }\n+\n+  // The same behaviour as in CompactObj\n+  void* ptr =\n+      JsonFamilyMemoryTest::GetMemoryResource()->allocate(sizeof(JsonType), alignof(JsonType));\n+  JsonType* json_on_heap = new (ptr) JsonType(std::move(json).value());\n+  DCHECK(json_on_heap);\n+\n+  size_t result = GetMemoryUsage() - start;\n+\n+  // Free the memory\n+  json_on_heap->~JsonType();\n+  JsonFamilyMemoryTest::GetMemoryResource()->deallocate(json_on_heap, sizeof(JsonType),\n+                                                        alignof(JsonType));\n+  return result;\n+}\n+\n+TEST_F(JsonFamilyMemoryTest, SimpleSet) {\n+  std::string_view big_json = R\"({\"a\":\"some big string asdkasdkasdfkkasjdkfjka\"})\";\n+  size_t start_size = GetJsonMemoryUsageFromString(big_json);\n+\n+  auto resp = Run({\"JSON.SET\", \"j1\", \"$\", big_json});\n+  EXPECT_EQ(resp, \"OK\");\n+  resp = GetJsonMemoryUsageFromDb(\"j1\");\n+  EXPECT_THAT(resp, IntArg(start_size));\n+\n+  std::string_view small_json = R\"({\"a\":\" \"})\";\n+  size_t next_size = GetJsonMemoryUsageFromString(small_json);\n+\n+  resp = Run({\"JSON.SET\", \"j1\", \"$\", small_json});\n+  EXPECT_EQ(resp, \"OK\");\n+  resp = GetJsonMemoryUsageFromDb(\"j1\");\n+  EXPECT_THAT(resp, IntArg(next_size));\n+\n+  // Again set big json\n+  resp = Run({\"JSON.SET\", \"j1\", \"$\", big_json});\n+  EXPECT_EQ(resp, \"OK\");\n+  resp = GetJsonMemoryUsageFromDb(\"j1\");\n+  EXPECT_THAT(resp, IntArg(start_size));\n+}\n+\n+TEST_F(JsonFamilyMemoryTest, PartialSet) {\n+  std::string_view start_json = R\"({\"a\":\"some text\", \"b\":\" \"})\";\n+  size_t start_size = GetJsonMemoryUsageFromString(start_json);\n+\n+  auto resp = Run({\"JSON.SET\", \"j1\", \"$\", start_json});\n+  EXPECT_EQ(resp, \"OK\");\n+  resp = GetJsonMemoryUsageFromDb(\"j1\");\n+  EXPECT_THAT(resp, IntArg(start_size));\n+\n+  std::string_view json_after_set = R\"({\"a\":\"some text\", \"b\":\"some another text\"})\";\n+  size_t size_after_set = GetJsonMemoryUsageFromString(json_after_set);\n+\n+  resp = Run({\"JSON.SET\", \"j1\", \"$.b\", \"\\\"some another text\\\"\"});\n+  EXPECT_EQ(resp, \"OK\");\n+  resp = GetJsonMemoryUsageFromDb(\"j1\");\n+  EXPECT_THAT(resp, IntArg(size_after_set));\n+\n+  // Again set start json\n+  resp = Run({\"JSON.SET\", \"j1\", \"$.b\", \"\\\" \\\"\"});\n+  EXPECT_EQ(resp, \"OK\");\n+  resp = GetJsonMemoryUsageFromDb(\"j1\");\n+  EXPECT_THAT(resp, IntArg(start_size));\n+}\n+\n+}  // namespace dfly\ndiff --git a/src/server/search/search_family_test.cc b/src/server/search/search_family_test.cc\nindex 38dc0a9bdefb..7411a2ea0709 100644\n--- a/src/server/search/search_family_test.cc\n+++ b/src/server/search/search_family_test.cc\n@@ -2753,4 +2753,18 @@ TEST_F(SearchFamilyTest, RenameDocumentBetweenIndices) {\n   EXPECT_EQ(Run({\"rename\", \"idx2:{doc}1\", \"idx1:{doc}1\"}), \"OK\");\n }\n \n+TEST_F(SearchFamilyTest, JsonSetIndexesBug) {\n+  auto resp = Run({\"JSON.SET\", \"j1\", \"$\", R\"({\"text\":\"some text\"})\"});\n+  EXPECT_THAT(resp, \"OK\");\n+\n+  resp = Run(\n+      {\"FT.CREATE\", \"index\", \"ON\", \"json\", \"SCHEMA\", \"$.text\", \"AS\", \"text\", \"TEXT\", \"SORTABLE\"});\n+  EXPECT_THAT(resp, \"OK\");\n+\n+  resp = Run({\"JSON.SET\", \"j1\", \"$\", R\"({\"asd}\"})\"});\n+  EXPECT_THAT(resp, ErrArg(\"ERR failed to parse JSON\"));\n+\n+  resp = Run({\"FT.AGGREGATE\", \"index\", \"*\", \"GROUPBY\", \"1\", \"@text\"});\n+  EXPECT_THAT(resp, IsUnordArrayWithSize(IsMap(\"text\", \"some text\")));\n+}\n }  // namespace dfly\n",
  "problem_statement": "Memory tracking tests for JSON and STREAMs\nWe need to add memory tracking tests for JSON and STREAMs. During the read commands we should assert that no memory were allocated.\n\n- [ ] Add tests for JSON\n         - Simple tests are added by #5056\n- [ ] Add tests for STREAM\n",
  "hints_text": "",
  "created_at": "2025-05-06T07:49:35Z",
  "modified_files": [
    "src/server/CMakeLists.txt",
    "src/server/json_family.cc"
  ],
  "modified_test_files": [
    "b/src/server/json_family_memory_test.cc",
    "src/server/search/search_family_test.cc"
  ]
}