{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 2613,
  "instance_id": "dragonflydb__dragonfly-2613",
  "issue_numbers": [
    "2597"
  ],
  "base_commit": "fa75360227f751b505eaf4218e2f5cf52e4f1571",
  "patch": "diff --git a/src/server/common.cc b/src/server/common.cc\nindex 9b308e123656..6a208f714f32 100644\n--- a/src/server/common.cc\n+++ b/src/server/common.cc\n@@ -76,8 +76,6 @@ const char* GlobalStateName(GlobalState s) {\n       return \"ACTIVE\";\n     case GlobalState::LOADING:\n       return \"LOADING\";\n-    case GlobalState::SAVING:\n-      return \"SAVING\";\n     case GlobalState::SHUTTING_DOWN:\n       return \"SHUTTING DOWN\";\n     case GlobalState::TAKEN_OVER:\ndiff --git a/src/server/common.h b/src/server/common.h\nindex 325a4ea7d46e..b3b5b3b72d0e 100644\n--- a/src/server/common.h\n+++ b/src/server/common.h\n@@ -154,7 +154,6 @@ struct SearchStats {\n enum class GlobalState : uint8_t {\n   ACTIVE,\n   LOADING,\n-  SAVING,\n   SHUTTING_DOWN,\n   TAKEN_OVER,\n };\ndiff --git a/src/server/detail/save_stages_controller.cc b/src/server/detail/save_stages_controller.cc\nindex 18ce620fed9a..70ef99d04688 100644\n--- a/src/server/detail/save_stages_controller.cc\n+++ b/src/server/detail/save_stages_controller.cc\n@@ -9,6 +9,7 @@\n \n #include \"base/flags.h\"\n #include \"base/logging.h\"\n+#include \"server/detail/snapshot_storage.h\"\n #include \"server/main_service.h\"\n #include \"server/script_mgr.h\"\n #include \"server/transaction.h\"\n@@ -147,40 +148,26 @@ SaveStagesController::SaveStagesController(SaveStagesInputs&& inputs)\n SaveStagesController::~SaveStagesController() {\n }\n \n-GenericError SaveStagesController::Save() {\n-  if (auto err = BuildFullPath(); err)\n-    return err;\n+SaveInfo SaveStagesController::Save() {\n+  if (auto err = BuildFullPath(); err) {\n+    shared_err_ = err;\n+    return GetSaveInfo();\n+  }\n \n-  if (auto err = InitResources(); err)\n-    return err;\n+  InitResources();\n \n-  // The stages below report errors to shared_err_\n   if (use_dfs_format_)\n     SaveDfs();\n   else\n     SaveRdb();\n \n-  is_saving_->store(true, memory_order_relaxed);\n-  {\n-    lock_guard lk{*save_mu_};\n-    *save_bytes_cb_ = [this]() { return GetSaveBuffersSize(); };\n-  }\n-\n   RunStage(&SaveStagesController::SaveCb);\n-  {\n-    lock_guard lk{*save_mu_};\n-    *save_bytes_cb_ = nullptr;\n-  }\n-\n-  is_saving_->store(false, memory_order_relaxed);\n \n   RunStage(&SaveStagesController::CloseCb);\n \n   FinalizeFileMovement();\n \n-  UpdateSaveInfo();\n-\n-  return *shared_err_;\n+  return GetSaveInfo();\n }\n \n size_t SaveStagesController::GetSaveBuffersSize() {\n@@ -264,14 +251,18 @@ void SaveStagesController::SaveRdb() {\n   trans_->ScheduleSingleHop(std::move(cb));\n }\n \n-void SaveStagesController::UpdateSaveInfo() {\n-  auto seconds = (absl::Now() - start_time_) / absl::Seconds(1);\n+uint32_t SaveStagesController::GetCurrentSaveDuration() {\n+  return (absl::Now() - start_time_) / absl::Seconds(1);\n+}\n+\n+SaveInfo SaveStagesController::GetSaveInfo() {\n+  SaveInfo info;\n+  info.save_time = absl::ToUnixSeconds(start_time_);\n+  info.duration_sec = GetCurrentSaveDuration();\n+\n   if (shared_err_) {\n-    lock_guard lk{*save_mu_};\n-    last_save_info_->last_error = *shared_err_;\n-    last_save_info_->last_error_time = absl::ToUnixSeconds(start_time_);\n-    last_save_info_->failed_duration_sec = seconds;\n-    return;\n+    info.error = *shared_err_;\n+    return info;\n   }\n \n   fs::path resulting_path = full_path_;\n@@ -281,23 +272,22 @@ void SaveStagesController::UpdateSaveInfo() {\n     resulting_path.replace_extension();  // remove .tmp\n \n   LOG(INFO) << \"Saving \" << resulting_path << \" finished after \"\n-            << strings::HumanReadableElapsedTime(seconds);\n+            << strings::HumanReadableElapsedTime(info.duration_sec);\n \n-  lock_guard lk{*save_mu_};\n-  last_save_info_->freq_map.clear();\n+  info.freq_map.clear();\n   for (const auto& k_v : rdb_name_map_) {\n-    last_save_info_->freq_map.emplace_back(k_v);\n+    info.freq_map.emplace_back(k_v);\n   }\n-  last_save_info_->save_time = absl::ToUnixSeconds(start_time_);\n-  last_save_info_->file_name = resulting_path.generic_string();\n-  last_save_info_->success_duration_sec = seconds;\n+\n+  info.file_name = resulting_path.generic_string();\n+\n+  return info;\n }\n \n-GenericError SaveStagesController::InitResources() {\n+void SaveStagesController::InitResources() {\n   snapshots_.resize(use_dfs_format_ ? shard_set->size() + 1 : 1);\n   for (auto& [snapshot, _] : snapshots_)\n     snapshot = make_unique<RdbSnapshot>(fq_threadpool_, snapshot_storage_.get());\n-  return {};\n }\n \n // Remove .tmp extension or delete files in case of error\ndiff --git a/src/server/detail/save_stages_controller.h b/src/server/detail/save_stages_controller.h\nindex d9526570088d..cb40d50e3b79 100644\n--- a/src/server/detail/save_stages_controller.h\n+++ b/src/server/detail/save_stages_controller.h\n@@ -7,9 +7,7 @@\n \n #include <filesystem>\n \n-#include \"server/detail/snapshot_storage.h\"\n #include \"server/rdb_save.h\"\n-#include \"server/server_family.h\"\n #include \"util/fibers/fiberqueue_threadpool.h\"\n \n namespace dfly {\n@@ -19,16 +17,22 @@ class Service;\n \n namespace detail {\n \n+class SnapshotStorage;\n+\n+struct SaveInfo {\n+  time_t save_time = 0;  // epoch time in seconds.\n+  uint32_t duration_sec = 0;\n+  std::string file_name;\n+  std::vector<std::pair<std::string_view, size_t>> freq_map;  // RDB_TYPE_xxx -> count mapping.\n+  GenericError error;\n+};\n+\n struct SaveStagesInputs {\n   bool use_dfs_format_;\n   std::string_view basename_;\n   Transaction* trans_;\n   Service* service_;\n-  std::atomic_bool* is_saving_;\n   util::fb2::FiberQueueThreadPool* fq_threadpool_;\n-  LastSaveInfo* last_save_info_ ABSL_GUARDED_BY(save_mu_);\n-  util::fb2::Mutex* save_mu_;\n-  std::function<size_t()>* save_bytes_cb_;\n   std::shared_ptr<SnapshotStorage> snapshot_storage_;\n };\n \n@@ -70,7 +74,9 @@ struct SaveStagesController : public SaveStagesInputs {\n \n   ~SaveStagesController();\n \n-  GenericError Save();\n+  SaveInfo Save();\n+  size_t GetSaveBuffersSize();\n+  uint32_t GetCurrentSaveDuration();\n \n  private:\n   // In the new version (.dfs) we store a file for every shard and one more summary file.\n@@ -83,9 +89,9 @@ struct SaveStagesController : public SaveStagesInputs {\n   // Save a single rdb file\n   void SaveRdb();\n \n-  void UpdateSaveInfo();\n+  SaveInfo GetSaveInfo();\n \n-  GenericError InitResources();\n+  void InitResources();\n \n   // Remove .tmp extension or delete files in case of error\n   void FinalizeFileMovement();\n@@ -102,8 +108,6 @@ struct SaveStagesController : public SaveStagesInputs {\n \n   void RunStage(void (SaveStagesController::*cb)(unsigned));\n \n-  size_t GetSaveBuffersSize();\n-\n  private:\n   absl::Time start_time_;\n   std::filesystem::path full_path_;\ndiff --git a/src/server/server_family.cc b/src/server/server_family.cc\nindex e9f935eb274d..759e14346470 100644\n--- a/src/server/server_family.cc\n+++ b/src/server/server_family.cc\n@@ -40,6 +40,7 @@ extern \"C\" {\n #include \"server/conn_context.h\"\n #include \"server/debugcmd.h\"\n #include \"server/detail/save_stages_controller.h\"\n+#include \"server/detail/snapshot_storage.h\"\n #include \"server/dflycmd.h\"\n #include \"server/engine_shard_set.h\"\n #include \"server/error.h\"\n@@ -52,6 +53,7 @@ extern \"C\" {\n #include \"server/rdb_save.h\"\n #include \"server/script_mgr.h\"\n #include \"server/server_state.h\"\n+#include \"server/snapshot.h\"\n #include \"server/tiered_storage.h\"\n #include \"server/transaction.h\"\n #include \"server/version.h\"\n@@ -1290,28 +1292,51 @@ GenericError ServerFamily::DoSave(bool new_version, string_view basename, Transa\n     return GenericError{make_error_code(errc::operation_not_permitted),\n                         StrCat(\"Can not save database in tiering mode\")};\n   }\n-  if (!ignore_state) {\n-    auto [new_state, success] = service_.SwitchState(GlobalState::ACTIVE, GlobalState::SAVING);\n-    if (!success) {\n-      return GenericError{make_error_code(errc::operation_in_progress),\n-                          StrCat(GlobalStateName(new_state), \" - can not save database\")};\n-    }\n+  auto state = service_.GetGlobalState();\n+  // In some cases we want to create a snapshot even if server is not active, f.e in takeover\n+  if (!ignore_state && (state != GlobalState::ACTIVE)) {\n+    return GenericError{make_error_code(errc::operation_in_progress),\n+                        StrCat(GlobalStateName(state), \" - can not save database\")};\n   }\n+\n   {\n-    std::lock_guard lck(save_mu_);\n-    start_save_time_ = absl::Now();\n+    std::lock_guard lk(save_mu_);\n+    if (save_controller_) {\n+      return GenericError{make_error_code(errc::operation_in_progress),\n+                          \"SAVING - can not save database\"};\n+    }\n+    save_controller_ = make_unique<SaveStagesController>(detail::SaveStagesInputs{\n+        new_version, basename, trans, &service_, fq_threadpool_.get(), snapshot_storage_});\n   }\n-  SaveStagesController sc{detail::SaveStagesInputs{\n-      new_version, basename, trans, &service_, &is_saving_, fq_threadpool_.get(), &last_save_info_,\n-      &save_mu_, &save_bytes_cb_, snapshot_storage_}};\n-  auto res = sc.Save();\n+\n+  detail::SaveInfo save_info = save_controller_->Save();\n+\n   {\n-    std::lock_guard lck(save_mu_);\n-    start_save_time_.reset();\n+    std::lock_guard lk(save_mu_);\n+\n+    if (save_info.error) {\n+      last_save_info_.last_error = save_info.error;\n+      last_save_info_.last_error_time = save_info.save_time;\n+      last_save_info_.failed_duration_sec = save_info.duration_sec;\n+    } else {\n+      last_save_info_.save_time = save_info.save_time;\n+      last_save_info_.success_duration_sec = save_info.duration_sec;\n+      last_save_info_.file_name = save_info.file_name;\n+      last_save_info_.freq_map = save_info.freq_map;\n+    }\n+    save_controller_.reset();\n   }\n-  if (!ignore_state)\n-    service_.SwitchState(GlobalState::SAVING, GlobalState::ACTIVE);\n-  return res;\n+\n+  return save_info.error;\n+}\n+\n+bool ServerFamily::TEST_IsSaving() const {\n+  std::atomic_bool is_saving{false};\n+  shard_set->pool()->AwaitFiberOnAll([&](auto*) {\n+    if (SliceSnapshot::IsSnaphotInProgress())\n+      is_saving.store(true, std::memory_order_relaxed);\n+  });\n+  return is_saving.load(std::memory_order_relaxed);\n }\n \n error_code ServerFamily::Drakarys(Transaction* transaction, DbIndex db_ind) {\n@@ -1841,10 +1866,10 @@ void ServerFamily::Info(CmdArgList args, ConnectionContext* cntx) {\n       append(\"replication_full_sync_buffer_bytes\", repl_mem.full_sync_buf_bytes_);\n     }\n \n-    if (IsSaving()) {\n+    {\n       lock_guard lk{save_mu_};\n-      if (save_bytes_cb_) {\n-        append(\"save_buffer_bytes\", save_bytes_cb_());\n+      if (save_controller_) {\n+        append(\"save_buffer_bytes\", save_controller_->GetSaveBuffersSize());\n       }\n     }\n   }\n@@ -1914,9 +1939,17 @@ void ServerFamily::Info(CmdArgList args, ConnectionContext* cntx) {\n     size_t is_loading = service_.GetGlobalState() == GlobalState::LOADING;\n     append(\"loading\", is_loading);\n \n-    auto curent_durration_sec =\n-        start_save_time_ ? (absl::Now() - *start_save_time_) / absl::Seconds(1) : 0;\n-    append(\"saving\", curent_durration_sec != 0);\n+    bool is_saving = false;\n+    uint32_t curent_durration_sec = 0;\n+    {\n+      lock_guard lk{save_mu_};\n+      if (save_controller_) {\n+        is_saving = true;\n+        curent_durration_sec = save_controller_->GetCurrentSaveDuration();\n+      }\n+    }\n+\n+    append(\"saving\", is_saving);\n     append(\"current_save_duration_sec\", curent_durration_sec);\n \n     for (const auto& k_v : save_info.freq_map) {\ndiff --git a/src/server/server_family.h b/src/server/server_family.h\nindex 290119f9f226..822055f5d810 100644\n--- a/src/server/server_family.h\n+++ b/src/server/server_family.h\n@@ -12,6 +12,7 @@\n #include \"facade/redis_parser.h\"\n #include \"facade/reply_builder.h\"\n #include \"server/channel_store.h\"\n+#include \"server/detail/save_stages_controller.h\"\n #include \"server/engine_shard_set.h\"\n #include \"server/replica.h\"\n #include \"server/server_state.h\"\n@@ -173,9 +174,7 @@ class ServerFamily {\n   // future with error_code.\n   util::fb2::Future<GenericError> Load(const std::string& file_name);\n \n-  bool IsSaving() const {\n-    return is_saving_.load(std::memory_order_relaxed);\n-  }\n+  bool TEST_IsSaving() const;\n \n   void ConfigureMetrics(util::HttpListenerBase* listener);\n \n@@ -282,13 +281,7 @@ class ServerFamily {\n   time_t start_time_ = 0;  // in seconds, epoch time.\n \n   LastSaveInfo last_save_info_ ABSL_GUARDED_BY(save_mu_);\n-  std::atomic_bool is_saving_{false};\n-  // this field duplicate SaveStagesController::start_save_time_\n-  // TODO make SaveStagesController as member of this class\n-  std::optional<absl::Time> start_save_time_;\n-  // If a save operation is currently in progress, calling this function will provide information\n-  // about the memory consumption during the save operation.\n-  std::function<size_t()> save_bytes_cb_ = nullptr;\n+  std::unique_ptr<detail::SaveStagesController> save_controller_ ABSL_GUARDED_BY(save_mu_);\n \n   // Used to override save on shutdown behavior that is usually set\n   // be --dbfilename.\ndiff --git a/src/server/snapshot.cc b/src/server/snapshot.cc\nindex c39a0e8d2931..b3aa21ab18e5 100644\n--- a/src/server/snapshot.cc\n+++ b/src/server/snapshot.cc\n@@ -52,6 +52,10 @@ size_t SliceSnapshot::GetThreadLocalMemoryUsage() {\n   return mem;\n }\n \n+bool SliceSnapshot::IsSnaphotInProgress() {\n+  return tl_slice_snapshots.size() > 0;\n+}\n+\n void SliceSnapshot::Start(bool stream_journal, const Cancellation* cll) {\n   DCHECK(!snapshot_fb_.IsJoinable());\n \ndiff --git a/src/server/snapshot.h b/src/server/snapshot.h\nindex 0e98bc79f258..eb1d33f8d5ab 100644\n--- a/src/server/snapshot.h\n+++ b/src/server/snapshot.h\n@@ -61,6 +61,7 @@ class SliceSnapshot {\n   ~SliceSnapshot();\n \n   static size_t GetThreadLocalMemoryUsage();\n+  static bool IsSnaphotInProgress();\n \n   // Initialize snapshot, start bucket iteration fiber, register listeners.\n   // In journal streaming mode it needs to be stopped by either Stop or Cancel.\n",
  "test_patch": "diff --git a/src/server/rdb_test.cc b/src/server/rdb_test.cc\nindex b5fb8bd59e1d..466dd3ec5648 100644\n--- a/src/server/rdb_test.cc\n+++ b/src/server/rdb_test.cc\n@@ -325,7 +325,7 @@ TEST_F(RdbTest, SaveFlush) {\n \n   do {\n     usleep(10);\n-  } while (!service_->server_family().IsSaving());\n+  } while (!service_->server_family().TEST_IsSaving());\n \n   Run({\"flushdb\"});\n   save_fb.Join();\n@@ -355,7 +355,7 @@ TEST_F(RdbTest, SaveManyDbs) {\n \n   do {\n     usleep(10);\n-  } while (!service_->server_family().IsSaving());\n+  } while (!service_->server_family().TEST_IsSaving());\n \n   pp_->at(1)->Await([&] {\n     Run({\"select\", \"1\"});\ndiff --git a/tests/dragonfly/replication_test.py b/tests/dragonfly/replication_test.py\nindex 863ada5c7730..d23451cbe535 100644\n--- a/tests/dragonfly/replication_test.py\n+++ b/tests/dragonfly/replication_test.py\n@@ -1999,3 +1999,35 @@ async def send_setex():\n     assert set(keys_master) == set(keys_replica)\n \n     await disconnect_clients(c_master, *[c_replica])\n+\n+\n+@pytest.mark.asyncio\n+async def test_saving_replica(df_local_factory):\n+    tmp_file_name = \"\".join(random.choices(string.ascii_letters, k=10))\n+\n+    master = df_local_factory.create(proactor_threads=1)\n+    replica = df_local_factory.create(proactor_threads=1, dbfilename=f\"dump_{tmp_file_name}\")\n+    df_local_factory.start_all([master, replica])\n+\n+    c_master = master.client()\n+    c_replica = replica.client()\n+\n+    await c_master.execute_command(\"DEBUG POPULATE 10000 key 4048 RAND\")\n+    await c_replica.execute_command(f\"REPLICAOF localhost {master.port}\")\n+    await wait_available_async(c_replica)\n+\n+    async def save_replica():\n+        await c_replica.execute_command(\"save\")\n+\n+    async def is_saving():\n+        return \"saving:1\" in (await c_replica.execute_command(\"INFO PERSISTENCE\"))\n+\n+    save_task = asyncio.create_task(save_replica())\n+    while not await is_saving():  # wait for replica start saving\n+        asyncio.sleep(0.1)\n+    await c_replica.execute_command(\"replicaof no one\")\n+    assert await is_saving()\n+    await save_task\n+    assert not await is_saving()\n+\n+    await disconnect_clients(c_master, *[c_replica])\ndiff --git a/tests/dragonfly/snapshot_test.py b/tests/dragonfly/snapshot_test.py\nindex 78d916744187..fd23faceef16 100644\n--- a/tests/dragonfly/snapshot_test.py\n+++ b/tests/dragonfly/snapshot_test.py\n@@ -125,21 +125,21 @@ async def test_dbfilenames(\n \n @pytest.mark.slow\n @dfly_args({**BASIC_ARGS, \"dbfilename\": \"test-cron\", \"snapshot_cron\": \"* * * * *\"})\n-async def test_cron_snapshot(tmp_path: Path, async_client: aioredis.Redis):\n+async def test_cron_snapshot(tmp_dir: Path, async_client: aioredis.Redis):\n     await StaticSeeder(**LIGHTWEIGHT_SEEDER_ARGS).run(async_client)\n \n     file = None\n     with async_timeout.timeout(65):\n         while file is None:\n             await asyncio.sleep(1)\n-            file = find_main_file(tmp_path, \"test-cron-summary.dfs\")\n+            file = find_main_file(tmp_dir, \"test-cron-summary.dfs\")\n \n-    assert file is not None, os.listdir(tmp_path)\n+    assert file is not None, os.listdir(tmp_dir)\n \n \n @pytest.mark.slow\n @dfly_args({**BASIC_ARGS, \"dbfilename\": \"test-cron-set\"})\n-async def test_set_cron_snapshot(tmp_path: Path, async_client: aioredis.Redis):\n+async def test_set_cron_snapshot(tmp_dir: Path, async_client: aioredis.Redis):\n     await StaticSeeder(**LIGHTWEIGHT_SEEDER_ARGS).run(async_client)\n \n     await async_client.config_set(\"snapshot_cron\", \"* * * * *\")\n@@ -148,7 +148,7 @@ async def test_set_cron_snapshot(tmp_path: Path, async_client: aioredis.Redis):\n     with async_timeout.timeout(65):\n         while file is None:\n             await asyncio.sleep(1)\n-            file = find_main_file(tmp_path, \"test-cron-set-summary.dfs\")\n+            file = find_main_file(tmp_dir, \"test-cron-set-summary.dfs\")\n \n     assert file is not None\n \n",
  "problem_statement": "Server crashes after issuing `replicaof no one`\n**Describe the bug**\r\nProcess crashes after issuing `replicaof no one` while it's replica of another node.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Issue `replicaof no one` on the node while it's replica of another node \r\n2. Server crashes with logs below\r\n\r\n```\r\nFeb 15 09:20:31 thanos-dragonfly-eu-5 taskset[75]: I20240215 09:20:31.842679    81 server_family.cc:2123] Replicating no:one\r\nFeb 15 09:20:31 thanos-dragonfly-eu-5 taskset[75]: I20240215 09:20:31.843235    77 replica.cc:629] Exit stable sync\r\nFeb 15 09:20:31 thanos-dragonfly-eu-5 taskset[75]: W20240215 09:20:31.843266    77 replica.cc:237] Error stable sync with thanos-dragonfly-eu-3.aiven-metrics.aiven.local:17673 generic:125 Operation canceled\r\nFeb 15 09:20:31 thanos-dragonfly-eu-5 taskset[75]: F20240215 09:20:31.843624    81 server_family.cc:2142] Check failed: service_.SwitchState(GlobalState::LOADING, GlobalState::ACTIVE).first == GlobalState::ACTIVE Server is set to replica no one, yet state is not active!\r\nFeb 15 09:20:31 thanos-dragonfly-eu-5 taskset[75]: *** Check failure stack trace: ***\r\nFeb 15 09:20:31 thanos-dragonfly-eu-5 taskset[75]:     @           0xc7f9f7  (unknown)\r\nFeb 15 09:20:31 thanos-dragonfly-eu-5 taskset[75]:     @           0xc77426  (unknown)\r\nFeb 15 09:20:31 thanos-dragonfly-eu-5 taskset[75]:     @           0xc78cb9  (unknown)\r\nFeb 15 09:20:31 thanos-dragonfly-eu-5 taskset[75]:     @           0x5f029f  (unknown)\r\nFeb 15 09:20:31 thanos-dragonfly-eu-5 taskset[75]:     @           0x5f04d4  (unknown)\r\nFeb 15 09:20:31 thanos-dragonfly-eu-5 taskset[75]:     @           0x79903b  (unknown)\r\nFeb 15 09:20:31 thanos-dragonfly-eu-5 taskset[75]:     @           0x593c19  (unknown)\r\nFeb 15 09:20:31 thanos-dragonfly-eu-5 taskset[75]:     @           0x59951c  (unknown)\r\nFeb 15 09:20:31 thanos-dragonfly-eu-5 taskset[75]:     @           0x886fc9  (unknown)\r\nFeb 15 09:20:31 thanos-dragonfly-eu-5 taskset[75]:     @           0x8871ac  (unknown)\r\nFeb 15 09:20:31 thanos-dragonfly-eu-5 taskset[75]:     @           0x88ac38  (unknown)\r\nFeb 15 09:20:31 thanos-dragonfly-eu-5 taskset[75]:     @           0x88af09  (unknown)\r\nFeb 15 09:20:31 thanos-dragonfly-eu-5 taskset[75]:     @           0x88bee2  (unknown)\r\nFeb 15 09:20:31 thanos-dragonfly-eu-5 taskset[75]:     @           0xc26e01  (unknown)\r\nFeb 15 09:20:31 thanos-dragonfly-eu-5 taskset[75]:     @           0xc272d3  (unknown)\r\nFeb 15 09:20:31 thanos-dragonfly-eu-5 taskset[75]:     @     0x7f82aed3d18f  make_fcontext\r\nFeb 15 09:20:31 thanos-dragonfly-eu-5 taskset[75]: *** SIGABRT received at time=1707988831 on cpu 13 ***\r\nFeb 15 09:20:31 thanos-dragonfly-eu-5 taskset[75]: PC: @     0x7f82ae57e884  (unknown)  __pthread_kill_implementation\r\nFeb 15 09:20:33 thanos-dragonfly-eu-5 systemd[1]: dragonfly.service: Main process exited, code=dumped, status=6/ABRT\r\n```\r\n**Expected behavior**\r\nServer shouldn't crash after `replicaof no one`\r\n\r\n**Environment (please complete the following information):**\r\n - OS: Fedora 38\r\n - Kernel: 6.3.12-200.fc38.x86_64\r\n - Containerized?: toolbox\r\n - Dragonfly Version: 1.14.1\r\n\r\n\n",
  "hints_text": "",
  "created_at": "2024-02-18T19:50:17Z",
  "modified_files": [
    "src/server/common.cc",
    "src/server/common.h",
    "src/server/detail/save_stages_controller.cc",
    "src/server/detail/save_stages_controller.h",
    "src/server/server_family.cc",
    "src/server/server_family.h",
    "src/server/snapshot.cc",
    "src/server/snapshot.h"
  ],
  "modified_test_files": [
    "src/server/rdb_test.cc",
    "tests/dragonfly/replication_test.py",
    "tests/dragonfly/snapshot_test.py"
  ]
}