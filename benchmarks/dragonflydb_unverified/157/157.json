{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 157,
  "instance_id": "dragonflydb__dragonfly-157",
  "issue_numbers": [
    "59"
  ],
  "base_commit": "46220183aefa003c1a60ee50bbbaaa17609b2cdd",
  "patch": "diff --git a/src/server/command_registry.cc b/src/server/command_registry.cc\nindex ece7e7d63222..d52dc84d9233 100644\n--- a/src/server/command_registry.cc\n+++ b/src/server/command_registry.cc\n@@ -111,8 +111,8 @@ const char* OptName(CO::CommandOpt fl) {\n       return \"blocking\";\n     case GLOBAL_TRANS:\n       return \"global-trans\";\n-    case DESTINATION_KEY:\n-      return \"dest-key\";\n+    case VARIADIC_KEYS:\n+      return \"variadic-keys\";\n   }\n   return \"unknown\";\n }\ndiff --git a/src/server/command_registry.h b/src/server/command_registry.h\nindex 1bd6a15f28ed..439edf9af37c 100644\n--- a/src/server/command_registry.h\n+++ b/src/server/command_registry.h\n@@ -30,7 +30,9 @@ enum CommandOpt : uint32_t {\n   NOSCRIPT = 0x100,\n   BLOCKING = 0x200,  // implies REVERSE_MAPPING\n   GLOBAL_TRANS = 0x1000,\n-  DESTINATION_KEY = 0x2000,\n+\n+  // arg 2 determines number of keys. Relevant for ZUNIONSTORE, EVAL etc.\n+  VARIADIC_KEYS = 0x2000,\n };\n \n const char* OptName(CommandOpt fl);\n@@ -85,7 +87,7 @@ class CommandId {\n   }\n \n   bool is_multi_key() const {\n-    return (last_key_ != first_key_) || (opt_mask_ & CO::DESTINATION_KEY);\n+    return (last_key_ != first_key_) || (opt_mask_ & CO::VARIADIC_KEYS);\n   }\n \n   int8_t key_arg_step() const {\ndiff --git a/src/server/main_service.cc b/src/server/main_service.cc\nindex 07fc8e8ee42b..d28cb914c12e 100644\n--- a/src/server/main_service.cc\n+++ b/src/server/main_service.cc\n@@ -511,21 +511,23 @@ void Service::DispatchCommand(CmdArgList args, facade::ConnectionContext* cntx)\n \n   if (under_script) {\n     DCHECK(dfly_cntx->transaction);\n-    OpResult<KeyIndex> key_index_res = DetermineKeys(cid, args);\n-    if (!key_index_res)\n-      return (*cntx)->SendError(key_index_res.status());\n-\n-    const auto& key_index = *key_index_res;\n-    for (unsigned i = key_index.start; i < key_index.end; ++i) {\n-      string_view key = ArgS(args, i);\n-      if (!dfly_cntx->conn_state.script_info->keys.contains(key)) {\n-        return (*cntx)->SendError(\"script tried accessing undeclared key\");\n+    if (IsTransactional(cid)) {\n+      OpResult<KeyIndex> key_index_res = DetermineKeys(cid, args);\n+      if (!key_index_res)\n+        return (*cntx)->SendError(key_index_res.status());\n+\n+      const auto& key_index = *key_index_res;\n+      for (unsigned i = key_index.start; i < key_index.end; ++i) {\n+        string_view key = ArgS(args, i);\n+        if (!dfly_cntx->conn_state.script_info->keys.contains(key)) {\n+          return (*cntx)->SendError(\"script tried accessing undeclared key\");\n+        }\n       }\n+      dfly_cntx->transaction->SetExecCmd(cid);\n+      OpStatus st = dfly_cntx->transaction->InitByArgs(dfly_cntx->conn_state.db_index, args);\n+      if (st != OpStatus::OK)\n+        return (*cntx)->SendError(st);\n     }\n-    dfly_cntx->transaction->SetExecCmd(cid);\n-    OpStatus st = dfly_cntx->transaction->InitByArgs(dfly_cntx->conn_state.db_index, args);\n-    if (st != OpStatus::OK)\n-      return (*cntx)->SendError(st);\n   } else {\n     DCHECK(dfly_cntx->transaction == nullptr);\n \n@@ -1081,18 +1083,21 @@ void Service::RegisterCommands() {\n \n   constexpr auto kExecMask = CO::LOADING | CO::NOSCRIPT | CO::GLOBAL_TRANS;\n \n-  registry_ << CI{\"QUIT\", CO::READONLY | CO::FAST, 1, 0, 0, 0}.HFUNC(Quit)\n-            << CI{\"MULTI\", CO::NOSCRIPT | CO::FAST | CO::LOADING, 1, 0, 0, 0}.HFUNC(Multi)\n-            << CI{\"DISCARD\", CO::NOSCRIPT | CO::FAST | CO::LOADING, 1, 0, 0, 0}.MFUNC(Discard)\n-            << CI{\"EVAL\", CO::NOSCRIPT, -3, 3, 3, 1}.MFUNC(Eval).SetValidator(&EvalValidator)\n-            << CI{\"EVALSHA\", CO::NOSCRIPT, -3, 3, 3, 1}.MFUNC(EvalSha).SetValidator(&EvalValidator)\n-            << CI{\"EXEC\", kExecMask, 1, 0, 0, 0}.MFUNC(Exec)\n-            << CI{\"PUBLISH\", CO::LOADING | CO::FAST, 3, 0, 0, 0}.MFUNC(Publish)\n-            << CI{\"SUBSCRIBE\", CO::NOSCRIPT | CO::LOADING, -2, 0, 0, 0}.MFUNC(Subscribe)\n-            << CI{\"UNSUBSCRIBE\", CO::NOSCRIPT | CO::LOADING, -1, 0, 0, 0}.MFUNC(Unsubscribe)\n-            << CI{\"PSUBSCRIBE\", CO::NOSCRIPT | CO::LOADING, -2, 0, 0, 0}.MFUNC(PSubscribe)\n-            << CI{\"PUNSUBSCRIBE\", CO::NOSCRIPT | CO::LOADING, -1, 0, 0, 0}.MFUNC(PUnsubscribe)\n-            << CI{\"FUNCTION\", CO::NOSCRIPT, 2, 0, 0, 0}.MFUNC(Function);\n+  registry_\n+      << CI{\"QUIT\", CO::READONLY | CO::FAST, 1, 0, 0, 0}.HFUNC(Quit)\n+      << CI{\"MULTI\", CO::NOSCRIPT | CO::FAST | CO::LOADING, 1, 0, 0, 0}.HFUNC(Multi)\n+      << CI{\"DISCARD\", CO::NOSCRIPT | CO::FAST | CO::LOADING, 1, 0, 0, 0}.MFUNC(Discard)\n+      << CI{\"EVAL\", CO::NOSCRIPT | CO::VARIADIC_KEYS, -3, 3, 3, 1}.MFUNC(Eval).SetValidator(\n+             &EvalValidator)\n+      << CI{\"EVALSHA\", CO::NOSCRIPT | CO::VARIADIC_KEYS, -3, 3, 3, 1}.MFUNC(EvalSha).SetValidator(\n+             &EvalValidator)\n+      << CI{\"EXEC\", kExecMask, 1, 0, 0, 0}.MFUNC(Exec)\n+      << CI{\"PUBLISH\", CO::LOADING | CO::FAST, 3, 0, 0, 0}.MFUNC(Publish)\n+      << CI{\"SUBSCRIBE\", CO::NOSCRIPT | CO::LOADING, -2, 0, 0, 0}.MFUNC(Subscribe)\n+      << CI{\"UNSUBSCRIBE\", CO::NOSCRIPT | CO::LOADING, -1, 0, 0, 0}.MFUNC(Unsubscribe)\n+      << CI{\"PSUBSCRIBE\", CO::NOSCRIPT | CO::LOADING, -2, 0, 0, 0}.MFUNC(PSubscribe)\n+      << CI{\"PUNSUBSCRIBE\", CO::NOSCRIPT | CO::LOADING, -1, 0, 0, 0}.MFUNC(PUnsubscribe)\n+      << CI{\"FUNCTION\", CO::NOSCRIPT, 2, 0, 0, 0}.MFUNC(Function);\n \n   StreamFamily::Register(&registry_);\n   StringFamily::Register(&registry_);\n@@ -1116,6 +1121,13 @@ void Service::RegisterCommands() {\n         LOG(INFO) << \"    \" << key << \": with \" << key_len << \" keys\";\n       }\n     });\n+\n+    LOG(INFO) << \"Non-transactional commands are: \";\n+    registry_.Traverse([](std::string_view name, const CI& cid) {\n+      if (!IsTransactional(&cid)) {\n+        LOG(INFO) << \"    \" << name;\n+      }\n+    });\n   }\n }\n \ndiff --git a/src/server/transaction.cc b/src/server/transaction.cc\nindex 786302a21a80..950126729859 100644\n--- a/src/server/transaction.cc\n+++ b/src/server/transaction.cc\n@@ -16,6 +16,7 @@ namespace dfly {\n \n using namespace std;\n using namespace util;\n+using absl::StrCat;\n \n thread_local Transaction::TLTmpSpace Transaction::tmp_space;\n \n@@ -51,7 +52,8 @@ Transaction::Transaction(const CommandId* cid) : cid_(cid) {\n }\n \n Transaction::~Transaction() {\n-  DVLOG(2) << \"Transaction \" << DebugId() << \" destroyed\";\n+  DVLOG(2) << \"Transaction \" << StrCat(Name(), \"@\", txid_, \"/\", unique_shard_cnt_, \")\")\n+           << \" destroyed\";\n }\n \n /**\n@@ -286,7 +288,7 @@ void Transaction::SetExecCmd(const CommandId* cid) {\n string Transaction::DebugId() const {\n   DCHECK_GT(use_count_.load(memory_order_relaxed), 0u);\n \n-  return absl::StrCat(Name(), \"@\", txid_, \"/\", unique_shard_cnt_, \" (\", trans_id(this), \")\");\n+  return StrCat(Name(), \"@\", txid_, \"/\", unique_shard_cnt_, \" (\", trans_id(this), \")\");\n }\n \n // Runs in the dbslice thread. Returns true if transaction needs to be kept in the queue.\n@@ -496,9 +498,7 @@ void Transaction::ScheduleInternal() {\n         if (!is_active(i))\n           continue;\n \n-        shard_set->Add(i, [] {\n-          EngineShard::tlocal()->PollExecution(\"cancel_cleanup\", nullptr);\n-        });\n+        shard_set->Add(i, [] { EngineShard::tlocal()->PollExecution(\"cancel_cleanup\", nullptr); });\n       }\n     }\n   }\n@@ -1156,14 +1156,19 @@ OpResult<KeyIndex> DetermineKeys(const CommandId* cid, CmdArgList args) {\n   DCHECK_EQ(0u, cid->opt_mask() & CO::GLOBAL_TRANS);\n \n   KeyIndex key_index;\n+\n   int num_custom_keys = -1;\n \n-  if (cid->opt_mask() & CO::DESTINATION_KEY) {\n-    key_index.bonus = 1;\n+  if (cid->opt_mask() & CO::VARIADIC_KEYS) {\n     if (args.size() < 3) {\n       return OpStatus::SYNTAX_ERR;\n     }\n \n+    string_view name{cid->name()};\n+\n+    if (!absl::StartsWith(name, \"EVAL\")) {\n+      key_index.bonus = 1;  // Z<xxx>STORE commands\n+    }\n     string_view num(ArgS(args, 2));\n     if (!absl::SimpleAtoi(num, &num_custom_keys) || num_custom_keys < 0)\n       return OpStatus::INVALID_INT;\n@@ -1185,20 +1190,7 @@ OpResult<KeyIndex> DetermineKeys(const CommandId* cid, CmdArgList args) {\n     return key_index;\n   }\n \n-  string_view name{cid->name()};\n-  if (name == \"EVAL\" || name == \"EVALSHA\") {\n-    DCHECK_GE(args.size(), 3u);\n-    uint32_t num_keys;\n-\n-    CHECK(absl::SimpleAtoi(ArgS(args, 2), &num_keys));\n-    key_index.start = 3;\n-    key_index.end = 3 + num_keys;\n-    key_index.step = 1;\n-\n-    return key_index;\n-  }\n-\n-  LOG(FATAL) << \"TBD: Not supported\";\n+  LOG(FATAL) << \"TBD: Not supported \" << cid->name();\n \n   return key_index;\n }\ndiff --git a/src/server/zset_family.cc b/src/server/zset_family.cc\nindex 132b27fefb89..2630a5f2b110 100644\n--- a/src/server/zset_family.cc\n+++ b/src/server/zset_family.cc\n@@ -1875,7 +1875,7 @@ OpResult<unsigned> ZSetFamily::OpLexCount(const OpArgs& op_args, string_view key\n #define HFUNC(x) SetHandler(&ZSetFamily::x)\n \n void ZSetFamily::Register(CommandRegistry* registry) {\n-  constexpr uint32_t kUnionMask = CO::WRITE | CO::DESTINATION_KEY | CO::REVERSE_MAPPING;\n+  constexpr uint32_t kUnionMask = CO::WRITE | CO::VARIADIC_KEYS | CO::REVERSE_MAPPING;\n \n   *registry << CI{\"ZADD\", CO::FAST | CO::WRITE | CO::DENYOOM, -4, 1, 1, 1}.HFUNC(ZAdd)\n             << CI{\"ZCARD\", CO::FAST | CO::READONLY, 2, 1, 1, 1}.HFUNC(ZCard)\n",
  "test_patch": "diff --git a/src/server/dragonfly_test.cc b/src/server/dragonfly_test.cc\nindex 81f9069c057b..92d6548987b5 100644\n--- a/src/server/dragonfly_test.cc\n+++ b/src/server/dragonfly_test.cc\n@@ -24,10 +24,10 @@ namespace dfly {\n \n using namespace std;\n using namespace util;\n+using absl::StrCat;\n using ::io::Result;\n using testing::ElementsAre;\n using testing::HasSubstr;\n-using absl::StrCat;\n namespace this_fiber = boost::this_fiber;\n \n namespace {\n@@ -286,6 +286,11 @@ TEST_F(DflyEngineTest, Eval) {\n \n   resp = Run({\"eval\", \"return 77\", \"2\", \"foo\", \"zoo\"});\n   EXPECT_THAT(resp, IntArg(77));\n+\n+  // a,b important here to spawn multiple shards.\n+  resp = Run({\"eval\", \"return redis.call('exists', KEYS[2])\", \"2\", \"a\", \"b\"});\n+  EXPECT_EQ(2, GetDebugInfo().shards_count);\n+  EXPECT_THAT(resp, IntArg(0));\n }\n \n TEST_F(DflyEngineTest, EvalResp) {\n@@ -297,23 +302,40 @@ TEST_F(DflyEngineTest, EvalResp) {\n   EXPECT_THAT(resp.GetVec(), ElementsAre(IntArg(5), \"foo\", \"17.5\"));\n }\n \n-TEST_F(DflyEngineTest, Hello) {\n-  auto resp = Run({\"hello\"});\n-  ASSERT_THAT(resp, ArrLen(12));\n-  resp = Run({\"hello\", \"2\"});\n-  ASSERT_THAT(resp, ArrLen(12));\n+TEST_F(DflyEngineTest, EvalPublish) {\n+  auto resp = pp_->at(1)->Await([&] { return Run({\"subscribe\", \"foo\"}); });\n+  EXPECT_THAT(resp, ArrLen(3));\n \n-  EXPECT_THAT(resp.GetVec(), ElementsAre(\"server\", \"redis\", \"version\", ArgType(RespExpr::STRING),\n-                                         \"proto\", IntArg(2), \"id\", ArgType(RespExpr::INT64), \"mode\",\n-                                         \"standalone\", \"role\", \"master\"));\n+  resp = Run({\"eval\", \"return redis.call('publish', 'foo', 'bar')\", \"0\"});\n+  EXPECT_THAT(resp, IntArg(1));\n+}\n \n-  // These are valid arguments to HELLO, however as they are not yet supported the implementation\n-  // is degraded to 'unknown command'.\n-  EXPECT_THAT(Run({\"hello\", \"3\"}),\n-              ErrArg(\"ERR unknown command 'HELLO' with args beginning with: `3`\"));\n-  EXPECT_THAT(\n-      Run({\"hello\", \"2\", \"AUTH\", \"uname\", \"pwd\"}),\n-      ErrArg(\"ERR unknown command 'HELLO' with args beginning with: `2`, `AUTH`, `uname`, `pwd`\"));\n+TEST_F(DflyEngineTest, EvalBug59) {\n+  auto resp = Run({\"eval\", R\"(\n+local epoch\n+if redis.call('exists', KEYS[2]) ~= 0 then\n+  epoch = redis.call(\"hget\", KEYS[2], \"e\")\n+end\n+if epoch == false or epoch == nil then\n+  epoch = ARGV[6]\n+  redis.call(\"hset\", KEYS[2], \"e\", epoch)\n+end\n+local offset = redis.call(\"hincrby\", KEYS[2], \"s\", 1)\n+if ARGV[5] ~= '0' then\n+\tredis.call(\"expire\", KEYS[2], ARGV[5])\n+end\n+redis.call(\"xadd\", KEYS[1], \"MAXLEN\", ARGV[2], offset, \"d\", ARGV[1])\n+redis.call(\"expire\", KEYS[1], ARGV[3])\n+if ARGV[4] ~= '' then\n+\tlocal payload = \"__\" .. \"p1:\" .. offset .. \":\" .. epoch .. \"__\" .. ARGV[1]\n+\tredis.call(\"publish\", ARGV[4], payload)\n+end\n+\n+return {offset, epoch}\n+    )\",\n+                   \"2\", \"x\", \"y\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\"});\n+  ASSERT_THAT(resp, ArrLen(2));\n+  EXPECT_THAT(resp.GetVec(), ElementsAre(IntArg(1), \"6\"));\n }\n \n TEST_F(DflyEngineTest, EvalSha) {\n@@ -339,6 +361,25 @@ TEST_F(DflyEngineTest, EvalSha) {\n   EXPECT_THAT(resp, \"c6459b95a0e81df97af6fdd49b1a9e0287a57363\");\n }\n \n+TEST_F(DflyEngineTest, Hello) {\n+  auto resp = Run({\"hello\"});\n+  ASSERT_THAT(resp, ArrLen(12));\n+  resp = Run({\"hello\", \"2\"});\n+  ASSERT_THAT(resp, ArrLen(12));\n+\n+  EXPECT_THAT(resp.GetVec(), ElementsAre(\"server\", \"redis\", \"version\", ArgType(RespExpr::STRING),\n+                                         \"proto\", IntArg(2), \"id\", ArgType(RespExpr::INT64), \"mode\",\n+                                         \"standalone\", \"role\", \"master\"));\n+\n+  // These are valid arguments to HELLO, however as they are not yet supported the implementation\n+  // is degraded to 'unknown command'.\n+  EXPECT_THAT(Run({\"hello\", \"3\"}),\n+              ErrArg(\"ERR unknown command 'HELLO' with args beginning with: `3`\"));\n+  EXPECT_THAT(\n+      Run({\"hello\", \"2\", \"AUTH\", \"uname\", \"pwd\"}),\n+      ErrArg(\"ERR unknown command 'HELLO' with args beginning with: `2`, `AUTH`, `uname`, `pwd`\"));\n+}\n+\n TEST_F(DflyEngineTest, Memcache) {\n   using MP = MemcacheParser;\n \n@@ -437,9 +478,7 @@ TEST_F(DflyEngineTest, OOM) {\n }\n \n TEST_F(DflyEngineTest, PSubscribe) {\n-  auto resp = pp_->at(1)->Await([&] {\n-    return Run({\"psubscribe\", \"a*\", \"b*\"});\n-  });\n+  auto resp = pp_->at(1)->Await([&] { return Run({\"psubscribe\", \"a*\", \"b*\"}); });\n   EXPECT_THAT(resp, ArrLen(3));\n   resp = pp_->at(0)->Await([&] { return Run({\"publish\", \"ab\", \"foo\"}); });\n   EXPECT_THAT(resp, IntArg(1));\n",
  "problem_statement": "Support Stream data structure\nHello, came across Dragonfly on Hacker News. Very cool project \u2013 good luck with it!\r\n\r\nI am very interested in [Stream data structure](https://redis.io/docs/manual/data-types/streams/) support - think that's the only missing command for me to start experimenting with Dragonfly.\r\n\r\nSpecifically, in my use case I am using:\r\n\r\n* XADD\r\n* XRANGE\r\n* XREVRANGE\r\n\r\nHope this will be added at some point.\n",
  "hints_text": "Ok ok, I hear you load and clear. Your wish is my command.\n@FZambia  you do not use XREAD? how do you pull from the stream?\nYep, not using it \ud83d\ude00 In my use case I read stream content using two commands: XRANGE and XREVRANGE. The system is https://github.com/centrifugal/centrifugo. There is actually a combination of Redis PUB/SUB and Redis stream for message broadcasting.\r\n\r\nBut I suppose XREAD is definitely useful for most of other Redis users.\nSo how do you flush it? Or you use maxlimit to control the capacity?\n\nOn Sat, Jun 11, 2022, 17:43 Alexander Emelin ***@***.***>\nwrote:\n\n> Yep, not using it \ud83d\ude00 In my use case I read stream content using two\n> commands: XRANGE and XREVRANGE. The system is\n> https://github.com/centrifugal/centrifugo. There is actually a\n> combination of Redis PUB/SUB and Redis stream for message broadcasting.\n>\n> But I suppose XREAD is definitely useful for most of other Redis users.\n>\n> \u2014\n> Reply to this email directly, view it on GitHub\n> <https://github.com/dragonflydb/dragonfly/issues/59#issuecomment-1152941104>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AA4BFCA2EERM3V5SN2Q3DY3VOSQ2HANCNFSM5XMWYDZA>\n> .\n> You are receiving this because you commented.Message ID:\n> ***@***.***>\n>\n\n> So how do you flush it? Or you use maxlimit to control the capacity?\r\n\r\nYep, limiting size using `MAXLEN` option and having expiration time for the entire stream. I am using stream as a windowed log of messages.\nVery cool project, btw. https://centrifugal.dev/  beautiful site as well.\n\nOn Sat, Jun 11, 2022 at 6:18 PM Alexander Emelin ***@***.***>\nwrote:\n\n> So how do you flush it? Or you use maxlimit to control the capacity?\n>\n> Yep, limiting size using MAXLEN option and having expiration time for the\n> entire stream.\n>\n> \u2014\n> Reply to this email directly, view it on GitHub\n> <https://github.com/dragonflydb/dragonfly/issues/59#issuecomment-1152949256>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AA4BFCDBMWUXC4VAVLMVXM3VOSU3RANCNFSM5XMWYDZA>\n> .\n> You are receiving this because you commented.Message ID:\n> ***@***.***>\n>\n\n@FZambia  please take a look at https://github.com/dragonflydb/dragonfly/releases/tag/v0.3.0-alpha \r\n\r\nthis should support everything you need in streams.\r\n\nMany thanks! I'll try and report results here.\nExperimented a bit!\r\n\r\nDebian 11: `5.10.0-10-amd64 #1 SMP Debian 5.10.84-1 (2021-12-08) x86_64 GNU/Linux`\r\n\r\nIn a VM with shared CPU (`Intel Xeon Processor (Icelake)`).\r\n\r\nRedis version 6.0.16, Dragonflydb built from source from v0.3.0-alpha\r\n\r\nRedis benchmark for PUBLISH op (this is without STREAM - just a pipelined PUBLISH op):\r\n\r\n```\r\nBenchmarkRedisPublish_1Ch-2           \t  313024\t      3251 ns/op\r\n```\r\n\r\nDragonflydb (`./dragonfly --alsologtostderr`):\r\n\r\n```\r\nBenchmarkRedisPublish_1Ch-2           \t  138049\t     12593 ns/op\r\n```\r\n\r\nLatency is much higher in dragonflydb case. And throughput seems to be also less correspondingly (I am using pipelining over single connection \u2013 so latency affects throughput). I looked at CPU usage on a broker side during a benchmark \u2013 and it actually seems lower on dragonfly (2 times less than in Redis case). As I mentioned this is on 2-CPU VM, so maybe the real gain should come on multicore machines? Maybe the latency caused by some internal batching in dragonfly which collects commands for calling io-uring API? \r\n\r\nNow for checking streams. Unfortunately I was not able to make it work, I am using Lua and in Dragonflydb case I am getting an error `NOSCRIPT No matching script. Please use EVAL`.\r\n\r\nI was not able to reproduce this using `redis-cli` - LOAD'ed scripts are then executed fine with `EVALSHA`. Since `MONITOR` not available - can't quickly look which commands are sent to reproduce with `redis-cli`. I am using pipelining in bench - not sure can this be important or not (tried to use pipelining in console with simple script example \u2013 but also works fine..).\r\n\r\nOne interesting thing BTW, managed to put dragonfly into busy loop (100% CPU all the time, not responding to commands anymore) with this:\r\n\r\n```\r\nredis-cli\r\nSCRIPT LOAD \"return ARGV[1]\"\r\nEVALSHA 098e0f0d1448c0a81dafe820f66d460eb09263da 2 s d arg1\r\n```\r\n\r\nResult is never returned, Redis worked fine with this.\r\n\r\n\r\n\nThanks for letting me know! Is it possible to reproduce  `BenchmarkRedisPublish_1Ch-2` ?\r\n\r\nIs it possible to reproduce the streaming case?\r\n\r\nre latency and throughput - yes, the internal latency avg latency in DF may be higher than in Redis due to message passing between threads. \r\n\r\nre - monitor - you can run dragonfly with `./dragonfly --vmodule=main_service=2` and get all the commands in the log.\r\nit's stored as `/tmp/dragonfly.INFO`\nIn addition - see https://github.com/dragonflydb/dragonfly/issues/113\r\n\r\napparently, Debian 11 has a performance problem with DF but I am not sure it applies in this case.\n> re - monitor - you can run dragonfly with ./dragonfly --vmodule=main_service=2\r\n\r\nThx, this was useful\r\n\r\n> Thanks for letting me know! Is it possible to reproduce BenchmarkRedisPublish_1Ch-2 ?\r\n\r\nYou need Go language installed:\r\n\r\n```\r\ngit clone https://github.com/centrifugal/centrifuge.git\r\ncd centrifuge\r\ngo test -run xxx -benchmem -tags integration -bench BenchmarkRedisPublish_1Ch -benchtime 1s\r\n```\r\n\r\n> Is it possible to reproduce the streaming case?\r\n\r\nThink I found the reason. In Redis:\r\n\r\n```\r\n127.0.0.1:6379> SCRIPT LOAD \"\\nlocal epoch\\nif redis.call(\\'exists\\', KEYS[2]) ~= 0 then\\n  epoch = redis.call(\\\"hget\\\", KEYS[2], \\\"e\\\")\\nend\\nif epoch == false or epoch == nil then\\n  epoch = ARGV[6]\\n  redis.call(\\\"hset\\\", KEYS[2], \\\"e\\\", epoch)\\nend\\nlocal offset = redis.call(\\\"hincrby\\\", KEYS[2], \\\"s\\\", 1)\\nif ARGV[5] ~= \\'0\\' then\\n\\tredis.call(\\\"expire\\\", KEYS[2], ARGV[5])\\nend\\nredis.call(\\\"xadd\\\", KEYS[1], \\\"MAXLEN\\\", ARGV[2], offset, \\\"d\\\", ARGV[1])\\nredis.call(\\\"expire\\\", KEYS[1], ARGV[3])\\nif ARGV[4] ~= \\'\\' then\\n\\tlocal payload = \\\"__\\\" .. \\\"p1:\\\" .. offset .. \\\":\\\" .. epoch .. \\\"__\\\" .. ARGV[1]\\n\\tredis.call(\\\"publish\\\", ARGV[4], payload)\\nend\\nreturn {offset, epoch}\\n\\t\"\r\n\"5707131deda7789195310ee90da9fab71faf2e68\"\r\n```\r\n\r\nIn Dragonfly:\r\n\r\n```\r\nSCRIPT LOAD \"\\nlocal epoch\\nif redis.call(\\'exists\\', KEYS[2]) ~= 0 then\\n  epoch = redis.call(\\\"hget\\\", KEYS[2], \\\"e\\\")\\nend\\nif epoch == false or epoch == nil then\\n  epoch = ARGV[6]\\n  redis.call(\\\"hset\\\", KEYS[2], \\\"e\\\", epoch)\\nend\\nlocal offset = redis.call(\\\"hincrby\\\", KEYS[2], \\\"s\\\", 1)\\nif ARGV[5] ~= \\'0\\' then\\n\\tredis.call(\\\"expire\\\", KEYS[2], ARGV[5])\\nend\\nredis.call(\\\"xadd\\\", KEYS[1], \\\"MAXLEN\\\", ARGV[2], offset, \\\"d\\\", ARGV[1])\\nredis.call(\\\"expire\\\", KEYS[1], ARGV[3])\\nif ARGV[4] ~= \\'\\' then\\n\\tlocal payload = \\\"__\\\" .. \\\"p1:\\\" .. offset .. \\\":\\\" .. epoch .. \\\"__\\\" .. ARGV[1]\\n\\tredis.call(\\\"publish\\\", ARGV[4], payload)\\nend\\nreturn {offset, epoch}\\n\\t\"\r\n\"002c257c910c6033e88c9280f4fe9bb08fa3b131\"\r\n```\r\n\r\nI.e. different SHA-sums. I am using Redigo client - https://github.com/gomodule/redigo - it calculates script sha sum [on client side](https://github.com/gomodule/redigo/blob/master/redis/script.go#L39). It matches the one from Redis, but as you can see Dragonfly hashes to a different sum for some reason.\r\n\r\nOne more thing, even if I try to execute a script above with hash sum returned by Dragonfly I still get hanging and 100% CPU, i.e.:\r\n\r\n```\r\nEVALSHA 002c257c910c6033e88c9280f4fe9bb08fa3b131 2 x y 1 2 3 4 5 6\r\n``` \r\n\r\nIn Redis the same script works with the same EVALSHA.\r\n\nOk, it's me being a smartass: https://github.com/dragonflydb/dragonfly/blob/main/src/server/main_service.cc#L705\r\n\r\nI will follow up on your feedback, thank you very much, Alexander!\n@FZambia  I checked the loadtest you provided.  I can confirm that with such setup Redis will provide more throughput than Dragonfly. The reason for this is that DF uses message passing between threads (similar to go channels).  Therefore a single PUBLISH request will incur 10-20us server-side latency compared to 1-2us for Redis. However, if you use multiple connections with DF, things will change dramatically. DF connections are asynchronous, meaning that even one the first one waits for an answer from the message bus, others will still progress.  With dozens of incoming connections the latency factor will stop being important and DF will provide much better throughput with enough CPU power.\n@romange many thanks for the explanation! Actually it sounds good \u2013 in practice many server nodes connect to Redis, having a higher throughput is more important. Will be experimenting with different cases in the future.\r\n\r\nAlso, thanks for fixing LUA issues. Hope to try this all again very soon.\nFailed \ud83d\ude00 \r\n\r\n```\r\nSCRIPT LOAD \"\\nlocal epoch\\nif redis.call(\\'exists\\', KEYS[2]) ~= 0 then\\n  epoch = redis.call(\\\"hget\\\", KEYS[2], \\\"e\\\")\\nend\\nif epoch == false or epoch == nil then\\n  epoch = ARGV[6]\\n  redis.call(\\\"hset\\\", KEYS[2], \\\"e\\\", epoch)\\nend\\nlocal offset = redis.call(\\\"hincrby\\\", KEYS[2], \\\"s\\\", 1)\\nif ARGV[5] ~= \\'0\\' then\\n\\tredis.call(\\\"expire\\\", KEYS[2], ARGV[5])\\nend\\nredis.call(\\\"xadd\\\", KEYS[1], \\\"MAXLEN\\\", ARGV[2], offset, \\\"d\\\", ARGV[1])\\nredis.call(\\\"expire\\\", KEYS[1], ARGV[3])\\nif ARGV[4] ~= \\'\\' then\\n\\tlocal payload = \\\"__\\\" .. \\\"p1:\\\" .. offset .. \\\":\\\" .. epoch .. \\\"__\\\" .. ARGV[1]\\n\\tredis.call(\\\"publish\\\", ARGV[4], payload)\\nend\\nreturn {offset, epoch}\\n\\t\"\r\n\r\nEVALSHA 5707131deda7789195310ee90da9fab71faf2e68 2 x y 1 2 3 4 5 6\r\n```\r\n\r\n```\r\nF20220615 21:27:01.492447 18153 transaction.cc:1201] TBD: Not supported\r\n*** Check failure stack trace: ***\r\n    @     0x5653be2bed3a  google::LogMessage::Fail()\r\n    @     0x5653be2c51a7  google::LogMessage::SendToLog()\r\n    @     0x5653be2be72d  google::LogMessage::Flush()\r\n    @     0x5653be2bff59  google::LogMessageFatal::~LogMessageFatal()\r\n    @     0x5653be1a666a  dfly::DetermineKeys()\r\n    @     0x5653be148637  dfly::Service::DispatchCommand()\r\n    @     0x5653be1501b6  _ZNSt17_Function_handlerIFvN4absl12lts_202111024SpanINS2_IcEEEEPN4dfly14ObjectExplorerEEZNS5_7Service12EvalInternalERKNS9_8EvalArgsEPNS5_11InterpreterEPNS5_17ConnectionContextEEUlS4_S7_E_E9_M_invokeERKSt9_Any_dataOS4_OS7_.lto_priv.0\r\n    @     0x5653be201e60  dfly::Interpreter::RedisGenericCommand()\r\n    @     0x5653be276ea1  luaD_precall\r\n    @     0x5653be284ec8  luaV_execute\r\n    @     0x5653be277210  luaD_callnoyield\r\n    @     0x5653be2761ca  luaD_rawrunprotected\r\n    @     0x5653be277560  luaD_pcall\r\n    @     0x5653be273f3a  lua_pcallk\r\n    @     0x5653be146e07  dfly::Service::EvalInternal()\r\n    @     0x5653be14b304  dfly::Service::EvalSha()\r\n    @     0x5653be147f4f  dfly::Service::DispatchCommand()\r\n    @     0x5653be209862  facade::Connection::ParseRedis()\r\n    @     0x5653be20c902  facade::Connection::HandleRequests()\r\n    @     0x5653be22f7e4  util::ListenerInterface::RunSingleConnection()\r\n    @     0x5653be22fa92  _ZN5boost6fibers14worker_contextIZN4util17ListenerInterface13RunAcceptLoopEvEUlvE0_JEE4run_EONS_7context5fiberE\r\n    @     0x5653be22c300  _ZN5boost7context6detail11fiber_entryINS1_12fiber_recordINS0_5fiberENS0_21basic_fixedsize_stackINS0_12stack_traitsEEESt5_BindIFMNS_6fibers14worker_contextIZN4util17ListenerInterface13RunAcceptLoopEvEUlvE0_JEEEFS4_OS4_EPSE_St12_PlaceholderILi1EEEEEEEEvNS1_10transfer_tE\r\n    @     0x7faae91ce19f  make_fcontext\r\n*** SIGABRT received at time=1655328421 on cpu 0 ***\r\nPC: @     0x7faae8c61ce1  (unknown)  raise\r\n    @ ... and at least 1 more frames\r\nAborted\r\n```",
  "created_at": "2022-06-16T10:21:45Z",
  "modified_files": [
    "src/server/command_registry.cc",
    "src/server/command_registry.h",
    "src/server/main_service.cc",
    "src/server/transaction.cc",
    "src/server/zset_family.cc"
  ],
  "modified_test_files": [
    "src/server/dragonfly_test.cc"
  ]
}