{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 3241,
  "instance_id": "dragonflydb__dragonfly-3241",
  "issue_numbers": [
    "3223"
  ],
  "base_commit": "e1b03d605c5376fe36d8a45633ee964f52a70af0",
  "patch": "diff --git a/src/server/db_slice.cc b/src/server/db_slice.cc\nindex cd67ffad70d9..62d463781bd8 100644\n--- a/src/server/db_slice.cc\n+++ b/src/server/db_slice.cc\n@@ -220,6 +220,24 @@ unsigned PrimeEvictionPolicy::Evict(const PrimeTable::HotspotBuckets& eb, PrimeT\n   return 1;\n }\n \n+// Helper class to cache and restore fetched_items_ of DbSlice for flows that preempt\n+// because some other transaction might conclude and clear the fetched_items_ with OnCbFinish()\n+class FetchedItemsRestorer {\n+ public:\n+  using RestoreType = absl::flat_hash_set<CompactObjectView>;\n+  explicit FetchedItemsRestorer(RestoreType* dst) : dst_to_restore_(dst) {\n+    cached_ = std::move(*dst_to_restore_);\n+  }\n+\n+  ~FetchedItemsRestorer() {\n+    *dst_to_restore_ = std::move(cached_);\n+  }\n+\n+ private:\n+  RestoreType cached_;\n+  RestoreType* dst_to_restore_;\n+};\n+\n }  // namespace\n \n #define ADD(x) (x) += o.x\n@@ -455,7 +473,6 @@ OpResult<DbSlice::PrimeItAndExp> DbSlice::FindInternal(const Context& cntx, std:\n     return OpStatus::WRONG_TYPE;\n   }\n \n-  FiberAtomicGuard fg;\n   if (res.it->second.HasExpire()) {  // check expiry state\n     res = ExpireIfNeeded(cntx, res.it);\n     if (!IsValid(res.it)) {\n@@ -971,8 +988,6 @@ bool DbSlice::CheckLock(IntentLock::Mode mode, DbIndex dbid, uint64_t fp) const\n }\n \n void DbSlice::PreUpdate(DbIndex db_ind, Iterator it, std::string_view key) {\n-  FiberAtomicGuard fg;\n-\n   DVLOG(2) << \"Running callbacks in dbid \" << db_ind;\n   CallChangeCallbacks(db_ind, ChangeReq{it.GetInnerIt()});\n \n@@ -1105,7 +1120,8 @@ uint64_t DbSlice::RegisterOnChange(ChangeCallback cb) {\n }\n \n void DbSlice::FlushChangeToEarlierCallbacks(DbIndex db_ind, Iterator it, uint64_t upper_bound) {\n-  FiberAtomicGuard fg;\n+  FetchedItemsRestorer fetched_restorer(&fetched_items_);\n+\n   uint64_t bucket_version = it.GetVersion();\n   // change_cb_ is ordered by version.\n   DVLOG(2) << \"Running callbacks in dbid \" << db_ind << \" with bucket_version=\" << bucket_version\n@@ -1532,6 +1548,7 @@ void DbSlice::OnCbFinish() {\n }\n \n void DbSlice::CallChangeCallbacks(DbIndex id, const ChangeReq& cr) const {\n+  FetchedItemsRestorer fetched_restorer(&fetched_items_);\n   for (const auto& ccb : change_cb_) {\n     ccb.second(id, cr);\n   }\ndiff --git a/src/server/rdb_save.cc b/src/server/rdb_save.cc\nindex 9166bdc97906..d39374adc8e0 100644\n--- a/src/server/rdb_save.cc\n+++ b/src/server/rdb_save.cc\n@@ -292,7 +292,9 @@ SerializerBase::SerializerBase(CompressionMode compression_mode)\n     : compression_mode_(compression_mode), mem_buf_{4_KB}, tmp_buf_(nullptr) {\n }\n \n-RdbSerializer::RdbSerializer(CompressionMode compression_mode) : SerializerBase(compression_mode) {\n+RdbSerializer::RdbSerializer(CompressionMode compression_mode,\n+                             std::function<bool(size_t)> flush_fun)\n+    : SerializerBase(compression_mode), flush_fun_(std::move(flush_fun)) {\n }\n \n RdbSerializer::~RdbSerializer() {\n@@ -430,6 +432,7 @@ error_code RdbSerializer::SaveListObject(const PrimeValue& pv) {\n         RETURN_ON_ERR(SaveLzfBlob(Bytes{reinterpret_cast<uint8_t*>(data), compress_len}, node->sz));\n       } else {\n         RETURN_ON_ERR(SaveString(node->entry, node->sz));\n+        FlushIfNeeded();\n       }\n     } else {\n       // listpack\n@@ -474,6 +477,7 @@ error_code RdbSerializer::SaveSetObject(const PrimeValue& obj) {\n           expiry = it.ExpiryTime();\n         RETURN_ON_ERR(SaveLongLongAsString(expiry));\n       }\n+      FlushIfNeeded();\n     }\n   } else {\n     CHECK_EQ(obj.Encoding(), kEncodingIntSet);\n@@ -504,6 +508,7 @@ error_code RdbSerializer::SaveHSetObject(const PrimeValue& pv) {\n           expiry = it.ExpiryTime();\n         RETURN_ON_ERR(SaveLongLongAsString(expiry));\n       }\n+      FlushIfNeeded();\n     }\n   } else {\n     CHECK_EQ(kEncodingListPack, pv.Encoding());\n@@ -537,6 +542,7 @@ error_code RdbSerializer::SaveZSetObject(const PrimeValue& pv) {\n       ec = SaveBinaryDouble(score);\n       if (ec)\n         return false;\n+      FlushIfNeeded();\n       return true;\n     });\n   } else {\n@@ -647,6 +653,7 @@ std::error_code RdbSerializer::SaveSBFObject(const PrimeValue& pv) {\n \n     string_view blob = sbf->data(i);\n     RETURN_ON_ERR(SaveString(blob));\n+    FlushIfNeeded();\n   }\n \n   return {};\n@@ -1118,6 +1125,7 @@ class RdbSaver::Impl {\n   // Multi entry compression is available only on df snapshot, this will\n   // make snapshot size smaller and opreation faster.\n   CompressionMode compression_mode_;\n+  SaveMode save_mode_;\n };\n \n // We pass K=sz to say how many producers are pushing data in order to maintain\n@@ -1139,6 +1147,7 @@ RdbSaver::Impl::Impl(bool align_writes, unsigned producers_len, CompressionMode\n   }\n \n   DCHECK(producers_len > 0 || channel_.IsClosing());\n+  save_mode_ = sm;\n }\n \n void RdbSaver::Impl::CleanShardSnapshots() {\n@@ -1253,7 +1262,9 @@ void RdbSaver::Impl::StartSnapshotting(bool stream_journal, const Cancellation*\n   auto& s = GetSnapshot(shard);\n   s = std::make_unique<SliceSnapshot>(&shard->db_slice(), &channel_, compression_mode_);\n \n-  s->Start(stream_journal, cll);\n+  const auto allow_flush = (save_mode_ != SaveMode::RDB) ? SliceSnapshot::SnapshotFlush::kAllow\n+                                                         : SliceSnapshot::SnapshotFlush::kDisallow;\n+  s->Start(stream_journal, cll, allow_flush);\n }\n \n void RdbSaver::Impl::StartIncrementalSnapshotting(Context* cntx, EngineShard* shard,\n@@ -1594,4 +1605,11 @@ size_t RdbSerializer::GetTempBufferSize() const {\n   return SerializerBase::GetTempBufferSize() + tmp_str_.size();\n }\n \n+bool RdbSerializer::FlushIfNeeded() {\n+  if (flush_fun_) {\n+    return flush_fun_(SerializedLen());\n+  }\n+  return false;\n+}\n+\n }  // namespace dfly\ndiff --git a/src/server/rdb_save.h b/src/server/rdb_save.h\nindex cd6b2461a0a4..22b3a6d2db20 100644\n--- a/src/server/rdb_save.h\n+++ b/src/server/rdb_save.h\n@@ -199,7 +199,8 @@ class SerializerBase {\n \n class RdbSerializer : public SerializerBase {\n  public:\n-  explicit RdbSerializer(CompressionMode compression_mode);\n+  explicit RdbSerializer(CompressionMode compression_mode,\n+                         std::function<bool(size_t)> flush_fun = {});\n \n   ~RdbSerializer();\n \n@@ -215,7 +216,8 @@ class RdbSerializer : public SerializerBase {\n   // This would work for either string or an object.\n   // The arg pv is taken from it->second if accessing\n   // this by finding the key. This function is used\n-  // for the dump command - thus it is public function\n+  // for the dump command - thus it is public function.\n+  // This function might preempt if flush_fun_ is used.\n   std::error_code SaveValue(const PrimeValue& pv);\n \n   std::error_code SendJournalOffset(uint64_t journal_offset);\n@@ -223,6 +225,7 @@ class RdbSerializer : public SerializerBase {\n   size_t GetTempBufferSize() const override;\n \n  private:\n+  // Might preempt if flush_fun_ is used\n   std::error_code SaveObject(const PrimeValue& pv);\n   std::error_code SaveListObject(const PrimeValue& pv);\n   std::error_code SaveSetObject(const PrimeValue& pv);\n@@ -238,8 +241,12 @@ class RdbSerializer : public SerializerBase {\n   std::error_code SaveStreamPEL(rax* pel, bool nacks);\n   std::error_code SaveStreamConsumers(streamCG* cg);\n \n+  // Might preempt\n+  bool FlushIfNeeded();\n+\n   std::string tmp_str_;\n   DbIndex last_entry_db_index_ = kInvalidDbId;\n+  std::function<bool(size_t)> flush_fun_;\n };\n \n }  // namespace dfly\ndiff --git a/src/server/snapshot.cc b/src/server/snapshot.cc\nindex 6ddeee3ff1d3..f3036005453e 100644\n--- a/src/server/snapshot.cc\n+++ b/src/server/snapshot.cc\n@@ -10,6 +10,7 @@\n \n #include <mutex>\n \n+#include \"base/flags.h\"\n #include \"base/logging.h\"\n #include \"core/heap_size.h\"\n #include \"server/db_slice.h\"\n@@ -20,6 +21,8 @@\n #include \"server/tiered_storage.h\"\n #include \"util/fibers/synchronization.h\"\n \n+ABSL_FLAG(size_t, serialization_max_chunk_size, 0, \"Total bytes before flushing big entries\");\n+\n namespace dfly {\n \n using namespace std;\n@@ -56,7 +59,7 @@ bool SliceSnapshot::IsSnaphotInProgress() {\n   return tl_slice_snapshots.size() > 0;\n }\n \n-void SliceSnapshot::Start(bool stream_journal, const Cancellation* cll) {\n+void SliceSnapshot::Start(bool stream_journal, const Cancellation* cll, SnapshotFlush allow_flush) {\n   DCHECK(!snapshot_fb_.IsJoinable());\n \n   auto db_cb = absl::bind_front(&SliceSnapshot::OnDbChange, this);\n@@ -69,7 +72,19 @@ void SliceSnapshot::Start(bool stream_journal, const Cancellation* cll) {\n     journal_cb_id_ = journal->RegisterOnChange(std::move(journal_cb));\n   }\n \n-  serializer_ = std::make_unique<RdbSerializer>(compression_mode_);\n+  const auto flush_threshold = absl::GetFlag(FLAGS_serialization_max_chunk_size);\n+  std::function<bool(size_t)> flush_fun;\n+  if (flush_threshold != 0 && allow_flush == SnapshotFlush::kAllow) {\n+    flush_fun = [this, flush_threshold](size_t bytes_serialized) {\n+      if (bytes_serialized > flush_threshold) {\n+        auto serialized = Serialize();\n+        VLOG(2) << \"FlushedToChannel \" << serialized << \" bytes\";\n+        return true;\n+      }\n+      return false;\n+    };\n+  }\n+  serializer_ = std::make_unique<RdbSerializer>(compression_mode_, flush_fun);\n \n   VLOG(1) << \"DbSaver::Start - saving entries with version less than \" << snapshot_version_;\n \n@@ -276,7 +291,7 @@ unsigned SliceSnapshot::SerializeBucket(DbIndex db_index, PrimeTable::bucket_ite\n \n   while (!it.is_done()) {\n     ++result;\n-    // might yield\n+    // might preempt\n     SerializeEntry(db_index, it->first, it->second, nullopt, serializer_.get());\n     ++it;\n   }\n@@ -284,8 +299,6 @@ unsigned SliceSnapshot::SerializeBucket(DbIndex db_index, PrimeTable::bucket_ite\n   return result;\n }\n \n-// This function should not block and should not preempt because it's called\n-// from SerializeBucket which should execute atomically.\n void SliceSnapshot::SerializeEntry(DbIndex db_indx, const PrimeKey& pk, const PrimeValue& pv,\n                                    optional<uint64_t> expire, RdbSerializer* serializer) {\n   time_t expire_time = expire.value_or(0);\n@@ -309,18 +322,7 @@ void SliceSnapshot::SerializeEntry(DbIndex db_indx, const PrimeKey& pk, const Pr\n   }\n }\n \n-bool SliceSnapshot::PushSerializedToChannel(bool force) {\n-  // Bucket serialization might have accumulated some delayed values.\n-  // Because we can finally block in this function, we'll await and serialize them\n-  while (!delayed_entries_.empty()) {\n-    auto& entry = delayed_entries_.back();\n-    serializer_->SaveEntry(entry.key, entry.value.Get(), entry.expire, entry.dbid);\n-    delayed_entries_.pop_back();\n-  }\n-\n-  if (!force && serializer_->SerializedLen() < 4096)\n-    return false;\n-\n+size_t SliceSnapshot::Serialize() {\n   io::StringFile sfile;\n   serializer_->FlushToSink(&sfile);\n \n@@ -333,9 +335,29 @@ bool SliceSnapshot::PushSerializedToChannel(bool force) {\n   DbRecord db_rec{.id = id, .value = std::move(sfile.val)};\n \n   dest_->Push(std::move(db_rec));\n+  if (serialized != 0) {\n+    VLOG(2) << \"Pushed with Serialize() \" << serialized << \" bytes\";\n+  }\n+  return serialized;\n+}\n \n-  VLOG(2) << \"PushSerializedToChannel \" << serialized << \" bytes\";\n-  return true;\n+bool SliceSnapshot::PushSerializedToChannel(bool force) {\n+  if (!force && serializer_->SerializedLen() < 4096)\n+    return false;\n+\n+  // Flush any of the leftovers to avoid interleavings\n+  const auto serialized = Serialize();\n+\n+  // Bucket serialization might have accumulated some delayed values.\n+  // Because we can finally block in this function, we'll await and serialize them\n+  while (!delayed_entries_.empty()) {\n+    auto& entry = delayed_entries_.back();\n+    serializer_->SaveEntry(entry.key, entry.value.Get(), entry.expire, entry.dbid);\n+    delayed_entries_.pop_back();\n+  }\n+\n+  const auto total_serialized = Serialize() + serialized;\n+  return total_serialized > 0;\n }\n \n void SliceSnapshot::OnDbChange(DbIndex db_index, const DbSlice::ChangeReq& req) {\n@@ -377,6 +399,8 @@ void SliceSnapshot::OnJournalEntry(const journal::JournalItem& item, bool await)\n }\n \n void SliceSnapshot::CloseRecordChannel() {\n+  ConditionGuard guard(&bucket_ser_);\n+\n   CHECK(!serialize_bucket_running_);\n   // Make sure we close the channel only once with a CAS check.\n   bool expected = false;\ndiff --git a/src/server/snapshot.h b/src/server/snapshot.h\nindex af58cf4d9138..95529dca3beb 100644\n--- a/src/server/snapshot.h\n+++ b/src/server/snapshot.h\n@@ -67,7 +67,10 @@ class SliceSnapshot {\n \n   // Initialize snapshot, start bucket iteration fiber, register listeners.\n   // In journal streaming mode it needs to be stopped by either Stop or Cancel.\n-  void Start(bool stream_journal, const Cancellation* cll);\n+  enum class SnapshotFlush { kAllow, kDisallow };\n+\n+  void Start(bool stream_journal, const Cancellation* cll,\n+             SnapshotFlush allow_flush = SnapshotFlush::kDisallow);\n \n   // Initialize a snapshot that sends only the missing journal updates\n   // since start_lsn and then registers a callback switches into the\n@@ -117,6 +120,9 @@ class SliceSnapshot {\n   // Return if pushed.\n   bool PushSerializedToChannel(bool force);\n \n+  // Helper function that flushes the serialized items into the RecordStream\n+  size_t Serialize();\n+\n  public:\n   uint64_t snapshot_version() const {\n     return snapshot_version_;\n",
  "test_patch": "diff --git a/tests/dragonfly/replication_test.py b/tests/dragonfly/replication_test.py\nindex cca33c9d59c9..505b20a534f9 100644\n--- a/tests/dragonfly/replication_test.py\n+++ b/tests/dragonfly/replication_test.py\n@@ -38,28 +38,42 @@ async def wait_for_replicas_state(*clients, state=\"stable_sync\", timeout=0.05):\n \n \n @pytest.mark.parametrize(\n-    \"t_master, t_replicas, seeder_config, stream_target\",\n+    \"t_master, t_replicas, seeder_config, stream_target, big_value\",\n     [\n         # Quick general test that replication is working\n-        (1, 3 * [1], dict(key_target=1_000), 500),\n-        (4, [4, 4], dict(key_target=10_000), 1_000),\n-        pytest.param(6, [6, 6, 6], dict(key_target=100_000), 20_000, marks=M_OPT),\n+        (1, 3 * [1], dict(key_target=1_000), 500, False),\n+        (4, [4, 4], dict(key_target=10_000), 1_000, False),\n+        pytest.param(6, [6, 6, 6], dict(key_target=100_000), 20_000, False, marks=M_OPT),\n         # Skewed tests with different thread ratio\n-        pytest.param(8, 6 * [1], dict(key_target=5_000), 2_000, marks=M_SLOW),\n-        pytest.param(2, [8, 8], dict(key_target=10_000), 2_000, marks=M_SLOW),\n+        pytest.param(8, 6 * [1], dict(key_target=5_000), 2_000, False, marks=M_SLOW),\n+        pytest.param(2, [8, 8], dict(key_target=10_000), 2_000, False, marks=M_SLOW),\n         # Test with big value size\n-        pytest.param(2, [2], dict(key_target=1_000, data_size=10_000), 100, marks=M_SLOW),\n+        pytest.param(2, [2], dict(key_target=1_000, data_size=10_000), 100, False, marks=M_SLOW),\n+        # Test with big value and big value serialization\n+        pytest.param(2, [2], dict(key_target=1_000, data_size=10_000), 100, True, marks=M_SLOW),\n         # Stress test\n-        pytest.param(8, [8, 8], dict(key_target=1_000_000, units=16), 50_000, marks=M_STRESS),\n+        pytest.param(\n+            8, [8, 8], dict(key_target=1_000_000, units=16), 50_000, False, marks=M_STRESS\n+        ),\n     ],\n )\n @pytest.mark.parametrize(\"mode\", [({}), ({\"cache_mode\": \"true\"})])\n async def test_replication_all(\n-    df_factory: DflyInstanceFactory, t_master, t_replicas, seeder_config, stream_target, mode\n+    df_factory: DflyInstanceFactory,\n+    t_master,\n+    t_replicas,\n+    seeder_config,\n+    stream_target,\n+    big_value,\n+    mode,\n ):\n     if mode:\n         mode[\"maxmemory\"] = str(t_master * 256) + \"mb\"\n \n+    if big_value:\n+        mode[\"compression_mode\"] = 0\n+        mode[\"flush_big_entries_threshold\"] = 4096\n+\n     master = df_factory.create(admin_port=ADMIN_PORT, proactor_threads=t_master, **mode)\n     replicas = [\n         df_factory.create(admin_port=ADMIN_PORT + i + 1, proactor_threads=t)\n",
  "problem_statement": "Serialize bucket in chunks and allow preemption\nImplement chunking of slots per bucket allowing to preempt when the key/value is big enough.\n",
  "hints_text": "",
  "created_at": "2024-06-28T17:18:24Z",
  "modified_files": [
    "src/server/db_slice.cc",
    "src/server/rdb_save.cc",
    "src/server/rdb_save.h",
    "src/server/snapshot.cc",
    "src/server/snapshot.h"
  ],
  "modified_test_files": [
    "tests/dragonfly/replication_test.py"
  ]
}