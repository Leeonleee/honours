{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 3667,
  "instance_id": "dragonflydb__dragonfly-3667",
  "issue_numbers": [
    "3658"
  ],
  "base_commit": "14ac055a47c70003ed763811dc879283bfcef9ab",
  "patch": "diff --git a/src/core/size_tracking_channel.h b/src/core/size_tracking_channel.h\nindex df7f442fd688..894a82a5ccc1 100644\n--- a/src/core/size_tracking_channel.h\n+++ b/src/core/size_tracking_channel.h\n@@ -22,9 +22,11 @@ template <typename T, typename Queue = folly::ProducerConsumerQueue<T>> class Si\n \n   // Here and below, we must accept a T instead of building it from variadic args, as we need to\n   // know its size in case it is added.\n-  void Push(T t) noexcept {\n-    size_.fetch_add(t.size(), std::memory_order_relaxed);\n+  size_t Push(T t) noexcept {\n+    size_t tsize = t.size();\n+    size_t res = size_.fetch_add(tsize, std::memory_order_relaxed);\n     queue_.Push(std::move(t));\n+    return res + tsize;\n   }\n \n   bool TryPush(T t) noexcept {\ndiff --git a/src/server/rdb_save.cc b/src/server/rdb_save.cc\nindex 1d25c496bf4c..c9b917d709ee 100644\n--- a/src/server/rdb_save.cc\n+++ b/src/server/rdb_save.cc\n@@ -1071,42 +1071,6 @@ error_code AlignedBuffer::Flush() {\n \n class RdbSaver::Impl {\n  private:\n-  // This is a helper struct to pop records from channel while enfocing returned records order.\n-  struct RecordsPopper {\n-    RecordsPopper(bool enforce_order, SliceSnapshot::RecordChannel* c)\n-        : enforce_order(enforce_order), channel(c) {\n-    }\n-\n-    // Blocking function, pops from channel.\n-    // If enforce_order is enabled return the records by order.\n-    // returns nullopt if channel was closed.\n-    std::optional<SliceSnapshot::DbRecord> Pop();\n-\n-    // Non blocking function, trys to pop from channel.\n-    // If enforce_order is enabled return the records by order.\n-    // returns nullopt if nothing in channel.\n-    std::optional<SliceSnapshot::DbRecord> TryPop();\n-\n-   private:\n-    std::optional<SliceSnapshot::DbRecord> InternalPop(bool blocking);\n-    // Checks if next record is in queue, if so set record_holder and return true, otherwise\n-    // return false.\n-    bool TryPopFromQueue();\n-\n-    struct Compare {\n-      bool operator()(const SliceSnapshot::DbRecord& a, const SliceSnapshot::DbRecord& b) {\n-        return a.id > b.id;\n-      }\n-    };\n-    // min heap holds the DbRecord that poped from channel OOO\n-    std::priority_queue<SliceSnapshot::DbRecord, std::vector<SliceSnapshot::DbRecord>, Compare>\n-        q_records;\n-    uint64_t next_record_id = 0;\n-    bool enforce_order;\n-    SliceSnapshot::RecordChannel* channel;\n-    SliceSnapshot::DbRecord record_holder;\n-  };\n-\n   void CleanShardSnapshots();\n \n  public:\n@@ -1161,7 +1125,6 @@ class RdbSaver::Impl {\n   // used for serializing non-body components in the calling fiber.\n   RdbSerializer meta_serializer_;\n   SliceSnapshot::RecordChannel channel_;\n-  bool push_to_sink_with_order_ = false;\n   std::optional<AlignedBuffer> aligned_buf_;\n \n   // Single entry compression is compatible with redis rdb snapshot\n@@ -1185,9 +1148,6 @@ RdbSaver::Impl::Impl(bool align_writes, unsigned producers_len, CompressionMode\n     aligned_buf_.emplace(kBufLen, sink);\n     sink_ = &aligned_buf_.value();\n   }\n-  if (sm == SaveMode::SINGLE_SHARD || sm == SaveMode::SINGLE_SHARD_WITH_SUMMARY) {\n-    push_to_sink_with_order_ = true;\n-  }\n \n   DCHECK(producers_len > 0 || channel_.IsClosing());\n   save_mode_ = sm;\n@@ -1223,56 +1183,15 @@ error_code RdbSaver::Impl::SaveAuxFieldStrStr(string_view key, string_view val)\n   return error_code{};\n }\n \n-bool RdbSaver::Impl::RecordsPopper::TryPopFromQueue() {\n-  if (enforce_order && !q_records.empty() && q_records.top().id == next_record_id) {\n-    record_holder = std::move(const_cast<SliceSnapshot::DbRecord&>(q_records.top()));\n-    q_records.pop();\n-    ++next_record_id;\n-    return true;\n-  }\n-  return false;\n-}\n-\n-std::optional<SliceSnapshot::DbRecord> RdbSaver::Impl::RecordsPopper::Pop() {\n-  return InternalPop(true);\n-}\n-\n-std::optional<SliceSnapshot::DbRecord> RdbSaver::Impl::RecordsPopper::TryPop() {\n-  return InternalPop(false);\n-}\n-\n-std::optional<SliceSnapshot::DbRecord> RdbSaver::Impl::RecordsPopper::InternalPop(bool blocking) {\n-  if (TryPopFromQueue()) {\n-    return std::move(record_holder);\n-  }\n-\n-  auto pop_fn =\n-      blocking ? &SliceSnapshot::RecordChannel::Pop : &SliceSnapshot::RecordChannel::TryPop;\n-\n-  while ((channel->*pop_fn)(record_holder)) {\n-    if (!enforce_order) {\n-      return std::move(record_holder);\n-    }\n-    if (record_holder.id == next_record_id) {\n-      ++next_record_id;\n-      return std::move(record_holder);\n-    }\n-    // record popped from channel is ooo, push to queue\n-    q_records.emplace(std::move(record_holder));\n-  }\n-  return std::nullopt;\n-}\n-\n error_code RdbSaver::Impl::ConsumeChannel(const Cancellation* cll) {\n   error_code io_error;\n-  std::optional<SliceSnapshot::DbRecord> record;\n+  SliceSnapshot::DbRecord record;\n \n-  RecordsPopper records_popper(push_to_sink_with_order_, &channel_);\n   auto& stats = ServerState::tlocal()->stats;\n \n   // we can not exit on io-error since we spawn fibers that push data.\n   // TODO: we may signal them to stop processing and exit asap in case of the error.\n-  while ((record = records_popper.Pop())) {\n+  while (channel_.Pop(record)) {\n     if (io_error || cll->IsCancelled())\n       continue;\n \n@@ -1280,9 +1199,9 @@ error_code RdbSaver::Impl::ConsumeChannel(const Cancellation* cll) {\n       if (cll->IsCancelled())\n         continue;\n \n-      DVLOG(2) << \"Pulled \" << record->id;\n+      DVLOG(2) << \"Pulled \" << record.id;\n       last_write_time_ns_ = absl::GetCurrentTimeNanos();\n-      io_error = sink_->Write(io::Buffer(record->value));\n+      io_error = sink_->Write(io::Buffer(record.value));\n \n       stats.rdb_save_usec += (absl::GetCurrentTimeNanos() - last_write_time_ns_) / 1'000;\n       stats.rdb_save_count++;\n@@ -1291,14 +1210,14 @@ error_code RdbSaver::Impl::ConsumeChannel(const Cancellation* cll) {\n         VLOG(1) << \"Error writing to sink \" << io_error.message();\n         break;\n       }\n-    } while ((record = records_popper.TryPop()));\n-  }  // while (records_popper.Pop())\n+    } while ((channel_.TryPop(record)));\n+  }  // while (channel_.Pop())\n \n   for (auto& ptr : shard_snapshots_) {\n     ptr->Join();\n   }\n \n-  DCHECK(!record.has_value() || !channel_.TryPop(*record));\n+  DCHECK(!channel_.TryPop(record));\n \n   return io_error;\n }\ndiff --git a/src/server/snapshot.cc b/src/server/snapshot.cc\nindex e6674f41aabc..2365f642eb6d 100644\n--- a/src/server/snapshot.cc\n+++ b/src/server/snapshot.cc\n@@ -21,14 +21,14 @@\n #include \"server/tiered_storage.h\"\n #include \"util/fibers/synchronization.h\"\n \n-using facade::operator\"\"_MB;\n-\n namespace dfly {\n \n using namespace std;\n using namespace util;\n using namespace chrono_literals;\n \n+using facade::operator\"\"_MB;\n+using facade::operator\"\"_KB;\n namespace {\n thread_local absl::flat_hash_set<SliceSnapshot*> tl_slice_snapshots;\n }  // namespace\n@@ -78,7 +78,7 @@ void SliceSnapshot::Start(bool stream_journal, const Cancellation* cll, Snapshot\n     flush_fun = [this, flush_threshold](size_t bytes_serialized,\n                                         RdbSerializer::FlushState flush_state) {\n       if (bytes_serialized > flush_threshold) {\n-        auto serialized = Serialize(flush_state);\n+        size_t serialized = FlushChannelRecord(flush_state);\n         VLOG(2) << \"FlushedToChannel \" << serialized << \" bytes\";\n       }\n     };\n@@ -325,7 +325,7 @@ void SliceSnapshot::SerializeEntry(DbIndex db_indx, const PrimeKey& pk, const Pr\n   }\n }\n \n-size_t SliceSnapshot::Serialize(SerializerBase::FlushState flush_state) {\n+size_t SliceSnapshot::FlushChannelRecord(SerializerBase::FlushState flush_state) {\n   io::StringFile sfile;\n   serializer_->FlushToSink(&sfile, flush_state);\n \n@@ -333,34 +333,51 @@ size_t SliceSnapshot::Serialize(SerializerBase::FlushState flush_state) {\n   if (serialized == 0)\n     return 0;\n \n-  auto id = rec_id_++;\n-  DVLOG(2) << \"Pushed \" << id;\n+  uint64_t id = rec_id_++;\n+  DVLOG(2) << \"Pushing \" << id;\n   DbRecord db_rec{.id = id, .value = std::move(sfile.val)};\n+  fb2::NoOpLock lk;\n+\n+  // We create a critical section here that ensures that records are pushed in sequential order.\n+  // As a result, it is not possible for two fiber producers to push into channel concurrently.\n+  // If A.id = 5, and then B.id = 6, and both are blocked here, it means that last_pushed_id_ < 4.\n+  // Once last_pushed_id_ = 4, A will be unblocked, while B will wait until A finishes pushing and\n+  // update last_pushed_id_ to 5.\n+  seq_cond_.wait(lk, [&] { return id == this->last_pushed_id_ + 1; });\n+\n+  // Blocking point.\n+  size_t channel_usage = dest_->Push(std::move(db_rec));\n+  DCHECK_EQ(last_pushed_id_ + 1, id);\n+  last_pushed_id_ = id;\n+  seq_cond_.notify_all();\n+\n+  VLOG(2) << \"Pushed with Serialize() \" << serialized\n+          << \" bytes, channel total usage: \" << channel_usage;\n \n-  dest_->Push(std::move(db_rec));\n-  if (serialized != 0) {\n-    VLOG(2) << \"Pushed with Serialize() \" << serialized << \" bytes\";\n-  }\n   return serialized;\n }\n \n bool SliceSnapshot::PushSerializedToChannel(bool force) {\n-  if (!force && serializer_->SerializedLen() < 4096)\n+  if (!force && serializer_->SerializedLen() < 4_KB)\n     return false;\n \n   // Flush any of the leftovers to avoid interleavings\n-  size_t serialized = Serialize();\n-\n-  // Bucket serialization might have accumulated some delayed values.\n-  // Because we can finally block in this function, we'll await and serialize them\n-  while (!delayed_entries_.empty()) {\n-    auto& entry = delayed_entries_.back();\n-    serializer_->SaveEntry(entry.key, entry.value.Get(), entry.expire, entry.dbid, entry.mc_flags);\n-    delayed_entries_.pop_back();\n-  }\n+  size_t serialized = FlushChannelRecord(FlushState::kFlushMidEntry);\n \n-  size_t total_serialized = Serialize() + serialized;\n-  return total_serialized > 0;\n+  if (!delayed_entries_.empty()) {\n+    // Async bucket serialization might have accumulated some delayed values.\n+    // Because we can finally block in this function, we'll await and serialize them\n+    do {\n+      auto& entry = delayed_entries_.back();\n+      serializer_->SaveEntry(entry.key, entry.value.Get(), entry.expire, entry.dbid,\n+                             entry.mc_flags);\n+      delayed_entries_.pop_back();\n+    } while (!delayed_entries_.empty());\n+\n+    // blocking point.\n+    serialized += FlushChannelRecord(FlushState::kFlushMidEntry);\n+  }\n+  return serialized > 0;\n }\n \n void SliceSnapshot::OnDbChange(DbIndex db_index, const DbSlice::ChangeReq& req) {\ndiff --git a/src/server/snapshot.h b/src/server/snapshot.h\nindex 79e9243148b9..706d64614f33 100644\n--- a/src/server/snapshot.h\n+++ b/src/server/snapshot.h\n@@ -131,7 +131,7 @@ class SliceSnapshot {\n   // Helper function that flushes the serialized items into the RecordStream.\n   // Can block on the channel.\n   using FlushState = SerializerBase::FlushState;\n-  size_t Serialize(FlushState flush_state = FlushState::kFlushMidEntry);\n+  size_t FlushChannelRecord(FlushState flush_state);\n \n  public:\n   uint64_t snapshot_version() const {\n@@ -173,14 +173,15 @@ class SliceSnapshot {\n   // Used for sanity checks.\n   bool serialize_bucket_running_ = false;\n   util::fb2::Fiber snapshot_fb_;  // IterateEntriesFb\n-\n+  util::fb2::CondVarAny seq_cond_;\n   CompressionMode compression_mode_;\n   RdbTypeFreqMap type_freq_map_;\n \n   // version upper bound for entries that should be saved (not included).\n   uint64_t snapshot_version_ = 0;\n   uint32_t journal_cb_id_ = 0;\n-  uint64_t rec_id_ = 0;\n+\n+  uint64_t rec_id_ = 1, last_pushed_id_ = 0;\n \n   struct Stats {\n     size_t loop_serialized = 0;\n",
  "test_patch": "diff --git a/.github/workflows/test-fakeredis.yml b/.github/workflows/test-fakeredis.yml\nindex f5e9f1d960f8..0d02c977329a 100644\n--- a/.github/workflows/test-fakeredis.yml\n+++ b/.github/workflows/test-fakeredis.yml\n@@ -78,6 +78,7 @@ jobs:\n             --ignore test/test_geo_commands.py  \\\n             --ignore test/test_bitmap_commands.py  \\\n             --ignore test/test_json/ \\\n+            --ignore test/test_mixins/test_bitmap_commands.py \\\n             --junit-xml=results-tests.xml  --html=report-tests.html -v\n         continue-on-error: true  # For now to mark the flow as successful\n \ndiff --git a/tests/fakeredis/test/test_mixins/test_geo_commands.py b/tests/fakeredis/test/test_mixins/test_geo_commands.py\nindex 5e92e8811113..b93743ed0e9e 100644\n--- a/tests/fakeredis/test/test_mixins/test_geo_commands.py\n+++ b/tests/fakeredis/test/test_mixins/test_geo_commands.py\n@@ -364,6 +364,7 @@ def test_georadius_errors(r: redis.Redis):\n         testtools.raw_command(r, \"geoadd\", \"newgroup\", *bad_values)\n \n \n+@pytest.mark.unsupported_server_types(\"dragonfly\")\n def test_geosearch(r: redis.Redis):\n     values = (\n         2.1909389952632,\n",
  "problem_statement": "understand our snapshotting peak memory usage\nthe experiment is as follows:\r\n```\r\n1. ./dragonfly  --proactor_threads=2\r\n2.  debug populate 10000 test 1000000\r\n3. info memory\r\n4. save\r\n5. info memory\r\n```\r\n\r\nstep(3): used_memory_peak_rss:10080092160  \r\nstep(5): used_memory_peak_rss:13399830528\r\n\r\nincrease of 32% is a lot!\r\n\r\nif we use `debug populate 1000 test 10000000`  i.e. smaller values but with the same used memory, then\r\n(3) used_memory_peak_rss:10051952640\r\n(5) used_memory_peak_rss:14809550848\r\n\r\nwhich is even more surprising. In short, we need to learn why we spend so much memory during the snapshotting and devise mechanisms to limit it to well defined (expected) margin. \r\n\r\ncc @ashotland  :)\r\n\n",
  "hints_text": "btw, maybe (5) vastly differs between experiments just because RSS peaks quickly, and we sample it at random times in between, and maybe it might reach 14.8GB with both setups \ud83e\udd37\ud83c\udffc  (have not checked it)\nOk, I got totally confused. in `debug populate 10000 test 1000000` the first integer is count and the second is - value length. it is quite a big value so it is expected to require a big margin so the problem is not as serious as I thought @ashotland \r\n\r\nstill, understanding how we limit the memory usage is important.",
  "created_at": "2024-09-07T11:18:47Z",
  "modified_files": [
    "src/core/size_tracking_channel.h",
    "src/server/rdb_save.cc",
    "src/server/snapshot.cc",
    "src/server/snapshot.h"
  ],
  "modified_test_files": [
    ".github/workflows/test-fakeredis.yml",
    "tests/fakeredis/test/test_mixins/test_geo_commands.py"
  ]
}