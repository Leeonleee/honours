{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 4456,
  "instance_id": "dragonflydb__dragonfly-4456",
  "issue_numbers": [
    "4415"
  ],
  "base_commit": "f6441df57a6a87c595fbb9c356ba8e7d7eff6ca8",
  "patch": "diff --git a/src/server/journal/cmd_serializer.cc b/src/server/journal/cmd_serializer.cc\nindex f9c98b99f6e5..bcddcc8627d4 100644\n--- a/src/server/journal/cmd_serializer.cc\n+++ b/src/server/journal/cmd_serializer.cc\n@@ -26,13 +26,18 @@ class CommandAggregator {\n   }\n \n   enum class CommitMode { kAuto, kNoCommit };\n-  void AddArg(string arg, CommitMode commit_mode = CommitMode::kAuto) {\n+\n+  // Returns whether CommitPending() was called\n+  bool AddArg(string arg, CommitMode commit_mode = CommitMode::kAuto) {\n     agg_bytes_ += arg.size();\n     members_.push_back(std::move(arg));\n \n     if (commit_mode != CommitMode::kNoCommit && agg_bytes_ >= max_aggragation_bytes_) {\n       CommitPending();\n+      return true;\n     }\n+\n+    return false;\n   }\n \n  private:\n@@ -65,26 +70,27 @@ CmdSerializer::CmdSerializer(FlushSerialized cb, size_t max_serialization_buffer\n     : cb_(std::move(cb)), max_serialization_buffer_size_(max_serialization_buffer_size) {\n }\n \n-void CmdSerializer::SerializeEntry(string_view key, const PrimeValue& pk, const PrimeValue& pv,\n-                                   uint64_t expire_ms) {\n+size_t CmdSerializer::SerializeEntry(string_view key, const PrimeValue& pk, const PrimeValue& pv,\n+                                     uint64_t expire_ms) {\n   // We send RESTORE commands for small objects, or objects we don't support breaking.\n   bool use_restore_serialization = true;\n+  size_t commands = 1;\n   if (max_serialization_buffer_size_ > 0 && pv.MallocUsed() > max_serialization_buffer_size_) {\n     switch (pv.ObjType()) {\n       case OBJ_SET:\n-        SerializeSet(key, pv);\n+        commands = SerializeSet(key, pv);\n         use_restore_serialization = false;\n         break;\n       case OBJ_ZSET:\n-        SerializeZSet(key, pv);\n+        commands = SerializeZSet(key, pv);\n         use_restore_serialization = false;\n         break;\n       case OBJ_HASH:\n-        SerializeHash(key, pv);\n+        commands = SerializeHash(key, pv);\n         use_restore_serialization = false;\n         break;\n       case OBJ_LIST:\n-        SerializeList(key, pv);\n+        commands = SerializeList(key, pv);\n         use_restore_serialization = false;\n         break;\n       case OBJ_STRING:\n@@ -105,6 +111,7 @@ void CmdSerializer::SerializeEntry(string_view key, const PrimeValue& pk, const\n     SerializeStickIfNeeded(key, pk);\n     SerializeExpireIfNeeded(key, expire_ms);\n   }\n+  return commands;\n }\n \n void CmdSerializer::SerializeCommand(string_view cmd, absl::Span<const string_view> args) {\n@@ -139,54 +146,62 @@ void CmdSerializer::SerializeExpireIfNeeded(string_view key, uint64_t expire_ms)\n   SerializeCommand(\"PEXIRE\", {key, absl::StrCat(expire_ms)});\n }\n \n-void CmdSerializer::SerializeSet(string_view key, const PrimeValue& pv) {\n+size_t CmdSerializer::SerializeSet(string_view key, const PrimeValue& pv) {\n   CommandAggregator aggregator(\n       key, [&](absl::Span<const string_view> args) { SerializeCommand(\"SADD\", args); },\n       max_serialization_buffer_size_);\n \n+  size_t commands = 0;\n   container_utils::IterateSet(pv, [&](container_utils::ContainerEntry ce) {\n-    aggregator.AddArg(ce.ToString());\n+    commands += aggregator.AddArg(ce.ToString());\n     return true;\n   });\n+  return commands;\n }\n \n-void CmdSerializer::SerializeZSet(string_view key, const PrimeValue& pv) {\n+size_t CmdSerializer::SerializeZSet(string_view key, const PrimeValue& pv) {\n   CommandAggregator aggregator(\n       key, [&](absl::Span<const string_view> args) { SerializeCommand(\"ZADD\", args); },\n       max_serialization_buffer_size_);\n \n+  size_t commands = 0;\n   container_utils::IterateSortedSet(\n       pv.GetRobjWrapper(),\n       [&](container_utils::ContainerEntry ce, double score) {\n         aggregator.AddArg(absl::StrCat(score), CommandAggregator::CommitMode::kNoCommit);\n-        aggregator.AddArg(ce.ToString());\n+        commands += aggregator.AddArg(ce.ToString());\n         return true;\n       },\n       /*start=*/0, /*end=*/-1, /*reverse=*/false, /*use_score=*/true);\n+  return commands;\n }\n \n-void CmdSerializer::SerializeHash(string_view key, const PrimeValue& pv) {\n+size_t CmdSerializer::SerializeHash(string_view key, const PrimeValue& pv) {\n   CommandAggregator aggregator(\n       key, [&](absl::Span<const string_view> args) { SerializeCommand(\"HSET\", args); },\n       max_serialization_buffer_size_);\n \n+  size_t commands = 0;\n   container_utils::IterateMap(\n       pv, [&](container_utils::ContainerEntry k, container_utils::ContainerEntry v) {\n         aggregator.AddArg(k.ToString(), CommandAggregator::CommitMode::kNoCommit);\n-        aggregator.AddArg(v.ToString());\n+        commands += aggregator.AddArg(v.ToString());\n         return true;\n       });\n+  return commands;\n }\n \n-void CmdSerializer::SerializeList(string_view key, const PrimeValue& pv) {\n+size_t CmdSerializer::SerializeList(string_view key, const PrimeValue& pv) {\n   CommandAggregator aggregator(\n       key, [&](absl::Span<const string_view> args) { SerializeCommand(\"RPUSH\", args); },\n       max_serialization_buffer_size_);\n \n+  size_t commands = 0;\n   container_utils::IterateList(pv, [&](container_utils::ContainerEntry ce) {\n-    aggregator.AddArg(ce.ToString());\n+    commands += aggregator.AddArg(ce.ToString());\n     return true;\n   });\n+  return commands;\n }\n \n void CmdSerializer::SerializeRestore(string_view key, const PrimeValue& pk, const PrimeValue& pv,\ndiff --git a/src/server/journal/cmd_serializer.h b/src/server/journal/cmd_serializer.h\nindex 6c9e2a51d578..5963cd7f7228 100644\n--- a/src/server/journal/cmd_serializer.h\n+++ b/src/server/journal/cmd_serializer.h\n@@ -23,18 +23,19 @@ class CmdSerializer {\n \n   explicit CmdSerializer(FlushSerialized cb, size_t max_serialization_buffer_size);\n \n-  void SerializeEntry(std::string_view key, const PrimeValue& pk, const PrimeValue& pv,\n-                      uint64_t expire_ms);\n+  // Returns how many commands we broke this entry into (like multiple HSETs etc)\n+  size_t SerializeEntry(std::string_view key, const PrimeValue& pk, const PrimeValue& pv,\n+                        uint64_t expire_ms);\n \n  private:\n   void SerializeCommand(std::string_view cmd, absl::Span<const std::string_view> args);\n   void SerializeStickIfNeeded(std::string_view key, const PrimeValue& pk);\n   void SerializeExpireIfNeeded(std::string_view key, uint64_t expire_ms);\n \n-  void SerializeSet(std::string_view key, const PrimeValue& pv);\n-  void SerializeZSet(std::string_view key, const PrimeValue& pv);\n-  void SerializeHash(std::string_view key, const PrimeValue& pv);\n-  void SerializeList(std::string_view key, const PrimeValue& pv);\n+  size_t SerializeSet(std::string_view key, const PrimeValue& pv);\n+  size_t SerializeZSet(std::string_view key, const PrimeValue& pv);\n+  size_t SerializeHash(std::string_view key, const PrimeValue& pv);\n+  size_t SerializeList(std::string_view key, const PrimeValue& pv);\n   void SerializeRestore(std::string_view key, const PrimeValue& pk, const PrimeValue& pv,\n                         uint64_t expire_ms);\n \ndiff --git a/src/server/journal/streamer.cc b/src/server/journal/streamer.cc\nindex e2b04116bfa0..7cc3e038e2e1 100644\n--- a/src/server/journal/streamer.cc\n+++ b/src/server/journal/streamer.cc\n@@ -224,7 +224,7 @@ void RestoreStreamer::Run() {\n       auto* blocking_counter = db_slice_->BlockingCounter();\n       std::lock_guard blocking_counter_guard(*blocking_counter);\n \n-      WriteBucket(it);\n+      stats_.buckets_loop += WriteBucket(it);\n     });\n \n     if (++last_yield >= 100) {\n@@ -232,10 +232,19 @@ void RestoreStreamer::Run() {\n       last_yield = 0;\n     }\n   } while (cursor);\n+\n+  VLOG(1) << \"RestoreStreamer finished loop of \" << my_slots_.ToSlotRanges().ToString()\n+          << \", shard \" << db_slice_->shard_id() << \". Buckets looped \" << stats_.buckets_loop;\n }\n \n void RestoreStreamer::SendFinalize(long attempt) {\n-  VLOG(1) << \"RestoreStreamer LSN opcode for : \" << db_slice_->shard_id() << \" attempt \" << attempt;\n+  VLOG(1) << \"RestoreStreamer LSN of \" << my_slots_.ToSlotRanges().ToString() << \", shard \"\n+          << db_slice_->shard_id() << \" attempt \" << attempt << \" with \" << stats_.commands\n+          << \" commands. Buckets looped \" << stats_.buckets_loop << \", buckets on_db_update \"\n+          << stats_.buckets_on_db_update << \", buckets skipped \" << stats_.buckets_skipped\n+          << \", buckets written \" << stats_.buckets_written << \". Keys skipped \"\n+          << stats_.keys_skipped << \", keys written \" << stats_.keys_written;\n+\n   journal::Entry entry(journal::Op::LSN, attempt);\n \n   io::StringSink sink;\n@@ -285,14 +294,19 @@ bool RestoreStreamer::ShouldWrite(SlotId slot_id) const {\n   return my_slots_.Contains(slot_id);\n }\n \n-void RestoreStreamer::WriteBucket(PrimeTable::bucket_iterator it) {\n+bool RestoreStreamer::WriteBucket(PrimeTable::bucket_iterator it) {\n+  bool written = false;\n+\n   if (it.GetVersion() < snapshot_version_) {\n+    stats_.buckets_written++;\n+\n     it.SetVersion(snapshot_version_);\n     string key_buffer;  // we can reuse it\n     for (; !it.is_done(); ++it) {\n       const auto& pv = it->second;\n       string_view key = it->first.GetSlice(&key_buffer);\n       if (ShouldWrite(key)) {\n+        stats_.keys_written++;\n         uint64_t expire = 0;\n         if (pv.HasExpire()) {\n           auto eit = db_slice_->databases()[0]->expire.Find(it->first);\n@@ -300,10 +314,17 @@ void RestoreStreamer::WriteBucket(PrimeTable::bucket_iterator it) {\n         }\n \n         WriteEntry(key, it->first, pv, expire);\n+        written = true;\n+      } else {\n+        stats_.keys_skipped++;\n       }\n     }\n+  } else {\n+    stats_.buckets_skipped++;\n   }\n   ThrottleIfNeeded();\n+\n+  return written;\n }\n \n void RestoreStreamer::OnDbChange(DbIndex db_index, const DbSlice::ChangeReq& req) {\n@@ -313,12 +334,12 @@ void RestoreStreamer::OnDbChange(DbIndex db_index, const DbSlice::ChangeReq& req\n   PrimeTable* table = db_slice_->GetTables(0).first;\n \n   if (const PrimeTable::bucket_iterator* bit = req.update()) {\n-    WriteBucket(*bit);\n+    stats_.buckets_on_db_update += WriteBucket(*bit);\n   } else {\n     string_view key = get<string_view>(req.change);\n     table->CVCUponInsert(snapshot_version_, key, [this](PrimeTable::bucket_iterator it) {\n       DCHECK_LT(it.GetVersion(), snapshot_version_);\n-      WriteBucket(it);\n+      stats_.buckets_on_db_update += WriteBucket(it);\n     });\n   }\n }\n@@ -331,7 +352,7 @@ void RestoreStreamer::WriteEntry(string_view key, const PrimeValue& pk, const Pr\n         ThrottleIfNeeded();\n       },\n       ServerState::tlocal()->serialization_max_chunk_size);\n-  serializer.SerializeEntry(key, pk, pv, expire_ms);\n+  stats_.commands += serializer.SerializeEntry(key, pk, pv, expire_ms);\n }\n \n }  // namespace dfly\ndiff --git a/src/server/journal/streamer.h b/src/server/journal/streamer.h\nindex 6677bdcb08ca..e46713dd3c67 100644\n--- a/src/server/journal/streamer.h\n+++ b/src/server/journal/streamer.h\n@@ -101,11 +101,22 @@ class RestoreStreamer : public JournalStreamer {\n   bool ShouldWrite(std::string_view key) const;\n   bool ShouldWrite(SlotId slot_id) const;\n \n-  // Returns whether anything was written\n-  void WriteBucket(PrimeTable::bucket_iterator it);\n+  // Returns true if any entry was actually written\n+  bool WriteBucket(PrimeTable::bucket_iterator it);\n+\n   void WriteEntry(std::string_view key, const PrimeValue& pk, const PrimeValue& pv,\n                   uint64_t expire_ms);\n \n+  struct Stats {\n+    size_t buckets_skipped = 0;\n+    size_t buckets_written = 0;\n+    size_t buckets_loop = 0;\n+    size_t buckets_on_db_update = 0;\n+    size_t keys_written = 0;\n+    size_t keys_skipped = 0;\n+    size_t commands = 0;\n+  };\n+\n   DbSlice* db_slice_;\n   DbTableArray db_array_;\n   uint64_t snapshot_version_ = 0;\n@@ -113,6 +124,7 @@ class RestoreStreamer : public JournalStreamer {\n   bool fiber_cancelled_ = false;\n   bool snapshot_finished_ = false;\n   ThreadLocalMutex big_value_mu_;\n+  Stats stats_;\n };\n \n }  // namespace dfly\n",
  "test_patch": "diff --git a/tests/dragonfly/cluster_test.py b/tests/dragonfly/cluster_test.py\nindex effa56b5271d..0d7d1b044f0c 100644\n--- a/tests/dragonfly/cluster_test.py\n+++ b/tests/dragonfly/cluster_test.py\n@@ -214,6 +214,21 @@ async def get_node_id(connection):\n     return id\n \n \n+def stop_and_get_restore_log(instance):\n+    instance.stop()\n+    lines = instance.find_in_logs(\"RestoreStreamer LSN\")\n+    assert len(lines) == 1\n+    line = lines[0]\n+    logging.debug(f\"Streamer log line: {line}\")\n+    return line\n+\n+\n+def extract_int_after_prefix(prefix, line):\n+    match = re.search(prefix + \"(\\\\d+)\", line)\n+    assert match\n+    return int(match.group(1))\n+\n+\n @dfly_args({})\n class TestNotEmulated:\n     async def test_cluster_commands_fails_when_not_emulate(self, async_client: aioredis.Redis):\n@@ -2035,6 +2050,18 @@ async def test_cluster_migration_huge_container(df_factory: DflyInstanceFactory)\n     logging.debug(f\"Memory before {mem_before} after {mem_after}\")\n     assert mem_after < mem_before * 1.1\n \n+    line = stop_and_get_restore_log(nodes[0].instance)\n+\n+    # 'with X commands' - how many breakdowns we used for the keys\n+    assert extract_int_after_prefix(\"with \", line) > 500_000\n+\n+    assert extract_int_after_prefix(\"Keys skipped \", line) == 0\n+    assert extract_int_after_prefix(\"buckets skipped \", line) == 0\n+    assert extract_int_after_prefix(\"keys written \", line) > 90\n+\n+    # We don't send updates during the migration\n+    assert extract_int_after_prefix(\"buckets on_db_update \", line) == 0\n+\n \n @dfly_args({\"proactor_threads\": 2, \"cluster_mode\": \"yes\"})\n @pytest.mark.parametrize(\"chunk_size\", [1_000_000, 30])\n@@ -2056,7 +2083,6 @@ async def test_cluster_migration_while_seeding(\n     nodes[0].slots = [(0, 16383)]\n     nodes[1].slots = []\n     client0 = nodes[0].client\n-    client1 = nodes[1].client\n \n     await push_config(json.dumps(generate_config(nodes)), [node.admin_client for node in nodes])\n \n@@ -2098,6 +2124,12 @@ async def test_cluster_migration_while_seeding(\n     capture = await seeder.capture_fake_redis()\n     assert await seeder.compare(capture, instances[1].port)\n \n+    line = stop_and_get_restore_log(nodes[0].instance)\n+    assert extract_int_after_prefix(\"Keys skipped \", line) == 0\n+    assert extract_int_after_prefix(\"buckets skipped \", line) > 0\n+    assert extract_int_after_prefix(\"keys written \", line) >= 9_000\n+    assert extract_int_after_prefix(\"buckets on_db_update \", line) > 0\n+\n \n def parse_lag(replication_info: str):\n     lags = re.findall(\"lag=([0-9]+)\\r\\n\", replication_info)\ndiff --git a/tests/dragonfly/instance.py b/tests/dragonfly/instance.py\nindex 8e9e44536053..4a96aa67cdde 100644\n--- a/tests/dragonfly/instance.py\n+++ b/tests/dragonfly/instance.py\n@@ -380,16 +380,17 @@ async def metrics(self):\n             for metric_family in text_string_to_metric_families(data)\n         }\n \n-    def is_in_logs(self, pattern):\n+    def find_in_logs(self, pattern):\n         if self.proc is not None:\n             raise RuntimeError(\"Must close server first\")\n \n+        results = []\n         matcher = re.compile(pattern)\n         for path in self.log_files:\n             for line in open(path):\n                 if matcher.search(line):\n-                    return True\n-        return False\n+                    results.append(line)\n+        return results\n \n     @property\n     def rss(self):\n@@ -416,7 +417,7 @@ def create(self, existing_port=None, path=None, version=100, **kwargs) -> DflyIn\n         args.setdefault(\"noversion_check\", None)\n         # MacOs does not set it automatically, so we need to set it manually\n         args.setdefault(\"maxmemory\", \"8G\")\n-        vmod = \"dragonfly_connection=1,accept_server=1,listener_interface=1,main_service=1,rdb_save=1,replica=1,cluster_family=1,proactor_pool=1,dflycmd=1,snapshot=1\"\n+        vmod = \"dragonfly_connection=1,accept_server=1,listener_interface=1,main_service=1,rdb_save=1,replica=1,cluster_family=1,proactor_pool=1,dflycmd=1,snapshot=1,streamer=1\"\n         args.setdefault(\"vmodule\", vmod)\n         args.setdefault(\"jsonpathv2\")\n \n",
  "problem_statement": "Add stats to migration process and check them in test\n1. Add stats similar to SliceSnapshot::Stats + stats for big values which currently are not counted\r\n2. Print stats to log once migration is done\r\n3. Add test utility to grep specific line from log, today we have the DflyInstance.is_in_logs but we want to extract this line and check that a specific stats counter is bigger than some value.\r\n4. Add check relevant stats in tests - for tests checking big values lets check big value preemption flow was executed, when sending traffic while migrating check that OnDbChange was executed\r\n\r\n\n",
  "hints_text": "",
  "created_at": "2025-01-14T11:49:41Z",
  "modified_files": [
    "src/server/journal/cmd_serializer.cc",
    "src/server/journal/cmd_serializer.h",
    "src/server/journal/streamer.cc",
    "src/server/journal/streamer.h"
  ],
  "modified_test_files": [
    "tests/dragonfly/cluster_test.py",
    "tests/dragonfly/instance.py"
  ]
}