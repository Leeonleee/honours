{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 1287,
  "instance_id": "dragonflydb__dragonfly-1287",
  "issue_numbers": [
    "1285"
  ],
  "base_commit": "331076c95b4cc657391db03c446e74f777d9766d",
  "patch": "diff --git a/helio b/helio\nindex 288d85e4fad9..724eb6441516 160000\n--- a/helio\n+++ b/helio\n@@ -1,1 +1,1 @@\n-Subproject commit 288d85e4fad988994ff236fca8969e7751d19443\n+Subproject commit 724eb6441516fe07517ec1841e96e6b68f6ff183\ndiff --git a/src/facade/reply_builder.cc b/src/facade/reply_builder.cc\nindex a957644e28b1..9f68266ce02b 100644\n--- a/src/facade/reply_builder.cc\n+++ b/src/facade/reply_builder.cc\n@@ -45,8 +45,9 @@ void SinkReplyBuilder::CloseConnection() {\n \n void SinkReplyBuilder::Send(const iovec* v, uint32_t len) {\n   DCHECK(sink_);\n+  constexpr uint32_t kMaxBatchCnt = 25;\n \n-  if (should_batch_) {\n+  if ((should_batch_ || should_aggregate_) && batch_cnt_ < kMaxBatchCnt) {\n     size_t total_size = batch_.size();\n     for (unsigned i = 0; i < len; ++i) {\n       total_size += v[i].iov_len;\n@@ -57,6 +58,7 @@ void SinkReplyBuilder::Send(const iovec* v, uint32_t len) {\n         std::string_view src((char*)v[i].iov_base, v[i].iov_len);\n         DVLOG(2) << \"Appending to stream \" << src;\n         batch_.append(src.data(), src.size());\n+        ++batch_cnt_;\n       }\n       return;\n     }\n@@ -64,10 +66,12 @@ void SinkReplyBuilder::Send(const iovec* v, uint32_t len) {\n \n   error_code ec;\n   ++io_write_cnt_;\n-\n+  size_t bsize = 0;\n   for (unsigned i = 0; i < len; ++i) {\n-    io_write_bytes_ += v[i].iov_len;\n+    bsize += v[i].iov_len;\n   }\n+  io_write_bytes_ += bsize;\n+  DVLOG(2) << \"Writing \" << bsize << \" bytes of len \" << len;\n \n   if (batch_.empty()) {\n     ec = sink_->Write(v, len);\n@@ -75,6 +79,7 @@ void SinkReplyBuilder::Send(const iovec* v, uint32_t len) {\n     DVLOG(1) << \"Sending batch to stream \" << sink_ << \"\\n\" << batch_;\n \n     io_write_bytes_ += batch_.size();\n+    batch_cnt_ = 0;\n \n     iovec tmp[len + 1];\n     tmp[0].iov_base = batch_.data();\n@@ -105,6 +110,20 @@ void SinkReplyBuilder::SendRawVec(absl::Span<const std::string_view> msg_vec) {\n   Send(arr.data(), msg_vec.size());\n }\n \n+void SinkReplyBuilder::StopAggregate() {\n+  should_aggregate_ = false;\n+\n+  if (should_batch_ || batch_.empty())\n+    return;\n+\n+  error_code ec = sink_->Write(io::Buffer(batch_));\n+  batch_.clear();\n+  batch_cnt_ = 0;\n+\n+  if (ec)\n+    ec_ = ec;\n+}\n+\n MCReplyBuilder::MCReplyBuilder(::io::Sink* sink) : SinkReplyBuilder(sink), noreply_(false) {\n }\n \n@@ -287,6 +306,7 @@ void RedisReplyBuilder::SendLong(long num) {\n \n void RedisReplyBuilder::SendScoredArray(const std::vector<std::pair<std::string, double>>& arr,\n                                         bool with_scores) {\n+  ReplyAggregator agg(this);\n   if (!with_scores) {\n     StartArray(arr.size());\n     for (const auto& p : arr) {\n@@ -385,7 +405,13 @@ void RedisReplyBuilder::StartCollection(unsigned len, CollectionType type) {\n     type = ARRAY;\n   }\n \n+  // We do not want to send multiple packets for small responses because these\n+  // trigger TCP-related artifacts (e.g. Nagle's algorithm) that slow down the delivery of the whole\n+  // response.\n+  bool prev = should_aggregate_;\n+  should_aggregate_ |= (len > 0);\n   SendRaw(absl::StrCat(START_SYMBOLS[type], len, kCRLF));\n+  should_aggregate_ = prev;\n }\n \n // This implementation a bit complicated because it uses vectorized\ndiff --git a/src/facade/reply_builder.h b/src/facade/reply_builder.h\nindex 48d4254b61f5..64cb463c6875 100644\n--- a/src/facade/reply_builder.h\n+++ b/src/facade/reply_builder.h\n@@ -86,12 +86,31 @@ class SinkReplyBuilder {\n     return err_count_;\n   }\n \n+  struct ReplyAggregator {\n+    explicit ReplyAggregator(SinkReplyBuilder* builder) : builder_(builder) {\n+      builder_->StartAggregate();\n+    }\n+\n+    ~ReplyAggregator() {\n+      builder_->StopAggregate();\n+    }\n+\n+   private:\n+    SinkReplyBuilder* builder_;\n+  };\n+\n  protected:\n   void SendRaw(std::string_view str);  // Sends raw without any formatting.\n   void SendRawVec(absl::Span<const std::string_view> msg_vec);\n \n   void Send(const iovec* v, uint32_t len);\n \n+  void StartAggregate() {\n+    should_aggregate_ = true;\n+  }\n+\n+  void StopAggregate();\n+\n   std::string batch_;\n   ::io::Sink* sink_;\n   std::error_code ec_;\n@@ -100,7 +119,11 @@ class SinkReplyBuilder {\n   size_t io_write_bytes_ = 0;\n   absl::flat_hash_map<std::string, uint64_t> err_count_;\n \n-  bool should_batch_ = false;\n+  bool should_batch_ : 1 = false;\n+\n+  // Similarly to batch mode but is controlled by at operation level.\n+  bool should_aggregate_ : 2 = false;\n+  uint32_t batch_cnt_ = 0;\n };\n \n class MCReplyBuilder : public SinkReplyBuilder {\n@@ -161,6 +184,7 @@ class RedisReplyBuilder : public SinkReplyBuilder {\n                                bool with_scores);\n \n   void StartArray(unsigned len);  // StartCollection(len, ARRAY)\n+\n   virtual void StartCollection(unsigned len, CollectionType type);\n \n   static char* FormatDouble(double val, char* dest, unsigned dest_len);\ndiff --git a/src/server/hset_family.cc b/src/server/hset_family.cc\nindex 02370d0252d4..bdafd6f5a0a5 100644\n--- a/src/server/hset_family.cc\n+++ b/src/server/hset_family.cc\n@@ -775,6 +775,8 @@ void HSetFamily::HMGet(CmdArgList args, ConnectionContext* cntx) {\n   OpResult<vector<OptStr>> result = cntx->transaction->ScheduleSingleHopT(std::move(cb));\n \n   if (result) {\n+    SinkReplyBuilder::ReplyAggregator agg(cntx->reply_builder());\n+\n     (*cntx)->StartArray(result->size());\n     for (const auto& val : *result) {\n       if (val) {\n@@ -784,6 +786,8 @@ void HSetFamily::HMGet(CmdArgList args, ConnectionContext* cntx) {\n       }\n     }\n   } else if (result.status() == OpStatus::KEY_NOTFOUND) {\n+    SinkReplyBuilder::ReplyAggregator agg(cntx->reply_builder());\n+\n     (*cntx)->StartArray(args.size());\n     for (unsigned i = 0; i < args.size(); ++i) {\n       (*cntx)->SendNull();\ndiff --git a/src/server/list_family.cc b/src/server/list_family.cc\nindex 6eb1bc4965ad..0568c14be8ca 100644\n--- a/src/server/list_family.cc\n+++ b/src/server/list_family.cc\n@@ -965,6 +965,7 @@ void ListFamily::LPos(CmdArgList args, ConnectionContext* cntx) {\n       (*cntx)->SendLong((*result)[0]);\n     }\n   } else {\n+    SinkReplyBuilder::ReplyAggregator agg(cntx->reply_builder());\n     (*cntx)->StartArray(result->size());\n     const auto& array = result.value();\n     for (const auto& v : array) {\ndiff --git a/src/server/main_service.cc b/src/server/main_service.cc\nindex 7663de7bcfb6..bc5f597f5d38 100644\n--- a/src/server/main_service.cc\n+++ b/src/server/main_service.cc\n@@ -1524,6 +1524,7 @@ void Service::Exec(CmdArgList args, ConnectionContext* cntx) {\n     Transaction* trans = cntx->transaction;\n     cntx->transaction = nullptr;\n \n+    SinkReplyBuilder::ReplyAggregator agg(rb);\n     rb->StartArray(body.size());\n     for (auto& scmd : body) {\n       arg_vec.resize(scmd.NumArgs() + 1);\n@@ -1549,6 +1550,7 @@ void Service::Exec(CmdArgList args, ConnectionContext* cntx) {\n   }\n \n   VLOG(1) << \"StartExec \" << exec_info.body.size();\n+  SinkReplyBuilder::ReplyAggregator agg(rb);\n   rb->StartArray(exec_info.body.size());\n \n   if (!exec_info.body.empty()) {\n",
  "test_patch": "diff --git a/src/facade/reply_builder_test.cc b/src/facade/reply_builder_test.cc\nindex d4425f082a43..e3c990647a17 100644\n--- a/src/facade/reply_builder_test.cc\n+++ b/src/facade/reply_builder_test.cc\n@@ -185,12 +185,11 @@ TEST_F(RedisReplyBuilderTest, TestMessageSend) {\n   builder_->SendOk();\n   ASSERT_EQ(TakePayload(), kOKMessage);\n   builder_->StartArray(10);\n-  ASSERT_EQ(TakePayload(), \"*10\\r\\n\");\n-  sink_.Clear();\n+\n   std::string_view hello_msg = \"hello\";\n   builder_->SendBulkString(hello_msg);\n-  std::string expected_bulk_string =\n-      absl::StrCat(kBulkStringStart, std::to_string(hello_msg.size()), kCRLF, hello_msg, kCRLF);\n+  std::string expected_bulk_string = absl::StrCat(\n+      \"*10\\r\\n\", kBulkStringStart, std::to_string(hello_msg.size()), kCRLF, hello_msg, kCRLF);\n   ASSERT_EQ(TakePayload(), expected_bulk_string);\n }\n \n",
  "problem_statement": "Dragonfly is about 10x slower than Redis when used by JuiceFS\n[JuiceFS](https://github.com/juicedata/juicefs) supports using redis as the metadata engine, and we had feedback from the community that they wanted to use dragonfly to replace redis, but after testing, I found that dragonfly is very unstable. It is about 10 times slower than the average redis latency.(calculated by the mean of the latency)  I'm not sure if it's my usage or dragonfly's own problem. I would like to ask for help to determine the cause.\r\n\r\nAs you can see on this graph, Dragonfly's performance is similar to that of Redis under normal circumstances, but there are often exceptionally slow requests, resulting in very large latency fluctuations.\r\n\r\n<img width=\"851\" alt=\"image\" src=\"https://github.com/dragonflydb/dragonfly/assets/31313340/abc1c3d5-94df-4ced-bcf4-7ff812002d89\">\r\n\r\n**To Reproduce**\r\n1. install dragonfly by binary, listen on 127.0.0.1:6378\r\n2. start dragonfly \r\n`./dragonfly --logtostderr  -dbnum 10 --bind 127.0.0.1 --port 6378`\r\n3. install redis by binary, listen on 127.0.0.1:6379\r\n1. install golang first\r\n   ```\r\n    wget https://go.dev/dl/go1.20.4.linux-amd64.tar.gz\r\n    rm -rf /usr/local/go && tar -C /usr/local -xzf go1.20.4.linux-amd64.tar.gz\r\n    export PATH=$PATH:/usr/local/go/bin\r\n   ```\r\n4. `git clone -b  test_for_dragonfly https://github.com/juicedata/juicefs.git && cd juicefs`\r\n5. `go mod tidy`\r\n6. test redis \r\n`addr=redis://127.0.0.1:6379/1 go test -count=1  -v  ./pkg/meta/... -run=TestDgfAndRedis`\r\n```\r\nroot@bench2:~/juicefs# addr=redis://127.0.0.1:6379/2 go test -count=1  -v  ./pkg/meta/... -run=TestDgfAndRedis\r\n=== RUN   TestDgfAndRedis\r\n2023/05/24 04:12:16.195448 juicefs[10992] <INFO>: Meta address: redis://127.0.0.1:6379/2 [interface.go:494]\r\n2023/05/24 04:12:16.196587 juicefs[10992] <INFO>: Ping redis latency: 97.831\u00b5s [redis.go:3523]\r\n2023/05/24 04:12:16.197723 juicefs[10992] <INFO>: Create session 1 OK with version: 1.1.0-dev+unknown [base.go:474]\r\n    benchmarks_test.go:673: number:  0: cost: 494 us\r\n    benchmarks_test.go:673: number:  1: cost: 523 us\r\n    benchmarks_test.go:673: number:  2: cost: 507 us\r\n    benchmarks_test.go:673: number:  3: cost: 493 us\r\n    benchmarks_test.go:673: number:  4: cost: 497 us\r\n    benchmarks_test.go:673: number:  5: cost: 555 us\r\n    benchmarks_test.go:673: number:  6: cost: 544 us\r\n    benchmarks_test.go:673: number:  7: cost: 514 us\r\n    benchmarks_test.go:673: number:  8: cost: 511 us\r\n    benchmarks_test.go:673: number:  9: cost: 524 us\r\n    benchmarks_test.go:673: number: 10: cost: 487 us\r\n    benchmarks_test.go:673: number: 11: cost: 485 us\r\n    benchmarks_test.go:673: number: 12: cost: 475 us\r\n    benchmarks_test.go:673: number: 13: cost: 477 us\r\n    benchmarks_test.go:673: number: 14: cost: 474 us\r\n    benchmarks_test.go:673: number: 15: cost: 484 us\r\n    benchmarks_test.go:673: number: 16: cost: 475 us\r\n    benchmarks_test.go:673: number: 17: cost: 509 us\r\n    benchmarks_test.go:673: number: 18: cost: 513 us\r\n    benchmarks_test.go:673: number: 19: cost: 477 us\r\n    benchmarks_test.go:673: number: 20: cost: 504 us\r\n    benchmarks_test.go:673: number: 21: cost: 486 us\r\n    benchmarks_test.go:673: number: 22: cost: 476 us\r\n    benchmarks_test.go:673: number: 23: cost: 475 us\r\n    benchmarks_test.go:673: number: 24: cost: 475 us\r\n    benchmarks_test.go:673: number: 25: cost: 528 us\r\n    benchmarks_test.go:673: number: 26: cost: 510 us\r\n    benchmarks_test.go:673: number: 27: cost: 488 us\r\n    benchmarks_test.go:673: number: 28: cost: 469 us\r\n    benchmarks_test.go:673: number: 29: cost: 469 us\r\n    benchmarks_test.go:673: number: 30: cost: 476 us\r\n    benchmarks_test.go:673: number: 31: cost: 470 us\r\n    benchmarks_test.go:673: number: 32: cost: 468 us\r\n    benchmarks_test.go:673: number: 33: cost: 474 us\r\n    benchmarks_test.go:673: number: 34: cost: 497 us\r\n    benchmarks_test.go:673: number: 35: cost: 522 us\r\n    benchmarks_test.go:673: number: 36: cost: 475 us\r\n    benchmarks_test.go:673: number: 37: cost: 469 us\r\n    benchmarks_test.go:673: number: 38: cost: 481 us\r\n    benchmarks_test.go:673: number: 39: cost: 479 us\r\n    benchmarks_test.go:673: number: 40: cost: 464 us\r\n    benchmarks_test.go:673: number: 41: cost: 495 us\r\n    benchmarks_test.go:673: number: 42: cost: 470 us\r\n    benchmarks_test.go:673: number: 43: cost: 478 us\r\n    benchmarks_test.go:673: number: 44: cost: 485 us\r\n    benchmarks_test.go:673: number: 45: cost: 595 us\r\n    benchmarks_test.go:673: number: 46: cost: 542 us\r\n    benchmarks_test.go:673: number: 47: cost: 514 us\r\n    benchmarks_test.go:673: number: 48: cost: 474 us\r\n    benchmarks_test.go:673: number: 49: cost: 484 us\r\n    benchmarks_test.go:673: number: 50: cost: 490 us\r\n    benchmarks_test.go:673: number: 51: cost: 490 us\r\n    benchmarks_test.go:673: number: 52: cost: 478 us\r\n    benchmarks_test.go:673: number: 53: cost: 493 us\r\n    benchmarks_test.go:673: number: 54: cost: 491 us\r\n    benchmarks_test.go:673: number: 55: cost: 541 us\r\n    benchmarks_test.go:673: number: 56: cost: 489 us\r\n    benchmarks_test.go:673: number: 57: cost: 487 us\r\n    benchmarks_test.go:673: number: 58: cost: 480 us\r\n    benchmarks_test.go:673: number: 59: cost: 486 us\r\n    benchmarks_test.go:673: number: 60: cost: 491 us\r\n    benchmarks_test.go:673: number: 61: cost: 487 us\r\n    benchmarks_test.go:673: number: 62: cost: 484 us\r\n    benchmarks_test.go:673: number: 63: cost: 489 us\r\n    benchmarks_test.go:673: number: 64: cost: 493 us\r\n    benchmarks_test.go:673: number: 65: cost: 542 us\r\n    benchmarks_test.go:673: number: 66: cost: 492 us\r\n    benchmarks_test.go:673: number: 67: cost: 512 us\r\n    benchmarks_test.go:673: number: 68: cost: 493 us\r\n    benchmarks_test.go:673: number: 69: cost: 490 us\r\n    benchmarks_test.go:673: number: 70: cost: 492 us\r\n    benchmarks_test.go:673: number: 71: cost: 478 us\r\n    benchmarks_test.go:673: number: 72: cost: 494 us\r\n    benchmarks_test.go:673: number: 73: cost: 510 us\r\n    benchmarks_test.go:673: number: 74: cost: 512 us\r\n    benchmarks_test.go:673: number: 75: cost: 501 us\r\n    benchmarks_test.go:673: number: 76: cost: 475 us\r\n    benchmarks_test.go:673: number: 77: cost: 483 us\r\n    benchmarks_test.go:673: number: 78: cost: 481 us\r\n    benchmarks_test.go:673: number: 79: cost: 584 us\r\n    benchmarks_test.go:673: number: 80: cost: 486 us\r\n    benchmarks_test.go:673: number: 81: cost: 518 us\r\n    benchmarks_test.go:673: number: 82: cost: 521 us\r\n    benchmarks_test.go:673: number: 83: cost: 476 us\r\n    benchmarks_test.go:673: number: 84: cost: 570 us\r\n    benchmarks_test.go:673: number: 85: cost: 577 us\r\n    benchmarks_test.go:673: number: 86: cost: 479 us\r\n    benchmarks_test.go:673: number: 87: cost: 475 us\r\n    benchmarks_test.go:673: number: 88: cost: 501 us\r\n    benchmarks_test.go:673: number: 89: cost: 514 us\r\n    benchmarks_test.go:673: number: 90: cost: 485 us\r\n    benchmarks_test.go:673: number: 91: cost: 489 us\r\n    benchmarks_test.go:673: number: 92: cost: 516 us\r\n    benchmarks_test.go:673: number: 93: cost: 492 us\r\n    benchmarks_test.go:673: number: 94: cost: 501 us\r\n    benchmarks_test.go:673: number: 95: cost: 478 us\r\n    benchmarks_test.go:673: number: 96: cost: 473 us\r\n    benchmarks_test.go:673: number: 97: cost: 478 us\r\n    benchmarks_test.go:673: number: 98: cost: 577 us\r\n    benchmarks_test.go:673: number: 99: cost: 478 us\r\n    benchmarks_test.go:676: --------------------test redis://127.0.0.1:6379/2--------------------\r\n    benchmarks_test.go:677: mean: 497.02, standard deviation: 27.18\r\n--- PASS: TestDgfAndRedis (0.05s)\r\nPASS\r\nok  \tgithub.com/juicedata/juicefs/pkg/meta\t0.070s\r\n```\r\n8.  test dragonfly\r\n`addr=redis://127.0.0.1:6378/1 go test -count=1  -v  ./pkg/meta/... -run=TestDgfAndRedis`\r\n```\r\nroot@bench2:~/juicefs# addr=redis://127.0.0.1:6378/2 go test -count=1  -v  ./pkg/meta/... -run=TestDgfAndRedis\r\n=== RUN   TestDgfAndRedis\r\n2023/05/24 04:11:15.817867 juicefs[10886] <INFO>: Meta address: redis://127.0.0.1:6378/2 [interface.go:494]\r\n2023/05/24 04:11:15.819105 juicefs[10886] <INFO>: Ping redis latency: 86.584\u00b5s [redis.go:3523]\r\n2023/05/24 04:11:15.819355 juicefs[10886] <WARNING>: Existing volume will be overwrited: {\r\n  \"Name\": \"benchmarkAll\",\r\n  \"UUID\": \"\",\r\n  \"Storage\": \"\",\r\n  \"Bucket\": \"\",\r\n  \"BlockSize\": 0,\r\n  \"TrashDays\": 0\r\n} [config.go:96]\r\n2023/05/24 04:11:15.820231 juicefs[10886] <INFO>: Create session 2 OK with version: 1.1.0-dev+unknown [base.go:474]\r\n2023/05/24 04:11:15.820845 juicefs[10886] <WARNING>: unexpected error for lookup: ERR Error running script (call to 8526c64984678fc27f67f44755c8ba7dcdf7ea60): @user_script:12: script tried accessing undeclared key [redis.go:695]\r\n    benchmarks_test.go:673: number:  0: cost: 714 us\r\n    benchmarks_test.go:673: number:  1: cost: 716 us\r\n    benchmarks_test.go:673: number:  2: cost: 722 us\r\n    benchmarks_test.go:673: number:  3: cost: 732 us\r\n    benchmarks_test.go:673: number:  4: cost: 690 us\r\n    benchmarks_test.go:673: number:  5: cost: 698 us\r\n    benchmarks_test.go:673: number:  6: cost: 731 us\r\n    benchmarks_test.go:673: number:  7: cost: 673 us\r\n    benchmarks_test.go:673: number:  8: cost: 615 us\r\n    benchmarks_test.go:673: number:  9: cost: 714 us\r\n    benchmarks_test.go:673: number: 10: cost: 717 us\r\n    benchmarks_test.go:673: number: 11: cost: 700 us\r\n    benchmarks_test.go:673: number: 12: cost: 710 us\r\n    benchmarks_test.go:673: number: 13: cost: 6720 us\r\n    benchmarks_test.go:673: number: 14: cost: 43235 us\r\n    benchmarks_test.go:673: number: 15: cost: 692 us\r\n    benchmarks_test.go:673: number: 16: cost: 694 us\r\n    benchmarks_test.go:673: number: 17: cost: 698 us\r\n    benchmarks_test.go:673: number: 18: cost: 715 us\r\n    benchmarks_test.go:673: number: 19: cost: 733 us\r\n    benchmarks_test.go:673: number: 20: cost: 856 us\r\n    benchmarks_test.go:673: number: 21: cost: 717 us\r\n    benchmarks_test.go:673: number: 22: cost: 683 us\r\n    benchmarks_test.go:673: number: 23: cost: 672 us\r\n    benchmarks_test.go:673: number: 24: cost: 640 us\r\n    benchmarks_test.go:673: number: 25: cost: 726 us\r\n    benchmarks_test.go:673: number: 26: cost: 703 us\r\n    benchmarks_test.go:673: number: 27: cost: 709 us\r\n    benchmarks_test.go:673: number: 28: cost: 699 us\r\n    benchmarks_test.go:673: number: 29: cost: 2740 us\r\n    benchmarks_test.go:673: number: 30: cost: 43136 us\r\n    benchmarks_test.go:673: number: 31: cost: 705 us\r\n    benchmarks_test.go:673: number: 32: cost: 618 us\r\n    benchmarks_test.go:673: number: 33: cost: 708 us\r\n    benchmarks_test.go:673: number: 34: cost: 740 us\r\n    benchmarks_test.go:673: number: 35: cost: 713 us\r\n    benchmarks_test.go:673: number: 36: cost: 704 us\r\n    benchmarks_test.go:673: number: 37: cost: 676 us\r\n    benchmarks_test.go:673: number: 38: cost: 672 us\r\n    benchmarks_test.go:673: number: 39: cost: 696 us\r\n    benchmarks_test.go:673: number: 40: cost: 705 us\r\n    benchmarks_test.go:673: number: 41: cost: 715 us\r\n    benchmarks_test.go:673: number: 42: cost: 44201 us\r\n    benchmarks_test.go:673: number: 43: cost: 710 us\r\n    benchmarks_test.go:673: number: 44: cost: 698 us\r\n    benchmarks_test.go:673: number: 45: cost: 728 us\r\n    benchmarks_test.go:673: number: 46: cost: 667 us\r\n    benchmarks_test.go:673: number: 47: cost: 724 us\r\n    benchmarks_test.go:673: number: 48: cost: 723 us\r\n    benchmarks_test.go:673: number: 49: cost: 724 us\r\n    benchmarks_test.go:673: number: 50: cost: 739 us\r\n    benchmarks_test.go:673: number: 51: cost: 710 us\r\n    benchmarks_test.go:673: number: 52: cost: 702 us\r\n    benchmarks_test.go:673: number: 53: cost: 708 us\r\n    benchmarks_test.go:673: number: 54: cost: 678 us\r\n    benchmarks_test.go:673: number: 55: cost: 610 us\r\n    benchmarks_test.go:673: number: 56: cost: 709 us\r\n    benchmarks_test.go:673: number: 57: cost: 692 us\r\n    benchmarks_test.go:673: number: 58: cost: 690 us\r\n    benchmarks_test.go:673: number: 59: cost: 44570 us\r\n    benchmarks_test.go:673: number: 60: cost: 712 us\r\n    benchmarks_test.go:673: number: 61: cost: 708 us\r\n    benchmarks_test.go:673: number: 62: cost: 672 us\r\n    benchmarks_test.go:673: number: 63: cost: 638 us\r\n    benchmarks_test.go:673: number: 64: cost: 4791 us\r\n    benchmarks_test.go:673: number: 65: cost: 44406 us\r\n    benchmarks_test.go:673: number: 66: cost: 717 us\r\n    benchmarks_test.go:673: number: 67: cost: 605 us\r\n    benchmarks_test.go:673: number: 68: cost: 724 us\r\n    benchmarks_test.go:673: number: 69: cost: 710 us\r\n    benchmarks_test.go:673: number: 70: cost: 706 us\r\n    benchmarks_test.go:673: number: 71: cost: 705 us\r\n    benchmarks_test.go:673: number: 72: cost: 646 us\r\n    benchmarks_test.go:673: number: 73: cost: 679 us\r\n    benchmarks_test.go:673: number: 74: cost: 694 us\r\n    benchmarks_test.go:673: number: 75: cost: 699 us\r\n    benchmarks_test.go:673: number: 76: cost: 689 us\r\n    benchmarks_test.go:673: number: 77: cost: 44305 us\r\n    benchmarks_test.go:673: number: 78: cost: 760 us\r\n    benchmarks_test.go:673: number: 79: cost: 694 us\r\n    benchmarks_test.go:673: number: 80: cost: 716 us\r\n    benchmarks_test.go:673: number: 81: cost: 6768 us\r\n    benchmarks_test.go:673: number: 82: cost: 47010 us\r\n    benchmarks_test.go:673: number: 83: cost: 748 us\r\n    benchmarks_test.go:673: number: 84: cost: 2813 us\r\n    benchmarks_test.go:673: number: 85: cost: 728 us\r\n    benchmarks_test.go:673: number: 86: cost: 700 us\r\n    benchmarks_test.go:673: number: 87: cost: 705 us\r\n    benchmarks_test.go:673: number: 88: cost: 698 us\r\n    benchmarks_test.go:673: number: 89: cost: 645 us\r\n    benchmarks_test.go:673: number: 90: cost: 723 us\r\n    benchmarks_test.go:673: number: 91: cost: 691 us\r\n    benchmarks_test.go:673: number: 92: cost: 712 us\r\n    benchmarks_test.go:673: number: 93: cost: 721 us\r\n    benchmarks_test.go:673: number: 94: cost: 691 us\r\n    benchmarks_test.go:673: number: 95: cost: 669 us\r\n    benchmarks_test.go:673: number: 96: cost: 44559 us\r\n    benchmarks_test.go:673: number: 97: cost: 677 us\r\n    benchmarks_test.go:673: number: 98: cost: 680 us\r\n    benchmarks_test.go:673: number: 99: cost: 804 us\r\n    benchmarks_test.go:676: --------------------test redis://127.0.0.1:6378/2--------------------\r\n    benchmarks_test.go:677: mean: 4402.53, standard deviation: 11906.39\r\n--- PASS: TestDgfAndRedis (2.45s)\r\nPASS\r\nok  \tgithub.com/juicedata/juicefs/pkg/meta\t2.469s\r\n```\r\n\r\n**Expected behavior**\r\nPerformance on the same order of magnitude as redis or better\r\n\r\n\r\n**Environment (please complete the following information):**\r\n - OS: [ubuntu 20.04]\r\n - Kernel: \r\n Linux bench2 5.4.0-1029-aws #30-Ubuntu SMP Tue Oct 20 10:06:38 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n - Dragonfly Version:  \r\n dragonfly v1.3.0-f80afca9c23e2f30373437520a162c591eaa2005\r\n build time: 2023-05-18 07:11:31\n",
  "hints_text": "@zhijian-pro  how many cpus do you have on your machine? Is your memory store supposed to run locally? i.e. to be colocated with JuiceFS?\nHi, thanks for the clear reproduction instructions! I've looked at the latency problem and could reproduce it. I saw constant latencies of ~41ms, not spikes.  What I saw looked like some kind of network misconfiguration in the TCP socket that causes packets to be delayed until dragonfly gets an ACK from JuiceFS:\r\n\r\n![image](https://github.com/dragonflydb/dragonfly/assets/5706313/674d319d-2d21-4cf6-9a29-41d6c2d61478)\r\n\r\nWhen I switched to using unix sockets with I saw latencies of ~700us and no spikes.\r\n```\r\nmkfifo /tmp/my_unix_socket\r\ndragonfly --unixsocket /tmp/my_unix_socket\r\naddr=unix:///tmp/my_unix_socket?db=1 go test -count=1  -v  ./pkg/meta/... -run=TestDgfAndRedis\r\n```\r\nSo that's a temporary workaround and, if you plan to deploy locally, probably a better alternative anyway. We'll try to understand if that's some socket configuration problem we can fix ourselves.\nAlternatively, giving dragonfly `--tcp_nodelay` also seems to solve the problem.\n@romange  In fact, this phenomenon was discovered during a multi-machine test where redis and Dragonfly were running simultaneously on a 4c8g linux and the juicefs test program was running on another 4c8g machine. I simplified the model for that test to make it easier for everyone its easier to reproduce the problem.\r\n\r\nBut I can confirm that redis, dragonfly and juicefs all have enough cpu and memory. This should not be a resource allocation issue.\n@royjacobson  I tested it, and after adding `--tcp_nodelay ` to Dragonfly, the result is much better than before.\r\n```\r\nroot@bench2:~/juicefs# addr=redis://10.0.101.xx:6378/3 go test -count=1  -v  ./pkg/meta/... -run=TestDgfAndRedis\r\n=== RUN   TestDgfAndRedis\r\n2023/05/24 12:17:07.307180 juicefs[1145] <INFO>: Meta address: redis://10.0.101.xx:6378/3 [interface.go:494]\r\n2023/05/24 12:17:07.318705 juicefs[1145] <INFO>: Ping redis latency: 90.234\u00b5s [redis.go:3523]\r\n2023/05/24 12:17:07.321449 juicefs[1145] <INFO>: Create session 1 OK with version: 1.1.0-dev+unknown [base.go:474]\r\n    benchmarks_test.go:673: number:  0: cost: 595 us\r\n    benchmarks_test.go:673: number:  1: cost: 675 us\r\n    benchmarks_test.go:673: number:  2: cost: 703 us\r\n    benchmarks_test.go:673: number:  3: cost: 652 us\r\n    benchmarks_test.go:673: number:  4: cost: 666 us\r\n    benchmarks_test.go:673: number:  5: cost: 583 us\r\n    benchmarks_test.go:673: number:  6: cost: 570 us\r\n    benchmarks_test.go:673: number:  7: cost: 552 us\r\n    benchmarks_test.go:673: number:  8: cost: 620 us\r\n    benchmarks_test.go:673: number:  9: cost: 660 us\r\n    benchmarks_test.go:673: number: 10: cost: 691 us\r\n    benchmarks_test.go:673: number: 11: cost: 634 us\r\n    benchmarks_test.go:673: number: 12: cost: 673 us\r\n    benchmarks_test.go:673: number: 13: cost: 658 us\r\n    benchmarks_test.go:673: number: 14: cost: 626 us\r\n    benchmarks_test.go:673: number: 15: cost: 672 us\r\n    benchmarks_test.go:673: number: 16: cost: 659 us\r\n    benchmarks_test.go:673: number: 17: cost: 652 us\r\n    benchmarks_test.go:673: number: 18: cost: 654 us\r\n    benchmarks_test.go:673: number: 19: cost: 666 us\r\n    benchmarks_test.go:673: number: 20: cost: 646 us\r\n    benchmarks_test.go:673: number: 21: cost: 598 us\r\n    benchmarks_test.go:673: number: 22: cost: 529 us\r\n    benchmarks_test.go:673: number: 23: cost: 620 us\r\n    benchmarks_test.go:673: number: 24: cost: 655 us\r\n    benchmarks_test.go:673: number: 25: cost: 684 us\r\n    benchmarks_test.go:673: number: 26: cost: 695 us\r\n    benchmarks_test.go:673: number: 27: cost: 670 us\r\n    benchmarks_test.go:673: number: 28: cost: 641 us\r\n    benchmarks_test.go:673: number: 29: cost: 668 us\r\n    benchmarks_test.go:673: number: 30: cost: 667 us\r\n    benchmarks_test.go:673: number: 31: cost: 671 us\r\n    benchmarks_test.go:673: number: 32: cost: 673 us\r\n    benchmarks_test.go:673: number: 33: cost: 711 us\r\n    benchmarks_test.go:673: number: 34: cost: 676 us\r\n    benchmarks_test.go:673: number: 35: cost: 699 us\r\n    benchmarks_test.go:673: number: 36: cost: 606 us\r\n    benchmarks_test.go:673: number: 37: cost: 583 us\r\n    benchmarks_test.go:673: number: 38: cost: 627 us\r\n    benchmarks_test.go:673: number: 39: cost: 733 us\r\n    benchmarks_test.go:673: number: 40: cost: 715 us\r\n    benchmarks_test.go:673: number: 41: cost: 666 us\r\n    benchmarks_test.go:673: number: 42: cost: 680 us\r\n    benchmarks_test.go:673: number: 43: cost: 655 us\r\n    benchmarks_test.go:673: number: 44: cost: 654 us\r\n    benchmarks_test.go:673: number: 45: cost: 679 us\r\n    benchmarks_test.go:673: number: 46: cost: 666 us\r\n    benchmarks_test.go:673: number: 47: cost: 683 us\r\n    benchmarks_test.go:673: number: 48: cost: 669 us\r\n    benchmarks_test.go:673: number: 49: cost: 657 us\r\n    benchmarks_test.go:673: number: 50: cost: 686 us\r\n    benchmarks_test.go:673: number: 51: cost: 1644 us\r\n    benchmarks_test.go:673: number: 52: cost: 650 us\r\n    benchmarks_test.go:673: number: 53: cost: 660 us\r\n    benchmarks_test.go:673: number: 54: cost: 8705 us\r\n    benchmarks_test.go:673: number: 55: cost: 693 us\r\n    benchmarks_test.go:673: number: 56: cost: 649 us\r\n    benchmarks_test.go:673: number: 57: cost: 656 us\r\n    benchmarks_test.go:673: number: 58: cost: 699 us\r\n    benchmarks_test.go:673: number: 59: cost: 675 us\r\n    benchmarks_test.go:673: number: 60: cost: 655 us\r\n    benchmarks_test.go:673: number: 61: cost: 684 us\r\n    benchmarks_test.go:673: number: 62: cost: 671 us\r\n    benchmarks_test.go:673: number: 63: cost: 675 us\r\n    benchmarks_test.go:673: number: 64: cost: 675 us\r\n    benchmarks_test.go:673: number: 65: cost: 679 us\r\n    benchmarks_test.go:673: number: 66: cost: 686 us\r\n    benchmarks_test.go:673: number: 67: cost: 579 us\r\n    benchmarks_test.go:673: number: 68: cost: 574 us\r\n    benchmarks_test.go:673: number: 69: cost: 612 us\r\n    benchmarks_test.go:673: number: 70: cost: 719 us\r\n    benchmarks_test.go:673: number: 71: cost: 668 us\r\n    benchmarks_test.go:673: number: 72: cost: 673 us\r\n    benchmarks_test.go:673: number: 73: cost: 661 us\r\n    benchmarks_test.go:673: number: 74: cost: 656 us\r\n    benchmarks_test.go:673: number: 75: cost: 680 us\r\n    benchmarks_test.go:673: number: 76: cost: 658 us\r\n    benchmarks_test.go:673: number: 77: cost: 677 us\r\n    benchmarks_test.go:673: number: 78: cost: 662 us\r\n    benchmarks_test.go:673: number: 79: cost: 684 us\r\n    benchmarks_test.go:673: number: 80: cost: 684 us\r\n    benchmarks_test.go:673: number: 81: cost: 661 us\r\n    benchmarks_test.go:673: number: 82: cost: 611 us\r\n    benchmarks_test.go:673: number: 83: cost: 580 us\r\n    benchmarks_test.go:673: number: 84: cost: 622 us\r\n    benchmarks_test.go:673: number: 85: cost: 658 us\r\n    benchmarks_test.go:673: number: 86: cost: 663 us\r\n    benchmarks_test.go:673: number: 87: cost: 678 us\r\n    benchmarks_test.go:673: number: 88: cost: 678 us\r\n    benchmarks_test.go:673: number: 89: cost: 659 us\r\n    benchmarks_test.go:673: number: 90: cost: 663 us\r\n    benchmarks_test.go:673: number: 91: cost: 688 us\r\n    benchmarks_test.go:673: number: 92: cost: 690 us\r\n    benchmarks_test.go:673: number: 93: cost: 705 us\r\n    benchmarks_test.go:673: number: 94: cost: 671 us\r\n    benchmarks_test.go:673: number: 95: cost: 669 us\r\n    benchmarks_test.go:673: number: 96: cost: 667 us\r\n    benchmarks_test.go:673: number: 97: cost: 615 us\r\n    benchmarks_test.go:673: number: 98: cost: 641 us\r\n    benchmarks_test.go:673: number: 99: cost: 634 us\r\n    benchmarks_test.go:676: --------------------test redis://10.0.101.xx:6378/3--------------------\r\n    benchmarks_test.go:677: mean: 747.19, standard deviation: 810.68\r\n--- PASS: TestDgfAndRedis (0.09s)\r\nPASS\r\nok  \tgithub.com/juicedata/juicefs/pkg/meta\t0.107s\r\n```\nFor the record, the latency issue is reproducible with the following snippet:\r\n\r\n```python\r\nimport time, redis\r\nr = redis.Redis()\r\n\r\ndef test_multi():\r\n    r.execute_command(\"MULTI\")\r\n    r.execute_command(f\"SET val1 whatever\")\r\n    start = time.time()\r\n    r.execute_command(\"EXEC\")\r\n    lat_ms = 1000 * (time.time() - start)\r\n    print(f\"Latency: {lat_ms}\")\r\n```",
  "created_at": "2023-05-24T14:52:02Z",
  "modified_files": [
    "helio",
    "src/facade/reply_builder.cc",
    "src/facade/reply_builder.h",
    "src/server/hset_family.cc",
    "src/server/list_family.cc",
    "src/server/main_service.cc"
  ],
  "modified_test_files": [
    "src/facade/reply_builder_test.cc"
  ]
}