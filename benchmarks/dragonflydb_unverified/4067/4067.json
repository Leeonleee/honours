{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 4067,
  "instance_id": "dragonflydb__dragonfly-4067",
  "issue_numbers": [
    "4028"
  ],
  "base_commit": "5c84f21caf098d7a73d8aded3691addfcb623e99",
  "patch": "diff --git a/src/core/compact_object.cc b/src/core/compact_object.cc\nindex 846550c2c092..349094770a0a 100644\n--- a/src/core/compact_object.cc\n+++ b/src/core/compact_object.cc\n@@ -125,11 +125,6 @@ size_t MallocUsedZSet(unsigned encoding, void* ptr) {\n   return 0;\n }\n \n-size_t MallocUsedStream(unsigned encoding, void* streamv) {\n-  // stream* str_obj = (stream*)streamv;\n-  return 0;  // TODO\n-}\n-\n inline void FreeObjHash(unsigned encoding, void* ptr) {\n   switch (encoding) {\n     case kEncodingStrMap2:\n@@ -316,7 +311,7 @@ size_t RobjWrapper::MallocUsed(bool slow) const {\n     case OBJ_ZSET:\n       return MallocUsedZSet(encoding_, inner_obj_);\n     case OBJ_STREAM:\n-      return MallocUsedStream(encoding_, inner_obj_);\n+      return sz_;\n \n     default:\n       LOG(FATAL) << \"Not supported \" << type_;\n@@ -370,7 +365,12 @@ size_t RobjWrapper::Size() const {\n           StringMap* sm = (StringMap*)inner_obj_;\n           return sm->UpperBoundSize();\n         }\n+        default:\n+          LOG(FATAL) << \"Unexpected encoding \" << encoding_;\n       }\n+    case OBJ_STREAM:\n+      // Size mean malloc bytes for streams\n+      return sz_;\n     default:;\n   }\n   return 0;\n@@ -461,6 +461,10 @@ void RobjWrapper::SetString(string_view s, MemoryResource* mr) {\n   }\n }\n \n+void RobjWrapper::SetSize(uint64_t size) {\n+  sz_ = size;\n+}\n+\n bool RobjWrapper::DefragIfNeeded(float ratio) {\n   auto do_defrag = [this, ratio](auto defrag_fun) mutable {\n     auto [new_ptr, realloced] = defrag_fun(encoding_, inner_obj_, ratio);\n@@ -811,6 +815,17 @@ void CompactObj::SetJsonSize(int64_t size) {\n   }\n }\n \n+void CompactObj::AddStreamSize(int64_t size) {\n+  if (size < 0) {\n+    // We might have a negative size. For example, if we remove a consumer,\n+    // the tracker will report a negative net (since we deallocated),\n+    // so the object now consumes less memory than it did before. This DCHECK\n+    // is for fanity and to catch any potential issues with our tracking approach.\n+    DCHECK(static_cast<int64_t>(u_.r_obj.Size()) >= size);\n+  }\n+  u_.r_obj.SetSize((u_.r_obj.Size() + size));\n+}\n+\n void CompactObj::SetJson(const uint8_t* buf, size_t len) {\n   SetMeta(JSON_TAG);\n   u_.json_obj.flat.flat_ptr = (uint8_t*)tl.local_mr->allocate(len, kAlignSize);\ndiff --git a/src/core/compact_object.h b/src/core/compact_object.h\nindex 910b5ffc1627..785db15f7fa1 100644\n--- a/src/core/compact_object.h\n+++ b/src/core/compact_object.h\n@@ -46,6 +46,8 @@ class RobjWrapper {\n   void Free(MemoryResource* mr);\n \n   void SetString(std::string_view s, MemoryResource* mr);\n+  // Used when sz_ is used to denote memory usage\n+  void SetSize(uint64_t size);\n   void Init(unsigned type, unsigned encoding, void* inner);\n \n   unsigned type() const {\n@@ -315,6 +317,8 @@ class CompactObj {\n   void SetJson(const uint8_t* buf, size_t len);\n   // Adjusts the size used by json\n   void SetJsonSize(int64_t size);\n+  // Adjusts the size used by a stream\n+  void AddStreamSize(int64_t size);\n \n   // pre condition - the type here is OBJ_JSON and was set with SetJson\n   JsonType* GetJson() const;\ndiff --git a/src/server/stream_family.cc b/src/server/stream_family.cc\nindex 4d453410765b..774f2b676c47 100644\n--- a/src/server/stream_family.cc\n+++ b/src/server/stream_family.cc\n@@ -603,6 +603,24 @@ int StreamTrim(const AddTrimOpts& opts, stream* s) {\n   return 0;\n }\n \n+class StreamMemTracker {\n+ public:\n+  StreamMemTracker() {\n+    start_size_ = zmalloc_used_memory_tl;\n+  }\n+\n+  void UpdateStreamSize(PrimeValue& pv) const {\n+    const size_t current = zmalloc_used_memory_tl;\n+    int64_t diff = static_cast<int64_t>(current) - static_cast<int64_t>(start_size_);\n+    pv.AddStreamSize(diff);\n+    // Under any flow we must not end up with this special value.\n+    DCHECK(pv.MallocUsed() != 0);\n+  }\n+\n+ private:\n+  size_t start_size_{0};\n+};\n+\n OpResult<streamID> OpAdd(const OpArgs& op_args, const AddTrimOpts& opts, CmdArgList args) {\n   DCHECK(!args.empty() && args.size() % 2 == 0);\n   auto& db_slice = op_args.GetDbSlice();\n@@ -622,6 +640,8 @@ OpResult<streamID> OpAdd(const OpArgs& op_args, const AddTrimOpts& opts, CmdArgL\n \n   auto& it = add_res.it;\n \n+  StreamMemTracker mem_tracker;\n+\n   if (add_res.is_new) {\n     stream* s = streamNew();\n     it->second.InitRobj(OBJ_STREAM, OBJ_ENCODING_STREAM, s);\n@@ -648,6 +668,8 @@ OpResult<streamID> OpAdd(const OpArgs& op_args, const AddTrimOpts& opts, CmdArgL\n \n   StreamTrim(opts, stream_inst);\n \n+  mem_tracker.UpdateStreamSize(it->second);\n+\n   auto blocking_controller = op_args.db_cntx.ns->GetBlockingController(op_args.shard->shard_id());\n   if (blocking_controller) {\n     blocking_controller->AwakeWatched(op_args.db_cntx.db_index, opts.key);\n@@ -1093,6 +1115,7 @@ OpStatus OpCreate(const OpArgs& op_args, string_view key, const CreateOpts& opts\n   auto& db_slice = op_args.GetDbSlice();\n   auto res_it = db_slice.FindMutable(op_args.db_cntx, key, OBJ_STREAM);\n   int64_t entries_read = SCG_INVALID_ENTRIES_READ;\n+  StreamMemTracker mem_tracker;\n   if (!res_it) {\n     if (opts.flags & kCreateOptMkstream) {\n       // MKSTREAM is enabled, so create the stream\n@@ -1123,16 +1146,15 @@ OpStatus OpCreate(const OpArgs& op_args, string_view key, const CreateOpts& opts\n   }\n \n   streamCG* cg = streamCreateCG(s, opts.gname.data(), opts.gname.size(), &id, entries_read);\n-  if (cg) {\n-    return OpStatus::OK;\n-  }\n-  return OpStatus::BUSY_GROUP;\n+  mem_tracker.UpdateStreamSize(res_it->it->second);\n+  return cg ? OpStatus::OK : OpStatus::BUSY_GROUP;\n }\n \n struct FindGroupResult {\n   stream* s = nullptr;\n   streamCG* cg = nullptr;\n   DbSlice::AutoUpdater post_updater;\n+  DbSlice::Iterator it;\n };\n \n OpResult<FindGroupResult> FindGroup(const OpArgs& op_args, string_view key, string_view gname,\n@@ -1147,7 +1169,7 @@ OpResult<FindGroupResult> FindGroup(const OpArgs& op_args, string_view key, stri\n   if (skip_group && !cg)\n     return OpStatus::SKIPPED;\n \n-  return FindGroupResult{s, cg, std::move(res_it->post_updater)};\n+  return FindGroupResult{s, cg, std::move(res_it->post_updater), res_it->it};\n }\n \n constexpr uint8_t kClaimForce = 1 << 0;\n@@ -1221,6 +1243,8 @@ OpResult<ClaimInfo> OpClaim(const OpArgs& op_args, string_view key, const ClaimO\n     }\n   }\n \n+  StreamMemTracker tracker;\n+\n   for (streamID id : ids) {\n     std::array<uint8_t, sizeof(streamID)> buf;\n     StreamEncodeID(buf.begin(), &id);\n@@ -1292,6 +1316,7 @@ OpResult<ClaimInfo> OpClaim(const OpArgs& op_args, string_view key, const ClaimO\n       AppendClaimResultItem(result, cgr_res->s, id);\n     }\n   }\n+  tracker.UpdateStreamSize(cgr_res->it->second);\n   return result;\n }\n \n@@ -1299,10 +1324,13 @@ OpResult<ClaimInfo> OpClaim(const OpArgs& op_args, string_view key, const ClaimO\n OpStatus OpDestroyGroup(const OpArgs& op_args, string_view key, string_view gname) {\n   auto cgr_res = FindGroup(op_args, key, gname);\n   RETURN_ON_BAD_STATUS(cgr_res);\n+  StreamMemTracker mem_tracker;\n \n   raxRemove(cgr_res->s->cgroups, (uint8_t*)(gname.data()), gname.size(), NULL);\n   streamFreeCG(cgr_res->cg);\n \n+  mem_tracker.UpdateStreamSize(cgr_res->it->second);\n+\n   // Awake readers blocked on this group\n   auto blocking_controller = op_args.db_cntx.ns->GetBlockingController(op_args.shard->shard_id());\n   if (blocking_controller) {\n@@ -1328,12 +1356,13 @@ OpResult<uint32_t> OpCreateConsumer(const OpArgs& op_args, string_view key, stri\n   auto cgroup_res = FindGroup(op_args, key, gname);\n   RETURN_ON_BAD_STATUS(cgroup_res);\n \n+  StreamMemTracker mem_tracker;\n+\n   streamConsumer* consumer = streamCreateConsumer(cgroup_res->cg, WrapSds(consumer_name), NULL, 0,\n                                                   SCC_NO_NOTIFY | SCC_NO_DIRTIFY);\n \n-  if (consumer)\n-    return OpStatus::OK;\n-  return OpStatus::KEY_EXISTS;\n+  mem_tracker.UpdateStreamSize(cgroup_res->it->second);\n+  return consumer ? OpStatus::OK : OpStatus::KEY_EXISTS;\n }\n \n // XGROUP DELCONSUMER key groupname consumername\n@@ -1341,6 +1370,7 @@ OpResult<uint32_t> OpDelConsumer(const OpArgs& op_args, string_view key, string_\n                                  string_view consumer_name) {\n   auto cgroup_res = FindGroup(op_args, key, gname);\n   RETURN_ON_BAD_STATUS(cgroup_res);\n+  StreamMemTracker mem_tracker;\n \n   long long pending = 0;\n   streamConsumer* consumer =\n@@ -1350,6 +1380,7 @@ OpResult<uint32_t> OpDelConsumer(const OpArgs& op_args, string_view key, string_\n     streamDelConsumer(cgroup_res->cg, consumer);\n   }\n \n+  mem_tracker.UpdateStreamSize(cgroup_res->it->second);\n   return pending;\n }\n \n@@ -1379,6 +1410,8 @@ OpStatus OpSetId2(const OpArgs& op_args, string_view key, const streamID& sid) {\n   if (!res_it)\n     return res_it.status();\n \n+  StreamMemTracker mem_tracker;\n+\n   CompactObj& cobj = res_it->it->second;\n   stream* stream_inst = (stream*)cobj.RObjPtr();\n   long long entries_added = -1;\n@@ -1408,6 +1441,8 @@ OpStatus OpSetId2(const OpArgs& op_args, string_view key, const streamID& sid) {\n   if (!streamIDEqZero(&max_xdel_id))\n     stream_inst->max_deleted_entry_id = max_xdel_id;\n \n+  mem_tracker.UpdateStreamSize(cobj);\n+\n   return OpStatus::OK;\n }\n \n@@ -1423,6 +1458,8 @@ OpResult<uint32_t> OpDel(const OpArgs& op_args, string_view key, absl::Span<stre\n   uint32_t deleted = 0;\n   bool first_entry = false;\n \n+  StreamMemTracker tracker;\n+\n   for (size_t j = 0; j < ids.size(); j++) {\n     streamID id = ids[j];\n     if (!streamDeleteItem(stream_inst, &id))\n@@ -1450,6 +1487,7 @@ OpResult<uint32_t> OpDel(const OpArgs& op_args, string_view key, absl::Span<stre\n     }\n   }\n \n+  tracker.UpdateStreamSize(cobj);\n   return deleted;\n }\n \n@@ -1464,6 +1502,7 @@ OpResult<uint32_t> OpAck(const OpArgs& op_args, string_view key, string_view gna\n   }\n \n   int acknowledged = 0;\n+  StreamMemTracker mem_tracker;\n   for (auto& id : ids) {\n     unsigned char buf[sizeof(streamID)];\n     streamEncodeID(buf, &id);\n@@ -1480,6 +1519,7 @@ OpResult<uint32_t> OpAck(const OpArgs& op_args, string_view key, string_view gna\n       acknowledged++;\n     }\n   }\n+  mem_tracker.UpdateStreamSize(res->it->second);\n   return acknowledged;\n }\n \n@@ -1494,6 +1534,8 @@ OpResult<ClaimInfo> OpAutoClaim(const OpArgs& op_args, string_view key, const Cl\n     return OpStatus::KEY_NOTFOUND;\n   }\n \n+  StreamMemTracker mem_tracker;\n+\n   streamConsumer* consumer = nullptr;\n   // from Redis spec on XAutoClaim:\n   // https://redis.io/commands/xautoclaim/\n@@ -1572,6 +1614,8 @@ OpResult<ClaimInfo> OpAutoClaim(const OpArgs& op_args, string_view key, const Cl\n   raxStop(&ri);\n   result.end_id = end_id;\n \n+  mem_tracker.UpdateStreamSize(cgr_res->it->second);\n+\n   return result;\n }\n \n@@ -1874,10 +1918,15 @@ OpResult<int64_t> OpTrim(const OpArgs& op_args, const AddTrimOpts& opts) {\n     return res_it.status();\n   }\n \n+  StreamMemTracker mem_tracker;\n+\n   CompactObj& cobj = res_it->it->second;\n   stream* s = (stream*)cobj.RObjPtr();\n \n-  return StreamTrim(opts, s);\n+  auto res = StreamTrim(opts, s);\n+\n+  mem_tracker.UpdateStreamSize(cobj);\n+  return res;\n }\n \n optional<pair<AddTrimOpts, unsigned>> ParseAddOrTrimArgsOrReply(CmdArgList args, bool is_xadd,\n",
  "test_patch": "diff --git a/tests/dragonfly/memory_test.py b/tests/dragonfly/memory_test.py\nindex 843e7c606dc9..d52b266c3213 100644\n--- a/tests/dragonfly/memory_test.py\n+++ b/tests/dragonfly/memory_test.py\n@@ -16,6 +16,7 @@\n         (\"ZSET\", 250_000, 100, 100),\n         (\"LIST\", 300_000, 100, 100),\n         (\"STRING\", 3_500_000, 1000, 1),\n+        (\"STREAM\", 260_000, 100, 100),\n     ],\n )\n # We limit to 5gb just in case to sanity check the gh runner. Otherwise, if we ask for too much\n@@ -28,6 +29,12 @@ async def test_rss_used_mem_gap(df_server: DflyInstance, type, keys, val_size, e\n     min_rss = 3 * 1024 * 1024 * 1024  # 3gb\n     max_unaccounted = 200 * 1024 * 1024  # 200mb\n \n+    # There is a big rss spike when this test is ran in one the gh runners (not the self hosted)\n+    # and it fails. This rss spike is not observed locally or on our self host runner so\n+    # this adjustment is mostly for CI\n+    if type == \"STREAM\":\n+        max_unaccounted = max_unaccounted * 3\n+\n     client = df_server.client()\n     await asyncio.sleep(1)  # Wait for another RSS heartbeat update in Dragonfly\n \n@@ -46,7 +53,7 @@ async def test_rss_used_mem_gap(df_server: DflyInstance, type, keys, val_size, e\n     assert delta < max_unaccounted\n     delta = info[\"used_memory_rss\"] - info[\"object_used_memory\"]\n     # TODO investigate why it fails on string\n-    if type == \"json\":\n+    if type == \"JSON\" or type == \"STREAM\":\n         assert delta > 0\n         assert delta < max_unaccounted\n \n",
  "problem_statement": "MEMORY USAGE for STREAM keys always return (integer) 0\n**Describe the bug**\r\nMEMORY USAGE for STREAM keys always return (integer) 0\r\n\r\n**To Reproduce**\r\nSteps to reproduce:\r\n1. Create stream using `XADD test-stream * just test`\r\n2. Query stream size `MEMORY USAGE test-stream`\r\n3. Result `(integer) 0`\r\n\r\n**Expected behavior**\r\n1. Create stream using `XADD test-stream * just test`\r\n2. Query stream size `MEMORY USAGE test-stream`\r\n3. Result `(integer) 4736`  (example from redis_version:7.2.6)\r\n\r\n**Environment (please complete the following information):**\r\n - OS: `Ubuntu 24.04`\r\n - Kernel: `Linux 6.8.0-47-generic #47-Ubuntu SMP PREEMPT_DYNAMIC Fri Sep 27 22:03:50 UTC 2024 aarch64 aarch64 aarch64 GNU/Linux`\r\n - Containerized?: `Docker version 27.3.1, build ce12230` `image: 'docker.dragonflydb.io/dragonflydb/dragonfly:v1.24.0'`\r\n - Dragonfly Version: v1.24.0\r\n\n",
  "hints_text": "Hi @trisua, you are right this is a bug and thank you for reporting. \r\n\r\nSee: \r\n\r\n```\r\n  size_t MallocUsedStream(unsigned encoding, void* streamv) {\r\n    // stream* str_obj = (stream*)streamv;\r\n    return 0;  // TODO\r\n  }\r\n\r\n```",
  "created_at": "2024-11-05T12:43:59Z",
  "modified_files": [
    "src/core/compact_object.cc",
    "src/core/compact_object.h",
    "src/server/stream_family.cc"
  ],
  "modified_test_files": [
    "tests/dragonfly/memory_test.py"
  ]
}