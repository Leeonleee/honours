{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 4729,
  "instance_id": "dragonflydb__dragonfly-4729",
  "issue_numbers": [
    "4660"
  ],
  "base_commit": "4f70d1bdbc6fe8f126aab88bf209d0c9364ca3fa",
  "patch": "diff --git a/src/server/detail/save_stages_controller.cc b/src/server/detail/save_stages_controller.cc\nindex 0099974bd212..0f0b9a5b88e5 100644\n--- a/src/server/detail/save_stages_controller.cc\n+++ b/src/server/detail/save_stages_controller.cc\n@@ -35,10 +35,6 @@ namespace fs = std::filesystem;\n \n namespace {\n \n-bool IsCloudPath(string_view path) {\n-  return absl::StartsWith(path, kS3Prefix) || absl::StartsWith(path, kGCSPrefix);\n-}\n-\n // Create a directory and all its parents if they don't exist.\n error_code CreateDirs(fs::path dir_path) {\n   error_code ec;\n@@ -387,8 +383,8 @@ GenericError SaveStagesController::FinalizeFileMovement() {\n \n // Build full path: get dir, try creating dirs, get filename with placeholder\n GenericError SaveStagesController::BuildFullPath() {\n-  fs::path dir_path = GetFlag(FLAGS_dir);\n-  if (!dir_path.empty() && !IsCloudPath(GetFlag(FLAGS_dir))) {\n+  fs::path dir_path = cloud_uri_.empty() ? GetFlag(FLAGS_dir) : cloud_uri_;\n+  if (!dir_path.empty() && cloud_uri_.empty() && !IsCloudPath(GetFlag(FLAGS_dir))) {\n     if (auto ec = CreateDirs(dir_path); ec)\n       return {ec, \"Failed to create directories\"};\n   }\ndiff --git a/src/server/detail/save_stages_controller.h b/src/server/detail/save_stages_controller.h\nindex abf8bd6bdf0a..564a672aced3 100644\n--- a/src/server/detail/save_stages_controller.h\n+++ b/src/server/detail/save_stages_controller.h\n@@ -29,6 +29,7 @@ struct SaveInfo {\n \n struct SaveStagesInputs {\n   bool use_dfs_format_;\n+  std::string_view cloud_uri_;\n   std::string_view basename_;\n   Transaction* trans_;\n   Service* service_;\ndiff --git a/src/server/detail/snapshot_storage.cc b/src/server/detail/snapshot_storage.cc\nindex f327938a98f1..4ebeea78b97c 100644\n--- a/src/server/detail/snapshot_storage.cc\n+++ b/src/server/detail/snapshot_storage.cc\n@@ -34,9 +34,6 @@ using namespace util;\n using namespace std;\n \n namespace {\n-inline bool IsGcsPath(string_view path) {\n-  return absl::StartsWith(path, kGCSPrefix);\n-}\n \n constexpr string_view kSummarySuffix = \"summary.dfs\"sv;\n \n@@ -270,7 +267,7 @@ io::Result<std::pair<io::Sink*, uint8_t>, GenericError> GcsSnapshotStorage::Open\n }\n \n io::ReadonlyFileOrError GcsSnapshotStorage::OpenReadFile(const std::string& path) {\n-  if (!IsGcsPath(path))\n+  if (!IsGCSPath(path))\n     return nonstd::make_unexpected(GenericError(\"Invalid GCS path\"));\n \n   auto [bucket, key] = GetBucketPath(path);\n@@ -321,7 +318,7 @@ io::Result<std::string, GenericError> GcsSnapshotStorage::LoadPath(string_view d\n \n io::Result<vector<string>, GenericError> GcsSnapshotStorage::ExpandFromPath(\n     const string& load_path) {\n-  if (!IsGcsPath(load_path))\n+  if (!IsGCSPath(load_path))\n     return nonstd::make_unexpected(\n         GenericError(make_error_code(errc::invalid_argument), \"Invalid GCS path\"));\n \ndiff --git a/src/server/detail/snapshot_storage.h b/src/server/detail/snapshot_storage.h\nindex 6f217a5454ca..537235c0f2e9 100644\n--- a/src/server/detail/snapshot_storage.h\n+++ b/src/server/detail/snapshot_storage.h\n@@ -7,6 +7,8 @@\n #include <aws/s3/S3Client.h>\n #endif\n \n+#include <absl/strings/match.h>\n+\n #include <filesystem>\n #include <string>\n #include <string_view>\n@@ -186,5 +188,17 @@ struct FilenameSubstitutions {\n \n void SubstituteFilenamePlaceholders(fs::path* filename, const FilenameSubstitutions& fns);\n \n+inline bool IsS3Path(std::string_view path) {\n+  return absl::StartsWith(path, detail::kS3Prefix);\n+}\n+\n+inline bool IsGCSPath(std::string_view path) {\n+  return absl::StartsWith(path, detail::kGCSPrefix);\n+}\n+\n+inline bool IsCloudPath(std::string_view path) {\n+  return IsS3Path(path) || IsGCSPath(path);\n+}\n+\n }  // namespace detail\n }  // namespace dfly\ndiff --git a/src/server/server_family.cc b/src/server/server_family.cc\nindex 156634604a8f..a69fd3a637f0 100644\n--- a/src/server/server_family.cc\n+++ b/src/server/server_family.cc\n@@ -251,12 +251,29 @@ string UnknownCmd(string cmd, CmdArgList args) {\n                       absl::StrJoin(args.begin(), args.end(), \", \", CmdArgListFormatter()));\n }\n \n-bool IsS3Path(string_view path) {\n-  return absl::StartsWith(path, detail::kS3Prefix);\n-}\n-\n-bool IsGCSPath(string_view path) {\n-  return absl::StartsWith(path, detail::kGCSPrefix);\n+std::shared_ptr<detail::SnapshotStorage> CreateCloudSnapshotStorage(std::string_view uri) {\n+  if (detail::IsS3Path(uri)) {\n+#ifdef WITH_AWS\n+    shard_set->pool()->GetNextProactor()->Await([&] { util::aws::Init(); });\n+    return std::make_shared<detail::AwsS3SnapshotStorage>(\n+        absl::GetFlag(FLAGS_s3_endpoint), absl::GetFlag(FLAGS_s3_use_https),\n+        absl::GetFlag(FLAGS_s3_ec2_metadata), absl::GetFlag(FLAGS_s3_sign_payload));\n+#else\n+    LOG(ERROR) << \"Compiled without AWS support\";\n+    exit(1);\n+#endif\n+  } else if (detail::IsGCSPath(uri)) {\n+    auto gcs = std::make_shared<detail::GcsSnapshotStorage>();\n+    auto ec = shard_set->pool()->GetNextProactor()->Await([&] { return gcs->Init(3000); });\n+    if (ec) {\n+      LOG(ERROR) << \"Failed to initialize GCS snapshot storage: \" << ec.message();\n+      exit(1);\n+    }\n+    return gcs;\n+  } else {\n+    LOG(ERROR) << \"Uknown cloud storage \" << uri;\n+    exit(1);\n+  }\n }\n \n // Check that if TLS is used at least one form of client authentication is\n@@ -854,24 +871,9 @@ void ServerFamily::Init(util::AcceptServer* acceptor, std::vector<facade::Listen\n   }\n \n   string flag_dir = GetFlag(FLAGS_dir);\n-  if (IsS3Path(flag_dir)) {\n-#ifdef WITH_AWS\n-    shard_set->pool()->GetNextProactor()->Await([&] { util::aws::Init(); });\n-    snapshot_storage_ = std::make_shared<detail::AwsS3SnapshotStorage>(\n-        absl::GetFlag(FLAGS_s3_endpoint), absl::GetFlag(FLAGS_s3_use_https),\n-        absl::GetFlag(FLAGS_s3_ec2_metadata), absl::GetFlag(FLAGS_s3_sign_payload));\n-#else\n-    LOG(ERROR) << \"Compiled without AWS support\";\n-    exit(1);\n-#endif\n-  } else if (IsGCSPath(flag_dir)) {\n-    auto gcs = std::make_shared<detail::GcsSnapshotStorage>();\n-    auto ec = shard_set->pool()->GetNextProactor()->Await([&] { return gcs->Init(3000); });\n-    if (ec) {\n-      LOG(ERROR) << \"Failed to initialize GCS snapshot storage: \" << ec.message();\n-      exit(1);\n-    }\n-    snapshot_storage_ = std::move(gcs);\n+\n+  if (detail::IsCloudPath(flag_dir)) {\n+    snapshot_storage_ = CreateCloudSnapshotStorage(flag_dir);\n   } else if (fq_threadpool_) {\n     snapshot_storage_ = std::make_shared<detail::FileSnapshotStorage>(fq_threadpool_.get());\n   } else {\n@@ -1655,10 +1657,11 @@ GenericError ServerFamily::DoSave(bool ignore_state) {\n   CHECK_NOTNULL(cid);\n   boost::intrusive_ptr<Transaction> trans(new Transaction{cid});\n   trans->InitByArgs(&namespaces->GetDefaultNamespace(), 0, {});\n-  return DoSave(absl::GetFlag(FLAGS_df_snapshot_format), {}, trans.get(), ignore_state);\n+  return DoSave(SaveCmdOptions{absl::GetFlag(FLAGS_df_snapshot_format), {}, {}}, trans.get(),\n+                ignore_state);\n }\n \n-GenericError ServerFamily::DoSaveCheckAndStart(bool new_version, string_view basename,\n+GenericError ServerFamily::DoSaveCheckAndStart(const SaveCmdOptions& save_cmd_opts,\n                                                Transaction* trans, bool ignore_state) {\n   auto state = ServerState::tlocal()->gstate();\n \n@@ -1674,10 +1677,13 @@ GenericError ServerFamily::DoSaveCheckAndStart(bool new_version, string_view bas\n                           \"SAVING - can not save database\"};\n     }\n \n-    VLOG(1) << \"Saving snapshot to \" << basename;\n+    auto snapshot_storage = save_cmd_opts.cloud_uri.empty()\n+                                ? snapshot_storage_\n+                                : CreateCloudSnapshotStorage(save_cmd_opts.cloud_uri);\n \n     save_controller_ = make_unique<SaveStagesController>(detail::SaveStagesInputs{\n-        new_version, basename, trans, &service_, fq_threadpool_.get(), snapshot_storage_});\n+        save_cmd_opts.new_version, save_cmd_opts.cloud_uri, save_cmd_opts.basename, trans,\n+        &service_, fq_threadpool_.get(), snapshot_storage});\n \n     auto res = save_controller_->InitResourcesAndStart();\n \n@@ -1714,9 +1720,9 @@ GenericError ServerFamily::WaitUntilSaveFinished(Transaction* trans, bool ignore\n   return save_info.error;\n }\n \n-GenericError ServerFamily::DoSave(bool new_version, string_view basename, Transaction* trans,\n+GenericError ServerFamily::DoSave(const SaveCmdOptions& save_cmd_opts, Transaction* trans,\n                                   bool ignore_state) {\n-  if (auto ec = DoSaveCheckAndStart(new_version, basename, trans, ignore_state); ec) {\n+  if (auto ec = DoSaveCheckAndStart(save_cmd_opts, trans, ignore_state); ec) {\n     return ec;\n   }\n \n@@ -2078,46 +2084,61 @@ void ServerFamily::BgSaveFb(boost::intrusive_ptr<Transaction> trans) {\n   }\n }\n \n-std::optional<ServerFamily::VersionBasename> ServerFamily::GetVersionAndBasename(\n-    CmdArgList args, SinkReplyBuilder* builder) {\n-  if (args.size() > 2) {\n+std::optional<SaveCmdOptions> ServerFamily::GetSaveCmdOpts(CmdArgList args,\n+                                                           SinkReplyBuilder* builder) {\n+  if (args.size() > 3) {\n     builder->SendError(kSyntaxErr);\n     return {};\n   }\n \n-  bool new_version = absl::GetFlag(FLAGS_df_snapshot_format);\n+  SaveCmdOptions save_cmd_opts;\n+  save_cmd_opts.new_version = absl::GetFlag(FLAGS_df_snapshot_format);\n \n   if (args.size() >= 1) {\n     string sub_cmd = absl::AsciiStrToUpper(ArgS(args, 0));\n     if (sub_cmd == \"DF\") {\n-      new_version = true;\n+      save_cmd_opts.new_version = true;\n     } else if (sub_cmd == \"RDB\") {\n-      new_version = false;\n+      save_cmd_opts.new_version = false;\n     } else {\n       builder->SendError(UnknownSubCmd(sub_cmd, \"SAVE\"), kSyntaxErrType);\n       return {};\n     }\n   }\n \n-  string_view basename;\n-  if (args.size() == 2) {\n-    basename = ArgS(args, 1);\n+  if (args.size() >= 2) {\n+    if (detail::IsS3Path(ArgS(args, 1))) {\n+#ifdef WITH_AWS\n+      save_cmd_opts.cloud_uri = ArgS(args, 1);\n+#else\n+      LOG(ERROR) << \"Compiled without AWS support\";\n+      exit(1);\n+#endif\n+    } else if (detail::IsGCSPath(ArgS(args, 1))) {\n+      save_cmd_opts.cloud_uri = ArgS(args, 1);\n+    } else {\n+      // no cloud_uri get basename and return\n+      save_cmd_opts.basename = ArgS(args, 1);\n+      return save_cmd_opts;\n+    }\n+    // cloud_uri is set so get basename if provided\n+    if (args.size() == 3) {\n+      save_cmd_opts.basename = ArgS(args, 2);\n+    }\n   }\n \n-  return ServerFamily::VersionBasename{new_version, basename};\n+  return save_cmd_opts;\n }\n \n-// BGSAVE [DF|RDB] [basename]\n+// SAVE [DF|RDB] [CLOUD_URI] [BASENAME]\n // TODO add missing [SCHEDULE]\n void ServerFamily::BgSave(CmdArgList args, const CommandContext& cmd_cntx) {\n-  auto maybe_res = GetVersionAndBasename(args, cmd_cntx.rb);\n+  auto maybe_res = GetSaveCmdOpts(args, cmd_cntx.rb);\n   if (!maybe_res) {\n     return;\n   }\n \n-  const auto [version, basename] = *maybe_res;\n-\n-  if (auto ec = DoSaveCheckAndStart(version, basename, cmd_cntx.tx); ec) {\n+  if (auto ec = DoSaveCheckAndStart(*maybe_res, cmd_cntx.tx); ec) {\n     cmd_cntx.rb->SendError(ec.Format());\n     return;\n   }\n@@ -2127,18 +2148,16 @@ void ServerFamily::BgSave(CmdArgList args, const CommandContext& cmd_cntx) {\n   cmd_cntx.rb->SendOk();\n }\n \n-// SAVE [DF|RDB] [basename]\n+// SAVE [DF|RDB] [CLOUD_URI] [BASENAME]\n // Allows saving the snapshot of the dataset on disk, potentially overriding the format\n // and the snapshot name.\n void ServerFamily::Save(CmdArgList args, const CommandContext& cmd_cntx) {\n-  auto maybe_res = GetVersionAndBasename(args, cmd_cntx.rb);\n+  auto maybe_res = GetSaveCmdOpts(args, cmd_cntx.rb);\n   if (!maybe_res) {\n     return;\n   }\n \n-  const auto [version, basename] = *maybe_res;\n-\n-  GenericError ec = DoSave(version, basename, cmd_cntx.tx);\n+  GenericError ec = DoSave(*maybe_res, cmd_cntx.tx);\n   if (ec) {\n     cmd_cntx.rb->SendError(ec.Format());\n   } else {\ndiff --git a/src/server/server_family.h b/src/server/server_family.h\nindex db479ab1ccb7..092622701c35 100644\n--- a/src/server/server_family.h\n+++ b/src/server/server_family.h\n@@ -158,6 +158,15 @@ struct ReplicaOffsetInfo {\n   std::vector<uint64_t> flow_offsets;\n };\n \n+struct SaveCmdOptions {\n+  // if new_version is true, saves DF specific, non redis compatible snapshot.\n+  bool new_version;\n+  // cloud storage URI\n+  std::string_view cloud_uri;\n+  // if basename is not empty it will override dbfilename flag\n+  std::string_view basename;\n+};\n+\n class ServerFamily {\n   using SinkReplyBuilder = facade::SinkReplyBuilder;\n \n@@ -193,9 +202,7 @@ class ServerFamily {\n \n   void StatsMC(std::string_view section, SinkReplyBuilder* builder);\n \n-  // if new_version is true, saves DF specific, non redis compatible snapshot.\n-  // if basename is not empty it will override dbfilename flag.\n-  GenericError DoSave(bool new_version, std::string_view basename, Transaction* transaction,\n+  GenericError DoSave(const SaveCmdOptions& save_cmd_opts, Transaction* transaction,\n                       bool ignore_state = false);\n \n   // Calls DoSave with a default generated transaction and with the format\n@@ -313,14 +320,11 @@ class ServerFamily {\n \n   void SendInvalidationMessages() const;\n \n-  // Helper function to retrieve version(true if format is dfs rdb), and basename from args.\n-  // In case of an error an empty optional is returned.\n-  using VersionBasename = std::pair<bool, std::string_view>;\n-  std::optional<VersionBasename> GetVersionAndBasename(CmdArgList args, SinkReplyBuilder* builder);\n+  std::optional<SaveCmdOptions> GetSaveCmdOpts(CmdArgList args, SinkReplyBuilder* builder);\n \n   void BgSaveFb(boost::intrusive_ptr<Transaction> trans);\n \n-  GenericError DoSaveCheckAndStart(bool new_version, string_view basename, Transaction* trans,\n+  GenericError DoSaveCheckAndStart(const SaveCmdOptions& save_cmd_opts, Transaction* trans,\n                                    bool ignore_state = false) ABSL_LOCKS_EXCLUDED(save_mu_);\n \n   GenericError WaitUntilSaveFinished(Transaction* trans,\n",
  "test_patch": "diff --git a/tests/dragonfly/snapshot_test.py b/tests/dragonfly/snapshot_test.py\nindex ba6544f48f1c..483fca160a24 100644\n--- a/tests/dragonfly/snapshot_test.py\n+++ b/tests/dragonfly/snapshot_test.py\n@@ -311,6 +311,21 @@ async def test_info_persistence_field(async_client):\n     assert \"loading:0\" in (await async_client.execute_command(\"INFO PERSISTENCE\"))\n \n \n+def delete_s3_objects(bucket, prefix):\n+    client = boto3.client(\"s3\")\n+    resp = client.list_objects_v2(\n+        Bucket=bucket,\n+        Prefix=prefix,\n+    )\n+    keys = []\n+    for obj in resp[\"Contents\"]:\n+        keys.append({\"Key\": obj[\"Key\"]})\n+    client.delete_objects(\n+        Bucket=bucket,\n+        Delete={\"Objects\": keys},\n+    )\n+\n+\n # If DRAGONFLY_S3_BUCKET is configured, AWS credentials must also be\n # configured.\n @pytest.mark.skipif(\n@@ -338,27 +353,36 @@ async def test_s3_snapshot(async_client, tmp_dir):\n         assert await StaticSeeder.capture(async_client) == start_capture\n \n     finally:\n-\n-        def delete_objects(bucket, prefix):\n-            client = boto3.client(\"s3\")\n-            resp = client.list_objects_v2(\n-                Bucket=bucket,\n-                Prefix=prefix,\n-            )\n-            keys = []\n-            for obj in resp[\"Contents\"]:\n-                keys.append({\"Key\": obj[\"Key\"]})\n-            client.delete_objects(\n-                Bucket=bucket,\n-                Delete={\"Objects\": keys},\n-            )\n-\n-        delete_objects(\n+        delete_s3_objects(\n             os.environ[\"DRAGONFLY_S3_BUCKET\"],\n             str(tmp_dir)[1:],\n         )\n \n \n+# If DRAGONFLY_S3_BUCKET is configured, AWS credentials must also be\n+# configured.\n+@pytest.mark.skipif(\n+    \"DRAGONFLY_S3_BUCKET\" not in os.environ or os.environ[\"DRAGONFLY_S3_BUCKET\"] == \"\",\n+    reason=\"AWS S3 snapshots bucket is not configured\",\n+)\n+@dfly_args({**BASIC_ARGS})\n+async def test_s3_save_local_dir(async_client):\n+    seeder = StaticSeeder(key_target=10_000)\n+    await seeder.run(async_client)\n+\n+    try:\n+        # SAVE to S3 bucket with `s3_dump` as filename prefix\n+        await async_client.execute_command(\n+            \"SAVE\", \"DF\", \"s3://\" + os.environ[\"DRAGONFLY_S3_BUCKET\"], \"s3_dump\"\n+        )\n+\n+    finally:\n+        delete_s3_objects(\n+            os.environ[\"DRAGONFLY_S3_BUCKET\"],\n+            \"s3_dump\",\n+        )\n+\n+\n @dfly_args({**BASIC_ARGS, \"dbfilename\": \"test-shutdown\"})\n class TestDflySnapshotOnShutdown:\n     SEEDER_ARGS = dict(key_target=10_000)\n",
  "problem_statement": "Support dynamic s3 path to save df command\n**Is your feature request related to a problem? Please describe.**\nDragonfly has some flags to configure s3 path for backups. However the configuration is static in nature i.e. we only get to configure the path when starting the dragonfly instance. The downside is backups always end up in the same s3 storage path.\n\nI had configured s3 flags and executed the command `save df s3://path`. But it takes this as a file path.\n\n**Describe the solution you'd like**\nI need dragonfly to support s3 path argument in `save df` command so that we can store different backups in different s3 paths. Something like `save df s3://path/to/s3/storage`.\n\n",
  "hints_text": "",
  "created_at": "2025-03-07T12:36:47Z",
  "modified_files": [
    "src/server/detail/save_stages_controller.cc",
    "src/server/detail/save_stages_controller.h",
    "src/server/detail/snapshot_storage.cc",
    "src/server/detail/snapshot_storage.h",
    "src/server/server_family.cc",
    "src/server/server_family.h"
  ],
  "modified_test_files": [
    "tests/dragonfly/snapshot_test.py"
  ]
}