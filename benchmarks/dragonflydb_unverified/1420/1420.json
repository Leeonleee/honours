{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 1420,
  "instance_id": "dragonflydb__dragonfly-1420",
  "issue_numbers": [
    "1421"
  ],
  "base_commit": "956b39c5537811989e2f250019bc72af9980375b",
  "patch": "diff --git a/src/facade/dragonfly_connection.cc b/src/facade/dragonfly_connection.cc\nindex 2909cf6bd96f..c5286c61b932 100644\n--- a/src/facade/dragonfly_connection.cc\n+++ b/src/facade/dragonfly_connection.cc\n@@ -43,18 +43,13 @@ using nonstd::make_unexpected;\n namespace facade {\n namespace {\n \n-void SendProtocolError(RedisParser::Result pres, FiberSocketBase* peer) {\n+void SendProtocolError(RedisParser::Result pres, SinkReplyBuilder* builder) {\n   string res(\"-ERR Protocol error: \");\n   if (pres == RedisParser::BAD_BULKLEN) {\n-    res.append(\"invalid bulk length\\r\\n\");\n+    builder->SendProtocolError(\"invalid bulk length\");\n   } else {\n     CHECK_EQ(RedisParser::BAD_ARRAYLEN, pres);\n-    res.append(\"invalid multibulk length\\r\\n\");\n-  }\n-\n-  error_code ec = peer->Write(::io::Buffer(res));\n-  if (ec) {\n-    LOG(WARNING) << \"Error \" << ec;\n+    builder->SendProtocolError(\"invalid multibulk length\");\n   }\n }\n \n@@ -503,20 +498,17 @@ void Connection::ConnectionFlow(FiberSocketBase* peer) {\n   // offending request.\n   if (parse_status == ERROR) {\n     VLOG(1) << \"Error parser status \" << parser_error_;\n-    ++stats_->parser_err_cnt;\n \n     if (redis_parser_) {\n-      SendProtocolError(RedisParser::Result(parser_error_), peer);\n+      SendProtocolError(RedisParser::Result(parser_error_), orig_builder);\n     } else {\n-      string_view sv{\"CLIENT_ERROR bad command line format\\r\\n\"};\n-      error_code ec2 = peer->Write(::io::Buffer(sv));\n-      if (ec2) {\n-        LOG(WARNING) << \"Error \" << ec2;\n-        ec = ec2;\n-      }\n+      DCHECK(memcache_parser_);\n+      orig_builder->SendProtocolError(\"bad command line format\");\n     }\n     error_code ec2 = peer->Shutdown(SHUT_RDWR);\n     LOG_IF(WARNING, ec2) << \"Could not shutdown socket \" << ec2;\n+\n+    FetchBuilderStats(stats_, orig_builder);\n   }\n \n   if (ec && !FiberSocketBase::IsConnClosed(ec)) {\ndiff --git a/src/facade/facade.cc b/src/facade/facade.cc\nindex 69873f4ace73..8bc26ca99152 100644\n--- a/src/facade/facade.cc\n+++ b/src/facade/facade.cc\n@@ -21,7 +21,7 @@ constexpr size_t kSizeConnStats = sizeof(ConnectionStats);\n \n ConnectionStats& ConnectionStats::operator+=(const ConnectionStats& o) {\n   // To break this code deliberately if we add/remove a field to this struct.\n-  static_assert(kSizeConnStats == 184);\n+  static_assert(kSizeConnStats == 176);\n \n   ADD(read_buf_capacity);\n   ADD(pipeline_cache_capacity);\n@@ -31,7 +31,6 @@ ConnectionStats& ConnectionStats::operator+=(const ConnectionStats& o) {\n   ADD(io_write_bytes);\n   ADD(command_cnt);\n   ADD(pipelined_cmd_cnt);\n-  ADD(parser_err_cnt);\n   ADD(async_writes_cnt);\n   ADD(conn_received_cnt);\n   ADD(num_conns);\ndiff --git a/src/facade/facade_types.h b/src/facade/facade_types.h\nindex 42a531a1016f..b25420876cb5 100644\n--- a/src/facade/facade_types.h\n+++ b/src/facade/facade_types.h\n@@ -44,7 +44,6 @@ struct ConnectionStats {\n   size_t io_write_bytes = 0;\n   uint64_t command_cnt = 0;\n   uint64_t pipelined_cmd_cnt = 0;\n-  uint64_t parser_err_cnt = 0;\n \n   // Writes count that happened via DispatchOperations call.\n   uint64_t async_writes_cnt = 0;\ndiff --git a/src/facade/redis_parser.cc b/src/facade/redis_parser.cc\nindex c3754c234b7b..5949094fb252 100644\n--- a/src/facade/redis_parser.cc\n+++ b/src/facade/redis_parser.cc\n@@ -13,6 +13,7 @@ using namespace std;\n \n namespace {\n \n+// When changing this constant, also update `test_large_cmd` test in connection_test.py.\n constexpr int kMaxArrayLen = 65536;\n constexpr int64_t kMaxBulkLen = 64 * (1ul << 20);  // 64MB.\n \ndiff --git a/src/facade/reply_builder.cc b/src/facade/reply_builder.cc\nindex 517199f40807..5bfb3be49593 100644\n--- a/src/facade/reply_builder.cc\n+++ b/src/facade/reply_builder.cc\n@@ -54,7 +54,7 @@ void SinkReplyBuilder::Send(const iovec* v, uint32_t len) {\n   }\n \n   // Allow batching with up to 8K of data.\n-  if ((should_batch_ || should_aggregate_) && batch_.size() + bsize < kMaxBatchSize) {\n+  if ((should_batch_ || should_aggregate_) && (batch_.size() + bsize < kMaxBatchSize)) {\n     for (unsigned i = 0; i < len; ++i) {\n       std::string_view src((char*)v[i].iov_base, v[i].iov_len);\n       DVLOG(2) << \"Appending to stream \" << src;\n@@ -71,7 +71,7 @@ void SinkReplyBuilder::Send(const iovec* v, uint32_t len) {\n   if (batch_.empty()) {\n     ec = sink_->Write(v, len);\n   } else {\n-    DVLOG(1) << \"Sending batch to stream \" << sink_ << \"\\n\" << batch_;\n+    DVLOG(2) << \"Sending batch to stream \" << sink_ << \"\\n\" << batch_;\n \n     io_write_bytes_ += batch_.size();\n \n@@ -162,6 +162,10 @@ void MCReplyBuilder::SendError(string_view str, std::string_view type) {\n   SendSimpleString(\"ERROR\");\n }\n \n+void MCReplyBuilder::SendProtocolError(std::string_view str) {\n+  SendSimpleString(absl::StrCat(\"CLIENT_ERROR \", str));\n+}\n+\n void MCReplyBuilder::SendClientError(string_view str) {\n   iovec v[] = {IoVec(\"CLIENT_ERROR \"), IoVec(str), IoVec(kCRLF)};\n   Send(v, ABSL_ARRAYSIZE(v));\n@@ -197,6 +201,8 @@ void RedisReplyBuilder::SetResp3(bool is_resp3) {\n }\n \n void RedisReplyBuilder::SendError(string_view str, string_view err_type) {\n+  VLOG(1) << \"Error: \" << str;\n+\n   if (err_type.empty()) {\n     err_type = str;\n     if (err_type == kSyntaxErr)\n@@ -214,6 +220,10 @@ void RedisReplyBuilder::SendError(string_view str, string_view err_type) {\n   }\n }\n \n+void RedisReplyBuilder::SendProtocolError(std::string_view str) {\n+  SendError(absl::StrCat(\"-ERR Protocol error: \", str), \"protocol_error\");\n+}\n+\n void RedisReplyBuilder::SendSimpleString(std::string_view str) {\n   iovec v[3] = {IoVec(kSimplePref), IoVec(str), IoVec(kCRLF)};\n \n@@ -483,7 +493,7 @@ void RedisReplyBuilder::SendStringArrInternal(WrappedStrSpan arr, CollectionType\n }\n \n void ReqSerializer::SendCommand(std::string_view str) {\n-  VLOG(1) << \"SendCommand: \" << str;\n+  VLOG(2) << \"SendCommand: \" << str;\n \n   iovec v[] = {IoVec(str), IoVec(kCRLF)};\n   ec_ = sink_->Write(v, ABSL_ARRAYSIZE(v));\ndiff --git a/src/facade/reply_builder.h b/src/facade/reply_builder.h\nindex 8652c7d48500..4dd51bd570b1 100644\n--- a/src/facade/reply_builder.h\n+++ b/src/facade/reply_builder.h\n@@ -54,6 +54,8 @@ class SinkReplyBuilder {\n     SendSimpleString(\"OK\");\n   }\n \n+  virtual void SendProtocolError(std::string_view str) = 0;\n+\n   // In order to reduce interrupt rate we allow coalescing responses together using\n   // Batch mode. It is controlled by Connection state machine because it makes sense only\n   // when pipelined requests are arriving.\n@@ -154,6 +156,7 @@ class MCReplyBuilder : public SinkReplyBuilder {\n   void SendClientError(std::string_view str);\n   void SendNotFound();\n   void SendSimpleString(std::string_view str) final;\n+  void SendProtocolError(std::string_view str) final;\n \n   void SetNoreply(bool noreply) {\n     noreply_ = noreply;\n@@ -176,6 +179,7 @@ class RedisReplyBuilder : public SinkReplyBuilder {\n   void SendStored() override;\n   void SendSetSkipped() override;\n   virtual void SendError(OpStatus status);\n+  void SendProtocolError(std::string_view str) override;\n \n   virtual void SendNullArray();   // Send *-1\n   virtual void SendEmptyArray();  // Send *0\ndiff --git a/src/server/server_family.cc b/src/server/server_family.cc\nindex 924ba7766b92..924c9e2b73f5 100644\n--- a/src/server/server_family.cc\n+++ b/src/server/server_family.cc\n@@ -1594,7 +1594,6 @@ void ServerFamily::Info(CmdArgList args, ConnectionContext* cntx) {\n     append(\"total_reads_processed\", m.conn_stats.io_read_cnt);\n     append(\"total_writes_processed\", m.conn_stats.io_write_cnt);\n     append(\"async_writes_count\", m.conn_stats.async_writes_cnt);\n-    append(\"parser_err_count\", m.conn_stats.parser_err_cnt);\n     append(\"defrag_attempt_total\", m.shard_stats.defrag_attempt_total);\n     append(\"defrag_realloc_total\", m.shard_stats.defrag_realloc_total);\n     append(\"defrag_task_invocation_total\", m.shard_stats.defrag_task_invocation_total);\ndiff --git a/src/server/transaction.cc b/src/server/transaction.cc\nindex b51867d92c63..54396be795ce 100644\n--- a/src/server/transaction.cc\n+++ b/src/server/transaction.cc\n@@ -133,8 +133,6 @@ void Transaction::InitShardData(absl::Span<const PerShardCache> shard_index, siz\n     auto& sd = shard_data_[i];\n     auto& si = shard_index[i];\n \n-    CHECK_LT(si.args.size(), 1u << 15);\n-\n     sd.arg_count = si.args.size();\n     sd.arg_start = args_.size();\n \n@@ -157,7 +155,7 @@ void Transaction::InitShardData(absl::Span<const PerShardCache> shard_index, siz\n     }\n   }\n \n-  CHECK(args_.size() == num_args);\n+  CHECK_EQ(args_.size(), num_args);\n }\n \n void Transaction::InitMultiData(KeyIndex key_index) {\ndiff --git a/src/server/transaction.h b/src/server/transaction.h\nindex 94ce97e52ddf..4e3bc7d574af 100644\n--- a/src/server/transaction.h\n+++ b/src/server/transaction.h\n@@ -329,16 +329,16 @@ class Transaction {\n     char pad[46];  // to make sure PerShardData is 64 bytes and takes full cacheline.\n \n     uint32_t arg_start = 0;  // Indices into args_ array.\n-    uint16_t arg_count = 0;\n-\n-    // Accessed within shard thread.\n-    // Bitmask of LocalState enums.\n-    uint16_t local_mask = 0;\n+    uint32_t arg_count = 0;\n \n     // Needed to rollback inconsistent schedulings or remove OOO transactions from\n     // tx queue.\n     uint32_t pq_pos = TxQueue::kEnd;\n \n+    // Accessed within shard thread.\n+    // Bitmask of LocalState enums.\n+    uint16_t local_mask = 0;\n+\n     // Index of key relative to args in shard that the shard was woken up after blocking wait.\n     uint16_t wake_key_pos = UINT16_MAX;\n   };\n",
  "test_patch": "diff --git a/tests/dragonfly/conftest.py b/tests/dragonfly/conftest.py\nindex b7c6d7845ccb..5de3fa3a6979 100644\n--- a/tests/dragonfly/conftest.py\n+++ b/tests/dragonfly/conftest.py\n@@ -80,7 +80,7 @@ def df_factory(request, tmp_dir, test_env) -> DflyInstanceFactory:\n         args=request.config.getoption(\"--df\"),\n         existing_port=int(existing) if existing else None,\n         existing_admin_port=int(existing_admin) if existing_admin else None,\n-        existing_mc_port=int(existing_mc) if existing else None,\n+        existing_mc_port=int(existing_mc) if existing_mc else None,\n         env=test_env\n     )\n \ndiff --git a/tests/dragonfly/connection_test.py b/tests/dragonfly/connection_test.py\nindex 059ee4d17fd7..8b32e3e71af5 100644\n--- a/tests/dragonfly/connection_test.py\n+++ b/tests/dragonfly/connection_test.py\n@@ -4,7 +4,8 @@\n from redis import asyncio as aioredis\n import async_timeout\n \n-from . import DflyInstance\n+from . import DflyInstance, dfly_args\n+\n \n async def run_monitor_eval(monitor, expected):\n     async with monitor as mon:\n@@ -346,7 +347,8 @@ async def test_subscribe_in_pipeline(async_client: aioredis.Redis):\n     pipe.echo(\"three\")\n     res = await pipe.execute()\n \n-    assert res == ['one', ['subscribe', 'ch1', 1], 'two', ['subscribe', 'ch2', 2], 'three']\n+    assert res == ['one', ['subscribe', 'ch1', 1],\n+                   'two', ['subscribe', 'ch2', 2], 'three']\n \n \"\"\"\n This test makes sure that Dragonfly can receive blocks of pipelined commands even\n@@ -376,6 +378,7 @@ async def test_subscribe_in_pipeline(async_client: aioredis.Redis):\n PING\n \"\"\" * 500 + \"ECHO DONE\\n\"\n \n+\n async def test_parser_while_script_running(async_client: aioredis.Redis, df_server: DflyInstance):\n     sha = await async_client.script_load(BUSY_SCRIPT)\n \n@@ -399,3 +402,16 @@ async def test_parser_while_script_running(async_client: aioredis.Redis, df_serv\n     await reader.readuntil(b\"DONE\")\n     writer.close()\n     await writer.wait_closed()\n+\n+\n+@dfly_args({\"proactor_threads\": 1})\n+async def test_large_cmd(async_client: aioredis.Redis):\n+    MAX_ARR_SIZE = 65535\n+    res = await async_client.hset('foo', mapping={f\"key{i}\": f\"val{i}\" for i in range(MAX_ARR_SIZE // 2)})\n+    assert res == MAX_ARR_SIZE // 2\n+\n+    res = await async_client.mset({f\"key{i}\": f\"val{i}\" for i in range(MAX_ARR_SIZE // 2)})\n+    assert res\n+\n+    res = await async_client.mget([f\"key{i}\" for i in range(MAX_ARR_SIZE)])\n+    assert len(res) == MAX_ARR_SIZE\n",
  "problem_statement": "crash on check-fail\n\r\nF20230617 01:35:51.923097 175984 transaction.cc:136] Check failed: si.args.size() < 1u << 15 (48040 vs. 32768)\n",
  "hints_text": "",
  "created_at": "2023-06-17T03:05:23Z",
  "modified_files": [
    "src/facade/dragonfly_connection.cc",
    "src/facade/facade.cc",
    "src/facade/facade_types.h",
    "src/facade/redis_parser.cc",
    "src/facade/reply_builder.cc",
    "src/facade/reply_builder.h",
    "src/server/server_family.cc",
    "src/server/transaction.cc",
    "src/server/transaction.h"
  ],
  "modified_test_files": [
    "tests/dragonfly/conftest.py",
    "tests/dragonfly/connection_test.py"
  ]
}