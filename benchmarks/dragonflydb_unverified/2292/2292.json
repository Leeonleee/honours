{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 2292,
  "instance_id": "dragonflydb__dragonfly-2292",
  "issue_numbers": [
    "2295"
  ],
  "base_commit": "6398a7394205064a198d7595341f96d20e849a07",
  "patch": "diff --git a/src/server/CMakeLists.txt b/src/server/CMakeLists.txt\nindex 01be21810e43..c099025746be 100644\n--- a/src/server/CMakeLists.txt\n+++ b/src/server/CMakeLists.txt\n@@ -40,6 +40,7 @@ add_library(dragonfly_lib engine_shard_set.cc channel_store.cc command_registry.\n             zset_family.cc version.cc bitops_family.cc container_utils.cc io_utils.cc\n             top_keys.cc multi_command_squasher.cc hll_family.cc cluster/cluster_config.cc\n             cluster/cluster_family.cc cluster/cluster_slot_migration.cc\n+            cluster/cluster_shard_migration.cc\n             acl/user.cc acl/user_registry.cc acl/acl_family.cc\n             acl/validator.cc acl/helpers.cc)\n \ndiff --git a/src/server/cluster/cluster_family.cc b/src/server/cluster/cluster_family.cc\nindex db6b357f15c2..103bf4e187b3 100644\n--- a/src/server/cluster/cluster_family.cc\n+++ b/src/server/cluster/cluster_family.cc\n@@ -41,6 +41,8 @@ using ClusterShards = ClusterConfig::ClusterShards;\n using Node = ClusterConfig::Node;\n using SlotRange = ClusterConfig::SlotRange;\n \n+constexpr char kIdNotFound[] = \"syncid not found\";\n+\n constexpr string_view kClusterDisabled =\n     \"Cluster is disabled. Enabled via passing --cluster_mode=emulated|yes\";\n constexpr string_view kDflyClusterCmdPort = \"DflyCluster command allowed only under admin port\";\n@@ -636,7 +638,7 @@ void ClusterFamily::DflySlotMigrationStatus(CmdArgList args, ConnectionContext*\n     return cntx->SendError(err->MakeReply());\n \n   auto state = [&] {\n-    lock_guard lk(migrations_jobs_mu_);\n+    lock_guard lk(migration_mu_);\n     for (const auto& m : migrations_jobs_) {\n       const auto& info = m->GetInfo();\n       if (info.host == host_ip && info.port == port)\n@@ -669,6 +671,10 @@ void ClusterFamily::DflyMigrate(CmdArgList args, ConnectionContext* cntx) {\n   args.remove_prefix(1);\n   if (sub_cmd == \"CONF\") {\n     MigrationConf(args, cntx);\n+  } else if (sub_cmd == \"FLOW\") {\n+    Flow(args, cntx);\n+  } else if (sub_cmd == \"SYNC\") {\n+    Sync(args, cntx);\n   } else {\n     cntx->SendError(facade::UnknownSubCmd(sub_cmd, \"DFLYMIGRATE\"), facade::kSyntaxErrType);\n   }\n@@ -676,7 +682,7 @@ void ClusterFamily::DflyMigrate(CmdArgList args, ConnectionContext* cntx) {\n \n ClusterSlotMigration* ClusterFamily::AddMigration(std::string host_ip, uint16_t port,\n                                                   std::vector<ClusterConfig::SlotRange> slots) {\n-  lock_guard lk(migrations_jobs_mu_);\n+  lock_guard lk(migration_mu_);\n   for (const auto& mj : migrations_jobs_) {\n     if (auto info = mj->GetInfo(); info.host == host_ip && info.port == port) {\n       return nullptr;\n@@ -691,7 +697,6 @@ void ClusterFamily::MigrationConf(CmdArgList args, ConnectionContext* cntx) {\n   VLOG(1) << \"Create slot migration config\";\n   CmdArgParser parser{args};\n   auto port = parser.Next<uint16_t>();\n-  (void)port;  // we need it for the next step\n \n   std::vector<ClusterConfig::SlotRange> slots;\n   do {\n@@ -718,12 +723,80 @@ void ClusterFamily::MigrationConf(CmdArgList args, ConnectionContext* cntx) {\n     }\n   }\n \n-  cntx->conn()->SetName(\"slot_migration_ctrl\");\n+  auto sync_id = CreateMigrationSession(cntx, port, std::move(slots));\n \n-  cntx->SendLong(shard_set->size());\n+  cntx->conn()->SetName(\"slot_migration_ctrl\");\n+  auto* rb = static_cast<RedisReplyBuilder*>(cntx->reply_builder());\n+  rb->StartArray(2);\n+  rb->SendLong(sync_id);\n+  rb->SendLong(shard_set->size());\n   return;\n }\n \n+uint32_t ClusterFamily::CreateMigrationSession(ConnectionContext* cntx, uint16_t port,\n+                                               std::vector<ClusterConfig::SlotRange> slots) {\n+  std::lock_guard lk(migration_mu_);\n+  auto sync_id = next_sync_id_++;\n+  auto info = make_shared<MigrationInfo>(shard_set->size(), cntx->conn()->RemoteEndpointAddress(),\n+                                         sync_id, port, std::move(slots));\n+  auto [it, inserted] = migration_infos_.emplace(sync_id, info);\n+  CHECK(inserted);\n+  return sync_id;\n+}\n+\n+void ClusterFamily::Flow(CmdArgList args, ConnectionContext* cntx) {\n+  CmdArgParser parser{args};\n+  auto [sync_id, shard_id] = parser.Next<uint32_t, uint32_t>();\n+\n+  if (auto err = parser.Error(); err) {\n+    return cntx->SendError(err->MakeReply());\n+  }\n+\n+  VLOG(1) << \"Create flow \"\n+          << \" sync_id: \" << sync_id << \" shard_id: \" << shard_id << \" shard\";\n+\n+  cntx->conn()->SetName(absl::StrCat(\"migration_flow_\", sync_id));\n+\n+  auto info = GetMigrationInfo(sync_id);\n+  if (!info)\n+    cntx->SendError(kIdNotFound);\n+\n+  info->flows[shard_id].conn = cntx->conn();\n+\n+  cntx->conn()->Migrate(shard_set->pool()->at(shard_id));\n+\n+  cntx->SendOk();\n+}\n+\n+void ClusterFamily::Sync(CmdArgList args, ConnectionContext* cntx) {\n+  CmdArgParser parser{args};\n+  auto sync_id = parser.Next<uint32_t>();\n+  if (auto err = parser.Error(); err)\n+    return cntx->SendError(err->MakeReply());\n+  RedisReplyBuilder* rb = static_cast<RedisReplyBuilder*>(cntx->reply_builder());\n+\n+  VLOG(1) << \"Got DFLYMIGRATE SYNC \" << sync_id;\n+\n+  auto info = GetMigrationInfo(sync_id);\n+  if (!info)\n+    cntx->SendError(kIdNotFound);\n+\n+  auto cb = [info](EngineShard* shard) {\n+    info->flows[shard->shard_id()].conn->socket()->Write(io::Buffer(\"OK\"));\n+  };\n+  shard_set->RunBlockingInParallel(std::move(cb));\n+\n+  LOG(INFO) << \"Started migation with target node \" << info->host_ip << \":\" << info->port;\n+\n+  return rb->SendOk();\n+}\n+\n+shared_ptr<ClusterFamily::MigrationInfo> ClusterFamily::GetMigrationInfo(uint32_t sync_id) {\n+  unique_lock lk(migration_mu_);\n+  auto sync_it = migration_infos_.find(sync_id);\n+  return sync_it != migration_infos_.end() ? sync_it->second : nullptr;\n+}\n+\n using EngineFunc = void (ClusterFamily::*)(CmdArgList args, ConnectionContext* cntx);\n \n inline CommandId::Handler HandlerFunc(ClusterFamily* se, EngineFunc f) {\ndiff --git a/src/server/cluster/cluster_family.h b/src/server/cluster/cluster_family.h\nindex 6ec07f1efcb2..ef5e92855e60 100644\n--- a/src/server/cluster/cluster_family.h\n+++ b/src/server/cluster/cluster_family.h\n@@ -4,6 +4,8 @@\n \n #pragma once\n \n+#include <absl/container/btree_map.h>\n+\n #include <string>\n \n #include \"facade/conn_context.h\"\n@@ -46,22 +48,75 @@ class ClusterFamily {\n   void DflyClusterGetSlotInfo(CmdArgList args, ConnectionContext* cntx);\n   void DflyClusterMyId(CmdArgList args, ConnectionContext* cntx);\n   void DflyClusterFlushSlots(CmdArgList args, ConnectionContext* cntx);\n+\n+ private:  // Slots migration section\n   void DflyClusterStartSlotMigration(CmdArgList args, ConnectionContext* cntx);\n   void DflySlotMigrationStatus(CmdArgList args, ConnectionContext* cntx);\n+\n+  // DFLYMIGRATE is internal command defines several steps in slots migrations process\n   void DflyMigrate(CmdArgList args, ConnectionContext* cntx);\n \n+  // DFLYMIGRATE CONF initiate first step in slots migration procedure\n+  // MigrationConf process this request and saving slots range and\n+  // target node port in migration_infos_.\n+  // return sync_id and shard number to the target node\n   void MigrationConf(CmdArgList args, ConnectionContext* cntx);\n+\n+  // DFLYMIGRATE FLOW initiate second step in slots migration procedure\n+  // this request should be done for every shard on the target node\n+  // this method assocciate connection and shard that will be the data\n+  // source for migration\n+  void Flow(CmdArgList args, ConnectionContext* cntx);\n+\n+  // DFLYMIGRATE SYNC is the third step that trigger data transferring\n+  // for all flows simultaneously\n+  // This method can be removed in the future if we decide to tranfser\n+  // data without any synchronization in FLOW step\n+  void Sync(CmdArgList args, ConnectionContext* cntx);\n+\n+  // create a ClusterSlotMigration entity which will execute migration\n   ClusterSlotMigration* AddMigration(std::string host_ip, uint16_t port,\n                                      std::vector<ClusterConfig::SlotRange> slots);\n \n+  // store info about migration and create unique session id\n+  uint32_t CreateMigrationSession(ConnectionContext* cntx, uint16_t port,\n+                                  std::vector<ClusterConfig::SlotRange> slots);\n+\n+  // FlowInfo is used to store state, connection, and all auxiliary data\n+  // that is needed for correct slots (per shard) data transfer\n+  struct FlowInfo {\n+    facade::Connection* conn = nullptr;\n+  };\n+\n+  // Whole slots migration process information\n+  struct MigrationInfo {\n+    MigrationInfo() = default;\n+    MigrationInfo(std::uint32_t flows_num, std::string ip, uint32_t sync_id, uint16_t port,\n+                  std::vector<ClusterConfig::SlotRange> slots)\n+        : host_ip(ip), flows(flows_num), slots(slots), sync_id(sync_id), port(port) {\n+    }\n+    std::string host_ip;\n+    std::vector<FlowInfo> flows;\n+    std::vector<ClusterConfig::SlotRange> slots;\n+    uint32_t sync_id;\n+    uint16_t port;\n+  };\n+\n+  std::shared_ptr<MigrationInfo> GetMigrationInfo(uint32_t sync_id);\n+\n+  mutable Mutex migration_mu_;  // guard migrations operations\n+  // holds all slots migrations that are currently in progress.\n+  std::vector<std::unique_ptr<ClusterSlotMigration>> migrations_jobs_\n+      ABSL_GUARDED_BY(migration_mu_);\n+\n+  uint32_t next_sync_id_ = 1;\n+  using MigrationInfoMap = absl::btree_map<uint32_t, std::shared_ptr<MigrationInfo>>;\n+  MigrationInfoMap migration_infos_;\n+\n+ private:\n   ClusterConfig::ClusterShard GetEmulatedShardInfo(ConnectionContext* cntx) const;\n \n   ServerFamily* server_family_ = nullptr;\n-\n-  mutable Mutex migrations_jobs_mu_;\n-  // holds all slot migrations that are currently in progress.\n-  std::vector<std::unique_ptr<ClusterSlotMigration>> migrations_jobs_\n-      ABSL_GUARDED_BY(migrations_jobs_mu_);\n };\n \n }  // namespace dfly\ndiff --git a/src/server/cluster/cluster_shard_migration.cc b/src/server/cluster/cluster_shard_migration.cc\nnew file mode 100644\nindex 000000000000..ea582544849e\n--- /dev/null\n+++ b/src/server/cluster/cluster_shard_migration.cc\n@@ -0,0 +1,77 @@\n+// Copyright 2023, DragonflyDB authors.  All rights reserved.\n+// See LICENSE for licensing terms.\n+//\n+#include \"server/cluster/cluster_shard_migration.h\"\n+\n+#include <absl/flags/flag.h>\n+#include <absl/strings/str_cat.h>\n+\n+#include \"base/logging.h\"\n+#include \"server/error.h\"\n+\n+ABSL_DECLARE_FLAG(int, source_connect_timeout_ms);\n+\n+namespace dfly {\n+\n+using namespace std;\n+using namespace facade;\n+using namespace util;\n+using absl::GetFlag;\n+\n+ClusterShardMigration::ClusterShardMigration(ServerContext server_context, uint32_t shard_id,\n+                                             uint32_t sync_id)\n+    : ProtocolClient(server_context), source_shard_id_(shard_id), sync_id_(sync_id) {\n+}\n+\n+ClusterShardMigration::~ClusterShardMigration() {\n+  JoinFlow();\n+}\n+\n+std::error_code ClusterShardMigration::StartSyncFlow(Context* cntx) {\n+  RETURN_ON_ERR(ConnectAndAuth(absl::GetFlag(FLAGS_source_connect_timeout_ms) * 1ms, &cntx_));\n+\n+  std::string cmd = absl::StrCat(\"DFLYMIGRATE FLOW \", sync_id_, \" \", source_shard_id_);\n+  VLOG(1) << \"cmd: \" << cmd;\n+\n+  ResetParser(/*server_mode=*/false);\n+  leftover_buf_.emplace(128);\n+  RETURN_ON_ERR(SendCommand(cmd));\n+  auto read_resp = ReadRespReply(&*leftover_buf_);\n+  if (!read_resp.has_value()) {\n+    return read_resp.error();\n+  }\n+\n+  PC_RETURN_ON_BAD_RESPONSE(CheckRespIsSimpleReply(\"OK\"));\n+\n+  leftover_buf_->ConsumeInput(read_resp->left_in_buffer);\n+\n+  sync_fb_ =\n+      fb2::Fiber(\"shard_migration_full_sync\", &ClusterShardMigration::FullSyncShardFb, this, cntx);\n+\n+  return {};\n+}\n+\n+void ClusterShardMigration::FullSyncShardFb(Context* cntx) {\n+  DCHECK(leftover_buf_);\n+  io::PrefixSource ps{leftover_buf_->InputBuffer(), Sock()};\n+\n+  uint8_t ok_buf[2];\n+  ps.ReadAtLeast(io::MutableBytes{ok_buf, 2}, 2);\n+\n+  if (string_view(reinterpret_cast<char*>(ok_buf), 2) != \"OK\") {\n+    cntx->ReportError(std::make_error_code(errc::protocol_error),\n+                      \"Incorrect FullSync data, only for tets\");\n+  }\n+\n+  VLOG(1) << \"FullSyncShardFb finished after reading 2 bytes\";\n+}\n+\n+void ClusterShardMigration::Cancel() {\n+  CloseSocket();\n+}\n+\n+void ClusterShardMigration::JoinFlow() {\n+  sync_fb_.JoinIfNeeded();\n+}\n+\n+}  // namespace dfly\ndiff --git a/src/server/cluster/cluster_shard_migration.h b/src/server/cluster/cluster_shard_migration.h\nnew file mode 100644\nindex 000000000000..e5d31484fdfe\n--- /dev/null\n+++ b/src/server/cluster/cluster_shard_migration.h\n@@ -0,0 +1,33 @@\n+// Copyright 2023, DragonflyDB authors.  All rights reserved.\n+// See LICENSE for licensing terms.\n+//\n+#pragma once\n+\n+#include \"base/io_buf.h\"\n+#include \"server/protocol_client.h\"\n+\n+namespace dfly {\n+\n+// ClusterShardMigration manage data receiving in slots migration process.\n+// It is created per shard on the target node to initiate FLOW step.\n+class ClusterShardMigration : public ProtocolClient {\n+ public:\n+  ClusterShardMigration(ServerContext server_context, uint32_t shard_id, uint32_t sync_id);\n+  ~ClusterShardMigration();\n+\n+  std::error_code StartSyncFlow(Context* cntx);\n+  void Cancel();\n+\n+ private:\n+  void FullSyncShardFb(Context* cntx);\n+  void JoinFlow();\n+\n+ private:\n+  uint32_t source_shard_id_;\n+  uint32_t sync_id_;\n+  std::optional<base::IoBuf> leftover_buf_;\n+\n+  Fiber sync_fb_;\n+};\n+\n+}  // namespace dfly\ndiff --git a/src/server/cluster/cluster_slot_migration.cc b/src/server/cluster/cluster_slot_migration.cc\nindex 8b47e55b65e4..acd661fdaa67 100644\n--- a/src/server/cluster/cluster_slot_migration.cc\n+++ b/src/server/cluster/cluster_slot_migration.cc\n@@ -3,9 +3,11 @@\n //\n #include \"server/cluster/cluster_slot_migration.h\"\n \n+#include <absl/cleanup/cleanup.h>\n #include <absl/flags/flag.h>\n \n #include \"base/logging.h\"\n+#include \"server/cluster/cluster_shard_migration.h\"\n #include \"server/error.h\"\n #include \"server/main_service.h\"\n \n@@ -17,15 +19,29 @@ ABSL_DECLARE_FLAG(int32_t, port);\n namespace dfly {\n \n using namespace std;\n+using namespace util;\n using namespace facade;\n using absl::GetFlag;\n \n+namespace {\n+// Distribute flow indices over all available threads (shard_set pool size).\n+vector<vector<unsigned>> Partition(unsigned num_flows) {\n+  vector<vector<unsigned>> partition(shard_set->pool()->size());\n+  for (unsigned i = 0; i < num_flows; ++i) {\n+    partition[i % partition.size()].push_back(i);\n+  }\n+  return partition;\n+}\n+\n+}  // namespace\n+\n ClusterSlotMigration::ClusterSlotMigration(string host_ip, uint16_t port,\n                                            std::vector<ClusterConfig::SlotRange> slots)\n-    : ProtocolClient(std::move(host_ip), port), slots_(std::move(slots)) {\n+    : ProtocolClient(move(host_ip), port), slots_(std::move(slots)) {\n }\n \n ClusterSlotMigration::~ClusterSlotMigration() {\n+  sync_fb_.JoinIfNeeded();\n }\n \n error_code ClusterSlotMigration::Start(ConnectionContext* cntx) {\n@@ -46,11 +62,13 @@ error_code ClusterSlotMigration::Start(ConnectionContext* cntx) {\n   ec = ConnectAndAuth(absl::GetFlag(FLAGS_source_connect_timeout_ms) * 1ms, &cntx_);\n   RETURN_ON_ERR(check_connection_error(ec, \"couldn't connect to source\"));\n \n+  state_ = ClusterSlotMigration::C_CONNECTING;\n+\n   VLOG(1) << \"Greeting\";\n   ec = Greet();\n   RETURN_ON_ERR(check_connection_error(ec, \"couldn't greet source \"));\n \n-  state_ = ClusterSlotMigration::C_CONNECTING;\n+  sync_fb_ = fb2::Fiber(\"main_migration\", &ClusterSlotMigration::MainMigrationFb, this);\n \n   return {};\n }\n@@ -68,11 +86,12 @@ error_code ClusterSlotMigration::Greet() {\n   }\n   VLOG(1) << \"Migration command: \" << cmd;\n   RETURN_ON_ERR(SendCommandAndReadResponse(cmd));\n-  // Response is: num_shards\n-  if (!CheckRespFirstTypes({RespExpr::INT64}))\n+  // Response is: sync_id, num_shards\n+  if (!CheckRespFirstTypes({RespExpr::INT64, RespExpr::INT64}))\n     return make_error_code(errc::bad_message);\n \n-  souce_shards_num_ = get<int64_t>(LastResponseArgs()[0].u);\n+  sync_id_ = get<int64_t>(LastResponseArgs()[0].u);\n+  source_shards_num_ = get<int64_t>(LastResponseArgs()[1].u);\n \n   return error_code{};\n }\n@@ -82,4 +101,69 @@ ClusterSlotMigration::Info ClusterSlotMigration::GetInfo() const {\n   return {ctx.host, ctx.port, state_};\n }\n \n+void ClusterSlotMigration::MainMigrationFb() {\n+  VLOG(1) << \"Main migration fiber started\";\n+\n+  state_ = ClusterSlotMigration::C_FULL_SYNC;\n+\n+  // TODO add reconnection code\n+  if (auto ec = InitiateSlotsMigration(); ec) {\n+    LOG(WARNING) << \"Error syncing with \" << server().Description() << \" \" << ec << \" \"\n+                 << ec.message();\n+  }\n+}\n+\n+std::error_code ClusterSlotMigration::InitiateSlotsMigration() {\n+  shard_flows_.resize(source_shards_num_);\n+  for (unsigned i = 0; i < source_shards_num_; ++i) {\n+    shard_flows_[i].reset(new ClusterShardMigration(server(), i, sync_id_));\n+  }\n+\n+  // Switch to new error handler that closes flow sockets.\n+  auto err_handler = [this](const auto& ge) mutable {\n+    // Make sure the flows are not in a state transition\n+    lock_guard lk{flows_op_mu_};\n+\n+    // Unblock all sockets.\n+    DefaultErrorHandler(ge);\n+    for (auto& flow : shard_flows_)\n+      flow->Cancel();\n+  };\n+  RETURN_ON_ERR(cntx_.SwitchErrorHandler(std::move(err_handler)));\n+\n+  std::atomic_uint32_t synced_shards = 0;\n+  auto partition = Partition(source_shards_num_);\n+  auto shard_cb = [&](unsigned index, auto*) {\n+    for (auto id : partition[index]) {\n+      auto ec = shard_flows_[id]->StartSyncFlow(&cntx_);\n+      if (!ec) {\n+        ++synced_shards;\n+      } else {\n+        cntx_.ReportError(ec);\n+      }\n+    }\n+  };\n+  // Lock to prevent the error handler from running instantly\n+  // while the flows are in a mixed state.\n+  lock_guard lk{flows_op_mu_};\n+  shard_set->pool()->AwaitFiberOnAll(std::move(shard_cb));\n+\n+  VLOG(1) << synced_shards << \" from \" << source_shards_num_ << \" shards were set flow\";\n+  if (synced_shards != source_shards_num_) {\n+    cntx_.ReportError(std::make_error_code(errc::state_not_recoverable),\n+                      \"incorrect shards num, only for tests\");\n+  }\n+\n+  RETURN_ON_ERR(cntx_.GetError());\n+\n+  string request = absl::StrCat(\"DFLYMIGRATE SYNC \", sync_id_);\n+\n+  VLOG(1) << \"Sending: \" << request;\n+  RETURN_ON_ERR(SendCommandAndReadResponse(request));\n+\n+  PC_RETURN_ON_BAD_RESPONSE(CheckRespIsSimpleReply(\"OK\"));\n+\n+  return cntx_.GetError();\n+}\n+\n }  // namespace dfly\ndiff --git a/src/server/cluster/cluster_slot_migration.h b/src/server/cluster/cluster_slot_migration.h\nindex d85ec214cc0d..506fa0316a5e 100644\n--- a/src/server/cluster/cluster_slot_migration.h\n+++ b/src/server/cluster/cluster_slot_migration.h\n@@ -3,10 +3,14 @@\n //\n #pragma once\n \n+#include \"server/cluster/cluster_shard_migration.h\"\n #include \"server/protocol_client.h\"\n \n namespace dfly {\n \n+// The main entity on the target side that manage slots migration process\n+// Creates initial connection between the target and source node,\n+// manage migration process state and data\n class ClusterSlotMigration : ProtocolClient {\n  public:\n   enum State : uint8_t { C_NO_STATE, C_CONNECTING, C_FULL_SYNC, C_STABLE_SYNC };\n@@ -21,14 +25,26 @@ class ClusterSlotMigration : ProtocolClient {\n                        std::vector<ClusterConfig::SlotRange> slots);\n   ~ClusterSlotMigration();\n \n+  // Initiate connection with source node and create migration fiber\n   std::error_code Start(ConnectionContext* cntx);\n   Info GetInfo() const;\n \n  private:\n+  // Send DFLYMIGRATE CONF to the source and get info about migration process\n   std::error_code Greet();\n+  void MainMigrationFb();\n+  // Creates flows, one per shard on the source node and manage migration process\n+  std::error_code InitiateSlotsMigration();\n+\n+ private:\n+  Mutex flows_op_mu_;\n+  std::vector<std::unique_ptr<ClusterShardMigration>> shard_flows_;\n   std::vector<ClusterConfig::SlotRange> slots_;\n-  size_t souce_shards_num_ = 0;\n+  uint32_t source_shards_num_ = 0;\n+  uint32_t sync_id_ = 0;\n   State state_ = C_NO_STATE;\n+\n+  Fiber sync_fb_;\n };\n \n }  // namespace dfly\n",
  "test_patch": "diff --git a/tests/dragonfly/cluster_test.py b/tests/dragonfly/cluster_test.py\nindex d36bdfb958a0..da2d8214fd37 100644\n--- a/tests/dragonfly/cluster_test.py\n+++ b/tests/dragonfly/cluster_test.py\n@@ -801,10 +801,12 @@ async def test_cluster_slot_migration(df_local_factory: DflyInstanceFactory):\n     )\n     assert \"OK\" == res\n \n+    await asyncio.sleep(0.5)\n+\n     status = await c_nodes_admin[1].execute_command(\n         \"DFLYCLUSTER\", \"SLOT-MIGRATION-STATUS\", \"127.0.0.1\", str(nodes[0].admin_port)\n     )\n-    assert \"CONNECTING\" == status\n+    assert \"FULL_SYNC\" == status\n \n     try:\n         await c_nodes_admin[1].execute_command(\n",
  "problem_statement": "Second step for START-SLOT-MIGRATION command\nWe already have the configuration step for START-SLOT-MIGRATION command. \r\nWe must add DFLYMIGRATE FLOW command to establish connections for every shard replication process. \r\nThis step allows to start of the full_sync.\r\n\r\nNotes:\r\nFor now, the source node replies only with eof_token for the DFLYMIGRATE FLOW command\n",
  "hints_text": "",
  "created_at": "2023-12-11T13:55:16Z",
  "modified_files": [
    "src/server/CMakeLists.txt",
    "src/server/cluster/cluster_family.cc",
    "src/server/cluster/cluster_family.h",
    "b/src/server/cluster/cluster_shard_migration.cc",
    "b/src/server/cluster/cluster_shard_migration.h",
    "src/server/cluster/cluster_slot_migration.cc",
    "src/server/cluster/cluster_slot_migration.h"
  ],
  "modified_test_files": [
    "tests/dragonfly/cluster_test.py"
  ]
}