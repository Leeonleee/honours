{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 4407,
  "instance_id": "dragonflydb__dragonfly-4407",
  "issue_numbers": [
    "1677"
  ],
  "base_commit": "91435bc6af31fc807e7bdf1d9f9ad2112dd66ae4",
  "patch": "diff --git a/src/facade/conn_context.h b/src/facade/conn_context.h\nindex b87e901b473d..d4e777010ea1 100644\n--- a/src/facade/conn_context.h\n+++ b/src/facade/conn_context.h\n@@ -37,7 +37,7 @@ class ConnectionContext {\n   // connection state / properties.\n   bool conn_closing : 1;\n   bool req_auth : 1;\n-  bool replica_conn : 1;\n+  bool replica_conn : 1;  // whether it's a replica connection on the master side.\n   bool authenticated : 1;\n   bool async_dispatch : 1;    // whether this connection is amid an async dispatch\n   bool sync_dispatch : 1;     // whether this connection is amid a sync dispatch\ndiff --git a/src/facade/dragonfly_connection.cc b/src/facade/dragonfly_connection.cc\nindex a04645cdb256..bcab6c30f2f2 100644\n--- a/src/facade/dragonfly_connection.cc\n+++ b/src/facade/dragonfly_connection.cc\n@@ -610,6 +610,10 @@ Connection::~Connection() {\n   UpdateLibNameVerMap(lib_name_, lib_ver_, -1);\n }\n \n+bool Connection::IsSending() const {\n+  return reply_builder_ && reply_builder_->IsSendActive();\n+}\n+\n // Called from Connection::Shutdown() right after socket_->Shutdown call.\n void Connection::OnShutdown() {\n   VLOG(1) << \"Connection::OnShutdown\";\n@@ -1638,9 +1642,6 @@ bool Connection::Migrate(util::fb2::ProactorBase* dest) {\n \n Connection::WeakRef Connection::Borrow() {\n   DCHECK(self_);\n-  // If the connection is unaware of subscriptions, it could migrate threads, making this call\n-  // unsafe. All external mechanisms that borrow references should register subscriptions.\n-  DCHECK_GT(cc_->subscriptions, 0);\n \n   return WeakRef(self_, socket_->proactor()->GetPoolIndex(), id_);\n }\ndiff --git a/src/facade/dragonfly_connection.h b/src/facade/dragonfly_connection.h\nindex f5494396babc..75fecd67fc92 100644\n--- a/src/facade/dragonfly_connection.h\n+++ b/src/facade/dragonfly_connection.h\n@@ -303,6 +303,16 @@ class Connection : public util::Connection {\n   static void TrackRequestSize(bool enable);\n   static void EnsureMemoryBudget(unsigned tid);\n \n+  unsigned idle_time() const {\n+    return time(nullptr) - last_interaction_;\n+  }\n+\n+  Phase phase() const {\n+    return phase_;\n+  }\n+\n+  bool IsSending() const;\n+\n  protected:\n   void OnShutdown() override;\n   void OnPreMigrateThread() override;\ndiff --git a/src/server/main_service.cc b/src/server/main_service.cc\nindex 1b2c391b527d..cc705a38c9d6 100644\n--- a/src/server/main_service.cc\n+++ b/src/server/main_service.cc\n@@ -814,6 +814,7 @@ void Service::Init(util::AcceptServer* acceptor, std::vector<facade::Listener*>\n   config_registry.RegisterMutable(\"migration_finalization_timeout_ms\");\n   config_registry.RegisterMutable(\"table_growth_margin\");\n   config_registry.RegisterMutable(\"tcp_keepalive\");\n+  config_registry.RegisterMutable(\"timeout\");\n   config_registry.RegisterMutable(\"managed_service_info\");\n \n   config_registry.RegisterMutable(\n@@ -849,19 +850,23 @@ void Service::Init(util::AcceptServer* acceptor, std::vector<facade::Listener*>\n     shard_num = pp_.size();\n   }\n \n+  // We assume that listeners.front() is the main_listener\n+  // see dfly_main RunEngine. In unit tests, listeners are empty.\n+  facade::Listener* main_listener = listeners.empty() ? nullptr : listeners.front();\n+\n   ChannelStore* cs = new ChannelStore{};\n   // Must initialize before the shard_set because EngineShard::Init references ServerState.\n   pp_.AwaitBrief([&](uint32_t index, ProactorBase* pb) {\n     tl_facade_stats = new FacadeStats;\n-    ServerState::Init(index, shard_num, &user_registry_);\n+    ServerState::Init(index, shard_num, main_listener, &user_registry_);\n     ServerState::tlocal()->UpdateChannelStore(cs);\n   });\n \n   const auto tcp_disabled = GetFlag(FLAGS_port) == 0u;\n   // We assume that listeners.front() is the main_listener\n   // see dfly_main RunEngine\n-  if (!tcp_disabled && !listeners.empty()) {\n-    acl_family_.Init(listeners.front(), &user_registry_);\n+  if (!tcp_disabled && main_listener) {\n+    acl_family_.Init(main_listener, &user_registry_);\n   }\n \n   // Initialize shard_set with a callback running once in a while in the shard threads.\n@@ -907,7 +912,7 @@ void Service::Shutdown() {\n   shard_set->Shutdown();\n   Transaction::Shutdown();\n \n-  pp_.Await([](ProactorBase* pb) { ServerState::tlocal()->Destroy(); });\n+  pp_.AwaitFiberOnAll([](ProactorBase* pb) { ServerState::tlocal()->Destroy(); });\n \n   // wait for all the pending callbacks to stop.\n   ThisFiber::SleepFor(10ms);\ndiff --git a/src/server/server_state.cc b/src/server/server_state.cc\nindex 9bdedc1a7d28..5f29c7271bae 100644\n--- a/src/server/server_state.cc\n+++ b/src/server/server_state.cc\n@@ -15,12 +15,19 @@ extern \"C\" {\n #include \"base/flags.h\"\n #include \"base/logging.h\"\n #include \"facade/conn_context.h\"\n+#include \"facade/dragonfly_connection.h\"\n #include \"server/journal/journal.h\"\n+#include \"util/listener_interface.h\"\n \n ABSL_FLAG(uint32_t, interpreter_per_thread, 10, \"Lua interpreters per thread\");\n+ABSL_FLAG(uint32_t, timeout, 0,\n+          \"Close the connection after it is idle for N seconds (0 to disable)\");\n \n namespace dfly {\n \n+using namespace std;\n+using namespace std::chrono_literals;\n+\n __thread ServerState* ServerState::state_ = nullptr;\n \n ServerState::Stats::Stats(unsigned num_shards) : tx_width_freq_arr(num_shards) {\n@@ -102,14 +109,21 @@ ServerState::ServerState() : interpreter_mgr_{absl::GetFlag(FLAGS_interpreter_pe\n }\n \n ServerState::~ServerState() {\n+  watcher_fiber_.JoinIfNeeded();\n }\n \n-void ServerState::Init(uint32_t thread_index, uint32_t num_shards, acl::UserRegistry* registry) {\n+void ServerState::Init(uint32_t thread_index, uint32_t num_shards,\n+                       util::ListenerInterface* main_listener, acl::UserRegistry* registry) {\n   state_ = new ServerState();\n   state_->gstate_ = GlobalState::ACTIVE;\n   state_->thread_index_ = thread_index;\n   state_->user_registry = registry;\n   state_->stats = Stats(num_shards);\n+  if (main_listener) {\n+    state_->watcher_fiber_ = util::fb2::Fiber(\n+        util::fb2::Launch::post, \"ConnectionsWatcher\",\n+        [state = state_, main_listener] { state->ConnectionsWatcherFb(main_listener); });\n+  }\n }\n \n void ServerState::Destroy() {\n@@ -117,6 +131,11 @@ void ServerState::Destroy() {\n   state_ = nullptr;\n }\n \n+void ServerState::EnterLameDuck() {\n+  gstate_ = GlobalState::SHUTTING_DOWN;\n+  watcher_cv_.notify_all();\n+}\n+\n ServerState::MemoryUsageStats ServerState::GetMemoryUsage(uint64_t now_ns) {\n   static constexpr uint64_t kCacheEveryNs = 1000;\n   if (now_ns > used_mem_last_update_ + kCacheEveryNs) {\n@@ -208,4 +227,61 @@ ServerState* ServerState::SafeTLocal() {\n bool ServerState::ShouldLogSlowCmd(unsigned latency_usec) const {\n   return slow_log_shard_.IsEnabled() && latency_usec >= log_slower_than_usec;\n }\n+\n+void ServerState::ConnectionsWatcherFb(util::ListenerInterface* main) {\n+  optional<facade::Connection::WeakRef> last_reference;\n+\n+  while (true) {\n+    util::fb2::NoOpLock noop;\n+    if (watcher_cv_.wait_for(noop, 1s, [this] { return gstate_ == GlobalState::SHUTTING_DOWN; })) {\n+      break;\n+    }\n+\n+    uint32_t timeout = absl::GetFlag(FLAGS_timeout);\n+    if (timeout == 0) {\n+      continue;\n+    }\n+\n+    facade::Connection* from = nullptr;\n+    if (last_reference && !last_reference->IsExpired()) {\n+      from = last_reference->Get();\n+    }\n+\n+    // We use weak refs, because ShutdownSelf below can potentially block the fiber,\n+    // and during this time some of the connections might be destroyed. Weak refs allow checking\n+    // validity of each connection.\n+    vector<facade::Connection::WeakRef> conn_refs;\n+\n+    auto cb = [&](unsigned thread_index, util::Connection* conn) {\n+      facade::Connection* dfly_conn = static_cast<facade::Connection*>(conn);\n+      using Phase = facade::Connection::Phase;\n+      auto phase = dfly_conn->phase();\n+      bool is_replica = true;\n+      if (dfly_conn->cntx()) {\n+        is_replica = dfly_conn->cntx()->replica_conn;\n+      }\n+\n+      if ((phase == Phase::READ_SOCKET || dfly_conn->IsSending()) &&\n+          !is_replica && dfly_conn->idle_time() > timeout) {\n+        conn_refs.push_back(dfly_conn->Borrow());\n+      }\n+    };\n+\n+    util::Connection* next = main->TraverseConnectionsOnThread(cb, 100, from);\n+    if (next) {\n+      last_reference = static_cast<facade::Connection*>(next)->Borrow();\n+    } else {\n+      last_reference.reset();\n+    }\n+\n+    for (auto& ref : conn_refs) {\n+      facade::Connection* conn = ref.Get();\n+      if (conn) {\n+        VLOG(1) << \"Closing connection due to timeout: \" << conn->GetClientInfo();\n+        conn->ShutdownSelf();\n+      }\n+    }\n+  }\n+}\n+\n }  // end of namespace dfly\ndiff --git a/src/server/server_state.h b/src/server/server_state.h\nindex 6ea43787f48f..044cd6774c00 100644\n--- a/src/server/server_state.h\n+++ b/src/server/server_state.h\n@@ -23,6 +23,10 @@ namespace facade {\n class Connection;\n }\n \n+namespace util {\n+class ListenerInterface;\n+}\n+\n namespace dfly {\n \n namespace journal {\n@@ -150,12 +154,11 @@ class ServerState {  // public struct - to allow initialization.\n   ServerState();\n   ~ServerState();\n \n-  static void Init(uint32_t thread_index, uint32_t num_shards, acl::UserRegistry* registry);\n+  static void Init(uint32_t thread_index, uint32_t num_shards,\n+                   util::ListenerInterface* main_listener, acl::UserRegistry* registry);\n   static void Destroy();\n \n-  void EnterLameDuck() {\n-    state_->gstate_ = GlobalState::SHUTTING_DOWN;\n-  }\n+  void EnterLameDuck();\n \n   void TxCountInc() {\n     ++live_transactions_;\n@@ -302,6 +305,9 @@ class ServerState {  // public struct - to allow initialization.\n   size_t serialization_max_chunk_size;\n \n  private:\n+  // A fiber constantly watching connections on the main listener.\n+  void ConnectionsWatcherFb(util::ListenerInterface* main);\n+\n   int64_t live_transactions_ = 0;\n   SlowLogShard slow_log_shard_;\n   mi_heap_t* data_heap_;\n@@ -321,6 +327,10 @@ class ServerState {  // public struct - to allow initialization.\n   int client_pauses_[2] = {};\n   util::fb2::EventCount client_pause_ec_;\n \n+  // Monitors connections. Currently responsible for closing timed out connections.\n+  util::fb2::Fiber watcher_fiber_;\n+  util::fb2::CondVarAny watcher_cv_;\n+\n   using Counter = util::SlidingCounter<7>;\n   Counter qps_;\n \n",
  "test_patch": "diff --git a/src/server/blocking_controller_test.cc b/src/server/blocking_controller_test.cc\nindex 9f133c891d0a..1e0b74202a83 100644\n--- a/src/server/blocking_controller_test.cc\n+++ b/src/server/blocking_controller_test.cc\n@@ -29,8 +29,9 @@ class BlockingControllerTest : public Test {\n   }\n   void SetUp() override;\n   void TearDown() override;\n+\n   static void SetUpTestSuite() {\n-    ServerState::Init(kNumThreads, kNumThreads, nullptr);\n+    ServerState::Init(kNumThreads, kNumThreads, nullptr, nullptr);\n     facade::tl_facade_stats = new facade::FacadeStats;\n   }\n \n@@ -45,7 +46,7 @@ void BlockingControllerTest::SetUp() {\n   pp_.reset(fb2::Pool::Epoll(kNumThreads));\n   pp_->Run();\n   pp_->AwaitBrief([](unsigned index, ProactorBase* p) {\n-    ServerState::Init(index, kNumThreads, nullptr);\n+    ServerState::Init(index, kNumThreads, nullptr, nullptr);\n     if (facade::tl_facade_stats == nullptr) {\n       facade::tl_facade_stats = new facade::FacadeStats;\n     }\ndiff --git a/tests/dragonfly/connection_test.py b/tests/dragonfly/connection_test.py\nindex e7d74ad3d5e1..224f79e77baa 100755\n--- a/tests/dragonfly/connection_test.py\n+++ b/tests/dragonfly/connection_test.py\n@@ -1051,3 +1051,14 @@ async def test_hiredis(df_factory):\n     server.start()\n     client = base_redis.Redis(port=server.port, protocol=3, cache_config=CacheConfig())\n     client.ping()\n+\n+\n+@dfly_args({\"timeout\": 1})\n+async def test_timeout(df_server: DflyInstance, async_client: aioredis.Redis):\n+    another_client = df_server.client()\n+    await another_client.ping()\n+    clients = await async_client.client_list()\n+    assert len(clients) == 2\n+    await asyncio.sleep(2)\n+    clients = await async_client.client_list()\n+    assert len(clients) == 1\n",
  "problem_statement": "Add timeout flag\ntimeout flag - Close the connection after a client is idle for N seconds (0 to disable)\r\n\r\nWe should support updating this flag with config set command\n",
  "hints_text": "@adiholden  it's not a high priority. ",
  "created_at": "2025-01-05T18:40:27Z",
  "modified_files": [
    "src/facade/conn_context.h",
    "src/facade/dragonfly_connection.cc",
    "src/facade/dragonfly_connection.h",
    "src/server/main_service.cc",
    "src/server/server_state.cc",
    "src/server/server_state.h"
  ],
  "modified_test_files": [
    "src/server/blocking_controller_test.cc",
    "tests/dragonfly/connection_test.py"
  ]
}