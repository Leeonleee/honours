You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes

<issue>
JSON extract (`->`) sometimes doesn't work if path is parametrized
### What happens?

The behavior of the JSON extract operator (`->`) varies if the path is parametrized or a literal.

### To Reproduce

This script reproduces the issue. I've run it on both 5.1 and dev.

```python
import duckdb

con = duckdb.connect()

con.execute("CREATE TABLE test(js JSON);")
con.execute('INSERT INTO test VALUES (\'{"a": 1, "b": 2}\')')

# Literal: OK
res = con.execute("SELECT js->'a' FROM test").fetchall()
print(res)

# Literal with cast: OK
res = con.execute("SELECT js->CAST('a' AS STRING) FROM test").fetchall()
print(res)

# Parameter: OK
res = con.execute("SELECT js->? FROM test", ("a",)).fetchall()
print(res)

# Parameter with Cast: Broken
res = con.execute("SELECT js->CAST(? AS STRING) FROM test", ("a",)).fetchall()
print(res)

# Parameter with Cast and 2nd parameter: OK
res = con.execute("SELECT js->CAST(? AS STRING), ? FROM test", ("a", 2)).fetchall()
print(res)
```

Output:

```
[('1',)]
[('1',)]
[('1',)]
[('{"a":1,"b":2}',)]
[('1', 2)]
```

### OS:

linux

### DuckDB Version:

0.5.1

### DuckDB Client:

Python

### Full Name:

Jim Crist-Harif

### Affiliation:

Voltron Data

### Have you tried this on the latest `master` branch?

- [X] I agree

### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?

- [X] I agree
Bug in current_memory calculation of buffer manager
### What happens?

When running a query involving sort code, then the current_memory size increases by 24 bytes, even though it should not change.

### To Reproduce

```c++
TEST_CASE("Test buffer manager", "[art][.]") {
	auto storage_database = TestCreatePath("storage_test");
	auto config = GetTestConfig();
	// make sure the database does not exist
	DeleteDatabase(storage_database);
	DuckDB db(storage_database, config.get());
	Connection con(db);

	idx_t current_memory = 0;
	auto &buffer_manager = BufferManager::GetBufferManager(*con.context);
	D_ASSERT(buffer_manager.GetUsedMemory() == current_memory);

	REQUIRE_NO_FAIL(con.Query("CREATE TABLE leaf AS SELECT 42 AS id FROM range(42);"));
	current_memory = buffer_manager.GetUsedMemory();

	REQUIRE_NO_FAIL(con.Query("SELECT * FROM leaf ORDER BY 1;"));
	D_ASSERT(buffer_manager.GetUsedMemory() == current_memory);
}
```

### OS:

iOS

### DuckDB Version:

Master

### DuckDB Client:

CLI/ test runner

### Full Name:

Tania Bogatsch

### Affiliation:

DuckDB Labs

### Have you tried this on the latest `master` branch?

- [X] I agree

### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?

- [X] I agree

</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <img src="https://duckdb.org/images/DuckDB_Logo_dl.png" height="50">
3: </div>
4: <p>&nbsp;</p>
5: 
6: <p align="center">
7:   <a href="https://github.com/duckdb/duckdb/actions">
8:     <img src="https://github.com/duckdb/duckdb/actions/workflows/Main.yml/badge.svg?branch=master" alt="Github Actions Badge">
9:   </a>
10:   <a href="https://www.codefactor.io/repository/github/cwida/duckdb">
11:     <img src="https://www.codefactor.io/repository/github/cwida/duckdb/badge" alt="CodeFactor"/>
12:   </a>
13:   <a href="https://app.codecov.io/gh/duckdb/duckdb">
14:     <img src="https://codecov.io/gh/duckdb/duckdb/branch/master/graph/badge.svg?token=FaxjcfFghN" alt="codecov"/>
15:   </a>
16:   <a href="https://discord.gg/tcvwpjfnZx">
17:     <img src="https://shields.io/discord/909674491309850675" alt="discord" />
18:   </a>
19: </p>
20: 
21: ## DuckDB
22: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs), and more. For more information on the goals of DuckDB, please refer to [the Why DuckDB page on our website](https://duckdb.org/why_duckdb).
23: 
24: ## Installation
25: If you want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
26: 
27: ## Data Import
28: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
29: 
30: ```sql
31: SELECT * FROM 'myfile.csv';
32: SELECT * FROM 'myfile.parquet';
33: ```
34: 
35: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
36: 
37: ## SQL Reference
38: The [website](https://duckdb.org/docs/sql/introduction) contains a reference of functions and SQL constructs available in DuckDB.
39: 
40: ## Development
41: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run `BUILD_BENCHMARK=1 BUILD_TPCH=1 make` and then perform several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`. The detail of benchmarks is in our [Benchmark Guide](benchmark/README.md).
42: 
43: Please also refer to our [Contribution Guide](CONTRIBUTING.md).
[end of README.md]
[start of extension/json/include/json_common.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // json_common.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/common/operator/cast_operators.hpp"
12: #include "duckdb/common/operator/decimal_cast_operators.hpp"
13: #include "duckdb/common/operator/string_cast.hpp"
14: #include "duckdb/execution/expression_executor.hpp"
15: #include "duckdb/planner/expression/bound_function_expression.hpp"
16: #include "yyjson.hpp"
17: 
18: namespace duckdb {
19: 
20: struct JSONReadFunctionData : public FunctionData {
21: public:
22: 	JSONReadFunctionData(bool constant, string path_p, idx_t len);
23: 	unique_ptr<FunctionData> Copy() const override;
24: 	bool Equals(const FunctionData &other_p) const override;
25: 	static unique_ptr<FunctionData> Bind(ClientContext &context, ScalarFunction &bound_function,
26: 	                                     vector<unique_ptr<Expression>> &arguments);
27: 
28: public:
29: 	const bool constant;
30: 	const string path;
31: 	const char *ptr;
32: 	const size_t len;
33: };
34: 
35: struct JSONReadManyFunctionData : public FunctionData {
36: public:
37: 	JSONReadManyFunctionData(vector<string> paths_p, vector<size_t> lens_p);
38: 	unique_ptr<FunctionData> Copy() const override;
39: 	bool Equals(const FunctionData &other_p) const override;
40: 	static unique_ptr<FunctionData> Bind(ClientContext &context, ScalarFunction &bound_function,
41: 	                                     vector<unique_ptr<Expression>> &arguments);
42: 
43: public:
44: 	const vector<string> paths;
45: 	vector<const char *> ptrs;
46: 	const vector<size_t> lens;
47: };
48: 
49: template <class YYJSON_DOC_T>
50: static inline void CleanupDoc(YYJSON_DOC_T *doc) {
51: 	throw InternalException("Unknown yyjson document type");
52: }
53: 
54: template <>
55: inline void CleanupDoc(yyjson_doc *doc) {
56: 	yyjson_doc_free(doc);
57: }
58: 
59: template <>
60: inline void CleanupDoc(yyjson_mut_doc *doc) {
61: 	yyjson_mut_doc_free(doc);
62: }
63: 
64: template <class YYJSON_DOC_T>
65: class DocPointer {
66: private:
67: 	YYJSON_DOC_T *doc;
68: 
69: public:
70: 	explicit DocPointer(YYJSON_DOC_T *doc) : doc(doc) {
71: 	}
72: 
73: 	DocPointer(const DocPointer &obj) = delete;
74: 	DocPointer &operator=(const DocPointer &obj) = delete;
75: 
76: 	DocPointer(DocPointer &&other) noexcept {
77: 		this->doc = other.doc;
78: 		other.doc = nullptr;
79: 	}
80: 
81: 	void operator=(DocPointer &&other) noexcept {
82: 		CleanupDoc<YYJSON_DOC_T>(doc);
83: 		this->ptr = other.ptr;
84: 		other.ptr = nullptr;
85: 	}
86: 
87: 	inline YYJSON_DOC_T *operator*() const {
88: 		return doc;
89: 	}
90: 
91: 	inline YYJSON_DOC_T *operator->() const {
92: 		return doc;
93: 	}
94: 
95: 	inline bool IsNull() const {
96: 		return doc == nullptr;
97: 	}
98: 
99: 	~DocPointer() {
100: 		CleanupDoc<YYJSON_DOC_T>(doc);
101: 	}
102: };
103: 
104: struct JSONCommon {
105: private:
106: 	//! Read/Write flag that make sense for us
107: 	static constexpr auto READ_FLAG = YYJSON_READ_ALLOW_INF_AND_NAN | YYJSON_READ_ALLOW_TRAILING_COMMAS;
108: 	static constexpr auto WRITE_FLAG = YYJSON_WRITE_ALLOW_INF_AND_NAN;
109: 
110: public:
111: 	//! Constant JSON type strings
112: 	static constexpr auto TYPE_STRING_NULL = "NULL";
113: 	static constexpr auto TYPE_STRING_BOOLEAN = "BOOLEAN";
114: 	static constexpr auto TYPE_STRING_BIGINT = "BIGINT";
115: 	static constexpr auto TYPE_STRING_UBIGINT = "UBIGINT";
116: 	static constexpr auto TYPE_STRING_DOUBLE = "DOUBLE";
117: 	static constexpr auto TYPE_STRING_VARCHAR = "VARCHAR";
118: 	static constexpr auto TYPE_STRING_ARRAY = "ARRAY";
119: 	static constexpr auto TYPE_STRING_OBJECT = "OBJECT";
120: 
121: 	template <class YYJSON_VAL_T>
122: 	static inline const char *const ValTypeToString(YYJSON_VAL_T *val) {
123: 		switch (GetTag<YYJSON_VAL_T>(val)) {
124: 		case YYJSON_TYPE_NULL | YYJSON_SUBTYPE_NONE:
125: 			return JSONCommon::TYPE_STRING_NULL;
126: 		case YYJSON_TYPE_STR | YYJSON_SUBTYPE_NONE:
127: 			return JSONCommon::TYPE_STRING_VARCHAR;
128: 		case YYJSON_TYPE_ARR | YYJSON_SUBTYPE_NONE:
129: 			return JSONCommon::TYPE_STRING_ARRAY;
130: 		case YYJSON_TYPE_OBJ | YYJSON_SUBTYPE_NONE:
131: 			return JSONCommon::TYPE_STRING_OBJECT;
132: 		case YYJSON_TYPE_BOOL | YYJSON_SUBTYPE_TRUE:
133: 		case YYJSON_TYPE_BOOL | YYJSON_SUBTYPE_FALSE:
134: 			return JSONCommon::TYPE_STRING_BOOLEAN;
135: 		case YYJSON_TYPE_NUM | YYJSON_SUBTYPE_UINT:
136: 			return JSONCommon::TYPE_STRING_UBIGINT;
137: 		case YYJSON_TYPE_NUM | YYJSON_SUBTYPE_SINT:
138: 			return JSONCommon::TYPE_STRING_BIGINT;
139: 		case YYJSON_TYPE_NUM | YYJSON_SUBTYPE_REAL:
140: 			return JSONCommon::TYPE_STRING_DOUBLE;
141: 		default:
142: 			throw InternalException("Unexpected yyjson tag in ValTypeToString");
143: 		}
144: 	}
145: 
146: public:
147: 	static inline DocPointer<yyjson_mut_doc> CreateDocument() {
148: 		return DocPointer<yyjson_mut_doc>(yyjson_mut_doc_new(nullptr));
149: 	}
150: 
151: 	//! Read JSON document (returns nullptr if invalid JSON)
152: 	static inline DocPointer<yyjson_doc> ReadDocumentUnsafe(const string_t &input) {
153: 		return DocPointer<yyjson_doc>(yyjson_read(input.GetDataUnsafe(), input.GetSize(), READ_FLAG));
154: 	}
155: 	//! Read JSON document (throws error if malformed JSON)
156: 	static inline DocPointer<yyjson_doc> ReadDocument(const string_t &input) {
157: 		auto result = ReadDocumentUnsafe(input);
158: 		if (result.IsNull()) {
159: 			throw InvalidInputException("malformed JSON");
160: 		}
161: 		return result;
162: 	}
163: 	//! Some wrappers around writes so we don't have to free the malloc'ed char[]
164: 	static inline unique_ptr<char, void (*)(void *)> WriteVal(yyjson_val *val, idx_t &len) {
165: 		return unique_ptr<char, decltype(free) *>(
166: 		    reinterpret_cast<char *>(yyjson_val_write(val, WRITE_FLAG, (size_t *)&len)), free);
167: 	}
168: 	static inline unique_ptr<char, void (*)(void *)> WriteVal(yyjson_mut_val *val, idx_t &len) {
169: 		return unique_ptr<char, decltype(free) *>(
170: 		    reinterpret_cast<char *>(yyjson_mut_val_write(val, WRITE_FLAG, (size_t *)&len)), free);
171: 	}
172: 	static unique_ptr<char, void (*)(void *)> WriteMutDoc(yyjson_mut_doc *doc, idx_t &len) {
173: 		return unique_ptr<char, decltype(free) *>(
174: 		    reinterpret_cast<char *>(yyjson_mut_write(doc, WRITE_FLAG, (size_t *)&len)), free);
175: 	}
176: 	//! Vector writes
177: 	static inline string_t WriteVal(yyjson_val *val, Vector &vector) {
178: 		idx_t len;
179: 		auto data = WriteVal(val, len);
180: 		return StringVector::AddString(vector, data.get(), len);
181: 	}
182: 	static inline string_t WriteVal(yyjson_mut_val *val, Vector &vector) {
183: 		idx_t len;
184: 		auto data = WriteVal(val, len);
185: 		return StringVector::AddString(vector, data.get(), len);
186: 	}
187: 	static inline string_t WriteDoc(yyjson_mut_doc *doc, Vector &vector) {
188: 		idx_t len;
189: 		auto data = WriteMutDoc(doc, len);
190: 		return StringVector::AddString(vector, data.get(), len);
191: 	}
192: 	//! Throw an error with the printed yyjson_val
193: 	static void ThrowValFormatError(string error_string, yyjson_val *val) {
194: 		idx_t len;
195: 		auto data = WriteVal(val, len);
196: 		error_string = StringUtil::Format(error_string, string(data.get(), len));
197: 		throw InvalidInputException(error_string);
198: 	}
199: 
200: public:
201: 	//! Validate path with $ syntax
202: 	static void ValidatePathDollar(const char *ptr, const idx_t &len);
203: 
204: 	//! Get JSON value using JSON path query (safe, checks the path query)
205: 	template <class YYJSON_VAL_T>
206: 	static inline YYJSON_VAL_T *GetPointer(YYJSON_VAL_T *root, const string_t &path_str) {
207: 		auto ptr = path_str.GetDataUnsafe();
208: 		auto len = path_str.GetSize();
209: 		if (len == 0) {
210: 			return GetPointerUnsafe<YYJSON_VAL_T>(root, ptr, len);
211: 		}
212: 		switch (*ptr) {
213: 		case '/': {
214: 			// '/' notation must be '\0'-terminated
215: 			auto str = string(ptr, len);
216: 			return GetPointerUnsafe<YYJSON_VAL_T>(root, str.c_str(), len);
217: 		}
218: 		case '$': {
219: 			ValidatePathDollar(ptr, len);
220: 			return GetPointerUnsafe<YYJSON_VAL_T>(root, ptr, len);
221: 		}
222: 		default:
223: 			auto str = "/" + string(ptr, len);
224: 			return GetPointerUnsafe<YYJSON_VAL_T>(root, str.c_str(), len);
225: 		}
226: 	}
227: 
228: 	//! Get JSON value using JSON path query (unsafe)
229: 	template <class YYJSON_VAL_T>
230: 	static inline YYJSON_VAL_T *GetPointerUnsafe(YYJSON_VAL_T *root, const char *ptr, const idx_t &len) {
231: 		if (len == 0) {
232: 			return nullptr;
233: 		}
234: 		switch (*ptr) {
235: 		case '/':
236: 			return TemplatedGetPointer<YYJSON_VAL_T>(root, ptr, len);
237: 		case '$':
238: 			return TemplatedGetPointerDollar<YYJSON_VAL_T>(root, ptr, len);
239: 		default:
240: 			throw InternalException("JSON path does not start with '/' or '$'");
241: 		}
242: 	}
243: 
244: public:
245: 	//! Single-argument JSON read function, i.e. json_type('[1, 2, 3]')
246: 	template <class T>
247: 	static void UnaryExecute(DataChunk &args, ExpressionState &state, Vector &result,
248: 	                         std::function<T(yyjson_val *, Vector &)> fun) {
249: 		auto &inputs = args.data[0];
250: 		UnaryExecutor::Execute<string_t, T>(inputs, result, args.size(), [&](string_t input) {
251: 			auto doc = JSONCommon::ReadDocument(input);
252: 			return fun(doc->root, result);
253: 		});
254: 	}
255: 
256: 	//! Two-argument JSON read function (with path query), i.e. json_type('[1, 2, 3]', '$[0]')
257: 	template <class T>
258: 	static void BinaryExecute(DataChunk &args, ExpressionState &state, Vector &result,
259: 	                          std::function<T(yyjson_val *, Vector &)> fun) {
260: 		auto &func_expr = (BoundFunctionExpression &)state.expr;
261: 		const auto &info = (JSONReadFunctionData &)*func_expr.bind_info;
262: 
263: 		auto &inputs = args.data[0];
264: 		if (info.constant) {
265: 			// Constant path
266: 			const char *ptr = info.ptr;
267: 			const idx_t &len = info.len;
268: 			UnaryExecutor::ExecuteWithNulls<string_t, T>(
269: 			    inputs, result, args.size(), [&](string_t input, ValidityMask &mask, idx_t idx) {
270: 				    auto doc = ReadDocument(input);
271: 				    yyjson_val *val;
272: 				    if (!(val = GetPointerUnsafe<yyjson_val>(doc->root, ptr, len))) {
273: 					    mask.SetInvalid(idx);
274: 					    return T {};
275: 				    } else {
276: 					    return fun(val, result);
277: 				    }
278: 			    });
279: 		} else {
280: 			// Columnref path
281: 			auto &paths = args.data[1];
282: 			BinaryExecutor::ExecuteWithNulls<string_t, string_t, T>(
283: 			    inputs, paths, result, args.size(), [&](string_t input, string_t path, ValidityMask &mask, idx_t idx) {
284: 				    auto doc = ReadDocument(input);
285: 				    yyjson_val *val;
286: 				    if (!(val = GetPointer<yyjson_val>(doc->root, path))) {
287: 					    mask.SetInvalid(idx);
288: 					    return T {};
289: 				    } else {
290: 					    return fun(val, result);
291: 				    }
292: 			    });
293: 		}
294: 		if (args.AllConstant()) {
295: 			result.SetVectorType(VectorType::CONSTANT_VECTOR);
296: 		}
297: 	}
298: 
299: 	//! JSON read function with list of path queries, i.e. json_type('[1, 2, 3]', ['$[0]', '$[1]'])
300: 	template <class T>
301: 	static void ExecuteMany(DataChunk &args, ExpressionState &state, Vector &result,
302: 	                        std::function<T(yyjson_val *, Vector &)> fun) {
303: 		auto &func_expr = (BoundFunctionExpression &)state.expr;
304: 		const auto &info = (JSONReadManyFunctionData &)*func_expr.bind_info;
305: 		D_ASSERT(info.ptrs.size() == info.lens.size());
306: 
307: 		const auto count = args.size();
308: 		const idx_t num_paths = info.ptrs.size();
309: 		const idx_t list_size = count * num_paths;
310: 
311: 		UnifiedVectorFormat input_data;
312: 		auto &input_vector = args.data[0];
313: 		input_vector.ToUnifiedFormat(count, input_data);
314: 		auto inputs = (string_t *)input_data.data;
315: 
316: 		ListVector::Reserve(result, list_size);
317: 		auto list_entries = FlatVector::GetData<list_entry_t>(result);
318: 		auto &list_validity = FlatVector::Validity(result);
319: 
320: 		auto &child = ListVector::GetEntry(result);
321: 		auto child_data = FlatVector::GetData<T>(child);
322: 		auto &child_validity = FlatVector::Validity(child);
323: 
324: 		idx_t offset = 0;
325: 		yyjson_val *val;
326: 		for (idx_t i = 0; i < count; i++) {
327: 			auto idx = input_data.sel->get_index(i);
328: 			if (!input_data.validity.RowIsValid(idx)) {
329: 				list_validity.SetInvalid(i);
330: 				continue;
331: 			}
332: 
333: 			auto doc = ReadDocument(inputs[idx]);
334: 			for (idx_t path_i = 0; path_i < num_paths; path_i++) {
335: 				auto child_idx = offset + path_i;
336: 				if (!(val = GetPointerUnsafe<yyjson_val>(doc->root, info.ptrs[path_i], info.lens[path_i]))) {
337: 					child_validity.SetInvalid(child_idx);
338: 				} else {
339: 					child_data[child_idx] = fun(val, child);
340: 				}
341: 			}
342: 
343: 			list_entries[i].offset = offset;
344: 			list_entries[i].length = num_paths;
345: 			offset += num_paths;
346: 		}
347: 		ListVector::SetListSize(result, offset);
348: 
349: 		if (args.AllConstant()) {
350: 			result.SetVectorType(VectorType::CONSTANT_VECTOR);
351: 		}
352: 	}
353: 
354: private:
355: 	//! Get JSON pointer using /field/index/... notation
356: 	template <class YYJSON_VAL_T>
357: 	static inline YYJSON_VAL_T *TemplatedGetPointer(YYJSON_VAL_T *root, const char *ptr, const idx_t &len) {
358: 		throw InternalException("Unknown yyjson value type");
359: 	}
360: 
361: 	//! Get JSON pointer using $.field[index]... notation
362: 	template <class YYJSON_VAL_T>
363: 	static YYJSON_VAL_T *TemplatedGetPointerDollar(YYJSON_VAL_T *val, const char *ptr, const idx_t &len) {
364: 		if (len == 1) {
365: 			// Just '$'
366: 			return val;
367: 		}
368: 		const char *const end = ptr + len;
369: 		// Skip past '$'
370: 		ptr++;
371: 		while (val != nullptr && ptr != end) {
372: 			const auto &c = *ptr++;
373: 			if (c == '.') {
374: 				// Object
375: 				if (!IsObj<YYJSON_VAL_T>(val)) {
376: 					return nullptr;
377: 				}
378: 				bool escaped = false;
379: 				if (*ptr == '"') {
380: 					// Skip past opening '"'
381: 					ptr++;
382: 					escaped = true;
383: 				}
384: 				auto key_len = ReadString(ptr, end, escaped);
385: 				val = ObjGetN<YYJSON_VAL_T>(val, ptr, key_len);
386: 				ptr += key_len;
387: 				if (escaped) {
388: 					// Skip past closing '"'
389: 					ptr++;
390: 				}
391: 			} else if (c == '[') {
392: 				// Array
393: 				if (!IsArr<YYJSON_VAL_T>(val)) {
394: 					return nullptr;
395: 				}
396: 				bool from_back = false;
397: 				if (*ptr == '#') {
398: 					// Index from back of array
399: 					ptr++;
400: 					if (*ptr == ']') {
401: 						return nullptr;
402: 					}
403: 					from_back = true;
404: 					// Skip past '-'
405: 					ptr++;
406: 				}
407: 				// Read index
408: 				idx_t idx;
409: 				auto idx_len = ReadIndex(ptr, end, idx);
410: 				if (from_back) {
411: 					auto arr_size = ArrSize<YYJSON_VAL_T>(val);
412: 					idx = idx > arr_size ? arr_size : arr_size - idx;
413: 				}
414: 				val = ArrGet<YYJSON_VAL_T>(val, idx);
415: 				ptr += idx_len;
416: 				// Skip past closing ']'
417: 				ptr++;
418: 			} else {
419: 				throw InternalException("Unexpected char when parsing JSON path");
420: 			}
421: 		}
422: 		return val;
423: 	}
424: 
425: 	static inline idx_t ReadString(const char *ptr, const char *const end, const bool escaped) {
426: 		const char *const before = ptr;
427: 		if (escaped) {
428: 			while (ptr != end) {
429: 				if (*ptr == '"') {
430: 					break;
431: 				}
432: 				ptr++;
433: 			}
434: 			return ptr == end ? 0 : ptr - before;
435: 		} else {
436: 			while (ptr != end) {
437: 				if (*ptr == '.' || *ptr == '[') {
438: 					break;
439: 				}
440: 				ptr++;
441: 			}
442: 			return ptr - before;
443: 		}
444: 	}
445: 
446: 	static constexpr auto IDX_T_SAFE_DIG = 19;
447: 	static constexpr auto IDX_T_MAX = ((idx_t)(~(idx_t)0));
448: 
449: 	static inline idx_t ReadIndex(const char *ptr, const char *const end, idx_t &idx) {
450: 		const char *const before = ptr;
451: 		idx = 0;
452: 		for (idx_t i = 0; i < IDX_T_SAFE_DIG; i++) {
453: 			if (ptr == end) {
454: 				// No closing ']'
455: 				return 0;
456: 			}
457: 			if (*ptr == ']') {
458: 				break;
459: 			}
460: 			uint8_t add = (uint8_t)(*ptr - '0');
461: 			if (add <= 9) {
462: 				idx = add + idx * 10;
463: 			} else {
464: 				// Not a digit
465: 				return 0;
466: 			}
467: 			ptr++;
468: 		}
469: 		// Invalid if overflow
470: 		return idx >= (idx_t)IDX_T_MAX ? 0 : ptr - before;
471: 	}
472: 
473: private:
474: 	template <class YYJSON_VAL_T>
475: 	static inline bool IsObj(YYJSON_VAL_T *val) {
476: 		throw InternalException("Unknown yyjson value type");
477: 	}
478: 
479: 	template <class YYJSON_VAL_T>
480: 	static inline YYJSON_VAL_T *ObjGetN(YYJSON_VAL_T *val, const char *ptr, idx_t key_len) {
481: 		throw InternalException("Unknown yyjson value type");
482: 	}
483: 
484: 	template <class YYJSON_VAL_T>
485: 	static inline bool IsArr(YYJSON_VAL_T *val) {
486: 		throw InternalException("Unknown yyjson value type");
487: 	}
488: 
489: 	template <class YYJSON_VAL_T>
490: 	static inline size_t ArrSize(YYJSON_VAL_T *val) {
491: 		throw InternalException("Unknown yyjson value type");
492: 	}
493: 
494: 	template <class YYJSON_VAL_T>
495: 	static inline YYJSON_VAL_T *ArrGet(YYJSON_VAL_T *val, idx_t index) {
496: 		throw InternalException("Unknown yyjson value type");
497: 	}
498: 
499: 	template <class YYJSON_VAL_T>
500: 	static inline yyjson_type GetTag(YYJSON_VAL_T *val) {
501: 		throw InternalException("Unknown yyjson value type");
502: 	}
503: };
504: 
505: template <>
506: inline yyjson_val *JSONCommon::TemplatedGetPointer(yyjson_val *root, const char *ptr, const idx_t &len) {
507: 	return len == 1 ? root : unsafe_yyjson_get_pointer(root, ptr, len);
508: }
509: template <>
510: inline yyjson_mut_val *JSONCommon::TemplatedGetPointer(yyjson_mut_val *root, const char *ptr, const idx_t &len) {
511: 	return len == 1 ? root : unsafe_yyjson_mut_get_pointer(root, ptr, len);
512: }
513: 
514: template <>
515: inline bool JSONCommon::IsObj(yyjson_val *val) {
516: 	return yyjson_is_obj(val);
517: }
518: template <>
519: inline bool JSONCommon::IsObj(yyjson_mut_val *val) {
520: 	return yyjson_mut_is_obj(val);
521: }
522: 
523: template <>
524: inline yyjson_val *JSONCommon::ObjGetN(yyjson_val *val, const char *ptr, idx_t key_len) {
525: 	return yyjson_obj_getn(val, ptr, key_len);
526: }
527: template <>
528: inline yyjson_mut_val *JSONCommon::ObjGetN(yyjson_mut_val *val, const char *ptr, idx_t key_len) {
529: 	return yyjson_mut_obj_getn(val, ptr, key_len);
530: }
531: 
532: template <>
533: inline bool JSONCommon::IsArr(yyjson_val *val) {
534: 	return yyjson_is_arr(val);
535: }
536: template <>
537: inline bool JSONCommon::IsArr(yyjson_mut_val *val) {
538: 	return yyjson_mut_is_arr(val);
539: }
540: 
541: template <>
542: inline size_t JSONCommon::ArrSize(yyjson_val *val) {
543: 	return yyjson_arr_size(val);
544: }
545: template <>
546: inline size_t JSONCommon::ArrSize(yyjson_mut_val *val) {
547: 	return yyjson_mut_arr_size(val);
548: }
549: 
550: template <>
551: inline yyjson_val *JSONCommon::ArrGet(yyjson_val *val, idx_t index) {
552: 	return yyjson_arr_get(val, index);
553: }
554: template <>
555: inline yyjson_mut_val *JSONCommon::ArrGet(yyjson_mut_val *val, idx_t index) {
556: 	return yyjson_mut_arr_get(val, index);
557: }
558: 
559: template <>
560: inline yyjson_type JSONCommon::GetTag(yyjson_val *val) {
561: 	return yyjson_get_tag(val);
562: }
563: template <>
564: inline yyjson_type JSONCommon::GetTag(yyjson_mut_val *val) {
565: 	return yyjson_mut_get_tag(val);
566: }
567: 
568: } // namespace duckdb
[end of extension/json/include/json_common.hpp]
[start of src/parser/expression/lambda_expression.cpp]
1: #include "duckdb/parser/expression/lambda_expression.hpp"
2: #include "duckdb/common/field_writer.hpp"
3: #include "duckdb/common/types/hash.hpp"
4: #include "duckdb/common/string_util.hpp"
5: 
6: namespace duckdb {
7: 
8: LambdaExpression::LambdaExpression(unique_ptr<ParsedExpression> lhs, unique_ptr<ParsedExpression> expr)
9:     : ParsedExpression(ExpressionType::LAMBDA, ExpressionClass::LAMBDA), lhs(move(lhs)), expr(move(expr)) {
10: }
11: 
12: string LambdaExpression::ToString() const {
13: 	return lhs->ToString() + " -> " + expr->ToString();
14: }
15: 
16: bool LambdaExpression::Equals(const LambdaExpression *a, const LambdaExpression *b) {
17: 	return a->lhs->Equals(b->lhs.get()) && a->expr->Equals(b->expr.get());
18: }
19: 
20: hash_t LambdaExpression::Hash() const {
21: 
22: 	hash_t result = lhs->Hash();
23: 	ParsedExpression::Hash();
24: 	result = CombineHash(result, expr->Hash());
25: 	return result;
26: }
27: 
28: unique_ptr<ParsedExpression> LambdaExpression::Copy() const {
29: 	return make_unique<LambdaExpression>(lhs->Copy(), expr->Copy());
30: }
31: 
32: void LambdaExpression::Serialize(FieldWriter &writer) const {
33: 	writer.WriteSerializable(*lhs);
34: 	writer.WriteSerializable(*expr);
35: }
36: 
37: unique_ptr<ParsedExpression> LambdaExpression::Deserialize(ExpressionType type, FieldReader &reader) {
38: 	auto lhs = reader.ReadRequiredSerializable<ParsedExpression>();
39: 	auto expr = reader.ReadRequiredSerializable<ParsedExpression>();
40: 	return make_unique<LambdaExpression>(move(lhs), move(expr));
41: }
42: 
43: } // namespace duckdb
[end of src/parser/expression/lambda_expression.cpp]
[start of src/storage/buffer_manager.cpp]
1: #include "duckdb/storage/buffer_manager.hpp"
2: 
3: #include "duckdb/common/allocator.hpp"
4: #include "duckdb/common/exception.hpp"
5: #include "duckdb/common/set.hpp"
6: #include "duckdb/parallel/concurrentqueue.hpp"
7: #include "duckdb/storage/storage_manager.hpp"
8: #include "duckdb/storage/in_memory_block_manager.hpp"
9: 
10: namespace duckdb {
11: 
12: BufferPoolReservation::BufferPoolReservation(BufferPoolReservation &&src) noexcept {
13: 	size = src.size;
14: 	src.size = 0;
15: }
16: 
17: BufferPoolReservation &BufferPoolReservation::operator=(BufferPoolReservation &&src) noexcept {
18: 	size = src.size;
19: 	src.size = 0;
20: 	return *this;
21: }
22: 
23: BufferPoolReservation::~BufferPoolReservation() {
24: 	D_ASSERT(size == 0);
25: }
26: 
27: void BufferPoolReservation::Resize(atomic<idx_t> &counter, idx_t new_size) {
28: 	int64_t delta = (int64_t)new_size - size;
29: 	D_ASSERT(delta > 0 || (int64_t)counter >= -delta);
30: 	counter += delta;
31: 	size = new_size;
32: }
33: 
34: void BufferPoolReservation::Merge(BufferPoolReservation &&src) {
35: 	size += src.size;
36: 	src.size = 0;
37: }
38: 
39: struct BufferAllocatorData : PrivateAllocatorData {
40: 	explicit BufferAllocatorData(BufferManager &manager) : manager(manager) {
41: 	}
42: 
43: 	BufferManager &manager;
44: };
45: 
46: BlockHandle::BlockHandle(BlockManager &block_manager, block_id_t block_id_p)
47:     : block_manager(block_manager), readers(0), block_id(block_id_p), buffer(nullptr), eviction_timestamp(0),
48:       can_destroy(false), unswizzled(nullptr) {
49: 	eviction_timestamp = 0;
50: 	state = BlockState::BLOCK_UNLOADED;
51: 	memory_usage = Storage::BLOCK_ALLOC_SIZE;
52: }
53: 
54: BlockHandle::BlockHandle(BlockManager &block_manager, block_id_t block_id_p, unique_ptr<FileBuffer> buffer_p,
55:                          bool can_destroy_p, idx_t block_size, BufferPoolReservation &&reservation)
56:     : block_manager(block_manager), readers(0), block_id(block_id_p), eviction_timestamp(0), can_destroy(can_destroy_p),
57:       unswizzled(nullptr) {
58: 	buffer = move(buffer_p);
59: 	state = BlockState::BLOCK_LOADED;
60: 	memory_usage = buffer->AllocSize();
61: 	memory_charge = move(reservation);
62: }
63: 
64: BlockHandle::~BlockHandle() {
65: 	// being destroyed, so any unswizzled pointers are just binary junk now.
66: 	unswizzled = nullptr;
67: 	auto &buffer_manager = block_manager.buffer_manager;
68: 	// no references remain to this block: erase
69: 	if (buffer && state == BlockState::BLOCK_LOADED) {
70: 		D_ASSERT(memory_charge.size > 0);
71: 		// the block is still loaded in memory: erase it
72: 		buffer.reset();
73: 		memory_charge.Resize(buffer_manager.current_memory, 0);
74: 	} else {
75: 		D_ASSERT(memory_charge.size == 0);
76: 	}
77: 	block_manager.UnregisterBlock(block_id, can_destroy);
78: }
79: 
80: unique_ptr<Block> AllocateBlock(BlockManager &block_manager, unique_ptr<FileBuffer> reusable_buffer,
81:                                 block_id_t block_id) {
82: 	if (reusable_buffer) {
83: 		// re-usable buffer: re-use it
84: 		if (reusable_buffer->type == FileBufferType::BLOCK) {
85: 			// we can reuse the buffer entirely
86: 			auto &block = (Block &)*reusable_buffer;
87: 			block.id = block_id;
88: 			return unique_ptr_cast<FileBuffer, Block>(move(reusable_buffer));
89: 		}
90: 		auto block = block_manager.CreateBlock(block_id, reusable_buffer.get());
91: 		reusable_buffer.reset();
92: 		return block;
93: 	} else {
94: 		// no re-usable buffer: allocate a new block
95: 		return block_manager.CreateBlock(block_id, nullptr);
96: 	}
97: }
98: 
99: unique_ptr<FileBuffer> BufferManager::ConstructManagedBuffer(idx_t size, unique_ptr<FileBuffer> &&source,
100:                                                              FileBufferType type) {
101: 	if (source) {
102: 		auto tmp = move(source);
103: 		D_ASSERT(tmp->size == size);
104: 		return make_unique<FileBuffer>(*tmp, type);
105: 	} else {
106: 		// no re-usable buffer: allocate a new buffer
107: 		return make_unique<FileBuffer>(Allocator::Get(db), type, size);
108: 	}
109: }
110: 
111: BufferHandle BlockHandle::Load(shared_ptr<BlockHandle> &handle, unique_ptr<FileBuffer> reusable_buffer) {
112: 	if (handle->state == BlockState::BLOCK_LOADED) {
113: 		// already loaded
114: 		D_ASSERT(handle->buffer);
115: 		return BufferHandle(handle, handle->buffer.get());
116: 	}
117: 
118: 	auto &block_manager = handle->block_manager;
119: 	if (handle->block_id < MAXIMUM_BLOCK) {
120: 		auto block = AllocateBlock(block_manager, move(reusable_buffer), handle->block_id);
121: 		block_manager.Read(*block);
122: 		handle->buffer = move(block);
123: 	} else {
124: 		if (handle->can_destroy) {
125: 			return BufferHandle();
126: 		} else {
127: 			handle->buffer = block_manager.buffer_manager.ReadTemporaryBuffer(handle->block_id, move(reusable_buffer));
128: 		}
129: 	}
130: 	handle->state = BlockState::BLOCK_LOADED;
131: 	return BufferHandle(handle, handle->buffer.get());
132: }
133: 
134: unique_ptr<FileBuffer> BlockHandle::UnloadAndTakeBlock() {
135: 	if (state == BlockState::BLOCK_UNLOADED) {
136: 		// already unloaded: nothing to do
137: 		return nullptr;
138: 	}
139: 	D_ASSERT(!unswizzled);
140: 	D_ASSERT(CanUnload());
141: 
142: 	if (block_id >= MAXIMUM_BLOCK && !can_destroy) {
143: 		// temporary block that cannot be destroyed: write to temporary file
144: 		block_manager.buffer_manager.WriteTemporaryBuffer(block_id, *buffer);
145: 	}
146: 	memory_charge.Resize(block_manager.buffer_manager.current_memory, 0);
147: 	state = BlockState::BLOCK_UNLOADED;
148: 	return move(buffer);
149: }
150: 
151: void BlockHandle::Unload() {
152: 	auto block = UnloadAndTakeBlock();
153: 	block.reset();
154: }
155: 
156: bool BlockHandle::CanUnload() {
157: 	if (state == BlockState::BLOCK_UNLOADED) {
158: 		// already unloaded
159: 		return false;
160: 	}
161: 	if (readers > 0) {
162: 		// there are active readers
163: 		return false;
164: 	}
165: 	if (block_id >= MAXIMUM_BLOCK && !can_destroy && block_manager.buffer_manager.temp_directory.empty()) {
166: 		// in order to unload this block we need to write it to a temporary buffer
167: 		// however, no temporary directory is specified!
168: 		// hence we cannot unload the block
169: 		return false;
170: 	}
171: 	return true;
172: }
173: 
174: struct BufferEvictionNode {
175: 	BufferEvictionNode() {
176: 	}
177: 	BufferEvictionNode(weak_ptr<BlockHandle> handle_p, idx_t timestamp_p)
178: 	    : handle(move(handle_p)), timestamp(timestamp_p) {
179: 		D_ASSERT(!handle.expired());
180: 	}
181: 
182: 	weak_ptr<BlockHandle> handle;
183: 	idx_t timestamp;
184: 
185: 	bool CanUnload(BlockHandle &handle_p) {
186: 		if (timestamp != handle_p.eviction_timestamp) {
187: 			// handle was used in between
188: 			return false;
189: 		}
190: 		return handle_p.CanUnload();
191: 	}
192: 
193: 	shared_ptr<BlockHandle> TryGetBlockHandle() {
194: 		auto handle_p = handle.lock();
195: 		if (!handle_p) {
196: 			// BlockHandle has been destroyed
197: 			return nullptr;
198: 		}
199: 		if (!CanUnload(*handle_p)) {
200: 			// handle was used in between
201: 			return nullptr;
202: 		}
203: 		// this is the latest node in the queue with this handle
204: 		return handle_p;
205: 	}
206: };
207: 
208: typedef duckdb_moodycamel::ConcurrentQueue<BufferEvictionNode> eviction_queue_t;
209: 
210: struct EvictionQueue {
211: 	eviction_queue_t q;
212: };
213: 
214: class TemporaryFileManager;
215: 
216: class TemporaryDirectoryHandle {
217: public:
218: 	TemporaryDirectoryHandle(DatabaseInstance &db, string path_p);
219: 	~TemporaryDirectoryHandle();
220: 
221: 	TemporaryFileManager &GetTempFile();
222: 
223: private:
224: 	DatabaseInstance &db;
225: 	string temp_directory;
226: 	unique_ptr<TemporaryFileManager> temp_file;
227: };
228: 
229: void BufferManager::SetTemporaryDirectory(string new_dir) {
230: 	if (temp_directory_handle) {
231: 		throw NotImplementedException("Cannot switch temporary directory after the current one has been used");
232: 	}
233: 	this->temp_directory = move(new_dir);
234: }
235: 
236: BufferManager::BufferManager(DatabaseInstance &db, string tmp, idx_t maximum_memory)
237:     : db(db), current_memory(0), maximum_memory(maximum_memory), temp_directory(move(tmp)),
238:       queue(make_unique<EvictionQueue>()), temporary_id(MAXIMUM_BLOCK),
239:       buffer_allocator(BufferAllocatorAllocate, BufferAllocatorFree, BufferAllocatorRealloc,
240:                        make_unique<BufferAllocatorData>(*this)) {
241: 	temp_block_manager = make_unique<InMemoryBlockManager>(*this);
242: }
243: 
244: BufferManager::~BufferManager() {
245: }
246: 
247: shared_ptr<BlockHandle> BlockManager::RegisterBlock(block_id_t block_id) {
248: 	lock_guard<mutex> lock(blocks_lock);
249: 	// check if the block already exists
250: 	auto entry = blocks.find(block_id);
251: 	if (entry != blocks.end()) {
252: 		// already exists: check if it hasn't expired yet
253: 		auto existing_ptr = entry->second.lock();
254: 		if (existing_ptr) {
255: 			//! it hasn't! return it
256: 			return existing_ptr;
257: 		}
258: 	}
259: 	// create a new block pointer for this block
260: 	auto result = make_shared<BlockHandle>(*this, block_id);
261: 	// register the block pointer in the set of blocks as a weak pointer
262: 	blocks[block_id] = weak_ptr<BlockHandle>(result);
263: 	return result;
264: }
265: 
266: shared_ptr<BlockHandle> BlockManager::ConvertToPersistent(block_id_t block_id, shared_ptr<BlockHandle> old_block) {
267: 
268: 	// pin the old block to ensure we have it loaded in memory
269: 	auto old_handle = buffer_manager.Pin(old_block);
270: 	D_ASSERT(old_block->state == BlockState::BLOCK_LOADED);
271: 	D_ASSERT(old_block->buffer);
272: 
273: 	// Temp buffers can be larger than the storage block size. But persistent buffers
274: 	// cannot.
275: 	D_ASSERT(old_block->buffer->AllocSize() <= Storage::BLOCK_ALLOC_SIZE);
276: 
277: 	// register a block with the new block id
278: 	auto new_block = RegisterBlock(block_id);
279: 	D_ASSERT(new_block->state == BlockState::BLOCK_UNLOADED);
280: 	D_ASSERT(new_block->readers == 0);
281: 
282: 	// move the data from the old block into data for the new block
283: 	new_block->state = BlockState::BLOCK_LOADED;
284: 	new_block->buffer = CreateBlock(block_id, old_block->buffer.get());
285: 	new_block->memory_usage = old_block->memory_usage;
286: 	new_block->memory_charge = move(old_block->memory_charge);
287: 
288: 	// clear the old buffer and unload it
289: 	old_block->buffer.reset();
290: 	old_block->state = BlockState::BLOCK_UNLOADED;
291: 	old_block->memory_usage = 0;
292: 	old_handle.Destroy();
293: 	old_block.reset();
294: 
295: 	// persist the new block to disk
296: 	Write(*new_block->buffer, block_id);
297: 
298: 	buffer_manager.AddToEvictionQueue(new_block);
299: 
300: 	return new_block;
301: }
302: 
303: template <typename... ARGS>
304: TempBufferPoolReservation BufferManager::EvictBlocksOrThrow(idx_t memory_delta, idx_t limit,
305:                                                             unique_ptr<FileBuffer> *buffer, ARGS... args) {
306: 	auto r = EvictBlocks(memory_delta, limit, buffer);
307: 	if (!r.success) {
308: 		throw OutOfMemoryException(args..., InMemoryWarning());
309: 	}
310: 	return move(r.reservation);
311: }
312: 
313: shared_ptr<BlockHandle> BufferManager::RegisterSmallMemory(idx_t block_size) {
314: 	auto res = EvictBlocksOrThrow(block_size, maximum_memory, nullptr,
315: 	                              "could not allocate block of %lld bytes (%lld/%lld used) %s", block_size,
316: 	                              GetUsedMemory(), GetMaxMemory());
317: 
318: 	auto buffer = ConstructManagedBuffer(block_size, nullptr, FileBufferType::TINY_BUFFER);
319: 
320: 	// create a new block pointer for this block
321: 	return make_shared<BlockHandle>(*temp_block_manager, ++temporary_id, move(buffer), false, block_size, move(res));
322: }
323: 
324: shared_ptr<BlockHandle> BufferManager::RegisterMemory(idx_t block_size, bool can_destroy) {
325: 	D_ASSERT(block_size >= Storage::BLOCK_SIZE);
326: 	auto alloc_size = AlignValue<idx_t, Storage::SECTOR_SIZE>(block_size + Storage::BLOCK_HEADER_SIZE);
327: 	// first evict blocks until we have enough memory to store this buffer
328: 	unique_ptr<FileBuffer> reusable_buffer;
329: 	auto res = EvictBlocksOrThrow(alloc_size, maximum_memory, &reusable_buffer,
330: 	                              "could not allocate block of %lld bytes (%lld/%lld used) %s", alloc_size,
331: 	                              GetUsedMemory(), GetMaxMemory());
332: 
333: 	auto buffer = ConstructManagedBuffer(block_size, move(reusable_buffer));
334: 
335: 	// create a new block pointer for this block
336: 	return make_shared<BlockHandle>(*temp_block_manager, ++temporary_id, move(buffer), can_destroy, block_size,
337: 	                                move(res));
338: }
339: 
340: BufferHandle BufferManager::Allocate(idx_t block_size) {
341: 	auto block = RegisterMemory(block_size, true);
342: 	return Pin(block);
343: }
344: 
345: void BufferManager::ReAllocate(shared_ptr<BlockHandle> &handle, idx_t block_size) {
346: 	D_ASSERT(block_size >= Storage::BLOCK_SIZE);
347: 	lock_guard<mutex> lock(handle->lock);
348: 	D_ASSERT(handle->state == BlockState::BLOCK_LOADED);
349: 	D_ASSERT(handle->memory_usage == handle->buffer->AllocSize());
350: 	D_ASSERT(handle->memory_usage == handle->memory_charge.size);
351: 
352: 	auto req = handle->buffer->CalculateMemory(block_size);
353: 	int64_t memory_delta = (int64_t)req.alloc_size - handle->memory_usage;
354: 
355: 	if (memory_delta == 0) {
356: 		return;
357: 	} else if (memory_delta > 0) {
358: 		// evict blocks until we have space to resize this block
359: 		auto reservation =
360: 		    EvictBlocksOrThrow(memory_delta, maximum_memory, nullptr, "failed to resize block from %lld to %lld%s",
361: 		                       handle->memory_usage, req.alloc_size);
362: 		// EvictBlocks decrements 'current_memory' for us.
363: 		handle->memory_charge.Merge(move(reservation));
364: 	} else {
365: 		// no need to evict blocks, but we do need to decrement 'current_memory'.
366: 		handle->memory_charge.Resize(current_memory, req.alloc_size);
367: 	}
368: 
369: 	// resize and adjust current memory
370: 	handle->buffer->Resize(block_size);
371: 	handle->memory_usage += memory_delta;
372: }
373: 
374: BufferHandle BufferManager::Pin(shared_ptr<BlockHandle> &handle) {
375: 	idx_t required_memory;
376: 	{
377: 		// lock the block
378: 		lock_guard<mutex> lock(handle->lock);
379: 		// check if the block is already loaded
380: 		if (handle->state == BlockState::BLOCK_LOADED) {
381: 			// the block is loaded, increment the reader count and return a pointer to the handle
382: 			handle->readers++;
383: 			return handle->Load(handle);
384: 		}
385: 		required_memory = handle->memory_usage;
386: 	}
387: 	// evict blocks until we have space for the current block
388: 	unique_ptr<FileBuffer> reusable_buffer;
389: 	auto reservation = EvictBlocksOrThrow(required_memory, maximum_memory, &reusable_buffer,
390: 	                                      "failed to pin block of size %lld%s", required_memory);
391: 	// lock the handle again and repeat the check (in case anybody loaded in the mean time)
392: 	lock_guard<mutex> lock(handle->lock);
393: 	// check if the block is already loaded
394: 	if (handle->state == BlockState::BLOCK_LOADED) {
395: 		// the block is loaded, increment the reader count and return a pointer to the handle
396: 		handle->readers++;
397: 		reservation.Resize(current_memory, 0);
398: 		return handle->Load(handle);
399: 	}
400: 	// now we can actually load the current block
401: 	D_ASSERT(handle->readers == 0);
402: 	handle->readers = 1;
403: 	auto buf = handle->Load(handle, move(reusable_buffer));
404: 	handle->memory_charge = move(reservation);
405: 	// In the case of a variable sized block, the buffer may be smaller than a full block.
406: 	int64_t delta = handle->buffer->AllocSize() - handle->memory_usage;
407: 	if (delta) {
408: 		D_ASSERT(delta < 0);
409: 		handle->memory_usage += delta;
410: 		handle->memory_charge.Resize(current_memory, handle->memory_usage);
411: 	}
412: 	return buf;
413: }
414: 
415: void BufferManager::AddToEvictionQueue(shared_ptr<BlockHandle> &handle) {
416: 	constexpr int INSERT_INTERVAL = 1024;
417: 
418: 	D_ASSERT(handle->readers == 0);
419: 	handle->eviction_timestamp++;
420: 	// After each 1024 insertions, run through the queue and purge.
421: 	if ((++queue_insertions % INSERT_INTERVAL) == 0) {
422: 		PurgeQueue();
423: 	}
424: 	queue->q.enqueue(BufferEvictionNode(weak_ptr<BlockHandle>(handle), handle->eviction_timestamp));
425: }
426: 
427: void BufferManager::Unpin(shared_ptr<BlockHandle> &handle) {
428: 	lock_guard<mutex> lock(handle->lock);
429: 	if (!handle->buffer || handle->buffer->type == FileBufferType::TINY_BUFFER) {
430: 		return;
431: 	}
432: 	D_ASSERT(handle->readers > 0);
433: 	handle->readers--;
434: 	if (handle->readers == 0) {
435: 		AddToEvictionQueue(handle);
436: 	}
437: }
438: 
439: BufferManager::EvictionResult BufferManager::EvictBlocks(idx_t extra_memory, idx_t memory_limit,
440:                                                          unique_ptr<FileBuffer> *buffer) {
441: 	BufferEvictionNode node;
442: 	TempBufferPoolReservation r(current_memory, extra_memory);
443: 	while (current_memory > memory_limit) {
444: 		// get a block to unpin from the queue
445: 		if (!queue->q.try_dequeue(node)) {
446: 			// Failed to reserve. Adjust size of temp reservation to 0.
447: 			r.Resize(current_memory, 0);
448: 			return {false, move(r)};
449: 		}
450: 		// get a reference to the underlying block pointer
451: 		auto handle = node.TryGetBlockHandle();
452: 		if (!handle) {
453: 			continue;
454: 		}
455: 		// we might be able to free this block: grab the mutex and check if we can free it
456: 		lock_guard<mutex> lock(handle->lock);
457: 		if (!node.CanUnload(*handle)) {
458: 			// something changed in the mean-time, bail out
459: 			continue;
460: 		}
461: 		// hooray, we can unload the block
462: 		if (buffer && handle->buffer->AllocSize() == extra_memory) {
463: 			// we can actually re-use the memory directly!
464: 			*buffer = handle->UnloadAndTakeBlock();
465: 			return {true, move(r)};
466: 		} else {
467: 			// release the memory and mark the block as unloaded
468: 			handle->Unload();
469: 		}
470: 	}
471: 	return {true, move(r)};
472: }
473: 
474: void BufferManager::PurgeQueue() {
475: 	BufferEvictionNode node;
476: 	while (true) {
477: 		if (!queue->q.try_dequeue(node)) {
478: 			break;
479: 		}
480: 		auto handle = node.TryGetBlockHandle();
481: 		if (!handle) {
482: 			continue;
483: 		} else {
484: 			queue->q.enqueue(move(node));
485: 			break;
486: 		}
487: 	}
488: }
489: 
490: void BlockManager::UnregisterBlock(block_id_t block_id, bool can_destroy) {
491: 	if (block_id >= MAXIMUM_BLOCK) {
492: 		// in-memory buffer: destroy the buffer
493: 		if (!can_destroy) {
494: 			// buffer could have been offloaded to disk: remove the file
495: 			buffer_manager.DeleteTemporaryFile(block_id);
496: 		}
497: 	} else {
498: 		lock_guard<mutex> lock(blocks_lock);
499: 		// on-disk block: erase from list of blocks in manager
500: 		blocks.erase(block_id);
501: 	}
502: }
503: 
504: void BufferManager::SetLimit(idx_t limit) {
505: 	lock_guard<mutex> l_lock(limit_lock);
506: 	// try to evict until the limit is reached
507: 	if (!EvictBlocks(0, limit).success) {
508: 		throw OutOfMemoryException(
509: 		    "Failed to change memory limit to %lld: could not free up enough memory for the new limit%s", limit,
510: 		    InMemoryWarning());
511: 	}
512: 	idx_t old_limit = maximum_memory;
513: 	// set the global maximum memory to the new limit if successful
514: 	maximum_memory = limit;
515: 	// evict again
516: 	if (!EvictBlocks(0, limit).success) {
517: 		// failed: go back to old limit
518: 		maximum_memory = old_limit;
519: 		throw OutOfMemoryException(
520: 		    "Failed to change memory limit to %lld: could not free up enough memory for the new limit%s", limit,
521: 		    InMemoryWarning());
522: 	}
523: }
524: 
525: //===--------------------------------------------------------------------===//
526: // Temporary File Management
527: //===--------------------------------------------------------------------===//
528: unique_ptr<FileBuffer> ReadTemporaryBufferInternal(BufferManager &buffer_manager, FileHandle &handle, idx_t position,
529:                                                    idx_t size, block_id_t id, unique_ptr<FileBuffer> reusable_buffer) {
530: 	auto buffer = buffer_manager.ConstructManagedBuffer(size, move(reusable_buffer));
531: 	buffer->Read(handle, position);
532: 	return buffer;
533: }
534: 
535: struct TemporaryFileIndex {
536: 	explicit TemporaryFileIndex(idx_t file_index = DConstants::INVALID_INDEX,
537: 	                            idx_t block_index = DConstants::INVALID_INDEX)
538: 	    : file_index(file_index), block_index(block_index) {
539: 	}
540: 
541: 	idx_t file_index;
542: 	idx_t block_index;
543: 
544: public:
545: 	bool IsValid() {
546: 		return block_index != DConstants::INVALID_INDEX;
547: 	}
548: };
549: 
550: struct BlockIndexManager {
551: 	BlockIndexManager() : max_index(0) {
552: 	}
553: 
554: public:
555: 	//! Obtains a new block index from the index manager
556: 	idx_t GetNewBlockIndex() {
557: 		auto index = GetNewBlockIndexInternal();
558: 		indexes_in_use.insert(index);
559: 		return index;
560: 	}
561: 
562: 	//! Removes an index from the block manager
563: 	//! Returns true if the max_index has been altered
564: 	bool RemoveIndex(idx_t index) {
565: 		// remove this block from the set of blocks
566: 		indexes_in_use.erase(index);
567: 		free_indexes.insert(index);
568: 		// check if we can truncate the file
569: 
570: 		// get the max_index in use right now
571: 		auto max_index_in_use = indexes_in_use.empty() ? 0 : *indexes_in_use.rbegin();
572: 		if (max_index_in_use < max_index) {
573: 			// max index in use is lower than the max_index
574: 			// reduce the max_index
575: 			max_index = max_index_in_use + 1;
576: 			// we can remove any free_indexes that are larger than the current max_index
577: 			while (!free_indexes.empty()) {
578: 				auto max_entry = *free_indexes.rbegin();
579: 				if (max_entry < max_index) {
580: 					break;
581: 				}
582: 				free_indexes.erase(max_entry);
583: 			}
584: 			return true;
585: 		}
586: 		return false;
587: 	}
588: 
589: 	idx_t GetMaxIndex() {
590: 		return max_index;
591: 	}
592: 
593: 	bool HasFreeBlocks() {
594: 		return !free_indexes.empty();
595: 	}
596: 
597: private:
598: 	idx_t GetNewBlockIndexInternal() {
599: 		if (free_indexes.empty()) {
600: 			return max_index++;
601: 		}
602: 		auto entry = free_indexes.begin();
603: 		auto index = *entry;
604: 		free_indexes.erase(entry);
605: 		return index;
606: 	}
607: 
608: 	idx_t max_index;
609: 	set<idx_t> free_indexes;
610: 	set<idx_t> indexes_in_use;
611: };
612: 
613: class TemporaryFileHandle {
614: 	constexpr static idx_t MAX_ALLOWED_INDEX = 4000;
615: 
616: public:
617: 	TemporaryFileHandle(DatabaseInstance &db, const string &temp_directory, idx_t index)
618: 	    : db(db), file_index(index), path(FileSystem::GetFileSystem(db).JoinPath(
619: 	                                     temp_directory, "duckdb_temp_storage-" + to_string(index) + ".tmp")) {
620: 	}
621: 
622: public:
623: 	struct TemporaryFileLock {
624: 		explicit TemporaryFileLock(mutex &mutex) : lock(mutex) {
625: 		}
626: 
627: 		lock_guard<mutex> lock;
628: 	};
629: 
630: public:
631: 	TemporaryFileIndex TryGetBlockIndex() {
632: 		TemporaryFileLock lock(file_lock);
633: 		if (index_manager.GetMaxIndex() >= MAX_ALLOWED_INDEX && index_manager.HasFreeBlocks()) {
634: 			// file is at capacity
635: 			return TemporaryFileIndex();
636: 		}
637: 		// open the file handle if it does not yet exist
638: 		CreateFileIfNotExists(lock);
639: 		// fetch a new block index to write to
640: 		auto block_index = index_manager.GetNewBlockIndex();
641: 		return TemporaryFileIndex(file_index, block_index);
642: 	}
643: 
644: 	void WriteTemporaryFile(FileBuffer &buffer, TemporaryFileIndex index) {
645: 		D_ASSERT(buffer.size == Storage::BLOCK_SIZE);
646: 		buffer.Write(*handle, GetPositionInFile(index.block_index));
647: 	}
648: 
649: 	unique_ptr<FileBuffer> ReadTemporaryBuffer(block_id_t id, idx_t block_index,
650: 	                                           unique_ptr<FileBuffer> reusable_buffer) {
651: 		auto buffer =
652: 		    ReadTemporaryBufferInternal(BufferManager::GetBufferManager(db), *handle, GetPositionInFile(block_index),
653: 		                                Storage::BLOCK_SIZE, id, move(reusable_buffer));
654: 		{
655: 			// remove the block (and potentially truncate the temp file)
656: 			TemporaryFileLock lock(file_lock);
657: 			D_ASSERT(handle);
658: 			RemoveTempBlockIndex(lock, block_index);
659: 		}
660: 		return buffer;
661: 	}
662: 
663: 	bool DeleteIfEmpty() {
664: 		TemporaryFileLock lock(file_lock);
665: 		if (index_manager.GetMaxIndex() > 0) {
666: 			// there are still blocks in this file
667: 			return false;
668: 		}
669: 		// the file is empty: delete it
670: 		handle.reset();
671: 		auto &fs = FileSystem::GetFileSystem(db);
672: 		fs.RemoveFile(path);
673: 		return true;
674: 	}
675: 
676: private:
677: 	void CreateFileIfNotExists(TemporaryFileLock &) {
678: 		if (handle) {
679: 			return;
680: 		}
681: 		auto &fs = FileSystem::GetFileSystem(db);
682: 		handle = fs.OpenFile(path, FileFlags::FILE_FLAGS_READ | FileFlags::FILE_FLAGS_WRITE |
683: 		                               FileFlags::FILE_FLAGS_FILE_CREATE);
684: 	}
685: 
686: 	void RemoveTempBlockIndex(TemporaryFileLock &, idx_t index) {
687: 		// remove the block index from the index manager
688: 		if (index_manager.RemoveIndex(index)) {
689: 			// the max_index that is currently in use has decreased
690: 			// as a result we can truncate the file
691: 			auto max_index = index_manager.GetMaxIndex();
692: 			auto &fs = FileSystem::GetFileSystem(db);
693: 			fs.Truncate(*handle, GetPositionInFile(max_index + 1));
694: 		}
695: 	}
696: 
697: 	idx_t GetPositionInFile(idx_t index) {
698: 		return index * Storage::BLOCK_ALLOC_SIZE;
699: 	}
700: 
701: private:
702: 	DatabaseInstance &db;
703: 	unique_ptr<FileHandle> handle;
704: 	idx_t file_index;
705: 	string path;
706: 	mutex file_lock;
707: 	BlockIndexManager index_manager;
708: };
709: 
710: class TemporaryFileManager {
711: public:
712: 	TemporaryFileManager(DatabaseInstance &db, const string &temp_directory_p)
713: 	    : db(db), temp_directory(temp_directory_p) {
714: 	}
715: 
716: public:
717: 	struct TemporaryManagerLock {
718: 		explicit TemporaryManagerLock(mutex &mutex) : lock(mutex) {
719: 		}
720: 
721: 		lock_guard<mutex> lock;
722: 	};
723: 
724: 	void WriteTemporaryBuffer(block_id_t block_id, FileBuffer &buffer) {
725: 		D_ASSERT(buffer.size == Storage::BLOCK_SIZE);
726: 		TemporaryFileIndex index;
727: 		TemporaryFileHandle *handle = nullptr;
728: 
729: 		{
730: 			TemporaryManagerLock lock(manager_lock);
731: 			// first check if we can write to an open existing file
732: 			for (auto &entry : files) {
733: 				auto &temp_file = entry.second;
734: 				index = temp_file->TryGetBlockIndex();
735: 				if (index.IsValid()) {
736: 					handle = entry.second.get();
737: 					break;
738: 				}
739: 			}
740: 			if (!handle) {
741: 				// no existing handle to write to; we need to create & open a new file
742: 				auto new_file_index = index_manager.GetNewBlockIndex();
743: 				auto new_file = make_unique<TemporaryFileHandle>(db, temp_directory, new_file_index);
744: 				handle = new_file.get();
745: 				files[new_file_index] = move(new_file);
746: 
747: 				index = handle->TryGetBlockIndex();
748: 			}
749: 			D_ASSERT(used_blocks.find(block_id) == used_blocks.end());
750: 			used_blocks[block_id] = index;
751: 		}
752: 		D_ASSERT(handle);
753: 		D_ASSERT(index.IsValid());
754: 		handle->WriteTemporaryFile(buffer, index);
755: 	}
756: 
757: 	bool HasTemporaryBuffer(block_id_t block_id) {
758: 		lock_guard<mutex> lock(manager_lock);
759: 		return used_blocks.find(block_id) != used_blocks.end();
760: 	}
761: 
762: 	unique_ptr<FileBuffer> ReadTemporaryBuffer(block_id_t id, unique_ptr<FileBuffer> reusable_buffer) {
763: 		TemporaryFileIndex index;
764: 		TemporaryFileHandle *handle;
765: 		{
766: 			TemporaryManagerLock lock(manager_lock);
767: 			index = GetTempBlockIndex(lock, id);
768: 			handle = GetFileHandle(lock, index.file_index);
769: 		}
770: 		auto buffer = handle->ReadTemporaryBuffer(id, index.block_index, move(reusable_buffer));
771: 		{
772: 			// remove the block (and potentially erase the temp file)
773: 			TemporaryManagerLock lock(manager_lock);
774: 			EraseUsedBlock(lock, id, handle, index.file_index);
775: 		}
776: 		return buffer;
777: 	}
778: 
779: 	void DeleteTemporaryBuffer(block_id_t id) {
780: 		TemporaryManagerLock lock(manager_lock);
781: 		auto index = GetTempBlockIndex(lock, id);
782: 		auto handle = GetFileHandle(lock, index.file_index);
783: 		EraseUsedBlock(lock, id, handle, index.file_index);
784: 	}
785: 
786: private:
787: 	void EraseUsedBlock(TemporaryManagerLock &lock, block_id_t id, TemporaryFileHandle *handle, idx_t file_index) {
788: 		used_blocks.erase(id);
789: 		if (handle->DeleteIfEmpty()) {
790: 			EraseFileHandle(lock, file_index);
791: 		}
792: 	}
793: 
794: 	TemporaryFileHandle *GetFileHandle(TemporaryManagerLock &, idx_t index) {
795: 		return files[index].get();
796: 	}
797: 
798: 	TemporaryFileIndex GetTempBlockIndex(TemporaryManagerLock &, block_id_t id) {
799: 		D_ASSERT(used_blocks.find(id) != used_blocks.end());
800: 		return used_blocks[id];
801: 	}
802: 
803: 	void EraseFileHandle(TemporaryManagerLock &, idx_t file_index) {
804: 		files.erase(file_index);
805: 		index_manager.RemoveIndex(file_index);
806: 	}
807: 
808: private:
809: 	DatabaseInstance &db;
810: 	mutex manager_lock;
811: 	//! The temporary directory
812: 	string temp_directory;
813: 	//! The set of active temporary file handles
814: 	unordered_map<idx_t, unique_ptr<TemporaryFileHandle>> files;
815: 	//! map of block_id -> temporary file position
816: 	unordered_map<block_id_t, TemporaryFileIndex> used_blocks;
817: 	//! Manager of in-use temporary file indexes
818: 	BlockIndexManager index_manager;
819: };
820: 
821: TemporaryDirectoryHandle::TemporaryDirectoryHandle(DatabaseInstance &db, string path_p)
822:     : db(db), temp_directory(move(path_p)), temp_file(make_unique<TemporaryFileManager>(db, temp_directory)) {
823: 	auto &fs = FileSystem::GetFileSystem(db);
824: 	if (!temp_directory.empty()) {
825: 		fs.CreateDirectory(temp_directory);
826: 	}
827: }
828: TemporaryDirectoryHandle::~TemporaryDirectoryHandle() {
829: 	// first release any temporary files
830: 	temp_file.reset();
831: 	// then delete the temporary file directory
832: 	auto &fs = FileSystem::GetFileSystem(db);
833: 	if (!temp_directory.empty()) {
834: 		fs.RemoveDirectory(temp_directory);
835: 	}
836: }
837: 
838: TemporaryFileManager &TemporaryDirectoryHandle::GetTempFile() {
839: 	return *temp_file;
840: }
841: 
842: string BufferManager::GetTemporaryPath(block_id_t id) {
843: 	auto &fs = FileSystem::GetFileSystem(db);
844: 	return fs.JoinPath(temp_directory, to_string(id) + ".block");
845: }
846: 
847: void BufferManager::RequireTemporaryDirectory() {
848: 	if (temp_directory.empty()) {
849: 		throw Exception(
850: 		    "Out-of-memory: cannot write buffer because no temporary directory is specified!\nTo enable "
851: 		    "temporary buffer eviction set a temporary directory using PRAGMA temp_directory='/path/to/tmp.tmp'");
852: 	}
853: 	lock_guard<mutex> temp_handle_guard(temp_handle_lock);
854: 	if (!temp_directory_handle) {
855: 		// temp directory has not been created yet: initialize it
856: 		temp_directory_handle = make_unique<TemporaryDirectoryHandle>(db, temp_directory);
857: 	}
858: }
859: 
860: void BufferManager::WriteTemporaryBuffer(block_id_t block_id, FileBuffer &buffer) {
861: 	RequireTemporaryDirectory();
862: 	if (buffer.size == Storage::BLOCK_SIZE) {
863: 		temp_directory_handle->GetTempFile().WriteTemporaryBuffer(block_id, buffer);
864: 		return;
865: 	}
866: 	// get the path to write to
867: 	auto path = GetTemporaryPath(block_id);
868: 	D_ASSERT(buffer.size > Storage::BLOCK_SIZE);
869: 	// create the file and write the size followed by the buffer contents
870: 	auto &fs = FileSystem::GetFileSystem(db);
871: 	auto handle = fs.OpenFile(path, FileFlags::FILE_FLAGS_WRITE | FileFlags::FILE_FLAGS_FILE_CREATE);
872: 	handle->Write(&buffer.size, sizeof(idx_t), 0);
873: 	buffer.Write(*handle, sizeof(idx_t));
874: }
875: 
876: unique_ptr<FileBuffer> BufferManager::ReadTemporaryBuffer(block_id_t id, unique_ptr<FileBuffer> reusable_buffer) {
877: 	D_ASSERT(!temp_directory.empty());
878: 	D_ASSERT(temp_directory_handle.get());
879: 	if (temp_directory_handle->GetTempFile().HasTemporaryBuffer(id)) {
880: 		return temp_directory_handle->GetTempFile().ReadTemporaryBuffer(id, move(reusable_buffer));
881: 	}
882: 	idx_t block_size;
883: 	// open the temporary file and read the size
884: 	auto path = GetTemporaryPath(id);
885: 	auto &fs = FileSystem::GetFileSystem(db);
886: 	auto handle = fs.OpenFile(path, FileFlags::FILE_FLAGS_READ);
887: 	handle->Read(&block_size, sizeof(idx_t), 0);
888: 
889: 	// now allocate a buffer of this size and read the data into that buffer
890: 	auto buffer = ReadTemporaryBufferInternal(*this, *handle, sizeof(idx_t), block_size, id, move(reusable_buffer));
891: 
892: 	handle.reset();
893: 	DeleteTemporaryFile(id);
894: 	return buffer;
895: }
896: 
897: void BufferManager::DeleteTemporaryFile(block_id_t id) {
898: 	if (temp_directory.empty()) {
899: 		// no temporary directory specified: nothing to delete
900: 		return;
901: 	}
902: 	{
903: 		lock_guard<mutex> temp_handle_guard(temp_handle_lock);
904: 		if (!temp_directory_handle) {
905: 			// temporary directory was not initialized yet: nothing to delete
906: 			return;
907: 		}
908: 	}
909: 	// check if we should delete the file from the shared pool of files, or from the general file system
910: 	if (temp_directory_handle->GetTempFile().HasTemporaryBuffer(id)) {
911: 		temp_directory_handle->GetTempFile().DeleteTemporaryBuffer(id);
912: 		return;
913: 	}
914: 	auto &fs = FileSystem::GetFileSystem(db);
915: 	auto path = GetTemporaryPath(id);
916: 	if (fs.FileExists(path)) {
917: 		fs.RemoveFile(path);
918: 	}
919: }
920: 
921: string BufferManager::InMemoryWarning() {
922: 	if (!temp_directory.empty()) {
923: 		return "";
924: 	}
925: 	return "\nDatabase is launched in in-memory mode and no temporary directory is specified."
926: 	       "\nUnused blocks cannot be offloaded to disk."
927: 	       "\n\nLaunch the database with a persistent storage back-end"
928: 	       "\nOr set PRAGMA temp_directory='/path/to/tmp.tmp'";
929: }
930: 
931: //===--------------------------------------------------------------------===//
932: // Buffer Allocator
933: //===--------------------------------------------------------------------===//
934: data_ptr_t BufferManager::BufferAllocatorAllocate(PrivateAllocatorData *private_data, idx_t size) {
935: 	auto &data = (BufferAllocatorData &)*private_data;
936: 	auto reservation = data.manager.EvictBlocksOrThrow(size, data.manager.maximum_memory, nullptr,
937: 	                                                   "failed to allocate data of size %lld%s", size);
938: 	// We rely on manual tracking of this one. :(
939: 	reservation.size = 0;
940: 	return Allocator::Get(data.manager.db).AllocateData(size);
941: }
942: 
943: void BufferManager::BufferAllocatorFree(PrivateAllocatorData *private_data, data_ptr_t pointer, idx_t size) {
944: 	auto &data = (BufferAllocatorData &)*private_data;
945: 	BufferPoolReservation r;
946: 	r.size = size;
947: 	r.Resize(data.manager.current_memory, 0);
948: 	return Allocator::Get(data.manager.db).FreeData(pointer, size);
949: }
950: 
951: data_ptr_t BufferManager::BufferAllocatorRealloc(PrivateAllocatorData *private_data, data_ptr_t pointer, idx_t old_size,
952:                                                  idx_t size) {
953: 	auto &data = (BufferAllocatorData &)*private_data;
954: 	BufferPoolReservation r;
955: 	r.size = old_size;
956: 	r.Resize(data.manager.current_memory, size);
957: 	r.size = 0;
958: 	return Allocator::Get(data.manager.db).ReallocateData(pointer, old_size, size);
959: }
960: 
961: Allocator &BufferAllocator::Get(ClientContext &context) {
962: 	auto &manager = BufferManager::GetBufferManager(context);
963: 	return manager.GetBufferAllocator();
964: }
965: 
966: Allocator &BufferManager::GetBufferAllocator() {
967: 	return buffer_allocator;
968: }
969: 
970: } // namespace duckdb
[end of src/storage/buffer_manager.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: