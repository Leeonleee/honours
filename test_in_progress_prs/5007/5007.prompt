You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes.
In the patch file, please make sure to include the line numbers and a blank line at the end so it can be applied using git apply.

<issue>
Lambda functions do not work with lists of structs in `list_transform`
### What happens?

Attempting to use a lambda function over a list of structs in `list_transform` fails with the following error:

```
Error: Binder Error: Referenced table "0_macro_parametersx" not found!
```

Using regular macros works as expected, it's only the lambda functions (and only when the type of the list is a struct, not when it is a primitive type) that seem to be impacted by this.

### To Reproduce

SELECT list_transform([{'a': 1}], x -> x.a);

### OS:

OS X

### DuckDB Version:

v0.5.1 7c111322d

### DuckDB Client:

CLI

### Full Name:

Josh Wills

### Affiliation:

WeaveGrid

### Have you tried this on the latest `master` branch?

- [X] I agree

### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?

- [X] I agree

</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <img src="https://duckdb.org/images/DuckDB_Logo_dl.png" height="50">
3: </div>
4: <p>&nbsp;</p>
5: 
6: <p align="center">
7:   <a href="https://github.com/duckdb/duckdb/actions">
8:     <img src="https://github.com/duckdb/duckdb/actions/workflows/Main.yml/badge.svg?branch=master" alt="Github Actions Badge">
9:   </a>
10:   <a href="https://www.codefactor.io/repository/github/cwida/duckdb">
11:     <img src="https://www.codefactor.io/repository/github/cwida/duckdb/badge" alt="CodeFactor"/>
12:   </a>
13:   <a href="https://app.codecov.io/gh/duckdb/duckdb">
14:     <img src="https://codecov.io/gh/duckdb/duckdb/branch/master/graph/badge.svg?token=FaxjcfFghN" alt="codecov"/>
15:   </a>
16:   <a href="https://discord.gg/tcvwpjfnZx">
17:     <img src="https://shields.io/discord/909674491309850675" alt="discord" />
18:   </a>
19: </p>
20: 
21: ## DuckDB
22: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs), and more. For more information on the goals of DuckDB, please refer to [the Why DuckDB page on our website](https://duckdb.org/why_duckdb).
23: 
24: ## Installation
25: If you want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
26: 
27: ## Data Import
28: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
29: 
30: ```sql
31: SELECT * FROM 'myfile.csv';
32: SELECT * FROM 'myfile.parquet';
33: ```
34: 
35: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
36: 
37: ## SQL Reference
38: The [website](https://duckdb.org/docs/sql/introduction) contains a reference of functions and SQL constructs available in DuckDB.
39: 
40: ## Development
41: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run `BUILD_BENCHMARK=1 BUILD_TPCH=1 make` and then perform several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`. The detail of benchmarks is in our [Benchmark Guide](benchmark/README.md).
42: 
43: Please also refer to our [Contribution Guide](CONTRIBUTING.md).
[end of README.md]
[start of src/planner/binder/expression/bind_columnref_expression.cpp]
1: #include "duckdb/catalog/catalog_entry/schema_catalog_entry.hpp"
2: #include "duckdb/common/string_util.hpp"
3: #include "duckdb/function/scalar/nested_functions.hpp"
4: #include "duckdb/parser/expression/columnref_expression.hpp"
5: #include "duckdb/parser/expression/constant_expression.hpp"
6: #include "duckdb/parser/expression/function_expression.hpp"
7: #include "duckdb/parser/expression/operator_expression.hpp"
8: #include "duckdb/parser/expression/positional_reference_expression.hpp"
9: #include "duckdb/parser/expression/subquery_expression.hpp"
10: #include "duckdb/parser/parsed_expression_iterator.hpp"
11: #include "duckdb/planner/binder.hpp"
12: #include "duckdb/planner/expression/bound_columnref_expression.hpp"
13: #include "duckdb/planner/expression/bound_constant_expression.hpp"
14: #include "duckdb/planner/expression_binder.hpp"
15: #include "duckdb/planner/expression_binder/where_binder.hpp"
16: 
17: namespace duckdb {
18: 
19: unique_ptr<ParsedExpression> ExpressionBinder::QualifyColumnName(const string &column_name, string &error_message) {
20: 	auto using_binding = binder.bind_context.GetUsingBinding(column_name);
21: 	if (using_binding) {
22: 		// we are referencing a USING column
23: 		// check if we can refer to one of the base columns directly
24: 		unique_ptr<Expression> expression;
25: 		if (!using_binding->primary_binding.empty()) {
26: 			// we can! just assign the table name and re-bind
27: 			return make_unique<ColumnRefExpression>(column_name, using_binding->primary_binding);
28: 		} else {
29: 			// // we cannot! we need to bind this as a coalesce between all the relevant columns
30: 			auto coalesce = make_unique<OperatorExpression>(ExpressionType::OPERATOR_COALESCE);
31: 			for (auto &entry : using_binding->bindings) {
32: 				coalesce->children.push_back(make_unique<ColumnRefExpression>(column_name, entry));
33: 			}
34: 			return move(coalesce);
35: 		}
36: 	}
37: 
38: 	// find a binding that contains this
39: 	string table_name = binder.bind_context.GetMatchingBinding(column_name);
40: 
41: 	// throw an error if a macro conflicts with a column name
42: 	auto is_macro_column = false;
43: 	if (binder.macro_binding != nullptr && binder.macro_binding->HasMatchingBinding(column_name)) {
44: 		is_macro_column = true;
45: 		if (!table_name.empty()) {
46: 			throw BinderException("Conflicting column names for column " + column_name + "!");
47: 		}
48: 	}
49: 
50: 	if (lambda_bindings) {
51: 		for (idx_t i = 0; i < lambda_bindings->size(); i++) {
52: 			if ((*lambda_bindings)[i].HasMatchingBinding(column_name)) {
53: 
54: 				// throw an error if a lambda conflicts with a column name or a macro
55: 				if (!table_name.empty() || is_macro_column) {
56: 					throw BinderException("Conflicting column names for column " + column_name + "!");
57: 				}
58: 
59: 				D_ASSERT(!(*lambda_bindings)[i].alias.empty());
60: 				return make_unique<ColumnRefExpression>(column_name, (*lambda_bindings)[i].alias);
61: 			}
62: 		}
63: 	}
64: 
65: 	if (is_macro_column) {
66: 		D_ASSERT(!binder.macro_binding->alias.empty());
67: 		return make_unique<ColumnRefExpression>(column_name, binder.macro_binding->alias);
68: 	}
69: 	// see if it's a column
70: 	if (table_name.empty()) {
71: 		// it's not, find candidates and error
72: 		auto similar_bindings = binder.bind_context.GetSimilarBindings(column_name);
73: 		string candidate_str = StringUtil::CandidatesMessage(similar_bindings, "Candidate bindings");
74: 		error_message =
75: 		    StringUtil::Format("Referenced column \"%s\" not found in FROM clause!%s", column_name, candidate_str);
76: 		return nullptr;
77: 	}
78: 	return binder.bind_context.CreateColumnReference(table_name, column_name);
79: }
80: 
81: void ExpressionBinder::QualifyColumnNames(unique_ptr<ParsedExpression> &expr) {
82: 	switch (expr->type) {
83: 	case ExpressionType::COLUMN_REF: {
84: 		auto &colref = (ColumnRefExpression &)*expr;
85: 		string error_message;
86: 		auto new_expr = QualifyColumnName(colref, error_message);
87: 		if (new_expr) {
88: 			if (!expr->alias.empty()) {
89: 				new_expr->alias = expr->alias;
90: 			}
91: 			expr = move(new_expr);
92: 		}
93: 		break;
94: 	}
95: 	case ExpressionType::POSITIONAL_REFERENCE: {
96: 		auto &ref = (PositionalReferenceExpression &)*expr;
97: 		if (ref.alias.empty()) {
98: 			string table_name, column_name;
99: 			auto error = binder.bind_context.BindColumn(ref, table_name, column_name);
100: 			if (error.empty()) {
101: 				ref.alias = column_name;
102: 			}
103: 		}
104: 		break;
105: 	}
106: 	default:
107: 		break;
108: 	}
109: 	ParsedExpressionIterator::EnumerateChildren(
110: 	    *expr, [&](unique_ptr<ParsedExpression> &child) { QualifyColumnNames(child); });
111: }
112: 
113: void ExpressionBinder::QualifyColumnNames(Binder &binder, unique_ptr<ParsedExpression> &expr) {
114: 	WhereBinder where_binder(binder, binder.context);
115: 	where_binder.QualifyColumnNames(expr);
116: }
117: 
118: unique_ptr<ParsedExpression> ExpressionBinder::CreateStructExtract(unique_ptr<ParsedExpression> base,
119:                                                                    string field_name) {
120: 	vector<unique_ptr<ParsedExpression>> children;
121: 	children.push_back(move(base));
122: 	children.push_back(make_unique_base<ParsedExpression, ConstantExpression>(Value(move(field_name))));
123: 	auto extract_fun = make_unique<OperatorExpression>(ExpressionType::STRUCT_EXTRACT, move(children));
124: 	return move(extract_fun);
125: }
126: 
127: unique_ptr<ParsedExpression> ExpressionBinder::CreateStructPack(ColumnRefExpression &colref) {
128: 	D_ASSERT(colref.column_names.size() <= 2);
129: 	string error_message;
130: 	auto &table_name = colref.column_names.back();
131: 	auto binding = binder.bind_context.GetBinding(table_name, error_message);
132: 	if (!binding) {
133: 		return nullptr;
134: 	}
135: 	if (colref.column_names.size() == 2) {
136: 		// "schema_name.table_name"
137: 		auto catalog_entry = binding->GetStandardEntry();
138: 		if (!catalog_entry) {
139: 			return nullptr;
140: 		}
141: 		auto &schema_name = colref.column_names[0];
142: 		if (catalog_entry->schema->name != schema_name || catalog_entry->name != table_name) {
143: 			return nullptr;
144: 		}
145: 	}
146: 	// We found the table, now create the struct_pack expression
147: 	vector<unique_ptr<ParsedExpression>> child_exprs;
148: 	for (const auto &column_name : binding->names) {
149: 		child_exprs.push_back(make_unique<ColumnRefExpression>(column_name, table_name));
150: 	}
151: 	return make_unique<FunctionExpression>("struct_pack", move(child_exprs));
152: }
153: 
154: unique_ptr<ParsedExpression> ExpressionBinder::QualifyColumnName(ColumnRefExpression &colref, string &error_message) {
155: 	idx_t column_parts = colref.column_names.size();
156: 	// column names can have an arbitrary amount of dots
157: 	// here is how the resolution works:
158: 	if (column_parts == 1) {
159: 		// no dots (i.e. "part1")
160: 		// -> part1 refers to a column
161: 		// check if we can qualify the column name with the table name
162: 		auto qualified_colref = QualifyColumnName(colref.GetColumnName(), error_message);
163: 		if (qualified_colref) {
164: 			// we could: return it
165: 			return qualified_colref;
166: 		}
167: 		// we could not! Try creating an implicit struct_pack
168: 		return CreateStructPack(colref);
169: 	} else if (column_parts == 2) {
170: 		// one dot (i.e. "part1.part2")
171: 		// EITHER:
172: 		// -> part1 is a table, part2 is a column
173: 		// -> part1 is a column, part2 is a property of that column (i.e. struct_extract)
174: 
175: 		// first check if part1 is a table, and part2 is a standard column
176: 		if (binder.HasMatchingBinding(colref.column_names[0], colref.column_names[1], error_message)) {
177: 			// it is! return the colref directly
178: 			return binder.bind_context.CreateColumnReference(colref.column_names[0], colref.column_names[1]);
179: 		} else {
180: 			// otherwise check if we can turn this into a struct extract
181: 			auto new_colref = make_unique<ColumnRefExpression>(colref.column_names[0]);
182: 			string other_error;
183: 			auto qualified_colref = QualifyColumnName(colref.column_names[0], other_error);
184: 			if (qualified_colref) {
185: 				// we could: create a struct extract
186: 				return CreateStructExtract(move(qualified_colref), colref.column_names[1]);
187: 			}
188: 			// we could not! Try creating an implicit struct_pack
189: 			return CreateStructPack(colref);
190: 		}
191: 	} else {
192: 		// two or more dots (i.e. "part1.part2.part3.part4...")
193: 		// -> part1 is a schema, part2 is a table, part3 is a column name, part4 and beyond are struct fields
194: 		// -> part1 is a table, part2 is a column name, part3 and beyond are struct fields
195: 		// -> part1 is a column, part2 and beyond are struct fields
196: 
197: 		// we always prefer the most top-level view
198: 		// i.e. in case of multiple resolution options, we resolve in order:
199: 		// -> 1. resolve "part1" as a schema
200: 		// -> 2. resolve "part1" as a table
201: 		// -> 3. resolve "part1" as a column
202: 
203: 		unique_ptr<ParsedExpression> result_expr;
204: 		idx_t struct_extract_start;
205: 		// first check if part1 is a schema
206: 		if (binder.HasMatchingBinding(colref.column_names[0], colref.column_names[1], colref.column_names[2],
207: 		                              error_message)) {
208: 			// it is! the column reference is "schema.table.column"
209: 			// any additional fields are turned into struct_extract calls
210: 			result_expr = binder.bind_context.CreateColumnReference(colref.column_names[0], colref.column_names[1],
211: 			                                                        colref.column_names[2]);
212: 			struct_extract_start = 3;
213: 		} else if (binder.HasMatchingBinding(colref.column_names[0], colref.column_names[1], error_message)) {
214: 			// part1 is a table
215: 			// the column reference is "table.column"
216: 			// any additional fields are turned into struct_extract calls
217: 			result_expr = binder.bind_context.CreateColumnReference(colref.column_names[0], colref.column_names[1]);
218: 			struct_extract_start = 2;
219: 		} else {
220: 			// part1 could be a column
221: 			string col_error;
222: 			result_expr = QualifyColumnName(colref.column_names[0], col_error);
223: 			if (!result_expr) {
224: 				// it is not! return the error
225: 				return nullptr;
226: 			}
227: 			// it is! add the struct extract calls
228: 			struct_extract_start = 1;
229: 		}
230: 		for (idx_t i = struct_extract_start; i < colref.column_names.size(); i++) {
231: 			result_expr = CreateStructExtract(move(result_expr), colref.column_names[i]);
232: 		}
233: 		return result_expr;
234: 	}
235: }
236: 
237: BindResult ExpressionBinder::BindExpression(ColumnRefExpression &colref_p, idx_t depth) {
238: 	if (binder.GetBindingMode() == BindingMode::EXTRACT_NAMES) {
239: 		return BindResult(make_unique<BoundConstantExpression>(Value(LogicalType::SQLNULL)));
240: 	}
241: 	string error_message;
242: 	auto expr = QualifyColumnName(colref_p, error_message);
243: 	if (!expr) {
244: 		return BindResult(binder.FormatError(colref_p, error_message));
245: 	}
246: 	//! Generated column returns generated expression
247: 	if (expr->type != ExpressionType::COLUMN_REF) {
248: 		auto alias = expr->alias;
249: 		auto result = BindExpression(&expr, depth);
250: 		if (result.expression) {
251: 			result.expression->alias = move(alias);
252: 		}
253: 		return result;
254: 	}
255: 	auto &colref = (ColumnRefExpression &)*expr;
256: 	D_ASSERT(colref.IsQualified());
257: 	auto &table_name = colref.GetTableName();
258: 
259: 	// individual column reference
260: 	// resolve to either a base table or a subquery expression
261: 	// if it was a macro parameter, let macro_binding bind it to the argument
262: 	// if it was a lambda parameter, let lambda_bindings bind it to the argument
263: 
264: 	BindResult result;
265: 
266: 	auto found_lambda_binding = false;
267: 	if (lambda_bindings) {
268: 		for (idx_t i = 0; i < lambda_bindings->size(); i++) {
269: 			if (table_name == (*lambda_bindings)[i].alias) {
270: 				result = (*lambda_bindings)[i].Bind(colref, depth);
271: 				found_lambda_binding = true;
272: 				break;
273: 			}
274: 		}
275: 	}
276: 
277: 	if (!found_lambda_binding) {
278: 		if (binder.macro_binding && table_name == binder.macro_binding->alias) {
279: 			result = binder.macro_binding->Bind(colref, depth);
280: 		} else {
281: 			result = binder.bind_context.BindColumn(colref, depth);
282: 		}
283: 	}
284: 
285: 	if (!result.HasError()) {
286: 		BoundColumnReferenceInfo ref;
287: 		ref.name = colref.column_names.back();
288: 		ref.query_location = colref.query_location;
289: 		bound_columns.push_back(move(ref));
290: 	} else {
291: 		result.error = binder.FormatError(colref_p, result.error);
292: 	}
293: 	return result;
294: }
295: 
296: } // namespace duckdb
[end of src/planner/binder/expression/bind_columnref_expression.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: