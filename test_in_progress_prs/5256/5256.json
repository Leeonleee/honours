{
  "repo": "duckdb/duckdb",
  "pull_number": 5256,
  "instance_id": "duckdb__duckdb-5256",
  "issue_numbers": [
    "5253"
  ],
  "base_commit": "866efc2db6632bbccd281a8f47be5e4dfde530a7",
  "patch": "diff --git a/tools/pythonpkg/src/vector_conversion.cpp b/tools/pythonpkg/src/vector_conversion.cpp\nindex 9a75f6d04224..675cd7bfbf99 100644\n--- a/tools/pythonpkg/src/vector_conversion.cpp\n+++ b/tools/pythonpkg/src/vector_conversion.cpp\n@@ -86,13 +86,24 @@ bool ValueIsNull(double value) {\n }\n \n template <class T>\n-void ScanPandasFpColumn(T *src_ptr, idx_t count, idx_t offset, Vector &out) {\n-\tFlatVector::SetData(out, (data_ptr_t)(src_ptr + offset));\n-\tauto tgt_ptr = FlatVector::GetData<T>(out);\n+void ScanPandasFpColumn(T *src_ptr, idx_t stride, idx_t count, idx_t offset, Vector &out) {\n \tauto &mask = FlatVector::Validity(out);\n-\tfor (idx_t i = 0; i < count; i++) {\n-\t\tif (Value::IsNan<T>(tgt_ptr[i])) {\n-\t\t\tmask.SetInvalid(i);\n+\tif (stride == sizeof(T)) {\n+\t\tFlatVector::SetData(out, (data_ptr_t)(src_ptr + offset));\n+\t\t// Turn NaN values into NULL\n+\t\tauto tgt_ptr = FlatVector::GetData<T>(out);\n+\t\tfor (idx_t i = 0; i < count; i++) {\n+\t\t\tif (Value::IsNan<T>(tgt_ptr[i])) {\n+\t\t\t\tmask.SetInvalid(i);\n+\t\t\t}\n+\t\t}\n+\t} else {\n+\t\tauto tgt_ptr = FlatVector::GetData<T>(out);\n+\t\tfor (idx_t i = 0; i < count; i++) {\n+\t\t\ttgt_ptr[i] = src_ptr[stride / sizeof(T) * (i + offset)];\n+\t\t\tif (Value::IsNan<T>(tgt_ptr[i])) {\n+\t\t\t\tmask.SetInvalid(i);\n+\t\t\t}\n \t\t}\n \t}\n }\n@@ -232,10 +243,10 @@ void VectorConversion::NumpyToDuckDB(PandasColumnBindData &bind_data, py::array\n \t\tScanPandasMasked<int64_t>(bind_data, count, offset, out);\n \t\tbreak;\n \tcase PandasType::FLOAT_32:\n-\t\tScanPandasFpColumn<float>((float *)numpy_col.data(), count, offset, out);\n+\t\tScanPandasFpColumn<float>((float *)numpy_col.data(), bind_data.numpy_stride, count, offset, out);\n \t\tbreak;\n \tcase PandasType::FLOAT_64:\n-\t\tScanPandasFpColumn<double>((double *)numpy_col.data(), count, offset, out);\n+\t\tScanPandasFpColumn<double>((double *)numpy_col.data(), bind_data.numpy_stride, count, offset, out);\n \t\tbreak;\n \tcase PandasType::DATETIME:\n \tcase PandasType::DATETIME_TZ: {\n",
  "test_patch": "diff --git a/tools/pythonpkg/tests/fast/pandas/test_stride.py b/tools/pythonpkg/tests/fast/pandas/test_stride.py\nindex 987d39f68f62..08107cfe2040 100644\n--- a/tools/pythonpkg/tests/fast/pandas/test_stride.py\n+++ b/tools/pythonpkg/tests/fast/pandas/test_stride.py\n@@ -4,10 +4,27 @@\n \n class TestPandasStride(object):\n \n-    def test_stride(self, duckdb_cursor): \n+    def test_stride(self, duckdb_cursor):\n         expected_df = pd.DataFrame(np.arange(20).reshape(5, 4), columns=[\"a\", \"b\", \"c\", \"d\"])\n         con = duckdb.connect()\n         con.register('df_view', expected_df)\n         output_df = con.execute(\"SELECT * FROM df_view;\").fetchdf()\n         pd.testing.assert_frame_equal(expected_df, output_df)\n-   \n\\ No newline at end of file\n+\n+    def test_stride_fp32(self, duckdb_cursor):\n+        expected_df = pd.DataFrame(np.arange(20, dtype='float32').reshape(5, 4), columns=[\"a\", \"b\", \"c\", \"d\"])\n+        con = duckdb.connect()\n+        con.register('df_view', expected_df)\n+        output_df = con.execute(\"SELECT * FROM df_view;\").fetchdf()\n+        for col in output_df.columns:\n+            assert(str(output_df[col].dtype) == 'float32')\n+        pd.testing.assert_frame_equal(expected_df, output_df)\n+\n+    def test_stride_fp64(self, duckdb_cursor):\n+        expected_df = pd.DataFrame(np.arange(20, dtype='float64').reshape(5, 4), columns=[\"a\", \"b\", \"c\", \"d\"])\n+        con = duckdb.connect()\n+        con.register('df_view', expected_df)\n+        output_df = con.execute(\"SELECT * FROM df_view;\").fetchdf()\n+        for col in output_df.columns:\n+            assert(str(output_df[col].dtype) == 'float64')\n+        pd.testing.assert_frame_equal(expected_df, output_df)\n",
  "problem_statement": "Creating table from pandas dataframe produces incorrect results\n### What happens?\n\nI create a table from a pandas DataFrame. When I select the data back out, the data is different from the input.\n\n### To Reproduce\n\nI've attached the `example.pkl` file inside a zip. \r\n\r\n[example.pkl.zip](https://github.com/duckdb/duckdb/files/9962969/example.pkl.zip)\r\n\r\n```\r\nimport duckdb\r\nimport pyarrow as pa\r\nimport pandas as pd\r\nimport pickle\r\n\r\ncon = duckdb.connect()\r\nwith open('example.pkl', 'rb') as f:\r\n    in_df = pickle.load(f)\r\n# Replacing the load from pandas with a load from pyarrow produces correct results.\r\n# in_tbl = pa.Table.from_pandas(in_df)\r\n# con.execute('create table tiles as select * from in_tbl')\r\ncon.execute('create table tiles as select * from in_df')\r\nout = con.execute('select * from tiles limit 10000').fetch_df()\r\nprint(in_df['alpha0'])\r\nprint(out['alpha0'])\r\n```\r\n\r\nOutput:\r\n```\r\n0    0.011102\r\n1    0.011101\r\n2    0.011111\r\n3    0.011123\r\n4    0.011102\r\n5    0.011101\r\n6    0.011111\r\n7    0.011123\r\n8    0.011139\r\n9    0.011137\r\nName: alpha0, dtype: float32\r\n0    0.011102\r\n1    0.102584\r\n2    0.114941\r\n3    0.104812\r\n4    0.099318\r\n5    0.104231\r\n6    0.099771\r\n7    0.106665\r\n8    0.103630\r\n9    0.100998\r\nName: alpha0, dtype: float32\r\n```\r\n\r\nAlso note that saving the dataframe to CSV and then reloading it also fixes the issue. So, I'm guessing this is an edge case where the pandas data is stored \r\n\r\nThank you!!\n\n### OS:\n\nMac OS Ventura, M1\n\n### DuckDB Version:\n\n0.5.1\n\n### DuckDB Client:\n\nPython\n\n### Full Name:\n\nBen Thompson\n\n### Affiliation:\n\nConfirm Solutions\n\n### Have you tried this on the latest `master` branch?\n\n- [X] I agree\n\n### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?\n\n- [X] I agree\n",
  "hints_text": "The issue originates in `vector_conversion.cpp:454`\r\n```c++\r\n\t\t\t} else {\r\n\t\t\t\t// Otherwise we have to get it through 'to_numpy()'\r\n\t\t\t\tbind_data.numpy_col = py::array(column.attr(\"to_numpy\")());\r\n\t\t\t}\r\n```\r\nthis is equivalent to `df['alpha0'].array.to_numpy()` but somehow this results (when taking the data with `pybind11::array::data()`) in:\r\n(result of that is stored in `numpy_col_data`)\r\n```\r\n(lldb) p ((float*)numpy_col_data)[0]\r\n(float) $1 = 0.0111023095\r\n(lldb) p ((float*)numpy_col_data)[1]\r\n(float) $2 = 0.102584355\r\n(lldb) p ((float*)numpy_col_data)[2]\r\n(float) $3 = 0.114940837\r\n```",
  "created_at": "2022-11-08T20:01:13Z"
}