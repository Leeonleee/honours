diff --git a/.editorconfig b/.editorconfig
index 385fcae45934..de0e9020d3e4 100644
--- a/.editorconfig
+++ b/.editorconfig
@@ -20,7 +20,7 @@ insert_final_newline = true
 indent_style = tab
 tab_width = 4
 indent_size = tab
-trim_trailing_whitespace = true
+trim_trailing_whitespace = false
 charset = utf-8
 x-soft-wrap-text = false
 
diff --git a/extension/parquet/column_reader.cpp b/extension/parquet/column_reader.cpp
index b36aabe3f0f1..6a3df18657f0 100644
--- a/extension/parquet/column_reader.cpp
+++ b/extension/parquet/column_reader.cpp
@@ -665,7 +665,7 @@ idx_t ListColumnReader::Read(uint64_t num_values, parquet_filter_t &filter, uint
 		// we have read more values from the child reader than we can fit into the result for this read
 		// we have to pass everything from child_idx to child_actual_num_values into the next call
 		if (child_idx < child_actual_num_values && result_offset == num_values) {
-			read_vector.Slice(read_vector, child_idx);
+			read_vector.Slice(read_vector, child_idx, child_actual_num_values);
 			overflow_child_count = child_actual_num_values - child_idx;
 			read_vector.Verify(overflow_child_count);
 
diff --git a/src/common/types/validity_mask.cpp b/src/common/types/validity_mask.cpp
index 55f5756e1118..744af8b56405 100644
--- a/src/common/types/validity_mask.cpp
+++ b/src/common/types/validity_mask.cpp
@@ -68,7 +68,7 @@ void ValidityMask::Resize(idx_t old_size, idx_t new_size) {
 	}
 }
 
-void ValidityMask::Slice(const ValidityMask &other, idx_t offset) {
+void ValidityMask::Slice(const ValidityMask &other, idx_t offset, idx_t end) {
 	if (other.AllValid()) {
 		validity_mask = nullptr;
 		validity_data.reset();
@@ -78,11 +78,11 @@ void ValidityMask::Slice(const ValidityMask &other, idx_t offset) {
 		Initialize(other);
 		return;
 	}
-	ValidityMask new_mask(STANDARD_VECTOR_SIZE);
+	ValidityMask new_mask(end - offset);
 
 // FIXME THIS NEEDS FIXING!
 #if 1
-	for (idx_t i = offset; i < STANDARD_VECTOR_SIZE; i++) {
+	for (idx_t i = offset; i < end; i++) {
 		new_mask.Set(i - offset, other.RowIsValid(i));
 	}
 	Initialize(new_mask);
diff --git a/src/common/types/vector.cpp b/src/common/types/vector.cpp
index a7b222ca8106..cc0b534c9487 100644
--- a/src/common/types/vector.cpp
+++ b/src/common/types/vector.cpp
@@ -51,8 +51,8 @@ Vector::Vector(Vector &other, const SelectionVector &sel, idx_t count) : type(ot
 	Slice(other, sel, count);
 }
 
-Vector::Vector(Vector &other, idx_t offset) : type(other.type) {
-	Slice(other, offset);
+Vector::Vector(Vector &other, idx_t offset, idx_t end) : type(other.type) {
+	Slice(other, offset, end);
 }
 
 Vector::Vector(const Value &value) : type(value.type()) {
@@ -116,7 +116,7 @@ void Vector::ResetFromCache(const VectorCache &cache) {
 	cache.ResetFromCache(*this);
 }
 
-void Vector::Slice(Vector &other, idx_t offset) {
+void Vector::Slice(Vector &other, idx_t offset, idx_t end) {
 	if (other.GetVectorType() == VectorType::CONSTANT_VECTOR) {
 		Reference(other);
 		return;
@@ -130,10 +130,10 @@ void Vector::Slice(Vector &other, idx_t offset) {
 		auto &other_entries = StructVector::GetEntries(other);
 		D_ASSERT(entries.size() == other_entries.size());
 		for (idx_t i = 0; i < entries.size(); i++) {
-			entries[i]->Slice(*other_entries[i], offset);
+			entries[i]->Slice(*other_entries[i], offset, end);
 		}
 		if (offset > 0) {
-			new_vector.validity.Slice(other.validity, offset);
+			new_vector.validity.Slice(other.validity, offset, end);
 		} else {
 			new_vector.validity = other.validity;
 		}
@@ -142,7 +142,7 @@ void Vector::Slice(Vector &other, idx_t offset) {
 		Reference(other);
 		if (offset > 0) {
 			data = data + GetTypeIdSize(internal_type) * offset;
-			validity.Slice(other.validity, offset);
+			validity.Slice(other.validity, offset, end);
 		}
 	}
 }
diff --git a/src/execution/operator/aggregate/physical_window.cpp b/src/execution/operator/aggregate/physical_window.cpp
index 280b3aa55989..b3130894b58e 100644
--- a/src/execution/operator/aggregate/physical_window.cpp
+++ b/src/execution/operator/aggregate/physical_window.cpp
@@ -837,21 +837,23 @@ static bool WindowNeedsRank(BoundWindowExpression *wexpr) {
 }
 
 template <typename T>
-static T GetCell(ChunkCollection &collection, idx_t column, idx_t index) {
-	D_ASSERT(collection.ColumnCount() > column);
-	auto &chunk = collection.GetChunkForRow(index);
+static T GetCell(DataChunk &chunk, idx_t column, idx_t index) {
+	D_ASSERT(chunk.ColumnCount() > column);
 	auto &source = chunk.data[column];
-	const auto source_offset = index % STANDARD_VECTOR_SIZE;
 	const auto data = FlatVector::GetData<T>(source);
-	return data[source_offset];
+	return data[index];
 }
 
-static bool CellIsNull(ChunkCollection &collection, idx_t column, idx_t index) {
-	D_ASSERT(collection.ColumnCount() > column);
-	auto &chunk = collection.GetChunkForRow(index);
+static bool CellIsNull(DataChunk &chunk, idx_t column, idx_t index) {
+	D_ASSERT(chunk.ColumnCount() > column);
 	auto &source = chunk.data[column];
-	const auto source_offset = index % STANDARD_VECTOR_SIZE;
-	return FlatVector::IsNull(source, source_offset);
+	return FlatVector::IsNull(source, index);
+}
+
+static void CopyCell(DataChunk &chunk, idx_t column, idx_t index, Vector &target, idx_t target_offset) {
+	D_ASSERT(chunk.ColumnCount() > column);
+	auto &source = chunk.data[column];
+	VectorOperations::Copy(source, target, index + 1, index, target_offset);
 }
 
 template <typename T>
@@ -1150,7 +1152,7 @@ struct WindowExecutor {
 	uint64_t rank = 1;
 
 	// Expression collections
-	ChunkCollection payload_collection;
+	DataChunk payload_collection;
 	ExpressionExecutor payload_executor;
 	DataChunk payload_chunk;
 
@@ -1179,10 +1181,9 @@ struct WindowExecutor {
 };
 
 WindowExecutor::WindowExecutor(BoundWindowExpression *wexpr, Allocator &allocator, const idx_t count)
-    : wexpr(wexpr), bounds(wexpr, count), payload_collection(allocator), payload_executor(allocator),
-      filter_executor(allocator), leadlag_offset(wexpr->offset_expr.get(), allocator),
-      leadlag_default(wexpr->default_expr.get(), allocator), boundary_start(wexpr->start_expr.get(), allocator),
-      boundary_end(wexpr->end_expr.get(), allocator),
+    : wexpr(wexpr), bounds(wexpr, count), payload_collection(), payload_executor(allocator), filter_executor(allocator),
+      leadlag_offset(wexpr->offset_expr.get(), allocator), leadlag_default(wexpr->default_expr.get(), allocator),
+      boundary_start(wexpr->start_expr.get(), allocator), boundary_end(wexpr->end_expr.get(), allocator),
       range((bounds.has_preceding_range || bounds.has_following_range) ? wexpr->orders[0].expression.get() : nullptr,
             allocator, count)
 
@@ -1206,6 +1207,11 @@ WindowExecutor::WindowExecutor(BoundWindowExpression *wexpr, Allocator &allocato
 		exprs.push_back(child.get());
 	}
 	PrepareInputExpressions(exprs.data(), exprs.size(), payload_executor, payload_chunk);
+
+	auto types = payload_chunk.GetTypes();
+	if (!types.empty()) {
+		payload_collection.Initialize(allocator, types);
+	}
 }
 
 void WindowExecutor::Sink(DataChunk &input_chunk, const idx_t input_idx, const idx_t total_count) {
@@ -1234,7 +1240,7 @@ void WindowExecutor::Sink(DataChunk &input_chunk, const idx_t input_idx, const i
 		payload_chunk.Reset();
 		payload_executor.Execute(input_chunk, payload_chunk);
 		payload_chunk.Verify();
-		payload_collection.Append(payload_chunk);
+		payload_collection.Append(payload_chunk, true);
 
 		// process payload chunks while they are still piping hot
 		if (check_nulls) {
@@ -1246,11 +1252,18 @@ void WindowExecutor::Sink(DataChunk &input_chunk, const idx_t input_idx, const i
 					ignore_nulls.Initialize(total_count);
 				}
 				// Write to the current position
-				// Chunks in a collection are full, so we don't have to worry about raggedness
-				auto dst = ignore_nulls.GetData() + ignore_nulls.EntryCount(input_idx);
-				auto src = vdata.validity.GetData();
-				for (auto entry_count = vdata.validity.EntryCount(count); entry_count-- > 0;) {
-					*dst++ = *src++;
+				if (input_idx % ValidityMask::BITS_PER_VALUE == 0) {
+					// If we are at the edge of an output entry, just copy the entries
+					auto dst = ignore_nulls.GetData() + ignore_nulls.EntryCount(input_idx);
+					auto src = vdata.validity.GetData();
+					for (auto entry_count = vdata.validity.EntryCount(count); entry_count-- > 0;) {
+						*dst++ = *src++;
+					}
+				} else {
+					// If not, we have ragged data and need to copy one bit at a time.
+					for (idx_t i = 0; i < count; ++i) {
+						ignore_nulls.Set(input_idx + i, vdata.validity.RowIsValid(i));
+					}
 				}
 			}
 		}
@@ -1406,7 +1419,7 @@ void WindowExecutor::Evaluate(idx_t row_idx, DataChunk &input_chunk, Vector &res
 			// else offset is zero, so don't move.
 
 			if (!delta) {
-				payload_collection.CopyCell(0, val_idx, result, output_offset);
+				CopyCell(payload_collection, 0, val_idx, result, output_offset);
 			} else if (wexpr->default_expr) {
 				leadlag_default.CopyCell(result, output_offset);
 			} else {
@@ -1417,13 +1430,13 @@ void WindowExecutor::Evaluate(idx_t row_idx, DataChunk &input_chunk, Vector &res
 		case ExpressionType::WINDOW_FIRST_VALUE: {
 			idx_t n = 1;
 			const auto first_idx = FindNextStart(ignore_nulls, bounds.window_start, bounds.window_end, n);
-			payload_collection.CopyCell(0, first_idx, result, output_offset);
+			CopyCell(payload_collection, 0, first_idx, result, output_offset);
 			break;
 		}
 		case ExpressionType::WINDOW_LAST_VALUE: {
 			idx_t n = 1;
-			payload_collection.CopyCell(0, FindPrevStart(ignore_nulls, bounds.window_start, bounds.window_end, n),
-			                            result, output_offset);
+			CopyCell(payload_collection, 0, FindPrevStart(ignore_nulls, bounds.window_start, bounds.window_end, n),
+			         result, output_offset);
 			break;
 		}
 		case ExpressionType::WINDOW_NTH_VALUE: {
@@ -1440,7 +1453,7 @@ void WindowExecutor::Evaluate(idx_t row_idx, DataChunk &input_chunk, Vector &res
 					auto n = idx_t(n_param);
 					const auto nth_index = FindNextStart(ignore_nulls, bounds.window_start, bounds.window_end, n);
 					if (!n) {
-						payload_collection.CopyCell(0, nth_index, result, output_offset);
+						CopyCell(payload_collection, 0, nth_index, result, output_offset);
 					} else {
 						FlatVector::SetNull(result, output_offset, true);
 					}
diff --git a/src/execution/window_segment_tree.cpp b/src/execution/window_segment_tree.cpp
index 958deef65b47..ba39b704290a 100644
--- a/src/execution/window_segment_tree.cpp
+++ b/src/execution/window_segment_tree.cpp
@@ -7,27 +7,26 @@
 namespace duckdb {
 
 WindowSegmentTree::WindowSegmentTree(AggregateFunction &aggregate, FunctionData *bind_info,
-                                     const LogicalType &result_type_p, ChunkCollection *input,
+                                     const LogicalType &result_type_p, DataChunk *input,
                                      const ValidityMask &filter_mask_p, WindowAggregationMode mode_p)
     : aggregate(aggregate), bind_info(bind_info), result_type(result_type_p), state(aggregate.state_size()),
-      statep(Value::POINTER((idx_t)state.data())), frame(0, 0), active(0, 1),
-      statev(Value::POINTER((idx_t)state.data())), internal_nodes(0), input_ref(input), filter_mask(filter_mask_p),
-      mode(mode_p) {
-#if STANDARD_VECTOR_SIZE < 512
-	throw NotImplementedException("Window functions are not supported for vector sizes < 512");
-#endif
-	statep.Flatten(STANDARD_VECTOR_SIZE);
+      statep(Value::POINTER((idx_t)state.data())), frame(0, 0), statev(Value::POINTER((idx_t)state.data())),
+      internal_nodes(0), input_ref(input), filter_mask(filter_mask_p), mode(mode_p) {
+	statep.Flatten(input->size());
 	statev.SetVectorType(VectorType::FLAT_VECTOR); // Prevent conversion of results to constants
 
 	if (input_ref && input_ref->ColumnCount() > 0) {
-		filter_sel.Initialize(STANDARD_VECTOR_SIZE);
-		inputs.Initialize(Allocator::DefaultAllocator(), input_ref->Types());
+		filter_sel.Initialize(input->size());
+		inputs.Initialize(Allocator::DefaultAllocator(), input_ref->GetTypes());
 		// if we have a frame-by-frame method, share the single state
 		if (aggregate.window && UseWindowAPI()) {
 			AggregateInit();
-			inputs.Reference(input_ref->GetChunk(0));
-		} else if (aggregate.combine && UseCombineAPI()) {
-			ConstructTree();
+			inputs.Reference(*input_ref);
+		} else {
+			inputs.SetCapacity(*input_ref);
+			if (aggregate.combine && UseCombineAPI()) {
+				ConstructTree();
+			}
 		}
 	}
 }
@@ -72,35 +71,15 @@ void WindowSegmentTree::AggegateFinal(Vector &result, idx_t rid) {
 
 void WindowSegmentTree::ExtractFrame(idx_t begin, idx_t end) {
 	const auto size = end - begin;
-	if (size >= STANDARD_VECTOR_SIZE) {
-		throw InternalException("Cannot compute window aggregation: bounds are too large");
-	}
 
-	const idx_t start_in_vector = begin % STANDARD_VECTOR_SIZE;
+	auto &chunk = *input_ref;
 	const auto input_count = input_ref->ColumnCount();
-	if (start_in_vector + size <= STANDARD_VECTOR_SIZE) {
-		inputs.SetCardinality(size);
-		auto &chunk = input_ref->GetChunkForRow(begin);
-		for (idx_t i = 0; i < input_count; ++i) {
-			auto &v = inputs.data[i];
-			auto &vec = chunk.data[i];
-			v.Slice(vec, start_in_vector);
-			v.Verify(size);
-		}
-	} else {
-		inputs.Reset();
-		inputs.SetCardinality(size);
-
-		// we cannot just slice the individual vector!
-		auto &chunk_a = input_ref->GetChunkForRow(begin);
-		auto &chunk_b = input_ref->GetChunkForRow(end);
-		idx_t chunk_a_count = chunk_a.size() - start_in_vector;
-		idx_t chunk_b_count = inputs.size() - chunk_a_count;
-		for (idx_t i = 0; i < input_count; ++i) {
-			auto &v = inputs.data[i];
-			VectorOperations::Copy(chunk_a.data[i], v, chunk_a.size(), start_in_vector, 0);
-			VectorOperations::Copy(chunk_b.data[i], v, chunk_b_count, 0, chunk_a_count);
-		}
+	inputs.SetCardinality(size);
+	for (idx_t i = 0; i < input_count; ++i) {
+		auto &v = inputs.data[i];
+		auto &vec = chunk.data[i];
+		v.Slice(vec, begin, end);
+		v.Verify(size);
 	}
 
 	// Slice to any filtered rows
@@ -123,29 +102,24 @@ void WindowSegmentTree::WindowSegmentValue(idx_t l_idx, idx_t begin, idx_t end)
 		return;
 	}
 
-	if (end - begin >= STANDARD_VECTOR_SIZE) {
-		throw InternalException("Cannot compute window aggregation: bounds are too large");
-	}
-
-	Vector s(statep, 0);
+	const auto count = end - begin;
+	Vector s(statep, 0, count);
 	if (l_idx == 0) {
 		ExtractFrame(begin, end);
 		AggregateInputData aggr_input_data(bind_info, Allocator::DefaultAllocator());
 		aggregate.update(&inputs.data[0], aggr_input_data, input_ref->ColumnCount(), s, inputs.size());
 	} else {
-		inputs.Reset();
-		inputs.SetCardinality(end - begin);
 		// find out where the states begin
 		data_ptr_t begin_ptr = levels_flat_native.get() + state.size() * (begin + levels_flat_start[l_idx - 1]);
 		// set up a vector of pointers that point towards the set of states
-		Vector v(LogicalType::POINTER);
+		Vector v(LogicalType::POINTER, count);
 		auto pdata = FlatVector::GetData<data_ptr_t>(v);
-		for (idx_t i = 0; i < inputs.size(); i++) {
+		for (idx_t i = 0; i < count; i++) {
 			pdata[i] = begin_ptr + i * state.size();
 		}
-		v.Verify(inputs.size());
+		v.Verify(count);
 		AggregateInputData aggr_input_data(bind_info, Allocator::DefaultAllocator());
-		aggregate.combine(v, s, aggr_input_data, inputs.size());
+		aggregate.combine(v, s, aggr_input_data, count);
 	}
 }
 
@@ -155,7 +129,7 @@ void WindowSegmentTree::ConstructTree() {
 
 	// compute space required to store internal nodes of segment tree
 	internal_nodes = 0;
-	idx_t level_nodes = input_ref->Count();
+	idx_t level_nodes = input_ref->size();
 	do {
 		level_nodes = (level_nodes + (TREE_FANOUT - 1)) / TREE_FANOUT;
 		internal_nodes += level_nodes;
@@ -168,7 +142,7 @@ void WindowSegmentTree::ConstructTree() {
 	// level 0 is data itself
 	idx_t level_size;
 	// iterate over the levels of the segment tree
-	while ((level_size = (level_current == 0 ? input_ref->Count()
+	while ((level_size = (level_current == 0 ? input_ref->size()
 	                                         : levels_flat_offset - levels_flat_start[level_current - 1])) > 1) {
 		for (idx_t pos = 0; pos < level_size; pos += TREE_FANOUT) {
 			// compute the aggregate for this entry in the segment tree
@@ -217,39 +191,9 @@ void WindowSegmentTree::Compute(Vector &result, idx_t rid, idx_t begin, idx_t en
 		frame = FrameBounds(begin, end);
 
 		// Extract the range
-		auto &coll = *input_ref;
-		const auto prev_active = active;
-		const FrameBounds combined(MinValue(frame.first, prev.first), MaxValue(frame.second, prev.second));
-
-		// The chunk bounds are the range that includes the begin and end - 1
-		const FrameBounds prev_chunks(coll.LocateChunk(prev_active.first), coll.LocateChunk(prev_active.second - 1));
-		const FrameBounds active_chunks(coll.LocateChunk(combined.first), coll.LocateChunk(combined.second - 1));
-
-		// Extract the range
-		if (active_chunks.first == active_chunks.second) {
-			// If all the data is in a single chunk, then just reference it
-			if (prev_chunks != active_chunks || (!prev.first && !prev.second)) {
-				inputs.Reference(coll.GetChunk(active_chunks.first));
-			}
-		} else if (active_chunks.first == prev_chunks.first && prev_chunks.first != prev_chunks.second) {
-			// If the start chunk did not change, and we are not just a reference, then extend if necessary
-			for (auto chunk_idx = prev_chunks.second + 1; chunk_idx <= active_chunks.second; ++chunk_idx) {
-				inputs.Append(coll.GetChunk(chunk_idx), true);
-			}
-		} else {
-			// If the first chunk changed, start over
-			inputs.Reset();
-			for (auto chunk_idx = active_chunks.first; chunk_idx <= active_chunks.second; ++chunk_idx) {
-				inputs.Append(coll.GetChunk(chunk_idx), true);
-			}
-		}
-
-		active = FrameBounds(active_chunks.first * STANDARD_VECTOR_SIZE,
-		                     MinValue((active_chunks.second + 1) * STANDARD_VECTOR_SIZE, coll.Count()));
-
 		AggregateInputData aggr_input_data(bind_info, Allocator::DefaultAllocator());
-		aggregate.window(inputs.data.data(), filter_mask, aggr_input_data, inputs.ColumnCount(), state.data(), frame,
-		                 prev, result, rid, active.first);
+		aggregate.window(input_ref->data.data(), filter_mask, aggr_input_data, inputs.ColumnCount(), state.data(),
+		                 frame, prev, result, rid, 0);
 		return;
 	}
 
diff --git a/src/function/aggregate/distributive/approx_count.cpp b/src/function/aggregate/distributive/approx_count.cpp
index e5c76f324480..289a01e84930 100644
--- a/src/function/aggregate/distributive/approx_count.cpp
+++ b/src/function/aggregate/distributive/approx_count.cpp
@@ -9,13 +9,27 @@
 namespace duckdb {
 
 struct ApproxDistinctCountState {
+	ApproxDistinctCountState() : log(nullptr) {
+	}
+	~ApproxDistinctCountState() {
+		if (log) {
+			delete log;
+		}
+	}
+	void Resize(idx_t count) {
+		indices.resize(count);
+		counts.resize(count);
+	}
+
 	HyperLogLog *log;
+	vector<uint64_t> indices;
+	vector<uint8_t> counts;
 };
 
 struct ApproxCountDistinctFunction {
 	template <class STATE>
 	static void Initialize(STATE *state) {
-		state->log = nullptr;
+		new (state) STATE;
 	}
 
 	template <class STATE, class OP>
@@ -47,9 +61,7 @@ struct ApproxCountDistinctFunction {
 	}
 	template <class STATE>
 	static void Destroy(STATE *state) {
-		if (state->log) {
-			delete state->log;
-		}
+		state->~STATE();
 	}
 };
 
@@ -65,8 +77,9 @@ static void ApproxCountDistinctSimpleUpdateFunction(Vector inputs[], AggregateIn
 	UnifiedVectorFormat vdata;
 	inputs[0].ToUnifiedFormat(count, vdata);
 
-	uint64_t indices[STANDARD_VECTOR_SIZE];
-	uint8_t counts[STANDARD_VECTOR_SIZE];
+	agg_state->Resize(count);
+	auto indices = agg_state->indices.data();
+	auto counts = agg_state->counts.data();
 
 	HyperLogLog::ProcessEntries(vdata, inputs[0].GetType(), indices, counts, count);
 	agg_state->log->AddToLog(vdata, count, indices, counts);
@@ -80,19 +93,23 @@ static void ApproxCountDistinctUpdateFunction(Vector inputs[], AggregateInputDat
 	state_vector.ToUnifiedFormat(count, sdata);
 	auto states = (ApproxDistinctCountState **)sdata.data;
 
+	uint64_t *indices;
+	uint8_t *counts;
 	for (idx_t i = 0; i < count; i++) {
 		auto agg_state = states[sdata.sel->get_index(i)];
 		if (!agg_state->log) {
 			agg_state->log = new HyperLogLog();
 		}
+		if (i == 0) {
+			agg_state->Resize(count);
+			indices = agg_state->indices.data();
+			counts = agg_state->counts.data();
+		}
 	}
 
 	UnifiedVectorFormat vdata;
 	inputs[0].ToUnifiedFormat(count, vdata);
 
-	uint64_t indices[STANDARD_VECTOR_SIZE];
-	uint8_t counts[STANDARD_VECTOR_SIZE];
-
 	HyperLogLog::ProcessEntries(vdata, inputs[0].GetType(), indices, counts, count);
 	HyperLogLog::AddToLogs(vdata, count, indices, counts, (HyperLogLog ***)states, sdata.sel);
 }
diff --git a/src/include/duckdb/common/types/validity_mask.hpp b/src/include/duckdb/common/types/validity_mask.hpp
index e5a86f59587a..c09c3ac0b41b 100644
--- a/src/include/duckdb/common/types/validity_mask.hpp
+++ b/src/include/duckdb/common/types/validity_mask.hpp
@@ -331,7 +331,7 @@ struct ValidityMask : public TemplatedValidityMask<validity_t> {
 public:
 	DUCKDB_API void Resize(idx_t old_size, idx_t new_size);
 
-	DUCKDB_API void Slice(const ValidityMask &other, idx_t offset);
+	DUCKDB_API void Slice(const ValidityMask &other, idx_t offset, idx_t end);
 	DUCKDB_API void Combine(const ValidityMask &other, idx_t count);
 	DUCKDB_API string ToString(idx_t count) const;
 };
diff --git a/src/include/duckdb/common/types/vector.hpp b/src/include/duckdb/common/types/vector.hpp
index 9847d94781c4..34f3f04dec67 100644
--- a/src/include/duckdb/common/types/vector.hpp
+++ b/src/include/duckdb/common/types/vector.hpp
@@ -48,11 +48,11 @@ class Vector {
 
 public:
 	//! Create a vector that references the other vector
-	DUCKDB_API explicit Vector(Vector &other);
+	DUCKDB_API Vector(Vector &other);
 	//! Create a vector that slices another vector
 	DUCKDB_API explicit Vector(Vector &other, const SelectionVector &sel, idx_t count);
-	//! Create a vector that slices another vector starting from a specific offset
-	DUCKDB_API explicit Vector(Vector &other, idx_t offset);
+	//! Create a vector that slices another vector between a pair of offsets
+	DUCKDB_API explicit Vector(Vector &other, idx_t offset, idx_t end);
 	//! Create a vector of size one holding the passed on value
 	DUCKDB_API explicit Vector(const Value &value);
 	//! Create a vector of size tuple_count (non-standard)
@@ -93,7 +93,7 @@ class Vector {
 	DUCKDB_API void ResetFromCache(const VectorCache &cache);
 
 	//! Creates a reference to a slice of the other vector
-	DUCKDB_API void Slice(Vector &other, idx_t offset);
+	DUCKDB_API void Slice(Vector &other, idx_t offset, idx_t end);
 	//! Creates a reference to a slice of the other vector
 	DUCKDB_API void Slice(Vector &other, const SelectionVector &sel, idx_t count);
 	//! Turns the vector into a dictionary vector with the specified dictionary
@@ -200,7 +200,8 @@ class Vector {
 //! The DictionaryBuffer holds a selection vector
 class VectorChildBuffer : public VectorBuffer {
 public:
-	VectorChildBuffer(Vector vector) : VectorBuffer(VectorBufferType::VECTOR_CHILD_BUFFER), data(move(vector)) {
+	explicit VectorChildBuffer(Vector vector)
+	    : VectorBuffer(VectorBufferType::VECTOR_CHILD_BUFFER), data(move(vector)) {
 	}
 
 public:
diff --git a/src/include/duckdb/execution/window_segment_tree.hpp b/src/include/duckdb/execution/window_segment_tree.hpp
index 904507f6c6f0..e871848cab3b 100644
--- a/src/include/duckdb/execution/window_segment_tree.hpp
+++ b/src/include/duckdb/execution/window_segment_tree.hpp
@@ -8,7 +8,7 @@
 
 #pragma once
 
-#include "duckdb/common/types/chunk_collection.hpp"
+#include "duckdb/common/types/data_chunk.hpp"
 #include "duckdb/execution/physical_operator.hpp"
 #include "duckdb/function/aggregate_function.hpp"
 #include "duckdb/common/enums/window_aggregation_mode.hpp"
@@ -20,7 +20,7 @@ class WindowSegmentTree {
 	using FrameBounds = std::pair<idx_t, idx_t>;
 
 	WindowSegmentTree(AggregateFunction &aggregate, FunctionData *bind_info, const LogicalType &result_type,
-	                  ChunkCollection *input, const ValidityMask &filter_mask, WindowAggregationMode mode);
+	                  DataChunk *input, const ValidityMask &filter_mask, WindowAggregationMode mode);
 	~WindowSegmentTree();
 
 	//! First row contains the result.
@@ -59,8 +59,6 @@ class WindowSegmentTree {
 	Vector statep;
 	//! The frame boundaries, used for the window functions
 	FrameBounds frame;
-	//! The active data in the inputs. Used for the window functions
-	FrameBounds active;
 	//! Reused result state container for the window functions
 	Vector statev;
 
@@ -73,7 +71,7 @@ class WindowSegmentTree {
 	idx_t internal_nodes;
 
 	//! The (sorted) input chunk collection on which the tree is built
-	ChunkCollection *input_ref;
+	DataChunk *input_ref;
 
 	//! The filtered rows in input_ref.
 	const ValidityMask &filter_mask;
diff --git a/src/storage/table/row_group.cpp b/src/storage/table/row_group.cpp
index 779ad421ce11..fa0ba0d147af 100644
--- a/src/storage/table/row_group.cpp
+++ b/src/storage/table/row_group.cpp
@@ -637,7 +637,7 @@ void RowGroup::Update(TransactionData transaction, DataChunk &update_chunk, row_
 		D_ASSERT(column != COLUMN_IDENTIFIER_ROW_ID);
 		D_ASSERT(columns[column]->type.id() == update_chunk.data[i].GetType().id());
 		if (offset > 0) {
-			Vector sliced_vector(update_chunk.data[i], offset);
+			Vector sliced_vector(update_chunk.data[i], offset, offset + count);
 			sliced_vector.Flatten(count);
 			columns[column]->Update(transaction, column, sliced_vector, ids + offset, count);
 		} else {
diff --git a/tools/rpkg/src/statement.cpp b/tools/rpkg/src/statement.cpp
index 11ba7efe2458..54f06e02447c 100644
--- a/tools/rpkg/src/statement.cpp
+++ b/tools/rpkg/src/statement.cpp
@@ -493,7 +493,8 @@ static void transform(Vector &src_vec, SEXP &dest, idx_t dest_offset, idx_t n, b
 			if (!FlatVector::Validity(src_vec).RowIsValid(row_idx)) {
 				SET_ELEMENT(dest, dest_offset + row_idx, R_NilValue);
 			} else {
-				child_vector.Slice(ListVector::GetEntry(src_vec), src_data[row_idx].offset);
+				const auto end = src_data[row_idx].offset + src_data[row_idx].length;
+				child_vector.Slice(ListVector::GetEntry(src_vec), src_data[row_idx].offset, end);
 
 				RProtector ele_prot;
 				// transform the list child vector to a single R SEXP
