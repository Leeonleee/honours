You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes

<issue>
ORDER BY on problematic column error message needs improvement
### What happens?

When ordering by a column that is used in an aggregate function, a Binder error is thrown that suggests this should be possible.
```sql
SELECT COUNT(DISTINCT l) FROM lists_tbl group by groups order by l limit 10;
================================================================================
Binder Error: column "l" must appear in the GROUP BY clause or be used in an aggregate function
```

Either this is a bug and this should be possible - or the error message needs improvement, which I suspect is the actual problem.
Probably the error message should read:
```
Binder Error: column "l" must appear in the GROUP BY clause or be the result of an aggregate function
```


### To Reproduce

```sql
statement ok
CREATE TABLE lists_tbl AS SELECT i%20 as groups, [x + i for x in range(5)] AS l FROM range(1000000) tmp(i);

statement ok
SELECT COUNT(DISTINCT l) FROM lists_tbl group by groups order by l limit 10;
```

### OS:

MacOS

### DuckDB Version:

master

### DuckDB Client:

unittest/cli

### Full Name:

Thijs Bruineman

### Affiliation:

DuckDB Labs

### Have you tried this on the latest `master` branch?

- [X] I agree

### Have you tried the steps to reproduce? Do they include all relevant data and configuration? Does the issue you report still appear there?

- [X] I agree

</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <img src="https://duckdb.org/images/DuckDB_Logo_dl.png" height="50">
3: </div>
4: <p>&nbsp;</p>
5: 
6: <p align="center">
7:   <a href="https://github.com/duckdb/duckdb/actions">
8:     <img src="https://github.com/duckdb/duckdb/actions/workflows/Main.yml/badge.svg?branch=master" alt="Github Actions Badge">
9:   </a>
10:   <a href="https://www.codefactor.io/repository/github/cwida/duckdb">
11:     <img src="https://www.codefactor.io/repository/github/cwida/duckdb/badge" alt="CodeFactor"/>
12:   </a>
13:   <a href="https://app.codecov.io/gh/duckdb/duckdb">
14:     <img src="https://codecov.io/gh/duckdb/duckdb/branch/master/graph/badge.svg?token=FaxjcfFghN" alt="codecov"/>
15:   </a>
16:   <a href="https://discord.gg/tcvwpjfnZx">
17:     <img src="https://shields.io/discord/909674491309850675" alt="discord" />
18:   </a>
19: </p>
20: 
21: ## DuckDB
22: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs), and more. For more information on the goals of DuckDB, please refer to [the Why DuckDB page on our website](https://duckdb.org/why_duckdb).
23: 
24: ## Installation
25: If you want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
26: 
27: ## Data Import
28: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
29: 
30: ```sql
31: SELECT * FROM 'myfile.csv';
32: SELECT * FROM 'myfile.parquet';
33: ```
34: 
35: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
36: 
37: ## SQL Reference
38: The [website](https://duckdb.org/docs/sql/introduction) contains a reference of functions and SQL constructs available in DuckDB.
39: 
40: ## Development
41: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run `BUILD_BENCHMARK=1 BUILD_TPCH=1 make` and then perform several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`. The detail of benchmarks is in our [Benchmark Guide](benchmark/README.md).
42: 
43: Please also refer to our [Contribution Guide](CONTRIBUTING.md).
[end of README.md]
[start of src/planner/binder/expression/bind_columnref_expression.cpp]
1: #include "duckdb/catalog/catalog_entry/schema_catalog_entry.hpp"
2: #include "duckdb/common/string_util.hpp"
3: #include "duckdb/function/scalar/nested_functions.hpp"
4: #include "duckdb/parser/expression/columnref_expression.hpp"
5: #include "duckdb/parser/expression/constant_expression.hpp"
6: #include "duckdb/parser/expression/function_expression.hpp"
7: #include "duckdb/parser/expression/operator_expression.hpp"
8: #include "duckdb/parser/expression/positional_reference_expression.hpp"
9: #include "duckdb/parser/expression/subquery_expression.hpp"
10: #include "duckdb/parser/parsed_expression_iterator.hpp"
11: #include "duckdb/planner/binder.hpp"
12: #include "duckdb/planner/expression/bound_columnref_expression.hpp"
13: #include "duckdb/planner/expression/bound_constant_expression.hpp"
14: #include "duckdb/planner/expression_binder.hpp"
15: #include "duckdb/planner/expression_binder/where_binder.hpp"
16: 
17: namespace duckdb {
18: 
19: unique_ptr<ParsedExpression> ExpressionBinder::QualifyColumnName(const string &column_name, string &error_message) {
20: 	auto using_binding = binder.bind_context.GetUsingBinding(column_name);
21: 	if (using_binding) {
22: 		// we are referencing a USING column
23: 		// check if we can refer to one of the base columns directly
24: 		unique_ptr<Expression> expression;
25: 		if (!using_binding->primary_binding.empty()) {
26: 			// we can! just assign the table name and re-bind
27: 			return make_unique<ColumnRefExpression>(column_name, using_binding->primary_binding);
28: 		} else {
29: 			// // we cannot! we need to bind this as a coalesce between all the relevant columns
30: 			auto coalesce = make_unique<OperatorExpression>(ExpressionType::OPERATOR_COALESCE);
31: 			for (auto &entry : using_binding->bindings) {
32: 				coalesce->children.push_back(make_unique<ColumnRefExpression>(column_name, entry));
33: 			}
34: 			return move(coalesce);
35: 		}
36: 	}
37: 
38: 	// find a binding that contains this
39: 	string table_name = binder.bind_context.GetMatchingBinding(column_name);
40: 
41: 	// throw an error if a macro conflicts with a column name
42: 	auto is_macro_column = false;
43: 	if (binder.macro_binding != nullptr && binder.macro_binding->HasMatchingBinding(column_name)) {
44: 		is_macro_column = true;
45: 		if (!table_name.empty()) {
46: 			throw BinderException("Conflicting column names for column " + column_name + "!");
47: 		}
48: 	}
49: 
50: 	if (lambda_bindings) {
51: 		for (idx_t i = 0; i < lambda_bindings->size(); i++) {
52: 			if ((*lambda_bindings)[i].HasMatchingBinding(column_name)) {
53: 
54: 				// throw an error if a lambda conflicts with a column name or a macro
55: 				if (!table_name.empty() || is_macro_column) {
56: 					throw BinderException("Conflicting column names for column " + column_name + "!");
57: 				}
58: 
59: 				D_ASSERT(!(*lambda_bindings)[i].alias.empty());
60: 				return make_unique<ColumnRefExpression>(column_name, (*lambda_bindings)[i].alias);
61: 			}
62: 		}
63: 	}
64: 
65: 	if (is_macro_column) {
66: 		D_ASSERT(!binder.macro_binding->alias.empty());
67: 		return make_unique<ColumnRefExpression>(column_name, binder.macro_binding->alias);
68: 	}
69: 	// see if it's a column
70: 	if (table_name.empty()) {
71: 		// it's not, find candidates and error
72: 		auto similar_bindings = binder.bind_context.GetSimilarBindings(column_name);
73: 		string candidate_str = StringUtil::CandidatesMessage(similar_bindings, "Candidate bindings");
74: 		error_message =
75: 		    StringUtil::Format("Referenced column \"%s\" not found in FROM clause!%s", column_name, candidate_str);
76: 		return nullptr;
77: 	}
78: 	return binder.bind_context.CreateColumnReference(table_name, column_name);
79: }
80: 
81: void ExpressionBinder::QualifyColumnNames(unique_ptr<ParsedExpression> &expr) {
82: 	switch (expr->type) {
83: 	case ExpressionType::COLUMN_REF: {
84: 		auto &colref = (ColumnRefExpression &)*expr;
85: 		string error_message;
86: 		auto new_expr = QualifyColumnName(colref, error_message);
87: 		if (new_expr) {
88: 			if (!expr->alias.empty()) {
89: 				new_expr->alias = expr->alias;
90: 			}
91: 			expr = move(new_expr);
92: 		}
93: 		break;
94: 	}
95: 	case ExpressionType::POSITIONAL_REFERENCE: {
96: 		auto &ref = (PositionalReferenceExpression &)*expr;
97: 		if (ref.alias.empty()) {
98: 			string table_name, column_name;
99: 			auto error = binder.bind_context.BindColumn(ref, table_name, column_name);
100: 			if (error.empty()) {
101: 				ref.alias = column_name;
102: 			}
103: 		}
104: 		break;
105: 	}
106: 	default:
107: 		break;
108: 	}
109: 	ParsedExpressionIterator::EnumerateChildren(
110: 	    *expr, [&](unique_ptr<ParsedExpression> &child) { QualifyColumnNames(child); });
111: }
112: 
113: void ExpressionBinder::QualifyColumnNames(Binder &binder, unique_ptr<ParsedExpression> &expr) {
114: 	WhereBinder where_binder(binder, binder.context);
115: 	where_binder.QualifyColumnNames(expr);
116: }
117: 
118: unique_ptr<ParsedExpression> ExpressionBinder::CreateStructExtract(unique_ptr<ParsedExpression> base,
119:                                                                    string field_name) {
120: 
121: 	// we need to transform the struct extract if it is inside a lambda expression
122: 	// because we cannot bind to an existing table, so we remove the dummy table also
123: 	if (lambda_bindings && base->type == ExpressionType::COLUMN_REF) {
124: 		auto &lambda_column_ref = (ColumnRefExpression &)*base;
125: 		D_ASSERT(!lambda_column_ref.column_names.empty());
126: 
127: 		if (lambda_column_ref.column_names[0].find(DummyBinding::DUMMY_NAME) != string::npos) {
128: 			D_ASSERT(lambda_column_ref.column_names.size() == 2);
129: 			auto lambda_param_name = lambda_column_ref.column_names.back();
130: 			lambda_column_ref.column_names.clear();
131: 			lambda_column_ref.column_names.push_back(lambda_param_name);
132: 		}
133: 	}
134: 
135: 	vector<unique_ptr<ParsedExpression>> children;
136: 	children.push_back(move(base));
137: 	children.push_back(make_unique_base<ParsedExpression, ConstantExpression>(Value(move(field_name))));
138: 	auto extract_fun = make_unique<OperatorExpression>(ExpressionType::STRUCT_EXTRACT, move(children));
139: 	return move(extract_fun);
140: }
141: 
142: unique_ptr<ParsedExpression> ExpressionBinder::CreateStructPack(ColumnRefExpression &colref) {
143: 	D_ASSERT(colref.column_names.size() <= 2);
144: 	string error_message;
145: 	auto &table_name = colref.column_names.back();
146: 	auto binding = binder.bind_context.GetBinding(table_name, error_message);
147: 	if (!binding) {
148: 		return nullptr;
149: 	}
150: 	if (colref.column_names.size() == 2) {
151: 		// "schema_name.table_name"
152: 		auto catalog_entry = binding->GetStandardEntry();
153: 		if (!catalog_entry) {
154: 			return nullptr;
155: 		}
156: 		auto &schema_name = colref.column_names[0];
157: 		if (catalog_entry->schema->name != schema_name || catalog_entry->name != table_name) {
158: 			return nullptr;
159: 		}
160: 	}
161: 	// We found the table, now create the struct_pack expression
162: 	vector<unique_ptr<ParsedExpression>> child_exprs;
163: 	for (const auto &column_name : binding->names) {
164: 		child_exprs.push_back(make_unique<ColumnRefExpression>(column_name, table_name));
165: 	}
166: 	return make_unique<FunctionExpression>("struct_pack", move(child_exprs));
167: }
168: 
169: unique_ptr<ParsedExpression> ExpressionBinder::QualifyColumnName(ColumnRefExpression &colref, string &error_message) {
170: 	idx_t column_parts = colref.column_names.size();
171: 	// column names can have an arbitrary amount of dots
172: 	// here is how the resolution works:
173: 	if (column_parts == 1) {
174: 		// no dots (i.e. "part1")
175: 		// -> part1 refers to a column
176: 		// check if we can qualify the column name with the table name
177: 		auto qualified_colref = QualifyColumnName(colref.GetColumnName(), error_message);
178: 		if (qualified_colref) {
179: 			// we could: return it
180: 			return qualified_colref;
181: 		}
182: 		// we could not! Try creating an implicit struct_pack
183: 		return CreateStructPack(colref);
184: 	} else if (column_parts == 2) {
185: 		// one dot (i.e. "part1.part2")
186: 		// EITHER:
187: 		// -> part1 is a table, part2 is a column
188: 		// -> part1 is a column, part2 is a property of that column (i.e. struct_extract)
189: 
190: 		// first check if part1 is a table, and part2 is a standard column
191: 		if (binder.HasMatchingBinding(colref.column_names[0], colref.column_names[1], error_message)) {
192: 			// it is! return the colref directly
193: 			return binder.bind_context.CreateColumnReference(colref.column_names[0], colref.column_names[1]);
194: 		} else {
195: 			// otherwise check if we can turn this into a struct extract
196: 			auto new_colref = make_unique<ColumnRefExpression>(colref.column_names[0]);
197: 			string other_error;
198: 			auto qualified_colref = QualifyColumnName(colref.column_names[0], other_error);
199: 			if (qualified_colref) {
200: 				// we could: create a struct extract
201: 				return CreateStructExtract(move(qualified_colref), colref.column_names[1]);
202: 			}
203: 			// we could not! Try creating an implicit struct_pack
204: 			return CreateStructPack(colref);
205: 		}
206: 	} else {
207: 		// two or more dots (i.e. "part1.part2.part3.part4...")
208: 		// -> part1 is a schema, part2 is a table, part3 is a column name, part4 and beyond are struct fields
209: 		// -> part1 is a table, part2 is a column name, part3 and beyond are struct fields
210: 		// -> part1 is a column, part2 and beyond are struct fields
211: 
212: 		// we always prefer the most top-level view
213: 		// i.e. in case of multiple resolution options, we resolve in order:
214: 		// -> 1. resolve "part1" as a schema
215: 		// -> 2. resolve "part1" as a table
216: 		// -> 3. resolve "part1" as a column
217: 
218: 		unique_ptr<ParsedExpression> result_expr;
219: 		idx_t struct_extract_start;
220: 		// first check if part1 is a schema
221: 		if (binder.HasMatchingBinding(colref.column_names[0], colref.column_names[1], colref.column_names[2],
222: 		                              error_message)) {
223: 			// it is! the column reference is "schema.table.column"
224: 			// any additional fields are turned into struct_extract calls
225: 			result_expr = binder.bind_context.CreateColumnReference(colref.column_names[0], colref.column_names[1],
226: 			                                                        colref.column_names[2]);
227: 			struct_extract_start = 3;
228: 		} else if (binder.HasMatchingBinding(colref.column_names[0], colref.column_names[1], error_message)) {
229: 			// part1 is a table
230: 			// the column reference is "table.column"
231: 			// any additional fields are turned into struct_extract calls
232: 			result_expr = binder.bind_context.CreateColumnReference(colref.column_names[0], colref.column_names[1]);
233: 			struct_extract_start = 2;
234: 		} else {
235: 			// part1 could be a column
236: 			string col_error;
237: 			result_expr = QualifyColumnName(colref.column_names[0], col_error);
238: 			if (!result_expr) {
239: 				// it is not! return the error
240: 				return nullptr;
241: 			}
242: 			// it is! add the struct extract calls
243: 			struct_extract_start = 1;
244: 		}
245: 		for (idx_t i = struct_extract_start; i < colref.column_names.size(); i++) {
246: 			result_expr = CreateStructExtract(move(result_expr), colref.column_names[i]);
247: 		}
248: 		return result_expr;
249: 	}
250: }
251: 
252: BindResult ExpressionBinder::BindExpression(ColumnRefExpression &colref_p, idx_t depth) {
253: 	if (binder.GetBindingMode() == BindingMode::EXTRACT_NAMES) {
254: 		return BindResult(make_unique<BoundConstantExpression>(Value(LogicalType::SQLNULL)));
255: 	}
256: 	string error_message;
257: 	auto expr = QualifyColumnName(colref_p, error_message);
258: 	if (!expr) {
259: 		return BindResult(binder.FormatError(colref_p, error_message));
260: 	}
261: 
262: 	// a generated column returns a generated expression, a struct on a column returns a struct extract
263: 	if (expr->type != ExpressionType::COLUMN_REF) {
264: 		auto alias = expr->alias;
265: 		auto result = BindExpression(&expr, depth);
266: 		if (result.expression) {
267: 			result.expression->alias = move(alias);
268: 		}
269: 		return result;
270: 	}
271: 
272: 	auto &colref = (ColumnRefExpression &)*expr;
273: 	D_ASSERT(colref.IsQualified());
274: 	auto &table_name = colref.GetTableName();
275: 
276: 	// individual column reference
277: 	// resolve to either a base table or a subquery expression
278: 	// if it was a macro parameter, let macro_binding bind it to the argument
279: 	// if it was a lambda parameter, let lambda_bindings bind it to the argument
280: 
281: 	BindResult result;
282: 
283: 	auto found_lambda_binding = false;
284: 	if (lambda_bindings) {
285: 		for (idx_t i = 0; i < lambda_bindings->size(); i++) {
286: 			if (table_name == (*lambda_bindings)[i].alias) {
287: 				result = (*lambda_bindings)[i].Bind(colref, depth);
288: 				found_lambda_binding = true;
289: 				break;
290: 			}
291: 		}
292: 	}
293: 
294: 	if (!found_lambda_binding) {
295: 		if (binder.macro_binding && table_name == binder.macro_binding->alias) {
296: 			result = binder.macro_binding->Bind(colref, depth);
297: 		} else {
298: 			result = binder.bind_context.BindColumn(colref, depth);
299: 		}
300: 	}
301: 
302: 	if (!result.HasError()) {
303: 		BoundColumnReferenceInfo ref;
304: 		ref.name = colref.column_names.back();
305: 		ref.query_location = colref.query_location;
306: 		bound_columns.push_back(move(ref));
307: 	} else {
308: 		result.error = binder.FormatError(colref_p, result.error);
309: 	}
310: 	return result;
311: }
312: 
313: } // namespace duckdb
[end of src/planner/binder/expression/bind_columnref_expression.cpp]
[start of src/planner/binder/query_node/bind_select_node.cpp]
1: #include "duckdb/common/limits.hpp"
2: #include "duckdb/common/string_util.hpp"
3: #include "duckdb/execution/expression_executor.hpp"
4: #include "duckdb/main/config.hpp"
5: #include "duckdb/parser/expression/columnref_expression.hpp"
6: #include "duckdb/parser/expression/comparison_expression.hpp"
7: #include "duckdb/parser/expression/constant_expression.hpp"
8: #include "duckdb/parser/expression/subquery_expression.hpp"
9: #include "duckdb/parser/expression/star_expression.hpp"
10: #include "duckdb/parser/query_node/select_node.hpp"
11: #include "duckdb/parser/tableref/joinref.hpp"
12: #include "duckdb/planner/binder.hpp"
13: #include "duckdb/planner/expression_binder/column_alias_binder.hpp"
14: #include "duckdb/planner/expression_binder/constant_binder.hpp"
15: #include "duckdb/planner/expression_binder/group_binder.hpp"
16: #include "duckdb/planner/expression_binder/having_binder.hpp"
17: #include "duckdb/planner/expression_binder/qualify_binder.hpp"
18: #include "duckdb/planner/expression_binder/order_binder.hpp"
19: #include "duckdb/planner/expression_binder/select_binder.hpp"
20: #include "duckdb/planner/expression_binder/where_binder.hpp"
21: #include "duckdb/planner/query_node/bound_select_node.hpp"
22: #include "duckdb/planner/expression_binder/aggregate_binder.hpp"
23: #include "duckdb/parser/parsed_expression_iterator.hpp"
24: 
25: namespace duckdb {
26: 
27: unique_ptr<Expression> Binder::BindOrderExpression(OrderBinder &order_binder, unique_ptr<ParsedExpression> expr) {
28: 	// we treat the Distinct list as a order by
29: 	auto bound_expr = order_binder.Bind(move(expr));
30: 	if (!bound_expr) {
31: 		// DISTINCT ON non-integer constant
32: 		// remove the expression from the DISTINCT ON list
33: 		return nullptr;
34: 	}
35: 	D_ASSERT(bound_expr->type == ExpressionType::BOUND_COLUMN_REF);
36: 	return bound_expr;
37: }
38: 
39: unique_ptr<Expression> Binder::BindDelimiter(ClientContext &context, OrderBinder &order_binder,
40:                                              unique_ptr<ParsedExpression> delimiter, const LogicalType &type,
41:                                              Value &delimiter_value) {
42: 	auto new_binder = Binder::CreateBinder(context, this, true);
43: 	if (delimiter->HasSubquery()) {
44: 		if (!order_binder.HasExtraList()) {
45: 			throw BinderException("Subquery in LIMIT/OFFSET not supported in set operation");
46: 		}
47: 		return order_binder.CreateExtraReference(move(delimiter));
48: 	}
49: 	ExpressionBinder expr_binder(*new_binder, context);
50: 	expr_binder.target_type = type;
51: 	auto expr = expr_binder.Bind(delimiter);
52: 	if (expr->IsFoldable()) {
53: 		//! this is a constant
54: 		delimiter_value = ExpressionExecutor::EvaluateScalar(*expr).CastAs(context, type);
55: 		return nullptr;
56: 	}
57: 	// move any correlated columns to this binder
58: 	MoveCorrelatedExpressions(*new_binder);
59: 	return expr;
60: }
61: 
62: unique_ptr<BoundResultModifier> Binder::BindLimit(OrderBinder &order_binder, LimitModifier &limit_mod) {
63: 	auto result = make_unique<BoundLimitModifier>();
64: 	if (limit_mod.limit) {
65: 		Value val;
66: 		result->limit = BindDelimiter(context, order_binder, move(limit_mod.limit), LogicalType::BIGINT, val);
67: 		if (!result->limit) {
68: 			result->limit_val = val.IsNull() ? NumericLimits<int64_t>::Maximum() : val.GetValue<int64_t>();
69: 			if (result->limit_val < 0) {
70: 				throw BinderException("LIMIT cannot be negative");
71: 			}
72: 		}
73: 	}
74: 	if (limit_mod.offset) {
75: 		Value val;
76: 		result->offset = BindDelimiter(context, order_binder, move(limit_mod.offset), LogicalType::BIGINT, val);
77: 		if (!result->offset) {
78: 			result->offset_val = val.IsNull() ? 0 : val.GetValue<int64_t>();
79: 			if (result->offset_val < 0) {
80: 				throw BinderException("OFFSET cannot be negative");
81: 			}
82: 		}
83: 	}
84: 	return move(result);
85: }
86: 
87: unique_ptr<BoundResultModifier> Binder::BindLimitPercent(OrderBinder &order_binder, LimitPercentModifier &limit_mod) {
88: 	auto result = make_unique<BoundLimitPercentModifier>();
89: 	if (limit_mod.limit) {
90: 		Value val;
91: 		result->limit = BindDelimiter(context, order_binder, move(limit_mod.limit), LogicalType::DOUBLE, val);
92: 		if (!result->limit) {
93: 			result->limit_percent = val.IsNull() ? 100 : val.GetValue<double>();
94: 			if (result->limit_percent < 0.0) {
95: 				throw Exception("Limit percentage can't be negative value");
96: 			}
97: 		}
98: 	}
99: 	if (limit_mod.offset) {
100: 		Value val;
101: 		result->offset = BindDelimiter(context, order_binder, move(limit_mod.offset), LogicalType::BIGINT, val);
102: 		if (!result->offset) {
103: 			result->offset_val = val.IsNull() ? 0 : val.GetValue<int64_t>();
104: 		}
105: 	}
106: 	return move(result);
107: }
108: 
109: void Binder::BindModifiers(OrderBinder &order_binder, QueryNode &statement, BoundQueryNode &result) {
110: 	for (auto &mod : statement.modifiers) {
111: 		unique_ptr<BoundResultModifier> bound_modifier;
112: 		switch (mod->type) {
113: 		case ResultModifierType::DISTINCT_MODIFIER: {
114: 			auto &distinct = (DistinctModifier &)*mod;
115: 			auto bound_distinct = make_unique<BoundDistinctModifier>();
116: 			if (distinct.distinct_on_targets.empty()) {
117: 				for (idx_t i = 0; i < result.names.size(); i++) {
118: 					distinct.distinct_on_targets.push_back(make_unique<ConstantExpression>(Value::INTEGER(1 + i)));
119: 				}
120: 			}
121: 			for (auto &distinct_on_target : distinct.distinct_on_targets) {
122: 				auto expr = BindOrderExpression(order_binder, move(distinct_on_target));
123: 				if (!expr) {
124: 					continue;
125: 				}
126: 				bound_distinct->target_distincts.push_back(move(expr));
127: 			}
128: 			bound_modifier = move(bound_distinct);
129: 			break;
130: 		}
131: 		case ResultModifierType::ORDER_MODIFIER: {
132: 			auto &order = (OrderModifier &)*mod;
133: 			auto bound_order = make_unique<BoundOrderModifier>();
134: 			auto &config = DBConfig::GetConfig(context);
135: 			D_ASSERT(!order.orders.empty());
136: 			if (order.orders[0].expression->type == ExpressionType::STAR) {
137: 				// ORDER BY ALL
138: 				// replace the order list with the maximum order by count
139: 				D_ASSERT(order.orders.size() == 1);
140: 				auto order_type = order.orders[0].type;
141: 				auto null_order = order.orders[0].null_order;
142: 
143: 				vector<OrderByNode> new_orders;
144: 				for (idx_t i = 0; i < order_binder.MaxCount(); i++) {
145: 					new_orders.emplace_back(order_type, null_order,
146: 					                        make_unique<ConstantExpression>(Value::INTEGER(i + 1)));
147: 				}
148: 				order.orders = move(new_orders);
149: 			}
150: 			for (auto &order_node : order.orders) {
151: 				auto order_expression = BindOrderExpression(order_binder, move(order_node.expression));
152: 				if (!order_expression) {
153: 					continue;
154: 				}
155: 				auto type =
156: 				    order_node.type == OrderType::ORDER_DEFAULT ? config.options.default_order_type : order_node.type;
157: 				auto null_order = order_node.null_order == OrderByNullType::ORDER_DEFAULT
158: 				                      ? config.options.default_null_order
159: 				                      : order_node.null_order;
160: 				bound_order->orders.emplace_back(type, null_order, move(order_expression));
161: 			}
162: 			if (!bound_order->orders.empty()) {
163: 				bound_modifier = move(bound_order);
164: 			}
165: 			break;
166: 		}
167: 		case ResultModifierType::LIMIT_MODIFIER:
168: 			bound_modifier = BindLimit(order_binder, (LimitModifier &)*mod);
169: 			break;
170: 		case ResultModifierType::LIMIT_PERCENT_MODIFIER:
171: 			bound_modifier = BindLimitPercent(order_binder, (LimitPercentModifier &)*mod);
172: 			break;
173: 		default:
174: 			throw Exception("Unsupported result modifier");
175: 		}
176: 		if (bound_modifier) {
177: 			result.modifiers.push_back(move(bound_modifier));
178: 		}
179: 	}
180: }
181: 
182: static void AssignReturnType(unique_ptr<Expression> &expr, const vector<LogicalType> &sql_types,
183:                              idx_t projection_index) {
184: 	if (!expr) {
185: 		return;
186: 	}
187: 	if (expr->type != ExpressionType::BOUND_COLUMN_REF) {
188: 		return;
189: 	}
190: 	auto &bound_colref = (BoundColumnRefExpression &)*expr;
191: 	bound_colref.return_type = sql_types[bound_colref.binding.column_index];
192: }
193: 
194: void Binder::BindModifierTypes(BoundQueryNode &result, const vector<LogicalType> &sql_types, idx_t projection_index) {
195: 	for (auto &bound_mod : result.modifiers) {
196: 		switch (bound_mod->type) {
197: 		case ResultModifierType::DISTINCT_MODIFIER: {
198: 			auto &distinct = (BoundDistinctModifier &)*bound_mod;
199: 			if (distinct.target_distincts.empty()) {
200: 				// DISTINCT without a target: push references to the standard select list
201: 				for (idx_t i = 0; i < sql_types.size(); i++) {
202: 					distinct.target_distincts.push_back(
203: 					    make_unique<BoundColumnRefExpression>(sql_types[i], ColumnBinding(projection_index, i)));
204: 				}
205: 			} else {
206: 				// DISTINCT with target list: set types
207: 				for (auto &expr : distinct.target_distincts) {
208: 					D_ASSERT(expr->type == ExpressionType::BOUND_COLUMN_REF);
209: 					auto &bound_colref = (BoundColumnRefExpression &)*expr;
210: 					if (bound_colref.binding.column_index == DConstants::INVALID_INDEX) {
211: 						throw BinderException("Ambiguous name in DISTINCT ON!");
212: 					}
213: 					D_ASSERT(bound_colref.binding.column_index < sql_types.size());
214: 					bound_colref.return_type = sql_types[bound_colref.binding.column_index];
215: 				}
216: 			}
217: 			for (auto &target_distinct : distinct.target_distincts) {
218: 				auto &bound_colref = (BoundColumnRefExpression &)*target_distinct;
219: 				const auto &sql_type = sql_types[bound_colref.binding.column_index];
220: 				if (sql_type.id() == LogicalTypeId::VARCHAR) {
221: 					target_distinct = ExpressionBinder::PushCollation(context, move(target_distinct),
222: 					                                                  StringType::GetCollation(sql_type), true);
223: 				}
224: 			}
225: 			break;
226: 		}
227: 		case ResultModifierType::LIMIT_MODIFIER: {
228: 			auto &limit = (BoundLimitModifier &)*bound_mod;
229: 			AssignReturnType(limit.limit, sql_types, projection_index);
230: 			AssignReturnType(limit.offset, sql_types, projection_index);
231: 			break;
232: 		}
233: 		case ResultModifierType::LIMIT_PERCENT_MODIFIER: {
234: 			auto &limit = (BoundLimitPercentModifier &)*bound_mod;
235: 			AssignReturnType(limit.limit, sql_types, projection_index);
236: 			AssignReturnType(limit.offset, sql_types, projection_index);
237: 			break;
238: 		}
239: 		case ResultModifierType::ORDER_MODIFIER: {
240: 			auto &order = (BoundOrderModifier &)*bound_mod;
241: 			for (auto &order_node : order.orders) {
242: 				auto &expr = order_node.expression;
243: 				D_ASSERT(expr->type == ExpressionType::BOUND_COLUMN_REF);
244: 				auto &bound_colref = (BoundColumnRefExpression &)*expr;
245: 				if (bound_colref.binding.column_index == DConstants::INVALID_INDEX) {
246: 					throw BinderException("Ambiguous name in ORDER BY!");
247: 				}
248: 				D_ASSERT(bound_colref.binding.column_index < sql_types.size());
249: 				const auto &sql_type = sql_types[bound_colref.binding.column_index];
250: 				bound_colref.return_type = sql_types[bound_colref.binding.column_index];
251: 				if (sql_type.id() == LogicalTypeId::VARCHAR) {
252: 					order_node.expression = ExpressionBinder::PushCollation(context, move(order_node.expression),
253: 					                                                        StringType::GetCollation(sql_type));
254: 				}
255: 			}
256: 			break;
257: 		}
258: 		default:
259: 			break;
260: 		}
261: 	}
262: }
263: 
264: bool Binder::FindStarExpression(ParsedExpression &expr, StarExpression **star) {
265: 	if (expr.GetExpressionClass() == ExpressionClass::STAR) {
266: 		auto current_star = (StarExpression *)&expr;
267: 		if (*star) {
268: 			// we can have multiple
269: 			if (!StarExpression::Equals(*star, current_star)) {
270: 				throw BinderException(
271: 				    FormatError(expr, "Multiple different STAR/COLUMNS in the same expression are not supported"));
272: 			}
273: 			return true;
274: 		}
275: 		*star = current_star;
276: 		return true;
277: 	}
278: 	bool has_star = false;
279: 	ParsedExpressionIterator::EnumerateChildren(expr, [&](ParsedExpression &child_expr) {
280: 		if (FindStarExpression(child_expr, star)) {
281: 			has_star = true;
282: 		}
283: 	});
284: 	return has_star;
285: }
286: 
287: void Binder::ReplaceStarExpression(unique_ptr<ParsedExpression> &expr, unique_ptr<ParsedExpression> &replacement) {
288: 	D_ASSERT(expr);
289: 	if (expr->GetExpressionClass() == ExpressionClass::STAR) {
290: 		D_ASSERT(replacement);
291: 		expr = replacement->Copy();
292: 		return;
293: 	}
294: 	ParsedExpressionIterator::EnumerateChildren(
295: 	    *expr, [&](unique_ptr<ParsedExpression> &child_expr) { ReplaceStarExpression(child_expr, replacement); });
296: }
297: 
298: void Binder::ExpandStarExpression(unique_ptr<ParsedExpression> expr,
299:                                   vector<unique_ptr<ParsedExpression>> &new_select_list) {
300: 	StarExpression *star = nullptr;
301: 	if (!FindStarExpression(*expr, &star)) {
302: 		// no star expression: add it as-is
303: 		D_ASSERT(!star);
304: 		new_select_list.push_back(move(expr));
305: 		return;
306: 	}
307: 	D_ASSERT(star);
308: 	vector<unique_ptr<ParsedExpression>> star_list;
309: 	// we have star expressions! expand the list of star expressions
310: 	bind_context.GenerateAllColumnExpressions(*star, star_list);
311: 
312: 	// now perform the replacement
313: 	for (idx_t i = 0; i < star_list.size(); i++) {
314: 		auto new_expr = expr->Copy();
315: 		ReplaceStarExpression(new_expr, star_list[i]);
316: 		new_select_list.push_back(move(new_expr));
317: 	}
318: }
319: 
320: void Binder::ExpandStarExpressions(vector<unique_ptr<ParsedExpression>> &select_list,
321:                                    vector<unique_ptr<ParsedExpression>> &new_select_list) {
322: 	for (auto &select_element : select_list) {
323: 		ExpandStarExpression(move(select_element), new_select_list);
324: 	}
325: }
326: 
327: unique_ptr<BoundQueryNode> Binder::BindNode(SelectNode &statement) {
328: 	auto result = make_unique<BoundSelectNode>();
329: 	result->projection_index = GenerateTableIndex();
330: 	result->group_index = GenerateTableIndex();
331: 	result->aggregate_index = GenerateTableIndex();
332: 	result->groupings_index = GenerateTableIndex();
333: 	result->window_index = GenerateTableIndex();
334: 	result->unnest_index = GenerateTableIndex();
335: 	result->prune_index = GenerateTableIndex();
336: 
337: 	// first bind the FROM table statement
338: 	result->from_table = Bind(*statement.from_table);
339: 
340: 	// bind the sample clause
341: 	if (statement.sample) {
342: 		result->sample_options = move(statement.sample);
343: 	}
344: 
345: 	// visit the select list and expand any "*" statements
346: 	vector<unique_ptr<ParsedExpression>> new_select_list;
347: 	ExpandStarExpressions(statement.select_list, new_select_list);
348: 
349: 	if (new_select_list.empty()) {
350: 		throw BinderException("SELECT list is empty after resolving * expressions!");
351: 	}
352: 	statement.select_list = move(new_select_list);
353: 
354: 	// create a mapping of (alias -> index) and a mapping of (Expression -> index) for the SELECT list
355: 	case_insensitive_map_t<idx_t> alias_map;
356: 	expression_map_t<idx_t> projection_map;
357: 	for (idx_t i = 0; i < statement.select_list.size(); i++) {
358: 		auto &expr = statement.select_list[i];
359: 		result->names.push_back(expr->GetName());
360: 		ExpressionBinder::QualifyColumnNames(*this, expr);
361: 		if (!expr->alias.empty()) {
362: 			alias_map[expr->alias] = i;
363: 			result->names[i] = expr->alias;
364: 		}
365: 		projection_map[expr.get()] = i;
366: 		result->original_expressions.push_back(expr->Copy());
367: 	}
368: 	result->column_count = statement.select_list.size();
369: 
370: 	// first visit the WHERE clause
371: 	// the WHERE clause happens before the GROUP BY, PROJECTION or HAVING clauses
372: 	if (statement.where_clause) {
373: 		ColumnAliasBinder alias_binder(*result, alias_map);
374: 		WhereBinder where_binder(*this, context, &alias_binder);
375: 		unique_ptr<ParsedExpression> condition = move(statement.where_clause);
376: 		result->where_clause = where_binder.Bind(condition);
377: 	}
378: 
379: 	// now bind all the result modifiers; including DISTINCT and ORDER BY targets
380: 	OrderBinder order_binder({this}, result->projection_index, statement, alias_map, projection_map);
381: 	BindModifiers(order_binder, statement, *result);
382: 
383: 	vector<unique_ptr<ParsedExpression>> unbound_groups;
384: 	BoundGroupInformation info;
385: 	auto &group_expressions = statement.groups.group_expressions;
386: 	if (!group_expressions.empty()) {
387: 		// the statement has a GROUP BY clause, bind it
388: 		unbound_groups.resize(group_expressions.size());
389: 		GroupBinder group_binder(*this, context, statement, result->group_index, alias_map, info.alias_map);
390: 		for (idx_t i = 0; i < group_expressions.size(); i++) {
391: 
392: 			// we keep a copy of the unbound expression;
393: 			// we keep the unbound copy around to check for group references in the SELECT and HAVING clause
394: 			// the reason we want the unbound copy is because we want to figure out whether an expression
395: 			// is a group reference BEFORE binding in the SELECT/HAVING binder
396: 			group_binder.unbound_expression = group_expressions[i]->Copy();
397: 			group_binder.bind_index = i;
398: 
399: 			// bind the groups
400: 			LogicalType group_type;
401: 			auto bound_expr = group_binder.Bind(group_expressions[i], &group_type);
402: 			D_ASSERT(bound_expr->return_type.id() != LogicalTypeId::INVALID);
403: 
404: 			// push a potential collation, if necessary
405: 			bound_expr =
406: 			    ExpressionBinder::PushCollation(context, move(bound_expr), StringType::GetCollation(group_type), true);
407: 			result->groups.group_expressions.push_back(move(bound_expr));
408: 
409: 			// in the unbound expression we DO bind the table names of any ColumnRefs
410: 			// we do this to make sure that "table.a" and "a" are treated the same
411: 			// if we wouldn't do this then (SELECT test.a FROM test GROUP BY a) would not work because "test.a" <> "a"
412: 			// hence we convert "a" -> "test.a" in the unbound expression
413: 			unbound_groups[i] = move(group_binder.unbound_expression);
414: 			ExpressionBinder::QualifyColumnNames(*this, unbound_groups[i]);
415: 			info.map[unbound_groups[i].get()] = i;
416: 		}
417: 	}
418: 	result->groups.grouping_sets = move(statement.groups.grouping_sets);
419: 
420: 	// bind the HAVING clause, if any
421: 	if (statement.having) {
422: 		HavingBinder having_binder(*this, context, *result, info, alias_map);
423: 		ExpressionBinder::QualifyColumnNames(*this, statement.having);
424: 		result->having = having_binder.Bind(statement.having);
425: 	}
426: 
427: 	// bind the QUALIFY clause, if any
428: 	if (statement.qualify) {
429: 		QualifyBinder qualify_binder(*this, context, *result, info, alias_map);
430: 		ExpressionBinder::QualifyColumnNames(*this, statement.qualify);
431: 		result->qualify = qualify_binder.Bind(statement.qualify);
432: 	}
433: 
434: 	// after that, we bind to the SELECT list
435: 	SelectBinder select_binder(*this, context, *result, info, alias_map);
436: 	vector<LogicalType> internal_sql_types;
437: 	for (idx_t i = 0; i < statement.select_list.size(); i++) {
438: 		bool is_window = statement.select_list[i]->IsWindow();
439: 		LogicalType result_type;
440: 		auto expr = select_binder.Bind(statement.select_list[i], &result_type);
441: 		if (statement.aggregate_handling == AggregateHandling::FORCE_AGGREGATES && select_binder.HasBoundColumns()) {
442: 			if (select_binder.BoundAggregates()) {
443: 				throw BinderException("Cannot mix aggregates with non-aggregated columns!");
444: 			}
445: 			if (is_window) {
446: 				throw BinderException("Cannot group on a window clause");
447: 			}
448: 			// we are forcing aggregates, and the node has columns bound
449: 			// this entry becomes a group
450: 			auto group_ref = make_unique<BoundColumnRefExpression>(
451: 			    expr->return_type, ColumnBinding(result->group_index, result->groups.group_expressions.size()));
452: 			result->groups.group_expressions.push_back(move(expr));
453: 			expr = move(group_ref);
454: 		}
455: 		result->select_list.push_back(move(expr));
456: 		if (i < result->column_count) {
457: 			result->types.push_back(result_type);
458: 		}
459: 		internal_sql_types.push_back(result_type);
460: 		if (statement.aggregate_handling == AggregateHandling::FORCE_AGGREGATES) {
461: 			select_binder.ResetBindings();
462: 		}
463: 	}
464: 	result->need_prune = result->select_list.size() > result->column_count;
465: 
466: 	// in the normal select binder, we bind columns as if there is no aggregation
467: 	// i.e. in the query [SELECT i, SUM(i) FROM integers;] the "i" will be bound as a normal column
468: 	// since we have an aggregation, we need to either (1) throw an error, or (2) wrap the column in a FIRST() aggregate
469: 	// we choose the former one [CONTROVERSIAL: this is the PostgreSQL behavior]
470: 	if (!result->groups.group_expressions.empty() || !result->aggregates.empty() || statement.having ||
471: 	    !result->groups.grouping_sets.empty()) {
472: 		if (statement.aggregate_handling == AggregateHandling::NO_AGGREGATES_ALLOWED) {
473: 			throw BinderException("Aggregates cannot be present in a Project relation!");
474: 		} else if (statement.aggregate_handling == AggregateHandling::STANDARD_HANDLING) {
475: 			if (select_binder.HasBoundColumns()) {
476: 				auto &bound_columns = select_binder.GetBoundColumns();
477: 				throw BinderException(
478: 				    FormatError(bound_columns[0].query_location,
479: 				                "column \"%s\" must appear in the GROUP BY clause or be used in an aggregate function",
480: 				                bound_columns[0].name));
481: 			}
482: 		}
483: 	}
484: 
485: 	// QUALIFY clause requires at least one window function to be specified in at least one of the SELECT column list or
486: 	// the filter predicate of the QUALIFY clause
487: 	if (statement.qualify && result->windows.empty()) {
488: 		throw BinderException("at least one window function must appear in the SELECT column or QUALIFY clause");
489: 	}
490: 
491: 	// now that the SELECT list is bound, we set the types of DISTINCT/ORDER BY expressions
492: 	BindModifierTypes(*result, internal_sql_types, result->projection_index);
493: 	return move(result);
494: }
495: 
496: } // namespace duckdb
[end of src/planner/binder/query_node/bind_select_node.cpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: