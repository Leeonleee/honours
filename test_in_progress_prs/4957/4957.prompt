You will be provided with a partial code base and an issue statement explaining a problem to resolve.
In your output, give nothing but the code (no markdown) so that your output can be copy pasted and run immediately with no changes.
In the patch file, please make sure to include the line numbers and a blank line at the end so it can be applied using git apply.

<issue>
String Udfs crashing in loadable_extension_demo
#### What happens?
A use-after-free crash occurs when running the loadable_extension_demo udf function on strings above the string_t inline limit. This seems to be caused by the fact that the string created in the udf will go be freed as the udf returns freeing the memory that the string_t returned points to.

#### To Reproduce
```
make debug
./build/debug/duckdb
```
In duckdb
```
LOAD 'build/debug/test/extension/loadable_extension_demo.duckdb_extension';
select hello('World from italy');
```

</issue>
<code>
[start of README.md]
1: <div align="center">
2:   <img src="https://duckdb.org/images/DuckDB_Logo_dl.png" height="50">
3: </div>
4: <p>&nbsp;</p>
5: 
6: <p align="center">
7:   <a href="https://github.com/duckdb/duckdb/actions">
8:     <img src="https://github.com/duckdb/duckdb/actions/workflows/Main.yml/badge.svg?branch=master" alt="Github Actions Badge">
9:   </a>
10:   <a href="https://www.codefactor.io/repository/github/cwida/duckdb">
11:     <img src="https://www.codefactor.io/repository/github/cwida/duckdb/badge" alt="CodeFactor"/>
12:   </a>
13:   <a href="https://app.codecov.io/gh/duckdb/duckdb">
14:     <img src="https://codecov.io/gh/duckdb/duckdb/branch/master/graph/badge.svg?token=FaxjcfFghN" alt="codecov"/>
15:   </a>
16:   <a href="https://discord.gg/tcvwpjfnZx">
17:     <img src="https://shields.io/discord/909674491309850675" alt="discord" />
18:   </a>
19: </p>
20: 
21: ## DuckDB
22: DuckDB is a high-performance analytical database system. It is designed to be fast, reliable and easy to use. DuckDB provides a rich SQL dialect, with support far beyond basic SQL. DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (arrays, structs), and more. For more information on the goals of DuckDB, please refer to [the Why DuckDB page on our website](https://duckdb.org/why_duckdb).
23: 
24: ## Installation
25: If you want to install and use DuckDB, please see [our website](https://www.duckdb.org) for installation and usage instructions.
26: 
27: ## Data Import
28: For CSV files and Parquet files, data import is as simple as referencing the file in the FROM clause:
29: 
30: ```sql
31: SELECT * FROM 'myfile.csv';
32: SELECT * FROM 'myfile.parquet';
33: ```
34: 
35: Refer to our [Data Import](https://duckdb.org/docs/data/overview) section for more information.
36: 
37: ## SQL Reference
38: The [website](https://duckdb.org/docs/sql/introduction) contains a reference of functions and SQL constructs available in DuckDB.
39: 
40: ## Development
41: For development, DuckDB requires [CMake](https://cmake.org), Python3 and a `C++11` compliant compiler. Run `make` in the root directory to compile the sources. For development, use `make debug` to build a non-optimized debug version. You should run `make unit` and `make allunit` to verify that your version works properly after making changes. To test performance, you can run `BUILD_BENCHMARK=1 BUILD_TPCH=1 make` and then perform several standard benchmarks from the root directory by executing `./build/release/benchmark/benchmark_runner`. The detail of benchmarks is in our [Benchmark Guide](benchmark/README.md).
42: 
43: Please also refer to our [Contribution Guide](CONTRIBUTING.md).
[end of README.md]
[start of .github/workflows/Main.yml]
1: name: Main
2: on:
3:   push:
4:     paths-ignore:
5:       - '**.md'
6:   pull_request:
7:     paths-ignore:
8:       - '**.md'
9:       - 'tools/nodejs/**'
10:       - 'tools/juliapkg/**'
11:       - 'tools/pythonpkg/**'
12:       - 'tools/rpkg/**'
13:       - '.github/workflows/**'
14:       - '!.github/workflows/Main.yml'
15: 
16: concurrency:
17:   group: ${{ github.workflow }}-${{ github.ref }}-${{ github.head_ref || '' }}-${{ github.base_ref || '' }}-${{ github.ref != 'refs/heads/master' || github.sha }}
18:   cancel-in-progress: true
19: 
20: env:
21:   GH_TOKEN: ${{ secrets.GH_TOKEN }}
22:   TWINE_PASSWORD: ${{ secrets.TWINE_PASSWORD }}
23:   AWS_ACCESS_KEY_ID: AKIAVBLKPL2ZW2T7TYFQ
24:   AWS_SECRET_ACCESS_KEY: ${{ secrets.NODE_PRE_GYP_SECRETACCESSKEY }}
25:   NODE_AUTH_TOKEN: ${{secrets.NODE_AUTH_TOKEN}}
26: 
27: jobs:
28:  linux-debug:
29:     name: Linux Debug
30:     runs-on: ubuntu-20.04
31: 
32:     env:
33:       CC: gcc-10
34:       CXX: g++-10
35:       TREAT_WARNINGS_AS_ERRORS: 1
36:       BUILD_VISUALIZER: 1
37:       BUILD_INET: 1
38:       BUILD_TPCH: 1
39:       BUILD_TPCDS: 1
40:       BUILD_FTS: 1
41:       BUILD_ICU: 1
42:       BUILD_JSON: 1
43:       BUILD_EXCEL: 1
44:       BUILD_PARQUET: 1
45:       GEN: ninja
46: 
47:     steps:
48:     - uses: actions/checkout@v3
49:       with:
50:         fetch-depth: 0
51: 
52:     - name: Install
53:       shell: bash
54:       run: sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build
55: 
56:     - name: Setup Ccache
57:       uses: hendrikmuhs/ccache-action@main
58:       with:
59:         key: ${{ github.job }}
60: 
61:     - name: Build
62:       shell: bash
63:       run:  make debug
64: 
65:     - name: Test
66:       shell: bash
67:       run: make unittestci
68: 
69: 
70:  force-storage:
71:     name: Force Storage
72:     runs-on: ubuntu-20.04
73:     needs: linux-debug
74:     env:
75:       CC: gcc-10
76:       CXX: g++-10
77:       GEN: ninja
78:       BUILD_ICU: 1
79:       BUILD_INET: 1
80:       BUILD_PARQUET: 1
81:       BUILD_TPCH: 1
82:       BUILD_TPCDS: 1
83:       BUILD_FTS: 1
84:       BUILD_VISUALIZER: 1
85:       BUILD_JSON: 1
86:       BUILD_EXCEL: 1
87: 
88:     steps:
89:     - uses: actions/checkout@v3
90:       with:
91:         fetch-depth: 0
92: 
93:     - name: Install
94:       shell: bash
95:       run: sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build
96: 
97:     - name: Setup Ccache
98:       uses: hendrikmuhs/ccache-action@main
99:       with:
100:         key: ${{ github.job }}
101: 
102:     - name: Build
103:       shell: bash
104:       run: make reldebug
105: 
106:     - name: Test
107:       shell: bash
108:       run: build/reldebug/test/unittest "*" --force-storage
109: 
110:  force-restart:
111:     name: Force Restart
112:     runs-on: ubuntu-20.04
113:     needs: linux-debug
114:     env:
115:       CC: gcc-10
116:       CXX: g++-10
117:       GEN: ninja
118:       BUILD_ICU: 1
119:       BUILD_INET: 1
120:       BUILD_PARQUET: 1
121:       BUILD_TPCH: 1
122:       BUILD_TPCDS: 1
123:       BUILD_FTS: 1
124:       BUILD_VISUALIZER: 1
125:       BUILD_JSON: 1
126:       BUILD_EXCEL: 1
127: 
128:     steps:
129:     - uses: actions/checkout@v3
130:       with:
131:         fetch-depth: 0
132: 
133:     - name: Install
134:       shell: bash
135:       run: sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build
136: 
137:     - name: Setup Ccache
138:       uses: hendrikmuhs/ccache-action@main
139:       with:
140:         key: ${{ github.job }}
141: 
142:     - name: Build
143:       shell: bash
144:       run: make reldebug
145: 
146:     - name: Test
147:       shell: bash
148:       run: build/reldebug/test/unittest "*" --force-reload --force-storage
149: 
150:  linux-arrow:
151:       name: Linux Debug (Arrow Tests)
152:       runs-on: ubuntu-20.04
153:       needs: linux-debug
154:       env:
155:         CC: gcc-10
156:         CXX: g++-10
157:         TREAT_WARNINGS_AS_ERRORS: 1
158:         GEN: ninja
159: 
160:       steps:
161:       - uses: actions/checkout@v3
162:         with:
163:           fetch-depth: 0
164: 
165:       - name: Install
166:         shell: bash
167:         run: sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build
168: 
169:       - name: Setup Ccache
170:         uses: hendrikmuhs/ccache-action@main
171:         with:
172:           key: ${{ github.job }}
173: 
174:       - name: Build
175:         shell: bash
176:         run: BUILD_ARROW_ABI_TEST=1 make debug
177: 
178:       - name: Test
179:         shell: bash
180:         run: make unittestarrow
181: 
182:  threadsan:
183:     name: Thread Sanitizer
184:     runs-on: ubuntu-20.04
185:     needs: linux-debug
186:     env:
187:       CC: gcc-10
188:       CXX: g++-10
189:       GEN: ninja
190:       BUILD_ICU: 1
191:       BUILD_INET: 1
192:       BUILD_TPCH: 1
193:       BUILD_TPCDS: 1
194:       BUILD_FTS: 1
195:       BUILD_VISUALIZER: 1
196:       BUILD_JSON: 1
197:       BUILD_EXCEL: 1
198:       TSAN_OPTIONS: suppressions=.sanitizer-thread-suppressions.txt
199: 
200:     steps:
201:     - uses: actions/checkout@v3
202:       with:
203:         fetch-depth: 0
204: 
205:     - name: Install
206:       shell: bash
207:       run: sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build
208: 
209:     - name: Setup Ccache
210:       uses: hendrikmuhs/ccache-action@main
211:       with:
212:         key: ${{ github.job }}
213: 
214:     - name: Build
215:       shell: bash
216:       run: THREADSAN=1 make reldebug
217: 
218:     - name: Test
219:       shell: bash
220:       run: |
221:           python3 scripts/run_tests_one_by_one.py build/reldebug/test/unittest
222:           python3 scripts/run_tests_one_by_one.py build/reldebug/test/unittest "[intraquery]"
223:           python3 scripts/run_tests_one_by_one.py build/reldebug/test/unittest "[interquery]"
224:           python3 scripts/run_tests_one_by_one.py build/reldebug/test/unittest "[detailed_profiler]"
225:           python3 scripts/run_tests_one_by_one.py build/reldebug/test/unittest test/sql/tpch/tpch_sf01.test_slow
226: 
227: 
228:  valgrind:
229:     name: Valgrind
230:     runs-on: ubuntu-20.04
231:     needs: linux-debug
232:     env:
233:       CC: gcc-10
234:       CXX: g++-10
235:       DISABLE_SANITIZER: 1
236:       GEN: ninja
237: 
238:     steps:
239:     - uses: actions/checkout@v3
240:       with:
241:         fetch-depth: 0
242: 
243:     - name: Install
244:       shell: bash
245:       run: sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build valgrind
246: 
247:     - name: Setup Ccache
248:       uses: hendrikmuhs/ccache-action@main
249:       with:
250:         key: ${{ github.job }}
251: 
252:     - name: Build
253:       shell: bash
254:       run: make debug
255: 
256:     - name: Test
257:       shell: bash
258:       run: valgrind ./build/debug/test/unittest test/sql/tpch/tpch_sf001.test_slow
259: 
260:  docs:
261:     name: Website Docs
262:     runs-on: ubuntu-20.04
263:     needs: linux-debug
264:     steps:
265:     - uses: actions/checkout@v3
266:       with:
267:         fetch-depth: 0
268: 
269:     - name: Clone Website
270:       shell: bash
271:       run: git clone https://github.com/duckdb/duckdb-web
272: 
273:     - name: Set up Python 3.9
274:       uses: actions/setup-python@v2
275:       with:
276:         python-version: '3.9'
277: 
278:     - name: Package
279:       shell: bash
280:       run: |
281:         cd duckdb-web
282:         python3 scripts/generate_docs.py ..
283: 
284: 
285:  sqllogic:
286:     name: Sqllogic tests
287:     runs-on: ubuntu-20.04
288:     needs: linux-debug
289:     env:
290:       CC: gcc-10
291:       CXX: g++-10
292: 
293:     steps:
294:     - uses: actions/checkout@v3
295:       with:
296:         fetch-depth: 0
297: 
298:     - name: Test
299:       shell: bash
300:       run: make sqlite
301: 
302:  expanded:
303:     name: Expanded
304:     runs-on: ubuntu-20.04
305:     needs: linux-debug
306:     env:
307:       CC: gcc-10
308:       CXX: g++-10
309:       TREAT_WARNINGS_AS_ERRORS: 1
310:       DISABLE_UNITY: 1
311:       GEN: ninja
312: 
313:     steps:
314:     - uses: actions/checkout@v3
315:       with:
316:         fetch-depth: 0
317: 
318:     - uses: ./.github/actions/swap_space
319: 
320:     - name: Install
321:       shell: bash
322:       run: sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build
323: 
324:     - name: Setup Ccache
325:       uses: hendrikmuhs/ccache-action@main
326:       with:
327:         key: ${{ github.job }}
328: 
329:     - name: Build
330:       shell: bash
331:       run: make debug
332: 
333:  jdbc:
334:     name: JDBC Compliance
335:     runs-on: ubuntu-18.04
336:     needs: linux-debug
337:     env:
338:       CC: gcc-10
339:       CXX: g++-10
340:       BUILD_JDBC: 1
341:       GEN: ninja
342: 
343:     steps:
344:     - uses: actions/checkout@v3
345:       with:
346:         fetch-depth: 0
347: 
348:     - name: Install
349:       shell: bash
350:       run: |
351:         sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build
352:         git clone https://github.com/cwida/jdbccts.git
353: 
354:     - name: Setup Ccache
355:       uses: hendrikmuhs/ccache-action@main
356:       with:
357:         key: ${{ github.job }}
358: 
359:     - name: Build
360:       shell: bash
361:       run: make release
362: 
363:     - name: Test
364:       shell: bash
365:       run: (cd jdbccts && make DUCKDB_JAR=../build/release/tools/jdbc/duckdb_jdbc.jar test)
366: 
367:  odbc:
368:     name: ODBC
369:     runs-on: ubuntu-20.04
370:     needs: linux-debug
371:     env:
372:       BUILD_ODBC: 1
373:       GEN: ninja
374: 
375:     steps:
376:     - uses: actions/checkout@v3
377:       with:
378:         fetch-depth: 0
379: 
380:     - uses: actions/setup-python@v2
381:       with:
382:         python-version: '3.7'
383: 
384:     - name: Dependencies
385:       shell: bash
386:       run: |
387:         sudo apt-get update -y -qq && sudo apt-get install -y -qq ninja-build unixodbc-dev python3 python3-pip julia
388:         pip3 install pyodbc
389: 
390:     - name: Install nanodbc
391:       shell: bash
392:       run: |
393:         wget https://github.com/nanodbc/nanodbc/archive/refs/tags/v2.13.0.tar.gz -O nanodbc.tgz
394:         (mkdir nanodbc && tar xvf nanodbc.tgz -C nanodbc --strip-components=1 && cd nanodbc && sed -i -e "s/set(test_list/set(test_list odbc/" test/CMakeLists.txt && mkdir build && cd build && cmake -DNANODBC_DISABLE_TESTS=OFF .. && cmake --build .)
395: 
396:     - name: Install psqlodbc
397:       shell: bash
398:       run: |
399:         git clone https://github.com/Mytherin/psqlodbc.git
400:         (cd psqlodbc && git checkout 70fa016bde0b326d98803742aa570a1e5b3f6e89 && make debug)
401: 
402:     - name: Setup Ccache
403:       uses: hendrikmuhs/ccache-action@main
404:       with:
405:         key: ${{ github.job }}
406: 
407:     - name: Build
408:       shell: bash
409:       run: DISABLE_SANITIZER=1 make debug
410: 
411:     - name: Test nanodbc
412:       shell: bash
413:       run: ./tools/odbc/test/run_nanodbc_tests.sh
414: 
415:     - name: Test psqlodbc
416:       shell: bash
417:       run: ./tools/odbc/test/run_psqlodbc_tests.sh
418: 
419:     - name: Test isql
420:       shell: bash
421:       run: ./tools/odbc/test/run_isql_tests.sh
422: 
423:     - name: Test R ODBC
424:       shell: bash
425:       run: R -f tools/odbc/test/rodbc.R
426: 
427:     - name: Test Python ODBC
428:       shell: bash
429:       run: ./tools/odbc/test/run_pyodbc_tests.sh
430: 
431:     - name: Test Julia ODBC
432:       shell: bash
433:       run: |
434:         export ASAN_OPTIONS=verify_asan_link_order=0
435:         julia tools/odbc/test/julia-test.jl
[end of .github/workflows/Main.yml]
[start of CMakeLists.txt]
1: cmake_minimum_required(VERSION 2.8.12)
2: 
3: if(POLICY CMP0026)
4:   cmake_policy(SET CMP0026 NEW)
5: endif()
6: 
7: if(POLICY CMP0051)
8:   cmake_policy(SET CMP0051 NEW)
9: endif()
10: 
11: if(POLICY CMP0054)
12:   cmake_policy(SET CMP0054 NEW)
13: endif()
14: 
15: project(DuckDB)
16: 
17: find_package(Threads REQUIRED)
18: 
19: if (CMAKE_VERSION VERSION_LESS "3.1")
20:     set (CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -std=c++11")
21: else ()
22:   set (CMAKE_CXX_STANDARD 11)
23: endif ()
24: 
25: 
26: set(CMAKE_CXX_STANDARD_REQUIRED ON)
27: set(CMAKE_CXX_EXTENSIONS OFF)
28: 
29: set(CMAKE_VERBOSE_MAKEFILE OFF)
30: set(CMAKE_POSITION_INDEPENDENT_CODE ON)
31: set(CMAKE_MACOSX_RPATH 1)
32: 
33: find_program(CCACHE_PROGRAM ccache)
34: if(CCACHE_PROGRAM)
35:   set_property(GLOBAL PROPERTY RULE_LAUNCH_COMPILE "${CCACHE_PROGRAM}")
36: else()
37:   find_program(CCACHE_PROGRAM sccache)
38:   if(CCACHE_PROGRAM)
39:     set_property(GLOBAL PROPERTY RULE_LAUNCH_COMPILE "${CCACHE_PROGRAM}")
40:   endif()
41: endif()
42: 
43: # Determine install paths
44: set(INSTALL_LIB_DIR
45:     lib
46:     CACHE PATH "Installation directory for libraries")
47: set(INSTALL_BIN_DIR
48:     bin
49:     CACHE PATH "Installation directory for executables")
50: set(INSTALL_INCLUDE_DIR
51:     include
52:     CACHE PATH "Installation directory for header files")
53: if(WIN32 AND NOT CYGWIN)
54:   set(DEF_INSTALL_CMAKE_DIR cmake)
55: else()
56:   set(DEF_INSTALL_CMAKE_DIR lib/cmake/DuckDB)
57: endif()
58: set(INSTALL_CMAKE_DIR
59:     ${DEF_INSTALL_CMAKE_DIR}
60:     CACHE PATH "Installation directory for CMake files")
61: set(DUCKDB_EXPORT_SET "DuckDBExports")
62: 
63: # Make relative install paths absolute
64: foreach(p LIB BIN INCLUDE CMAKE)
65:   set(var INSTALL_${p}_DIR)
66:   if(NOT IS_ABSOLUTE "${${var}}")
67:     set(${var} "${CMAKE_INSTALL_PREFIX}/${${var}}")
68:   endif()
69: endforeach()
70: 
71: # This option allows --gc-sections flag during extension linking to discard any unused functions or data
72: if (EXTENSION_STATIC_BUILD AND "${CMAKE_CXX_COMPILER_ID}" STREQUAL "GNU")
73:   if ("${CMAKE_CXX_COMPILER_ID}" STREQUAL "GNU")
74:     set(CMAKE_CXX_FLAGS_RELEASE "${CMAKE_CXX_FLAGS_RELEASE} -ffunction-sections -fdata-sections")
75:   elseif(WIN32 AND MVSC)
76:     set(CMAKE_CXX_FLAGS_RELEASE "${CMAKE_CXX_FLAGS_RELEASE} /Gy")
77:   endif()
78: endif()
79: 
80: option(DISABLE_UNITY "Disable unity builds." FALSE)
81: 
82: option(FORCE_COLORED_OUTPUT
83:        "Always produce ANSI-colored output (GNU/Clang only)." FALSE)
84: if(${FORCE_COLORED_OUTPUT})
85:   if("${CMAKE_CXX_COMPILER_ID}" STREQUAL "GNU")
86:     add_compile_options(-fdiagnostics-color=always)
87:   elseif("${CMAKE_CXX_COMPILER_ID}" STREQUAL "Clang")
88:     add_compile_options(-fcolor-diagnostics)
89:   endif()
90: endif()
91: 
92: option("Enable address sanitizer." TRUE)
93: 
94: set(M32_FLAG "")
95: if(FORCE_32_BIT)
96:   set(M32_FLAG " -m32 ")
97: endif()
98: 
99: option(FORCE_WARN_UNUSED "Unused code objects lead to compiler warnings." FALSE)
100: 
101: option(ENABLE_SANITIZER "Enable address sanitizer." TRUE)
102: option(ENABLE_THREAD_SANITIZER "Enable thread sanitizer." FALSE)
103: option(ENABLE_UBSAN "Enable undefined behavior sanitizer." TRUE)
104: option(DISABLE_VPTR_SANITIZER "Disable vptr sanitizer; work-around for sanitizer false positive on Macbook M1" FALSE)
105: option(
106:   FORCE_SANITIZER
107:   "Forces building with sanitizers even if the Python and R modules are enabled."
108:   FALSE)
109: if((BUILD_PYTHON OR BUILD_R OR CONFIGURE_R)
110:    AND (ENABLE_SANITIZER OR ENABLE_UBSAN)
111:    AND ("${CMAKE_BUILD_TYPE}" STREQUAL "Debug"))
112:   if(FORCE_SANITIZER)
113:     message(
114:       WARNING
115:         "FORCE_SANITIZER is set and the Python/R builds are enabled. Sanitizers will be linked as a shared library (-shared-libasan). You may need to do LD_PRELOAD tricks to load packages built in this way."
116:     )
117:     set(CXX_EXTRA_DEBUG "${CXX_EXTRA_DEBUG} -shared-libasan")
118:   else()
119:     message(
120:       WARNING
121:         "Sanitizers are enabled but will not be built because the Python/R builds are enabled. Use FORCE_SANITIZER to force building of the sanitizers even when building these packages."
122:     )
123:     set(ENABLE_SANITIZER FALSE)
124:     set(ENABLE_UBSAN FALSE)
125:   endif()
126: endif()
127: if(${ENABLE_THREAD_SANITIZER})
128:   if(${ENABLE_SANITIZER})
129:     message(
130:       WARNING
131:         "Both thread and address sanitizers are enabled. This is not supported. The address sanitizer will be disabled, and we will run with only the thread sanitizer."
132:     )
133:   endif()
134:   set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -fsanitize=thread")
135: elseif(${ENABLE_SANITIZER})
136:   if(FORCE_ASSERT)
137:     set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -fsanitize=address")
138:   else()
139:     set(CXX_EXTRA_DEBUG "${CXX_EXTRA_DEBUG} -fsanitize=address")
140:   endif()
141: endif()
142: 
143: 
144: if (${DISABLE_VPTR_SANITIZER})
145: else()
146:   if(APPLE AND CMAKE_SYSTEM_PROCESSOR MATCHES "arm64")
147:     if("${CMAKE_CXX_COMPILER_VERSION}" VERSION_GREATER 14.0)
148:       message(
149:         WARNING
150:           "Not disabling vptr sanitizer on M1 Macbook - set DISABLE_VPTR_SANITIZER manually if you run into issues with false positives in the sanitizer"
151:       )
152:     else()
153:     set(DISABLE_VPTR_SANITIZER TRUE)
154:     endif()
155:   endif()
156: endif()
157: 
158: if(${ENABLE_UBSAN})
159:   if(${ENABLE_THREAD_SANITIZER})
160:     message(
161:       WARNING
162:         "Both thread and undefined sanitizers are enabled. This is not supported. The undefined sanitizer will be disabled, and we will run with only the thread sanitizer."
163:     )
164:   else()
165:     if(FORCE_ASSERT)
166:       set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -fsanitize=undefined -fno-sanitize-recover=all")
167:       if (${DISABLE_VPTR_SANITIZER})
168:         set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -fno-sanitize=vptr")
169:       endif()
170:     else()
171:       set(CXX_EXTRA_DEBUG "${CXX_EXTRA_DEBUG} -fsanitize=undefined -fno-sanitize-recover=all")
172:       if (${DISABLE_VPTR_SANITIZER})
173:         set(CXX_EXTRA_DEBUG "${CXX_EXTRA_DEBUG} -fno-sanitize=vptr")
174:       endif()
175:     endif()
176:   endif()
177: endif()
178: 
179: option(EXPLICIT_EXCEPTIONS "Explicitly enable C++ exceptions." FALSE)
180: if(${EXPLICIT_EXCEPTIONS})
181:   set(CXX_EXTRA "${CXX_EXTRA} -fexceptions")
182: endif()
183: 
184: option(OSX_BUILD_UNIVERSAL "Build both architectures on OSX and create a single binary containing both." FALSE)
185: if (OSX_BUILD_UNIVERSAL)
186:   if (NOT APPLE)
187:     error("This only makes sense on OSX")
188:   endif()
189:   SET(CMAKE_OSX_ARCHITECTURES "x86_64;arm64" CACHE STRING "Build architectures for Mac OS X" FORCE)
190: endif()
191: 
192: set(SUN FALSE)
193: if(${CMAKE_SYSTEM_NAME} STREQUAL "SunOS")
194:   set(CXX_EXTRA "${CXX_EXTRA} -mimpure-text")
195:   add_definitions(-DSUN=1)
196:   set(SUN TRUE)
197: endif()
198: 
199: execute_process(
200:         COMMAND git log -1 --format=%h
201:         WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}
202:         RESULT_VARIABLE GIT_RESULT
203:         OUTPUT_VARIABLE GIT_COMMIT_HASH
204:         OUTPUT_STRIP_TRAILING_WHITESPACE)
205: execute_process(
206:         COMMAND git describe --tags --abbrev=0
207:         WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}
208:         OUTPUT_VARIABLE GIT_LAST_TAG
209:         OUTPUT_STRIP_TRAILING_WHITESPACE)
210: execute_process(
211:         COMMAND git describe --tags --long
212:         WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}
213:         OUTPUT_VARIABLE GIT_ITERATION
214:         OUTPUT_STRIP_TRAILING_WHITESPACE)
215: 
216: if(GIT_RESULT EQUAL "0")
217:   string(REGEX REPLACE "v([0-9]+).[0-9]+.[0-9]+" "\\1" DUCKDB_MAJOR_VERSION "${GIT_LAST_TAG}")
218:   string(REGEX REPLACE "v[0-9]+.([0-9]+).[0-9]+" "\\1" DUCKDB_MINOR_VERSION "${GIT_LAST_TAG}")
219:   string(REGEX REPLACE "v[0-9]+.[0-9]+.([0-9]+)" "\\1" DUCKDB_PATCH_VERSION "${GIT_LAST_TAG}")
220:   string(REGEX REPLACE ".*-([0-9]+)-.*" "\\1" DUCKDB_DEV_ITERATION "${GIT_ITERATION}")
221: 
222:   if(DUCKDB_DEV_ITERATION EQUAL 0)
223:     # on a tag; directly use the version
224:     set(DUCKDB_VERSION "${GIT_LAST_TAG}")
225:   else()
226:     # not on a tag, increment the patch version by one and add a -devX suffix
227:     math(EXPR DUCKDB_PATCH_VERSION "${DUCKDB_PATCH_VERSION}+1")
228:     set(DUCKDB_VERSION "v${DUCKDB_MAJOR_VERSION}.${DUCKDB_MINOR_VERSION}.${DUCKDB_PATCH_VERSION}-dev${DUCKDB_DEV_ITERATION}")
229:   endif()
230: else()
231:   # fallback for when building from tarball
232:   set(DUCKDB_MAJOR_VERSION 0)
233:   set(DUCKDB_MINOR_VERSION 0)
234:   set(DUCKDB_PATCH_VERSION 1)
235:   set(DUCKDB_DEV_ITERATION 0)
236:   set(DUCKDB_VERSION "v${DUCKDB_MAJOR_VERSION}.${DUCKDB_MINOR_VERSION}.${DUCKDB_PATCH_VERSION}-dev${DUCKDB_DEV_ITERATION}")
237: endif()
238: 
239: option(AMALGAMATION_BUILD
240:        "Build from the amalgamation files, rather than from the normal sources."
241:        FALSE)
242: 
243: option(BUILD_MAIN_DUCKDB_LIBRARY
244:         "Build the main duckdb library and executable."
245:         TRUE)
246: option(EXTENSION_STATIC_BUILD
247:         "Extension build linking statically with DuckDB. Required for building linux loadable extensions."
248:         FALSE)
249: 
250: option(BUILD_ICU_EXTENSION "Build the ICU extension." FALSE)
251: option(BUILD_PARQUET_EXTENSION "Build the Parquet extension." FALSE)
252: option(BUILD_TPCH_EXTENSION "Build the TPC-H extension." FALSE)
253: option(BUILD_TPCDS_EXTENSION "Build the TPC-DS extension." FALSE)
254: option(BUILD_FTS_EXTENSION "Build the FTS extension." FALSE)
255: option(BUILD_HTTPFS_EXTENSION "Build the HTTP File System extension." FALSE)
256: option(BUILD_VISUALIZER_EXTENSION "Build the profiler-output visualizer extension." FALSE)
257: option(BUILD_JSON_EXTENSION "Build the JSON extension." FALSE)
258: option(BUILD_EXCEL_EXTENSION "Build the excel extension." FALSE)
259: option(BUILD_INET_EXTENSION "Build the inet extension." FALSE)
260: option(BUILD_BENCHMARKS "Enable building of the benchmark suite." FALSE)
261: option(BUILD_SQLSMITH_EXTENSION "Enable building of the SQLSmith extension." FALSE)
262: option(BUILD_TPCE "Enable building of the TPC-E tool." FALSE)
263: option(DISABLE_BUILTIN_EXTENSIONS "Disable linking extensions." FALSE)
264: option(JDBC_DRIVER "Build the DuckDB JDBC driver" FALSE)
265: option(BUILD_ODBC_DRIVER "Build the DuckDB ODBC driver" FALSE)
266: option(BUILD_PYTHON "Build the DuckDB Python extension" FALSE)
267: option(USER_SPACE "Build the DuckDB Python in the user space" FALSE)
268: option(FORCE_QUERY_LOG "If enabled, all queries will be logged to the specified path" OFF)
269: option(BUILD_SHELL "Build the DuckDB Shell and SQLite API Wrappers" TRUE)
270: option(DISABLE_THREADS "Disable support for multi-threading" FALSE)
271: option(CLANG_TIDY "Enable build for clang-tidy, this disables all source files excluding the core database. This does not produce a working build." FALSE)
272: option(BUILD_UNITTESTS "Build the C++ Unit Tests." TRUE)
273: option(
274:   ASSERT_EXCEPTION
275:   "Throw an exception on an assert failing, instead of triggering a sigabort"
276:   TRUE)
277: option(FORCE_ASSERT "Enable checking of assertions, even in release mode" FALSE)
278: 
279: option(TREAT_WARNINGS_AS_ERRORS "Treat warnings as errors" FALSE)
280: option(EXPORT_DLL_SYMBOLS "Export dll symbols on Windows, else import" TRUE)
281: option(BUILD_RDTSC "Enable the rdtsc instruction." FALSE)
282: option(BUILD_ARROW_ABI_TEST "Enable the Arrow ABI Test." FALSE)
283: option(TEST_REMOTE_INSTALL "Test installation of specific extensions." FALSE)
284: 
285: if(${BUILD_RDTSC})
286:   add_compile_definitions(RDTSC)
287: endif()
288: 
289: if (NOT BUILD_MAIN_DUCKDB_LIBRARY)
290:   set(BUILD_UNITTESTS FALSE)
291:   set(BUILD_SHELL FALSE)
292:   set(DISABLE_BUILTIN_EXTENSIONS TRUE)
293: endif()
294: 
295: if(BUILD_PYTHON
296:    OR BUILD_R
297:    OR CONFIGURE_R
298:    OR JDBC_DRIVER)
299:   set(BUILD_ICU_EXTENSION TRUE)
300:   set(BUILD_VISUALIZER_EXTENSION TRUE)
301:   set(BUILD_PARQUET_EXTENSION TRUE)
302: endif()
303: 
304: if(BUILD_PYTHON)
305:   set(BUILD_TPCH_EXTENSION TRUE)
306:   set(BUILD_TPCDS_EXTENSION TRUE)
307:   set(BUILD_FTS_EXTENSION TRUE)
308:   set(BUILD_EXCEL_EXTENSION TRUE)
309: endif()
310: 
311: if (BUILD_BENCHMARKS)
312:   set(BUILD_PARQUET_EXTENSION TRUE)
313: endif()
314: 
315: if(BUILD_SQLSMITH)
316:   set(BUILD_SQLSMITH_EXTENSION TRUE)
317: endif()
318: 
319: if(TREAT_WARNINGS_AS_ERRORS)
320:   message("Treating warnings as errors.")
321: endif()
322: 
323: if(ASSERT_EXCEPTION)
324: else()
325:   set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -DDUCKDB_CRASH_ON_ASSERT")
326: endif()
327: 
328: if(FORCE_ASSERT)
329:   set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -DDUCKDB_FORCE_ASSERT")
330: endif()
331: 
332: if(NOT MSVC)
333:   if(${FORCE_WARN_UNUSED})
334:     set(CXX_EXTRA "${CXX_EXTRA} -Wunused")
335:   endif()
336:   if(TREAT_WARNINGS_AS_ERRORS)
337:     set(CXX_EXTRA "${CXX_EXTRA} -Werror")
338:   endif()
339:   set(CMAKE_CXX_FLAGS_DEBUG
340:       "${CMAKE_CXX_FLAGS_DEBUG} -g -O0 -DDEBUG -Wall ${M32_FLAG} ${CXX_EXTRA}")
341:   set(CMAKE_CXX_FLAGS_RELEASE
342:       "${CMAKE_CXX_FLAGS_RELEASE} -O3 -DNDEBUG ${M32_FLAG} ${CXX_EXTRA}")
343:   set(CMAKE_CXX_FLAGS_RELWITHDEBINFO "${CMAKE_CXX_FLAGS_RELEASE} -g")
344: 
345:   set(CXX_EXTRA_DEBUG
346:       "${CXX_EXTRA_DEBUG} -Wunused -Werror=vla -Wnarrowing -pedantic"
347:   )
348: 
349:   if("${CMAKE_CXX_COMPILER_ID}" STREQUAL "GNU" AND CMAKE_CXX_COMPILER_VERSION
350:                                                    VERSION_GREATER 8.0)
351:     set(CMAKE_CXX_FLAGS_DEBUG "${CMAKE_CXX_FLAGS_DEBUG} ${CXX_EXTRA_DEBUG}")
352:   elseif("${CMAKE_CXX_COMPILER_ID}" STREQUAL "Clang"
353:          AND CMAKE_CXX_COMPILER_VERSION VERSION_GREATER 9.0)
354:     set(CMAKE_CXX_FLAGS_DEBUG "${CMAKE_CXX_FLAGS_DEBUG} ${CXX_EXTRA_DEBUG}")
355:   else()
356:     message(WARNING "Please use a recent compiler for debug builds")
357:   endif()
358: else()
359:   set(CMAKE_CXX_WINDOWS_FLAGS
360:       "/wd4244 /wd4267 /wd4200 /wd26451 /wd26495 /D_CRT_SECURE_NO_WARNINGS /utf-8")
361:   if(TREAT_WARNINGS_AS_ERRORS)
362:     set(CMAKE_CXX_WINDOWS_FLAGS "${CMAKE_CXX_WINDOWS_FLAGS} /WX")
363:   endif()
364:   # remove warning from CXX flags
365:   string(REGEX REPLACE "/W[0-4]" "" CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS}")
366:   # add to-be-ignored warnings
367:   set(CMAKE_CXX_FLAGS
368:       "${CMAKE_CXX_FLAGS} ${CMAKE_CXX_WINDOWS_FLAGS}"
369:   )
370: endif()
371: 
372: # todo use CHECK_CXX_COMPILER_FLAG(-fsanitize=address SUPPORTS_SANITIZER) etc.
373: 
374: set(CMAKE_C_FLAGS_DEBUG "${CMAKE_CXX_FLAGS_DEBUG}")
375: set(CMAKE_C_FLAGS_RELEASE "${CMAKE_CXX_FLAGS_RELEASE}")
376: set(CMAKE_C_FLAGS_RELWITHDEBINFO "${CMAKE_CXX_FLAGS_RELWITHDEBINFO}")
377: 
378: if(NOT CMAKE_BUILD_TYPE AND NOT CMAKE_CONFIGURATION_TYPES)
379:   set(DEFAULT_BUILD_TYPE "Release")
380:   message(STATUS "Setting build type to '${DEFAULT_BUILD_TYPE}'.")
381:   set(CMAKE_BUILD_TYPE
382:       "${DEFAULT_BUILD_TYPE}"
383:       CACHE STRING "Choose the type of build." FORCE)
384: endif()
385: 
386: 
387: set(OS_NAME "unknown")
388: set(OS_ARCH "amd64")
389: 
390: string(REGEX MATCH "(arm64|aarch64)" IS_ARM "${CMAKE_SYSTEM_PROCESSOR}")
391: if(IS_ARM)
392:   set(OS_ARCH "arm64")
393: elseif(FORCE_32_BIT)
394:   set(OS_ARCH "i386")
395: endif()
396: 
397: if(APPLE)
398:   set(OS_NAME "osx")
399: endif()
400: if(WIN32)
401:   set(OS_NAME "windows")
402: endif()
403: if(UNIX AND NOT APPLE)
404:   set(OS_NAME "linux") # sorry BSD
405: endif()
406: 
407: 
408: include_directories(src/include)
409: include_directories(third_party/fsst)
410: include_directories(third_party/fmt/include)
411: include_directories(third_party/hyperloglog)
412: include_directories(third_party/fastpforlib)
413: include_directories(third_party/fast_float)
414: include_directories(third_party/re2)
415: include_directories(third_party/miniz)
416: include_directories(third_party/utf8proc/include)
417: include_directories(third_party/miniparquet)
418: include_directories(third_party/concurrentqueue)
419: include_directories(third_party/pcg)
420: include_directories(third_party/tdigest)
421: include_directories(third_party/mbedtls/include)
422: include_directories(third_party/jaro_winkler)
423: 
424: # todo only regenerate ub file if one of the input files changed hack alert
425: function(enable_unity_build UB_SUFFIX SOURCE_VARIABLE_NAME)
426:   set(files ${${SOURCE_VARIABLE_NAME}})
427: 
428:   # Generate a unique filename for the unity build translation unit
429:   set(unit_build_file ${CMAKE_CURRENT_BINARY_DIR}/ub_${UB_SUFFIX}.cpp)
430:   set(temp_unit_build_file ${CMAKE_CURRENT_BINARY_DIR}/ub_${UB_SUFFIX}.cpp.tmp)
431:   # Exclude all translation units from compilation
432:   set_source_files_properties(${files} PROPERTIES HEADER_FILE_ONLY true)
433: 
434:   set(rebuild FALSE)
435:   # check if any of the source files have changed
436:   foreach(source_file ${files})
437:     if(${CMAKE_CURRENT_SOURCE_DIR}/${source_file} IS_NEWER_THAN
438:        ${unit_build_file})
439:       set(rebuild TRUE)
440:     endif()
441:   endforeach(source_file)
442:   # write a temporary file
443:   file(WRITE ${temp_unit_build_file} "// Unity Build generated by CMake\n")
444:   foreach(source_file ${files})
445:     file(
446:       APPEND ${temp_unit_build_file}
447:       "#include <${CMAKE_CURRENT_SOURCE_DIR}/${source_file}>\n"
448:     )
449:   endforeach(source_file)
450: 
451:   execute_process(
452:     COMMAND ${CMAKE_COMMAND} -E compare_files ${unit_build_file}
453:             ${temp_unit_build_file}
454:     RESULT_VARIABLE compare_result
455:     OUTPUT_VARIABLE bla
456:     ERROR_VARIABLE bla)
457:   if(compare_result EQUAL 0)
458:     # files are identical: do nothing
459:   elseif(compare_result EQUAL 1)
460:     # files are different: rebuild
461:     set(rebuild TRUE)
462:   else()
463:     # error while compiling: rebuild
464:     set(rebuild TRUE)
465:   endif()
466: 
467:   if(${rebuild})
468:     file(WRITE ${unit_build_file} "// Unity Build generated by CMake\n")
469:     foreach(source_file ${files})
470:       file(
471:         APPEND ${unit_build_file}
472:         "#include <${CMAKE_CURRENT_SOURCE_DIR}/${source_file}>\n"
473:       )
474:     endforeach(source_file)
475:   endif()
476: 
477:   # Complement list of translation units with the name of ub
478:   set(${SOURCE_VARIABLE_NAME}
479:       ${${SOURCE_VARIABLE_NAME}} ${unit_build_file}
480:       PARENT_SCOPE)
481: endfunction(enable_unity_build)
482: 
483: function(add_library_unity NAME MODE)
484:   set(SRCS ${ARGN})
485:   if(NOT DISABLE_UNITY)
486:     enable_unity_build(${NAME} SRCS)
487:   endif()
488:   add_library(${NAME} OBJECT ${SRCS})
489: endfunction()
490: 
491: function(disable_target_warnings NAME)
492:   if(MSVC)
493:     target_compile_options(${NAME} PRIVATE "/W0")
494:   elseif("${CMAKE_CXX_COMPILER_ID}" STREQUAL "Clang"
495:          OR "${CMAKE_CXX_COMPILER_ID}" STREQUAL "GNU")
496:     target_compile_options(${NAME} PRIVATE "-w")
497:   endif()
498: endfunction()
499: 
500: function(add_extension_definitions)
501:   include_directories(${PROJECT_SOURCE_DIR}/extension)
502: 
503:   if(NOT("${TEST_REMOTE_INSTALL}" STREQUAL "OFF"))
504:     add_definitions(-DDUCKDB_TEST_REMOTE_INSTALL="${TEST_REMOTE_INSTALL}")
505:   endif()
506: 
507:   if(${DISABLE_BUILTIN_EXTENSIONS})
508:     add_definitions(-DDISABLE_BUILTIN_EXTENSIONS=${DISABLE_BUILTIN_EXTENSIONS})
509:   endif()
510: 
511:   if(${BUILD_ICU_EXTENSION})
512:     include_directories(${PROJECT_SOURCE_DIR}/extension/icu/include)
513:     add_definitions(-DBUILD_ICU_EXTENSION=${BUILD_ICU_EXTENSION})
514:   endif()
515: 
516:   if(${BUILD_PARQUET_EXTENSION})
517:     include_directories(${PROJECT_SOURCE_DIR}/extension/parquet/include)
518:     add_definitions(-DBUILD_PARQUET_EXTENSION=${BUILD_PARQUET_EXTENSION})
519:   endif()
520: 
521:   if(${BUILD_TPCH_EXTENSION})
522:     include_directories(${PROJECT_SOURCE_DIR}/extension/tpch/include)
523:     add_definitions(-DBUILD_TPCH_EXTENSION=${BUILD_TPCH_EXTENSION})
524:   endif()
525: 
526:   if(${BUILD_TPCDS_EXTENSION})
527:     include_directories(${PROJECT_SOURCE_DIR}/extension/tpcds/include)
528:     add_definitions(-DBUILD_TPCDS_EXTENSION=${BUILD_TPCDS_EXTENSION})
529:   endif()
530: 
531:   if(${BUILD_FTS_EXTENSION})
532:     include_directories(${PROJECT_SOURCE_DIR}/extension/fts/include)
533:     add_definitions(-DBUILD_FTS_EXTENSION=${BUILD_FTS_EXTENSION})
534:   endif()
535: 
536:   if(${BUILD_HTTPFS_EXTENSION})
537:     find_package(OpenSSL REQUIRED)
538:     include_directories(${PROJECT_SOURCE_DIR}/extension/httpfs/include ${OPENSSL_INCLUDE_DIR})
539:     add_definitions(-DBUILD_HTTPFS_EXTENSION=${BUILD_HTTPFS_EXTENSION})
540:   endif()
541: 
542:   if(${BUILD_VISUALIZER_EXTENSION})
543:     include_directories(${PROJECT_SOURCE_DIR}/extension/visualizer/include)
544:     add_definitions(-DBUILD_VISUALIZER_EXTENSION=${BUILD_VISUALIZER_EXTENSION})
545:   endif()
546: 
547:   if(${BUILD_JSON_EXTENSION})
548:     include_directories(${PROJECT_SOURCE_DIR}/extension/json/include)
549:     add_definitions(-DBUILD_JSON_EXTENSION=${BUILD_JSON_EXTENSION})
550:   endif()
551: 
552:   if(${BUILD_EXCEL_EXTENSION})
553:     include_directories(${PROJECT_SOURCE_DIR}/extension/excel/include)
554:     add_definitions(-DBUILD_EXCEL_EXTENSION=${BUILD_EXCEL_EXTENSION})
555:   endif()
556: 
557:   if(${BUILD_SQLSMITH_EXTENSION})
558:     include_directories(${PROJECT_SOURCE_DIR}/extension/sqlsmith/include)
559:     add_definitions(-DBUILD_SQLSMITH_EXTENSION=${BUILD_SQLSMITH_EXTENSION})
560:   endif()
561: 
562:   if(${BUILD_INET_EXTENSION})
563:     include_directories(${PROJECT_SOURCE_DIR}/extension/inet/include)
564:     add_definitions(-DBUILD_INET_EXTENSION=${BUILD_INET_EXTENSION})
565:   endif()
566: endfunction()
567: 
568: function(add_extension_dependencies LIBRARY)
569:   if(${BUILD_PARQUET_EXTENSION})
570:     add_dependencies(${LIBRARY} parquet_extension)
571:   endif()
572: 
573:   if(${BUILD_ICU_EXTENSION})
574:     add_dependencies(${LIBRARY} icu_extension)
575:   endif()
576: 
577:   if(${BUILD_TPCH_EXTENSION})
578:     add_dependencies(${LIBRARY} tpch_extension)
579:   endif()
580: 
581:   if(${BUILD_TPCDS_EXTENSION})
582:     add_dependencies(${LIBRARY} tpcds_extension)
583:   endif()
584: 
585:   if(${BUILD_FTS_EXTENSION})
586:     add_dependencies(${LIBRARY} fts_extension)
587:   endif()
588: 
589:   if(${BUILD_HTTPFS_EXTENSION})
590:     add_dependencies(${LIBRARY} httpfs_extension)
591:   endif()
592: 
593:   if(${BUILD_VISUALIZER_EXTENSION})
594:     add_dependencies(${LIBRARY} visualizer_extension)
595:   endif()
596: 
597:   if(${BUILD_JSON_EXTENSION})
598:     add_dependencies(${LIBRARY} json_extension)
599:   endif()
600: 
601:   if(${BUILD_EXCEL_EXTENSION})
602:     add_dependencies(${LIBRARY} excel_extension)
603:   endif()
604: 
605:   if(${BUILD_SQLSMITH_EXTENSION})
606:     add_dependencies(${LIBRARY} sqlsmith_extension)
607:   endif()
608: 
609:   if(${BUILD_INET_EXTENSION})
610:     add_dependencies(${LIBRARY} inet_extension)
611:   endif()
612: 
613: endfunction()
614: 
615: function(link_extension_libraries LIBRARY)
616:   if(${DISABLE_BUILTIN_EXTENSIONS})
617:     return()
618:   endif()
619: 
620:   if(${BUILD_PARQUET_EXTENSION})
621:     target_link_libraries(${LIBRARY} parquet_extension)
622:   endif()
623: 
624:   if(${BUILD_ICU_EXTENSION})
625:     target_link_libraries(${LIBRARY} icu_extension)
626:   endif()
627: 
628:   if(${BUILD_TPCH_EXTENSION})
629:     target_link_libraries(${LIBRARY} tpch_extension)
630:   endif()
631: 
632:   if(${BUILD_TPCDS_EXTENSION})
633:     target_link_libraries(${LIBRARY} tpcds_extension)
634:   endif()
635: 
636:   if(${BUILD_FTS_EXTENSION})
637:     target_link_libraries(${LIBRARY} fts_extension)
638:   endif()
639: 
640:   if(${BUILD_HTTPFS_EXTENSION})
641:     find_package(OpenSSL REQUIRED)
642:     target_link_libraries(${LIBRARY} httpfs_extension ${OPENSSL_LIBRARIES})
643:   endif()
644: 
645:   if(${BUILD_VISUALIZER_EXTENSION})
646:     target_link_libraries(${LIBRARY} visualizer_extension)
647:   endif()
648: 
649:   if(${BUILD_JSON_EXTENSION})
650:     target_link_libraries(${LIBRARY} json_extension)
651:   endif()
652: 
653:   if(${BUILD_EXCEL_EXTENSION})
654:     target_link_libraries(${LIBRARY} excel_extension)
655:   endif()
656: 
657:   if(${BUILD_SQLSMITH_EXTENSION})
658:     target_link_libraries(${LIBRARY} sqlsmith_extension)
659:   endif()
660: 
661:   if(${BUILD_INET_EXTENSION})
662:     target_link_libraries(${LIBRARY} inet_extension)
663:   endif()
664: endfunction()
665: 
666: function(link_threads LIBRARY)
667:   if (CMAKE_VERSION VERSION_LESS "3.1")
668:     target_link_libraries(${LIBRARY} pthread)
669: 
670:   else()
671:     target_link_libraries(${LIBRARY} Threads::Threads)
672:   endif()
673: endfunction()
674: 
675: function(build_loadable_extension_directory NAME OUTPUT_DIRECTORY PARAMETERS)
676:   #  skip building extensions on mingw because its weird
677:   if(WIN32 AND NOT MSVC)
678:     return()
679:   endif()
680: 
681:   set(TARGET_NAME ${NAME}_loadable_extension)
682:   # all parameters after output_directory
683:   set(FILES ${ARGV})
684:   # remove name
685:   list(REMOVE_AT FILES 0)
686:   # remove output_directory
687:   list(REMOVE_AT FILES 0)
688:   # remove parameters
689:   list(REMOVE_AT FILES 0)
690: 
691:   # parse parameters
692:   string(FIND "${PARAMETERS}" "-no-warnings" IGNORE_WARNINGS)
693: 
694: 
695:   add_library(${TARGET_NAME} SHARED ${FILES})
696:   # this disables the -Dsome_target_EXPORTS define being added by cmake which otherwise trips clang-tidy (yay)
697:   set_target_properties(${TARGET_NAME} PROPERTIES DEFINE_SYMBOL "")
698:   set_target_properties(${TARGET_NAME} PROPERTIES OUTPUT_NAME ${NAME})
699:   set_target_properties(${TARGET_NAME} PROPERTIES PREFIX "")
700:   if(${IGNORE_WARNINGS} GREATER_EQUAL 0)
701:     disable_target_warnings(${TARGET_NAME})
702:   endif()
703:   # loadable extension binaries can be built two ways:
704:   # 1. EXTENSION_STATIC_BUILD=1
705:   #    DuckDB is statically linked into each extension binary. This increases portability because in several situations
706:   #    DuckDB itself may have been loaded with RTLD_LOCAL. This is currently the main way we distribute the lodable
707:   #    extension binaries
708:   # 2. EXTENSION_STATIC_BUILD=0
709:   #    The DuckDB symbols required by the loadable extensions are left unresolved. This will reduce the size of the binaries
710:   #    and works well when running the DuckDB cli directly. For windows this uses delay loading. For MacOS and linux the
711:   #    dynamic loader will look up the missing symbols when the extension is dlopen-ed.
712:   if (EXTENSION_STATIC_BUILD)
713:     if ("${CMAKE_CXX_COMPILER_ID}" STREQUAL "GNU")
714:       # For GNU we rely on fvisibility=hidden to hide the extension symbols and use -exclude-libs to hide the duckdb symbols
715:       set_target_properties(${TARGET_NAME} PROPERTIES CXX_VISIBILITY_PRESET hidden)
716:       target_link_libraries(${TARGET_NAME} duckdb_static ${DUCKDB_EXTRA_LINK_FLAGS} -Wl,--gc-sections -Wl,--exclude-libs,ALL)
717:     elseif (WIN32)
718:       target_link_libraries(${TARGET_NAME} duckdb_static ${DUCKDB_EXTRA_LINK_FLAGS})
719:     elseif("${CMAKE_CXX_COMPILER_ID}" STREQUAL "Clang")
720:       set_target_properties(${TARGET_NAME} PROPERTIES CXX_VISIBILITY_PRESET hidden)
721:       # Note that on MacOS we need to use the -exported_symbol whitelist feature due to a lack of -exclude-libs flag in mac's ld variant
722:       set(WHITELIST "-Wl,-exported_symbol,_${NAME}_init -Wl,-exported_symbol,_${NAME}_version -Wl,-exported_symbol,_${NAME}_replacement_open_*")
723:       target_link_libraries(${TARGET_NAME} duckdb_static ${DUCKDB_EXTRA_LINK_FLAGS} -Wl,-dead_strip ${WHITELIST})
724:     else()
725:       error("EXTENSION static build is only intended for Linux and Windows on MVSC")
726:     endif()
727:   else()
728:     if (WIN32)
729:       target_link_libraries(${TARGET_NAME} duckdb ${DUCKDB_EXTRA_LINK_FLAGS})
730:     elseif("${CMAKE_CXX_COMPILER_ID}" STREQUAL "Clang")
731:       set_target_properties(${TARGET_NAME} PROPERTIES LINK_FLAGS "-undefined dynamic_lookup")
732:     endif()
733:   endif()
734: 
735: 
736:   target_compile_definitions(${TARGET_NAME} PUBLIC -DDUCKDB_BUILD_LOADABLE_EXTENSION)
737:   set_target_properties(${TARGET_NAME} PROPERTIES SUFFIX
738:           ".duckdb_extension")
739: 
740:   if(MSVC)
741:     if (NOT EXTENSION_STATIC_BUILD)
742:       target_link_libraries(${TARGET_NAME} delayimp)
743:     endif()
744:     set_target_properties(
745:             ${TARGET_NAME} PROPERTIES RUNTIME_OUTPUT_DIRECTORY_DEBUG
746:             "${CMAKE_BINARY_DIR}/${OUTPUT_DIRECTORY}")
747:     set_target_properties(
748:             ${TARGET_NAME} PROPERTIES RUNTIME_OUTPUT_DIRECTORY_RELEASE
749:             "${CMAKE_BINARY_DIR}/${OUTPUT_DIRECTORY}")
750:   endif()
751: 
752:   if(WIN32 AND NOT EXTENSION_STATIC_BUILD)
753:     set_target_properties(${TARGET_NAME}
754:             PROPERTIES LINK_FLAGS_DEBUG "/DELAYLOAD:duckdb.dll")
755:     set(CMAKE_EXE_LINKER_FLAGS_DEBUG
756:             "${CMAKE_EXE_LINKER_FLAGS_DEBUG}  /DELAYLOAD:duckdb.dll")
757:     set_target_properties(${TARGET_NAME}
758:             PROPERTIES LINK_FLAGS_RELEASE "/DELAYLOAD:duckdb.dll")
759:     set(CMAKE_EXE_LINKER_FLAGS_RELEASE
760:             "${CMAKE_EXE_LINKER_FLAGS_RELEASE}  /DELAYLOAD:duckdb.dll")
761:     # This is only strictly required in non-Visual-Studio builds like Ninja:
762:     target_link_libraries(${TARGET_NAME}
763:             delayimp)
764: endif()
765: 
766: endfunction()
767: 
768: function(build_loadable_extension NAME PARAMETERS)
769:   # all parameters after name
770:   set(FILES ${ARGV})
771:   list(REMOVE_AT FILES 0)
772:   list(REMOVE_AT FILES 0)
773: 
774:   build_loadable_extension_directory(${NAME} "extension/${NAME}" "${PARAMETERS}" ${FILES})
775: endfunction()
776: 
777: if(${EXPORT_DLL_SYMBOLS})
778:   # For Windows DLL export symbols
779:   add_definitions(-DDUCKDB_BUILD_LIBRARY)
780: endif()
781: 
782: if (BUILD_MAIN_DUCKDB_LIBRARY)
783:   add_subdirectory(src)
784:   add_subdirectory(tools)
785: endif()
786: 
787: add_subdirectory(extension)
788: 
789: if(NOT CLANG_TIDY)
790:   if(${BUILD_UNITTESTS})
791:     add_subdirectory(test)
792:     if(NOT WIN32
793:       AND NOT SUN
794:       AND ${BUILD_BENCHMARKS})
795:       add_subdirectory(benchmark)
796:     endif()
797:   endif()
798:   add_subdirectory(third_party)
799: endif()
800: 
801: if (CMAKE_VERSION VERSION_GREATER "3.0") # this does not work with 2.8
802: # Write the export set for build and install tree
803: install(EXPORT "${DUCKDB_EXPORT_SET}" DESTINATION "${INSTALL_CMAKE_DIR}")
804: export(EXPORT "${DUCKDB_EXPORT_SET}"
805:        FILE "${PROJECT_BINARY_DIR}/${DUCKDB_EXPORT_SET}.cmake")
806: 
807: # Only write the cmake package configuration if the templates exist
808: set(CMAKE_CONFIG_TEMPLATE "${CMAKE_SOURCE_DIR}/DuckDBConfig.cmake.in")
809: set(CMAKE_CONFIG_VERSION_TEMPLATE
810:     "${CMAKE_SOURCE_DIR}/DuckDBConfigVersion.cmake.in")
811: if(EXISTS ${CMAKE_CONFIG_TEMPLATE} AND EXISTS ${CMAKE_CONFIG_VERSION_TEMPLATE})
812: 
813:   # Configure cmake package config for the build tree
814:   set(CONF_INCLUDE_DIRS "${PROJECT_SOURCE_DIR}/src/include")
815:   configure_file(${CMAKE_CONFIG_TEMPLATE}
816:                  "${PROJECT_BINARY_DIR}/DuckDBConfig.cmake" @ONLY)
817: 
818:   # Configure cmake package config for the install tree
819:   file(RELATIVE_PATH REL_INCLUDE_DIR "${INSTALL_CMAKE_DIR}"
820:        "${INSTALL_INCLUDE_DIR}")
821:   set(CONF_INCLUDE_DIRS "\${DuckDB_CMAKE_DIR}/${REL_INCLUDE_DIR}")
822:   configure_file(
823:     ${CMAKE_CONFIG_TEMPLATE}
824:     "${PROJECT_BINARY_DIR}${CMAKE_FILES_DIRECTORY}/DuckDBConfig.cmake" @ONLY)
825: 
826:   # Configure cmake package version for build and install tree
827:   configure_file(${CMAKE_CONFIG_VERSION_TEMPLATE}
828:                  "${PROJECT_BINARY_DIR}/DuckDBConfigVersion.cmake" @ONLY)
829: 
830:   # Install the cmake package
831:   install(
832:     FILES "${PROJECT_BINARY_DIR}${CMAKE_FILES_DIRECTORY}/DuckDBConfig.cmake"
833:           "${PROJECT_BINARY_DIR}/DuckDBConfigVersion.cmake"
834:     DESTINATION "${INSTALL_CMAKE_DIR}")
835: endif()
836: 
837: endif()
838: 
839: # build out-of-tree extensions on demand
840: if(NOT "${EXTERNAL_EXTENSION_DIRECTORIES}" STREQUAL "")
841:   separate_arguments(EXTERNAL_EXTENSION_DIRECTORIES)
842: 
843:   foreach(EXTERNAL_EXTENSION_DIRECTORY IN LISTS EXTERNAL_EXTENSION_DIRECTORIES)
844: 
845:     # the build path seems to get ignored on windows in just the right way. no idea why.
846:     get_filename_component(EXTERNAL_EXTENSION_NAME ${EXTERNAL_EXTENSION_DIRECTORY} NAME)
847:     add_subdirectory(${EXTERNAL_EXTENSION_DIRECTORY} "extension/${EXTERNAL_EXTENSION_NAME}")
848:   endforeach()
849: endif()
[end of CMakeLists.txt]
[start of Makefile]
1: .PHONY: all opt unit clean debug release release_expanded test unittest allunit benchmark docs doxygen format sqlite imdb
2: 
3: all: release
4: opt: release
5: unit: unittest
6: imdb: third_party/imdb/data
7: 
8: GENERATOR=
9: FORCE_COLOR=
10: WARNINGS_AS_ERRORS=
11: FORCE_WARN_UNUSED_FLAG=
12: DISABLE_UNITY_FLAG=
13: DISABLE_SANITIZER_FLAG=
14: OSX_BUILD_UNIVERSAL_FLAG=
15: FORCE_32_BIT_FLAG=
16: ifeq ($(GEN),ninja)
17: 	GENERATOR=-G "Ninja"
18: 	FORCE_COLOR=-DFORCE_COLORED_OUTPUT=1
19: endif
20: ifeq (${TREAT_WARNINGS_AS_ERRORS}, 1)
21: 	WARNINGS_AS_ERRORS=-DTREAT_WARNINGS_AS_ERRORS=1
22: endif
23: ifeq (${OSX_BUILD_UNIVERSAL}, 1)
24: 	OSX_BUILD_UNIVERSAL_FLAG=-DOSX_BUILD_UNIVERSAL=1
25: endif
26: ifeq (${FORCE_32_BIT}, 1)
27: 	FORCE_32_BIT_FLAG=-DFORCE_32_BIT=1
28: endif
29: ifeq (${FORCE_WARN_UNUSED}, 1)
30: 	FORCE_WARN_UNUSED_FLAG=-DFORCE_WARN_UNUSED=1
31: endif
32: ifeq (${DISABLE_UNITY}, 1)
33: 	DISABLE_UNITY_FLAG=-DDISABLE_UNITY=1
34: endif
35: ifeq (${DISABLE_SANITIZER}, 1)
36: 	DISABLE_SANITIZER_FLAG=-DENABLE_SANITIZER=FALSE -DENABLE_UBSAN=0
37: endif
38: ifeq (${DISABLE_UBSAN}, 1)
39: 	DISABLE_SANITIZER_FLAG=-DENABLE_UBSAN=0
40: endif
41: ifeq (${DISABLE_VPTR_SANITIZER}, 1)
42: 	DISABLE_SANITIZER_FLAG:=${DISABLE_SANITIZER_FLAG} -DDISABLE_VPTR_SANITIZER=1
43: endif
44: ifeq (${FORCE_SANITIZER}, 1)
45: 	DISABLE_SANITIZER_FLAG:=${DISABLE_SANITIZER_FLAG} -DFORCE_SANITIZER=1
46: endif
47: ifeq (${THREADSAN}, 1)
48: 	DISABLE_SANITIZER_FLAG:=${DISABLE_SANITIZER_FLAG} -DENABLE_THREAD_SANITIZER=1
49: endif
50: ifeq (${STATIC_LIBCPP}, 1)
51: 	STATIC_LIBCPP=-DSTATIC_LIBCPP=TRUE
52: endif
53: EXTENSIONS=-DBUILD_PARQUET_EXTENSION=TRUE
54: ifeq (${DISABLE_PARQUET}, 1)
55: 	EXTENSIONS:=
56: endif
57: ifeq (${DISABLE_MAIN_DUCKDB_LIBRARY}, 1)
58: 	EXTENSIONS:=${EXTENSIONS} -DBUILD_MAIN_DUCKDB_LIBRARY=0
59: endif
60: ifeq (${EXTENSION_STATIC_BUILD}, 1)
61: 	EXTENSIONS:=${EXTENSIONS} -DEXTENSION_STATIC_BUILD=1
62: endif
63: ifeq (${DISABLE_BUILTIN_EXTENSIONS}, 1)
64: 	EXTENSIONS:=${EXTENSIONS} -DDISABLE_BUILTIN_EXTENSIONS=1
65: endif
66: ifeq (${BUILD_BENCHMARK}, 1)
67: 	EXTENSIONS:=${EXTENSIONS} -DBUILD_BENCHMARKS=1
68: endif
69: ifeq (${BUILD_ICU}, 1)
70: 	EXTENSIONS:=${EXTENSIONS} -DBUILD_ICU_EXTENSION=1
71: endif
72: ifeq (${BUILD_TPCH}, 1)
73: 	EXTENSIONS:=${EXTENSIONS} -DBUILD_TPCH_EXTENSION=1
74: endif
75: ifeq (${BUILD_TPCDS}, 1)
76: 	EXTENSIONS:=${EXTENSIONS} -DBUILD_TPCDS_EXTENSION=1
77: endif
78: ifeq (${BUILD_FTS}, 1)
79: 	EXTENSIONS:=${EXTENSIONS} -DBUILD_FTS_EXTENSION=1
80: endif
81: ifeq (${BUILD_VISUALIZER}, 1)
82: 	EXTENSIONS:=${EXTENSIONS} -DBUILD_VISUALIZER_EXTENSION=1
83: endif
84: ifeq (${BUILD_HTTPFS}, 1)
85: 	EXTENSIONS:=${EXTENSIONS} -DBUILD_HTTPFS_EXTENSION=1
86: endif
87: ifeq (${BUILD_JSON}, 1)
88: 	EXTENSIONS:=${EXTENSIONS} -DBUILD_JSON_EXTENSION=1
89: endif
90: ifeq (${BUILD_EXCEL}, 1)
91: 	EXTENSIONS:=${EXTENSIONS} -DBUILD_EXCEL_EXTENSION=1
92: endif
93: ifeq (${BUILD_INET}, 1)
94: 	EXTENSIONS:=${EXTENSIONS} -DBUILD_INET_EXTENSION=1
95: endif
96: ifeq (${STATIC_OPENSSL}, 1)
97: 	EXTENSIONS:=${EXTENSIONS} -DOPENSSL_USE_STATIC_LIBS=1
98: endif
99: ifeq (${BUILD_SQLSMITH}, 1)
100: 	EXTENSIONS:=${EXTENSIONS} -DBUILD_SQLSMITH_EXTENSION=1
101: endif
102: ifeq (${BUILD_TPCE}, 1)
103: 	EXTENSIONS:=${EXTENSIONS} -DBUILD_TPCE=1
104: endif
105: ifeq (${BUILD_JDBC}, 1)
106: 	EXTENSIONS:=${EXTENSIONS} -DJDBC_DRIVER=1
107: endif
108: ifneq ($(OVERRIDE_JDBC_OS_ARCH),)
109: 	EXTENSIONS:=${EXTENSIONS} -DOVERRIDE_JDBC_OS_ARCH=$(OVERRIDE_JDBC_OS_ARCH)
110: endif
111: ifeq (${BUILD_ODBC}, 1)
112: 	EXTENSIONS:=${EXTENSIONS} -DBUILD_ODBC_DRIVER=1
113: endif
114: ifneq ($(ODBC_CONFIG),)
115: 	EXTENSIONS:=${EXTENSIONS} -DODBC_CONFIG=${ODBC_CONFIG}
116: endif
117: ifeq (${BUILD_PYTHON}, 1)
118: 	EXTENSIONS:=${EXTENSIONS} -DBUILD_PYTHON=1 -DBUILD_JSON_EXTENSION=1 -DBUILD_FTS_EXTENSION=1 -DBUILD_TPCH_EXTENSION=1 -DBUILD_VISUALIZER_EXTENSION=1 -DBUILD_TPCDS_EXTENSION=1
119: endif
120: ifeq (${BUILD_R}, 1)
121: 	EXTENSIONS:=${EXTENSIONS} -DBUILD_R=1
122: endif
123: ifeq (${CONFIGURE_R}, 1)
124: 	EXTENSIONS:=${EXTENSIONS} -DCONFIGURE_R=1
125: endif
126: ifneq ($(TIDY_THREADS),)
127: 	TIDY_THREAD_PARAMETER := -j ${TIDY_THREADS}
128: endif
129: ifneq ($(TIDY_BINARY),)
130: 	TIDY_BINARY_PARAMETER := -clang-tidy-binary ${TIDY_BINARY}
131: endif
132: ifeq ($(BUILD_ARROW_ABI_TEST), 1)
133: 	EXTENSIONS:=${EXTENSIONS} -DBUILD_ARROW_ABI_TEST=1
134: endif
135: ifneq ("${FORCE_QUERY_LOG}a", "a")
136: 	EXTENSIONS:=${EXTENSIONS} -DFORCE_QUERY_LOG=${FORCE_QUERY_LOG}
137: endif
138: ifneq ($(BUILD_OUT_OF_TREE_EXTENSION),)
139: 	EXTENSIONS:=${EXTENSIONS} -DEXTERNAL_EXTENSION_DIRECTORIES="$(BUILD_OUT_OF_TREE_EXTENSION)"
140: endif
141: ifeq (${CRASH_ON_ASSERT}, 1)
142: 	EXTENSIONS:=${EXTENSIONS} -DASSERT_EXCEPTION=0
143: endif
144: 
145: clean:
146: 	rm -rf build
147: 
148: debug:
149: 	mkdir -p build/debug && \
150: 	cd build/debug && \
151: 	cmake $(GENERATOR) $(FORCE_COLOR) ${WARNINGS_AS_ERRORS} ${FORCE_32_BIT_FLAG} ${DISABLE_UNITY_FLAG} ${DISABLE_SANITIZER_FLAG} ${STATIC_LIBCPP} ${EXTENSIONS} -DCMAKE_BUILD_TYPE=Debug ../.. && \
152: 	cmake --build . --config Debug
153: 
154: release_expanded:
155: 	mkdir -p build/release_expanded && \
156: 	cd build/release_expanded && \
157: 	cmake $(GENERATOR) $(FORCE_COLOR) ${WARNINGS_AS_ERRORS} ${FORCE_WARN_UNUSED_FLAG} ${FORCE_32_BIT_FLAG} ${DISABLE_UNITY_FLAG} ${DISABLE_SANITIZER_FLAG} ${STATIC_LIBCPP} ${EXTENSIONS} -DCMAKE_BUILD_TYPE=Release ../.. && \
158: 	cmake --build . --config Release
159: 
160: cldebug:
161: 	mkdir -p build/cldebug && \
162: 	cd build/cldebug && \
163: 	cmake $(GENERATOR) $(FORCE_COLOR) ${WARNINGS_AS_ERRORS} ${FORCE_32_BIT_FLAG} ${DISABLE_UNITY_FLAG} ${EXTENSIONS} -DBUILD_PYTHON=1 -DBUILD_R=1 -DENABLE_SANITIZER=0 -DENABLE_UBSAN=0 -DCMAKE_BUILD_TYPE=Debug ../.. && \
164: 	cmake --build . --config Debug
165: 
166: clreldebug:
167: 	mkdir -p build/clreldebug && \
168: 	cd build/clreldebug && \
169: 	cmake $(GENERATOR) $(FORCE_COLOR) ${WARNINGS_AS_ERRORS} ${FORCE_32_BIT_FLAG} ${DISABLE_UNITY_FLAG} ${STATIC_LIBCPP} ${EXTENSIONS} -DBUILD_PYTHON=1 -DBUILD_R=1 -DBUILD_FTS_EXTENSION=1 -DENABLE_SANITIZER=0 -DENABLE_UBSAN=0 -DCMAKE_BUILD_TYPE=RelWithDebInfo ../.. && \
170: 	cmake --build . --config RelWithDebInfo
171: 
172: unittest: debug
173: 	build/debug/test/unittest
174: 	build/debug/tools/sqlite3_api_wrapper/test_sqlite3_api_wrapper
175: 
176: unittestci:
177: 	python3 scripts/run_tests_one_by_one.py build/debug/test/unittest
178: 	build/debug/tools/sqlite3_api_wrapper/test_sqlite3_api_wrapper
179: 
180: unittestarrow:
181: 	build/debug/test/unittest "[arrow]"
182: 
183: 
184: allunit: release_expanded # uses release build because otherwise allunit takes forever
185: 	build/release_expanded/test/unittest "*"
186: 
187: docs:
188: 	mkdir -p build/docs && \
189: 	doxygen Doxyfile
190: 
191: doxygen: docs
192: 	open build/docs/html/index.html
193: 
194: release:
195: 	mkdir -p build/release && \
196: 	cd build/release && \
197: 	cmake $(GENERATOR) $(FORCE_COLOR) ${WARNINGS_AS_ERRORS} ${FORCE_WARN_UNUSED_FLAG} ${FORCE_32_BIT_FLAG} ${DISABLE_UNITY_FLAG} ${DISABLE_SANITIZER_FLAG} ${OSX_BUILD_UNIVERSAL_FLAG} ${STATIC_LIBCPP} ${EXTENSIONS} -DCMAKE_BUILD_TYPE=Release ../.. && \
198: 	cmake --build . --config Release
199: 
200: reldebug:
201: 	mkdir -p build/reldebug && \
202: 	cd build/reldebug && \
203: 	cmake $(GENERATOR) $(FORCE_COLOR) ${WARNINGS_AS_ERRORS} ${FORCE_32_BIT_FLAG} ${DISABLE_UNITY_FLAG} ${DISABLE_SANITIZER_FLAG}  ${STATIC_LIBCPP} ${EXTENSIONS} -DCMAKE_BUILD_TYPE=RelWithDebInfo ../.. && \
204: 	cmake --build . --config RelWithDebInfo
205: 
206: relassert:
207: 	mkdir -p build/relassert && \
208: 	cd build/relassert && \
209: 	cmake $(GENERATOR) $(FORCE_COLOR) ${WARNINGS_AS_ERRORS} ${FORCE_32_BIT_FLAG} ${DISABLE_UNITY_FLAG} ${DISABLE_SANITIZER_FLAG} ${STATIC_LIBCPP} ${EXTENSIONS} -DFORCE_ASSERT=1 -DCMAKE_BUILD_TYPE=RelWithDebInfo ../.. && \
210: 	cmake --build . --config RelWithDebInfo
211: 
212: benchmark:
213: 	mkdir -p build/release && \
214: 	cd build/release && \
215: 	cmake $(GENERATOR) $(FORCE_COLOR) ${WARNINGS_AS_ERRORS} ${FORCE_WARN_UNUSED_FLAG} ${FORCE_32_BIT_FLAG} ${DISABLE_UNITY_FLAG} ${DISABLE_SANITIZER_FLAG} ${OSX_BUILD_UNIVERSAL_FLAG} ${STATIC_LIBCPP} ${EXTENSIONS} -DBUILD_BENCHMARKS=1 -DCMAKE_BUILD_TYPE=Release ../.. && \
216: 	cmake --build . --config Release
217: 
218: amaldebug:
219: 	mkdir -p build/amaldebug && \
220: 	python scripts/amalgamation.py && \
221: 	cd build/amaldebug && \
222: 	cmake $(GENERATOR) $(FORCE_COLOR) ${STATIC_LIBCPP} ${EXTENSIONS} ${FORCE_32_BIT_FLAG} -DAMALGAMATION_BUILD=1 -DCMAKE_BUILD_TYPE=Debug ../.. && \
223: 	cmake --build . --config Debug
224: 
225: tidy-check:
226: 	mkdir -p build/tidy && \
227: 	cd build/tidy && \
228: 	cmake -DCLANG_TIDY=1 -DDISABLE_UNITY=1 -DBUILD_ODBC_DRIVER=TRUE -DBUILD_PARQUET_EXTENSION=TRUE -DBUILD_PYTHON_PKG=TRUE -DBUILD_SHELL=0 -DCMAKE_EXPORT_COMPILE_COMMANDS=ON ../.. && \
229: 	python3 ../../scripts/run-clang-tidy.py -quiet ${TIDY_THREAD_PARAMETER} ${TIDY_BINARY_PARAMETER}
230: 
231: tidy-fix:
232: 	mkdir -p build/tidy && \
233: 	cd build/tidy && \
234: 	cmake -DCLANG_TIDY=1 -DDISABLE_UNITY=1 -DBUILD_PARQUET_EXTENSION=TRUE -DBUILD_SHELL=0 -DCMAKE_EXPORT_COMPILE_COMMANDS=ON ../.. && \
235: 	python3 ../../scripts/run-clang-tidy.py -fix
236: 
237: test_compile: # test compilation of individual cpp files
238: 	python scripts/amalgamation.py --compile
239: 
240: format-check:
241: 	python3 scripts/format.py --all --check
242: 
243: format-check-silent:
244: 	python3 scripts/format.py --all --check --silent
245: 
246: format-fix:
247: 	rm -rf src/amalgamation/*
248: 	python3 scripts/format.py --all --fix --noconfirm
249: 
250: format-head:
251: 	python3 scripts/format.py HEAD --fix --noconfirm
252: 
253: format-changes:
254: 	python3 scripts/format.py HEAD --fix --noconfirm
255: 
256: format-master:
257: 	python3 scripts/format.py master --fix --noconfirm
258: 
259: third_party/sqllogictest:
260: 	git clone --depth=1 --branch hawkfish-statistical-rounding https://github.com/cwida/sqllogictest.git third_party/sqllogictest
261: 
262: third_party/imdb/data:
263: 	wget -i "http://download.duckdb.org/imdb/list.txt" -P third_party/imdb/data
264: 
265: sqlite: release_expanded | third_party/sqllogictest
266: 	git --git-dir third_party/sqllogictest/.git pull
267: 	./build/release_expanded/test/unittest "[sqlitelogic]"
268: 
269: sqlsmith: debug
270: 	./build/debug/third_party/sqlsmith/sqlsmith --duckdb=:memory:
271: 
272: clangd:
273: 	cmake -DCMAKE_BUILD_TYPE=Debug -DCMAKE_EXPORT_COMPILE_COMMANDS=1 ${EXTENSIONS} -B build/clangd .
[end of Makefile]
[start of src/common/row_operations/row_external.cpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/common/types/row_operations/row_external.cpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: #include "duckdb/common/row_operations/row_operations.hpp"
9: #include "duckdb/common/types/row_layout.hpp"
10: 
11: namespace duckdb {
12: 
13: using ValidityBytes = RowLayout::ValidityBytes;
14: 
15: void RowOperations::SwizzleColumns(const RowLayout &layout, const data_ptr_t base_row_ptr, const idx_t count) {
16: 	const idx_t row_width = layout.GetRowWidth();
17: 	data_ptr_t heap_row_ptrs[STANDARD_VECTOR_SIZE];
18: 	idx_t done = 0;
19: 	while (done != count) {
20: 		const idx_t next = MinValue<idx_t>(count - done, STANDARD_VECTOR_SIZE);
21: 		const data_ptr_t row_ptr = base_row_ptr + done * row_width;
22: 		// Load heap row pointers
23: 		data_ptr_t heap_ptr_ptr = row_ptr + layout.GetHeapOffset();
24: 		for (idx_t i = 0; i < next; i++) {
25: 			heap_row_ptrs[i] = Load<data_ptr_t>(heap_ptr_ptr);
26: 			heap_ptr_ptr += row_width;
27: 		}
28: 		// Loop through the blob columns
29: 		for (idx_t col_idx = 0; col_idx < layout.ColumnCount(); col_idx++) {
30: 			auto physical_type = layout.GetTypes()[col_idx].InternalType();
31: 			if (TypeIsConstantSize(physical_type)) {
32: 				continue;
33: 			}
34: 			data_ptr_t col_ptr = row_ptr + layout.GetOffsets()[col_idx];
35: 			if (physical_type == PhysicalType::VARCHAR) {
36: 				data_ptr_t string_ptr = col_ptr + sizeof(uint32_t) + string_t::PREFIX_LENGTH;
37: 				for (idx_t i = 0; i < next; i++) {
38: 					if (Load<uint32_t>(col_ptr) > string_t::INLINE_LENGTH) {
39: 						// Overwrite the string pointer with the within-row offset (if not inlined)
40: 						Store<idx_t>(Load<data_ptr_t>(string_ptr) - heap_row_ptrs[i], string_ptr);
41: 					}
42: 					col_ptr += row_width;
43: 					string_ptr += row_width;
44: 				}
45: 			} else {
46: 				// Non-varchar blob columns
47: 				for (idx_t i = 0; i < next; i++) {
48: 					// Overwrite the column data pointer with the within-row offset
49: 					Store<idx_t>(Load<data_ptr_t>(col_ptr) - heap_row_ptrs[i], col_ptr);
50: 					col_ptr += row_width;
51: 				}
52: 			}
53: 		}
54: 		done += next;
55: 	}
56: }
57: 
58: void RowOperations::SwizzleHeapPointer(const RowLayout &layout, data_ptr_t row_ptr, const data_ptr_t heap_base_ptr,
59:                                        const idx_t count, const idx_t base_offset) {
60: 	const idx_t row_width = layout.GetRowWidth();
61: 	row_ptr += layout.GetHeapOffset();
62: 	idx_t cumulative_offset = 0;
63: 	for (idx_t i = 0; i < count; i++) {
64: 		Store<idx_t>(base_offset + cumulative_offset, row_ptr);
65: 		cumulative_offset += Load<uint32_t>(heap_base_ptr + cumulative_offset);
66: 		row_ptr += row_width;
67: 	}
68: }
69: 
70: void RowOperations::CopyHeapAndSwizzle(const RowLayout &layout, data_ptr_t row_ptr, const data_ptr_t heap_base_ptr,
71:                                        data_ptr_t heap_ptr, const idx_t count) {
72: 	const auto row_width = layout.GetRowWidth();
73: 	const auto heap_offset = layout.GetHeapOffset();
74: 	for (idx_t i = 0; i < count; i++) {
75: 		// Figure out source and size
76: 		const auto source_heap_ptr = Load<data_ptr_t>(row_ptr + heap_offset);
77: 		const auto size = Load<uint32_t>(source_heap_ptr);
78: 		D_ASSERT(size >= sizeof(uint32_t));
79: 
80: 		// Copy and swizzle
81: 		memcpy(heap_ptr, source_heap_ptr, size);
82: 		Store<idx_t>(heap_ptr - heap_base_ptr, row_ptr + heap_offset);
83: 
84: 		// Increment for next iteration
85: 		row_ptr += row_width;
86: 		heap_ptr += size;
87: 	}
88: }
89: 
90: void RowOperations::UnswizzleHeapPointer(const RowLayout &layout, const data_ptr_t base_row_ptr,
91:                                          const data_ptr_t base_heap_ptr, const idx_t count) {
92: 	const auto row_width = layout.GetRowWidth();
93: 	data_ptr_t heap_ptr_ptr = base_row_ptr + layout.GetHeapOffset();
94: 	for (idx_t i = 0; i < count; i++) {
95: 		Store<data_ptr_t>(base_heap_ptr + Load<idx_t>(heap_ptr_ptr), heap_ptr_ptr);
96: 		heap_ptr_ptr += row_width;
97: 	}
98: }
99: 
100: static inline void VerifyUnswizzledString(const RowLayout &layout, const idx_t &col_idx, const data_ptr_t &row_ptr) {
101: #ifdef DEBUG
102: 	if (layout.GetTypes()[col_idx] == LogicalTypeId::BLOB) {
103: 		return;
104: 	}
105: 	idx_t entry_idx;
106: 	idx_t idx_in_entry;
107: 	ValidityBytes::GetEntryIndex(col_idx, entry_idx, idx_in_entry);
108: 
109: 	ValidityBytes row_mask(row_ptr);
110: 	if (row_mask.RowIsValid(row_mask.GetValidityEntry(entry_idx), idx_in_entry)) {
111: 		auto str = Load<string_t>(row_ptr + layout.GetOffsets()[col_idx]);
112: 		str.Verify();
113: 	}
114: #endif
115: }
116: 
117: void RowOperations::UnswizzlePointers(const RowLayout &layout, const data_ptr_t base_row_ptr,
118:                                       const data_ptr_t base_heap_ptr, const idx_t count) {
119: 	const idx_t row_width = layout.GetRowWidth();
120: 	data_ptr_t heap_row_ptrs[STANDARD_VECTOR_SIZE];
121: 	idx_t done = 0;
122: 	while (done != count) {
123: 		const idx_t next = MinValue<idx_t>(count - done, STANDARD_VECTOR_SIZE);
124: 		const data_ptr_t row_ptr = base_row_ptr + done * row_width;
125: 		// Restore heap row pointers
126: 		data_ptr_t heap_ptr_ptr = row_ptr + layout.GetHeapOffset();
127: 		for (idx_t i = 0; i < next; i++) {
128: 			heap_row_ptrs[i] = base_heap_ptr + Load<idx_t>(heap_ptr_ptr);
129: 			Store<data_ptr_t>(heap_row_ptrs[i], heap_ptr_ptr);
130: 			heap_ptr_ptr += row_width;
131: 		}
132: 		// Loop through the blob columns
133: 		for (idx_t col_idx = 0; col_idx < layout.ColumnCount(); col_idx++) {
134: 			auto physical_type = layout.GetTypes()[col_idx].InternalType();
135: 			if (TypeIsConstantSize(physical_type)) {
136: 				continue;
137: 			}
138: 			data_ptr_t col_ptr = row_ptr + layout.GetOffsets()[col_idx];
139: 			if (physical_type == PhysicalType::VARCHAR) {
140: 				data_ptr_t string_ptr = col_ptr + sizeof(uint32_t) + string_t::PREFIX_LENGTH;
141: 				for (idx_t i = 0; i < next; i++) {
142: 					if (Load<uint32_t>(col_ptr) > string_t::INLINE_LENGTH) {
143: 						// Overwrite the string offset with the pointer (if not inlined)
144: 						Store<data_ptr_t>(heap_row_ptrs[i] + Load<idx_t>(string_ptr), string_ptr);
145: 						VerifyUnswizzledString(layout, col_idx, row_ptr + i * row_width);
146: 					}
147: 					col_ptr += row_width;
148: 					string_ptr += row_width;
149: 				}
150: 			} else {
151: 				// Non-varchar blob columns
152: 				for (idx_t i = 0; i < next; i++) {
153: 					// Overwrite the column data offset with the pointer
154: 					Store<data_ptr_t>(heap_row_ptrs[i] + Load<idx_t>(col_ptr), col_ptr);
155: 					col_ptr += row_width;
156: 				}
157: 			}
158: 		}
159: 		done += next;
160: 	}
161: }
162: 
163: } // namespace duckdb
[end of src/common/row_operations/row_external.cpp]
[start of src/common/row_operations/row_gather.cpp]
1: //===--------------------------------------------------------------------===//
2: // row_gather.cpp
3: // Description: This file contains the implementation of the gather operators
4: //===--------------------------------------------------------------------===//
5: 
6: #include "duckdb/common/exception.hpp"
7: #include "duckdb/common/operator/constant_operators.hpp"
8: #include "duckdb/common/row_operations/row_operations.hpp"
9: #include "duckdb/common/types/row_data_collection.hpp"
10: #include "duckdb/common/types/row_layout.hpp"
11: 
12: namespace duckdb {
13: 
14: using ValidityBytes = RowLayout::ValidityBytes;
15: 
16: template <class T>
17: static void TemplatedGatherLoop(Vector &rows, const SelectionVector &row_sel, Vector &col,
18:                                 const SelectionVector &col_sel, idx_t count, const RowLayout &layout, idx_t col_no,
19:                                 idx_t build_size) {
20: 	// Precompute mask indexes
21: 	const auto &offsets = layout.GetOffsets();
22: 	const auto col_offset = offsets[col_no];
23: 	idx_t entry_idx;
24: 	idx_t idx_in_entry;
25: 	ValidityBytes::GetEntryIndex(col_no, entry_idx, idx_in_entry);
26: 
27: 	auto ptrs = FlatVector::GetData<data_ptr_t>(rows);
28: 	auto data = FlatVector::GetData<T>(col);
29: 	auto &col_mask = FlatVector::Validity(col);
30: 
31: 	for (idx_t i = 0; i < count; i++) {
32: 		auto row_idx = row_sel.get_index(i);
33: 		auto row = ptrs[row_idx];
34: 		auto col_idx = col_sel.get_index(i);
35: 		data[col_idx] = Load<T>(row + col_offset);
36: 		ValidityBytes row_mask(row);
37: 		if (!row_mask.RowIsValid(row_mask.GetValidityEntry(entry_idx), idx_in_entry)) {
38: 			if (build_size > STANDARD_VECTOR_SIZE && col_mask.AllValid()) {
39: 				//! We need to initialize the mask with the vector size.
40: 				col_mask.Initialize(build_size);
41: 			}
42: 			col_mask.SetInvalid(col_idx);
43: 		}
44: 	}
45: }
46: 
47: static void GatherVarchar(Vector &rows, const SelectionVector &row_sel, Vector &col, const SelectionVector &col_sel,
48:                           idx_t count, const RowLayout &layout, idx_t col_no, idx_t build_size,
49:                           data_ptr_t base_heap_ptr) {
50: 	// Precompute mask indexes
51: 	const auto &offsets = layout.GetOffsets();
52: 	const auto col_offset = offsets[col_no];
53: 	const auto heap_offset = layout.GetHeapOffset();
54: 	idx_t entry_idx;
55: 	idx_t idx_in_entry;
56: 	ValidityBytes::GetEntryIndex(col_no, entry_idx, idx_in_entry);
57: 
58: 	auto ptrs = FlatVector::GetData<data_ptr_t>(rows);
59: 	auto data = FlatVector::GetData<string_t>(col);
60: 	auto &col_mask = FlatVector::Validity(col);
61: 
62: 	for (idx_t i = 0; i < count; i++) {
63: 		auto row_idx = row_sel.get_index(i);
64: 		auto row = ptrs[row_idx];
65: 		auto col_idx = col_sel.get_index(i);
66: 		auto col_ptr = row + col_offset;
67: 		data[col_idx] = Load<string_t>(col_ptr);
68: 		ValidityBytes row_mask(row);
69: 		if (!row_mask.RowIsValid(row_mask.GetValidityEntry(entry_idx), idx_in_entry)) {
70: 			if (build_size > STANDARD_VECTOR_SIZE && col_mask.AllValid()) {
71: 				//! We need to initialize the mask with the vector size.
72: 				col_mask.Initialize(build_size);
73: 			}
74: 			col_mask.SetInvalid(col_idx);
75: 		} else if (base_heap_ptr && Load<uint32_t>(col_ptr) > string_t::INLINE_LENGTH) {
76: 			//	Not inline, so unswizzle the copied pointer the pointer
77: 			auto heap_ptr_ptr = row + heap_offset;
78: 			auto heap_row_ptr = base_heap_ptr + Load<idx_t>(heap_ptr_ptr);
79: 			auto string_ptr = data_ptr_t(data + col_idx) + sizeof(uint32_t) + string_t::PREFIX_LENGTH;
80: 			Store<data_ptr_t>(heap_row_ptr + Load<idx_t>(string_ptr), string_ptr);
81: #ifdef DEBUG
82: 			data[col_idx].Verify();
83: #endif
84: 		}
85: 	}
86: }
87: 
88: static void GatherNestedVector(Vector &rows, const SelectionVector &row_sel, Vector &col,
89:                                const SelectionVector &col_sel, idx_t count, const RowLayout &layout, idx_t col_no,
90:                                data_ptr_t base_heap_ptr) {
91: 	const auto &offsets = layout.GetOffsets();
92: 	const auto col_offset = offsets[col_no];
93: 	const auto heap_offset = layout.GetHeapOffset();
94: 	auto ptrs = FlatVector::GetData<data_ptr_t>(rows);
95: 
96: 	// Build the gather locations
97: 	auto data_locations = unique_ptr<data_ptr_t[]>(new data_ptr_t[count]);
98: 	auto mask_locations = unique_ptr<data_ptr_t[]>(new data_ptr_t[count]);
99: 	for (idx_t i = 0; i < count; i++) {
100: 		auto row_idx = row_sel.get_index(i);
101: 		auto row = ptrs[row_idx];
102: 		mask_locations[i] = row;
103: 		auto col_ptr = ptrs[row_idx] + col_offset;
104: 		if (base_heap_ptr) {
105: 			auto heap_ptr_ptr = row + heap_offset;
106: 			auto heap_row_ptr = base_heap_ptr + Load<idx_t>(heap_ptr_ptr);
107: 			data_locations[i] = heap_row_ptr + Load<idx_t>(col_ptr);
108: 		} else {
109: 			data_locations[i] = Load<data_ptr_t>(col_ptr);
110: 		}
111: 	}
112: 
113: 	// Deserialise into the selected locations
114: 	RowOperations::HeapGather(col, count, col_sel, col_no, data_locations.get(), mask_locations.get());
115: }
116: 
117: void RowOperations::Gather(Vector &rows, const SelectionVector &row_sel, Vector &col, const SelectionVector &col_sel,
118:                            const idx_t count, const RowLayout &layout, const idx_t col_no, const idx_t build_size,
119:                            data_ptr_t heap_ptr) {
120: 	D_ASSERT(rows.GetVectorType() == VectorType::FLAT_VECTOR);
121: 	D_ASSERT(rows.GetType().id() == LogicalTypeId::POINTER); // "Cannot gather from non-pointer type!"
122: 
123: 	col.SetVectorType(VectorType::FLAT_VECTOR);
124: 	switch (col.GetType().InternalType()) {
125: 	case PhysicalType::UINT8:
126: 		TemplatedGatherLoop<uint8_t>(rows, row_sel, col, col_sel, count, layout, col_no, build_size);
127: 		break;
128: 	case PhysicalType::UINT16:
129: 		TemplatedGatherLoop<uint16_t>(rows, row_sel, col, col_sel, count, layout, col_no, build_size);
130: 		break;
131: 	case PhysicalType::UINT32:
132: 		TemplatedGatherLoop<uint32_t>(rows, row_sel, col, col_sel, count, layout, col_no, build_size);
133: 		break;
134: 	case PhysicalType::UINT64:
135: 		TemplatedGatherLoop<uint64_t>(rows, row_sel, col, col_sel, count, layout, col_no, build_size);
136: 		break;
137: 	case PhysicalType::BOOL:
138: 	case PhysicalType::INT8:
139: 		TemplatedGatherLoop<int8_t>(rows, row_sel, col, col_sel, count, layout, col_no, build_size);
140: 		break;
141: 	case PhysicalType::INT16:
142: 		TemplatedGatherLoop<int16_t>(rows, row_sel, col, col_sel, count, layout, col_no, build_size);
143: 		break;
144: 	case PhysicalType::INT32:
145: 		TemplatedGatherLoop<int32_t>(rows, row_sel, col, col_sel, count, layout, col_no, build_size);
146: 		break;
147: 	case PhysicalType::INT64:
148: 		TemplatedGatherLoop<int64_t>(rows, row_sel, col, col_sel, count, layout, col_no, build_size);
149: 		break;
150: 	case PhysicalType::INT128:
151: 		TemplatedGatherLoop<hugeint_t>(rows, row_sel, col, col_sel, count, layout, col_no, build_size);
152: 		break;
153: 	case PhysicalType::FLOAT:
154: 		TemplatedGatherLoop<float>(rows, row_sel, col, col_sel, count, layout, col_no, build_size);
155: 		break;
156: 	case PhysicalType::DOUBLE:
157: 		TemplatedGatherLoop<double>(rows, row_sel, col, col_sel, count, layout, col_no, build_size);
158: 		break;
159: 	case PhysicalType::INTERVAL:
160: 		TemplatedGatherLoop<interval_t>(rows, row_sel, col, col_sel, count, layout, col_no, build_size);
161: 		break;
162: 	case PhysicalType::VARCHAR:
163: 		GatherVarchar(rows, row_sel, col, col_sel, count, layout, col_no, build_size, heap_ptr);
164: 		break;
165: 	case PhysicalType::LIST:
166: 	case PhysicalType::MAP:
167: 	case PhysicalType::STRUCT:
168: 		GatherNestedVector(rows, row_sel, col, col_sel, count, layout, col_no, heap_ptr);
169: 		break;
170: 	default:
171: 		throw InternalException("Unimplemented type for RowOperations::Gather");
172: 	}
173: }
174: 
175: template <class T>
176: static void TemplatedFullScanLoop(Vector &rows, Vector &col, idx_t count, idx_t col_offset, idx_t col_no) {
177: 	// Precompute mask indexes
178: 	idx_t entry_idx;
179: 	idx_t idx_in_entry;
180: 	ValidityBytes::GetEntryIndex(col_no, entry_idx, idx_in_entry);
181: 
182: 	auto ptrs = FlatVector::GetData<data_ptr_t>(rows);
183: 	auto data = FlatVector::GetData<T>(col);
184: 	//	auto &col_mask = FlatVector::Validity(col);
185: 
186: 	for (idx_t i = 0; i < count; i++) {
187: 		auto row = ptrs[i];
188: 		data[i] = Load<T>(row + col_offset);
189: 		ValidityBytes row_mask(row);
190: 		if (!row_mask.RowIsValid(row_mask.GetValidityEntry(entry_idx), idx_in_entry)) {
191: 			throw InternalException("Null value comparisons not implemented for perfect hash table yet");
192: 			//			col_mask.SetInvalid(i);
193: 		}
194: 	}
195: }
196: 
197: void RowOperations::FullScanColumn(const RowLayout &layout, Vector &rows, Vector &col, idx_t count, idx_t col_no) {
198: 	const auto col_offset = layout.GetOffsets()[col_no];
199: 	col.SetVectorType(VectorType::FLAT_VECTOR);
200: 	switch (col.GetType().InternalType()) {
201: 	case PhysicalType::UINT8:
202: 		TemplatedFullScanLoop<uint8_t>(rows, col, count, col_offset, col_no);
203: 		break;
204: 	case PhysicalType::UINT16:
205: 		TemplatedFullScanLoop<uint16_t>(rows, col, count, col_offset, col_no);
206: 		break;
207: 	case PhysicalType::UINT32:
208: 		TemplatedFullScanLoop<uint32_t>(rows, col, count, col_offset, col_no);
209: 		break;
210: 	case PhysicalType::UINT64:
211: 		TemplatedFullScanLoop<uint64_t>(rows, col, count, col_offset, col_no);
212: 		break;
213: 	case PhysicalType::INT8:
214: 		TemplatedFullScanLoop<int8_t>(rows, col, count, col_offset, col_no);
215: 		break;
216: 	case PhysicalType::INT16:
217: 		TemplatedFullScanLoop<int16_t>(rows, col, count, col_offset, col_no);
218: 		break;
219: 	case PhysicalType::INT32:
220: 		TemplatedFullScanLoop<int32_t>(rows, col, count, col_offset, col_no);
221: 		break;
222: 	case PhysicalType::INT64:
223: 		TemplatedFullScanLoop<int64_t>(rows, col, count, col_offset, col_no);
224: 		break;
225: 	default:
226: 		throw NotImplementedException("Unimplemented type for RowOperations::FullScanColumn");
227: 	}
228: }
229: 
230: } // namespace duckdb
[end of src/common/row_operations/row_gather.cpp]
[start of src/common/sort/comparators.cpp]
1: #include "duckdb/common/sort/comparators.hpp"
2: 
3: #include "duckdb/common/fast_mem.hpp"
4: #include "duckdb/common/sort/sort.hpp"
5: 
6: namespace duckdb {
7: 
8: bool Comparators::TieIsBreakable(const idx_t &tie_col, const data_ptr_t &row_ptr, const SortLayout &sort_layout) {
9: 	const auto &col_idx = sort_layout.sorting_to_blob_col.at(tie_col);
10: 	// Check if the blob is NULL
11: 	ValidityBytes row_mask(row_ptr);
12: 	idx_t entry_idx;
13: 	idx_t idx_in_entry;
14: 	ValidityBytes::GetEntryIndex(col_idx, entry_idx, idx_in_entry);
15: 	if (!row_mask.RowIsValid(row_mask.GetValidityEntry(entry_idx), idx_in_entry)) {
16: 		// Can't break a NULL tie
17: 		return false;
18: 	}
19: 	auto &row_layout = sort_layout.blob_layout;
20: 	if (row_layout.GetTypes()[col_idx].InternalType() != PhysicalType::VARCHAR) {
21: 		// Nested type, must be broken
22: 		return true;
23: 	}
24: 	const auto &tie_col_offset = row_layout.GetOffsets()[col_idx];
25: 	auto tie_string = Load<string_t>(row_ptr + tie_col_offset);
26: 	if (tie_string.GetSize() < sort_layout.prefix_lengths[tie_col]) {
27: 		// No need to break the tie - we already compared the full string
28: 		return false;
29: 	}
30: 	return true;
31: }
32: 
33: int Comparators::CompareTuple(const SBScanState &left, const SBScanState &right, const data_ptr_t &l_ptr,
34:                               const data_ptr_t &r_ptr, const SortLayout &sort_layout, const bool &external_sort) {
35: 	// Compare the sorting columns one by one
36: 	int comp_res = 0;
37: 	data_ptr_t l_ptr_offset = l_ptr;
38: 	data_ptr_t r_ptr_offset = r_ptr;
39: 	for (idx_t col_idx = 0; col_idx < sort_layout.column_count; col_idx++) {
40: 		comp_res = FastMemcmp(l_ptr_offset, r_ptr_offset, sort_layout.column_sizes[col_idx]);
41: 		if (comp_res == 0 && !sort_layout.constant_size[col_idx]) {
42: 			comp_res = BreakBlobTie(col_idx, left, right, sort_layout, external_sort);
43: 		}
44: 		if (comp_res != 0) {
45: 			break;
46: 		}
47: 		l_ptr_offset += sort_layout.column_sizes[col_idx];
48: 		r_ptr_offset += sort_layout.column_sizes[col_idx];
49: 	}
50: 	return comp_res;
51: }
52: 
53: int Comparators::CompareVal(const data_ptr_t l_ptr, const data_ptr_t r_ptr, const LogicalType &type) {
54: 	switch (type.InternalType()) {
55: 	case PhysicalType::VARCHAR:
56: 		return TemplatedCompareVal<string_t>(l_ptr, r_ptr);
57: 	case PhysicalType::LIST:
58: 	case PhysicalType::STRUCT: {
59: 		auto l_nested_ptr = Load<data_ptr_t>(l_ptr);
60: 		auto r_nested_ptr = Load<data_ptr_t>(r_ptr);
61: 		return CompareValAndAdvance(l_nested_ptr, r_nested_ptr, type);
62: 	}
63: 	default:
64: 		throw NotImplementedException("Unimplemented CompareVal for type %s", type.ToString());
65: 	}
66: }
67: 
68: int Comparators::BreakBlobTie(const idx_t &tie_col, const SBScanState &left, const SBScanState &right,
69:                               const SortLayout &sort_layout, const bool &external) {
70: 	data_ptr_t l_data_ptr = left.DataPtr(*left.sb->blob_sorting_data);
71: 	data_ptr_t r_data_ptr = right.DataPtr(*right.sb->blob_sorting_data);
72: 	if (!TieIsBreakable(tie_col, l_data_ptr, sort_layout)) {
73: 		// Quick check to see if ties can be broken
74: 		return 0;
75: 	}
76: 	// Align the pointers
77: 	const idx_t &col_idx = sort_layout.sorting_to_blob_col.at(tie_col);
78: 	const auto &tie_col_offset = sort_layout.blob_layout.GetOffsets()[col_idx];
79: 	l_data_ptr += tie_col_offset;
80: 	r_data_ptr += tie_col_offset;
81: 	// Do the comparison
82: 	const int order = sort_layout.order_types[tie_col] == OrderType::DESCENDING ? -1 : 1;
83: 	const auto &type = sort_layout.blob_layout.GetTypes()[col_idx];
84: 	int result;
85: 	if (external) {
86: 		// Store heap pointers
87: 		data_ptr_t l_heap_ptr = left.HeapPtr(*left.sb->blob_sorting_data);
88: 		data_ptr_t r_heap_ptr = right.HeapPtr(*right.sb->blob_sorting_data);
89: 		// Unswizzle offset to pointer
90: 		UnswizzleSingleValue(l_data_ptr, l_heap_ptr, type);
91: 		UnswizzleSingleValue(r_data_ptr, r_heap_ptr, type);
92: 		// Compare
93: 		result = CompareVal(l_data_ptr, r_data_ptr, type);
94: 		// Swizzle the pointers back to offsets
95: 		SwizzleSingleValue(l_data_ptr, l_heap_ptr, type);
96: 		SwizzleSingleValue(r_data_ptr, r_heap_ptr, type);
97: 	} else {
98: 		result = CompareVal(l_data_ptr, r_data_ptr, type);
99: 	}
100: 	return order * result;
101: }
102: 
103: template <class T>
104: int Comparators::TemplatedCompareVal(const data_ptr_t &left_ptr, const data_ptr_t &right_ptr) {
105: 	const auto left_val = Load<T>(left_ptr);
106: 	const auto right_val = Load<T>(right_ptr);
107: 	if (Equals::Operation<T>(left_val, right_val)) {
108: 		return 0;
109: 	} else if (LessThan::Operation<T>(left_val, right_val)) {
110: 		return -1;
111: 	} else {
112: 		return 1;
113: 	}
114: }
115: 
116: int Comparators::CompareValAndAdvance(data_ptr_t &l_ptr, data_ptr_t &r_ptr, const LogicalType &type) {
117: 	switch (type.InternalType()) {
118: 	case PhysicalType::BOOL:
119: 	case PhysicalType::INT8:
120: 		return TemplatedCompareAndAdvance<int8_t>(l_ptr, r_ptr);
121: 	case PhysicalType::INT16:
122: 		return TemplatedCompareAndAdvance<int16_t>(l_ptr, r_ptr);
123: 	case PhysicalType::INT32:
124: 		return TemplatedCompareAndAdvance<int32_t>(l_ptr, r_ptr);
125: 	case PhysicalType::INT64:
126: 		return TemplatedCompareAndAdvance<int64_t>(l_ptr, r_ptr);
127: 	case PhysicalType::UINT8:
128: 		return TemplatedCompareAndAdvance<uint8_t>(l_ptr, r_ptr);
129: 	case PhysicalType::UINT16:
130: 		return TemplatedCompareAndAdvance<uint16_t>(l_ptr, r_ptr);
131: 	case PhysicalType::UINT32:
132: 		return TemplatedCompareAndAdvance<uint32_t>(l_ptr, r_ptr);
133: 	case PhysicalType::UINT64:
134: 		return TemplatedCompareAndAdvance<uint64_t>(l_ptr, r_ptr);
135: 	case PhysicalType::INT128:
136: 		return TemplatedCompareAndAdvance<hugeint_t>(l_ptr, r_ptr);
137: 	case PhysicalType::FLOAT:
138: 		return TemplatedCompareAndAdvance<float>(l_ptr, r_ptr);
139: 	case PhysicalType::DOUBLE:
140: 		return TemplatedCompareAndAdvance<double>(l_ptr, r_ptr);
141: 	case PhysicalType::INTERVAL:
142: 		return TemplatedCompareAndAdvance<interval_t>(l_ptr, r_ptr);
143: 	case PhysicalType::VARCHAR:
144: 		return CompareStringAndAdvance(l_ptr, r_ptr);
145: 	case PhysicalType::LIST:
146: 		return CompareListAndAdvance(l_ptr, r_ptr, ListType::GetChildType(type));
147: 	case PhysicalType::STRUCT:
148: 		return CompareStructAndAdvance(l_ptr, r_ptr, StructType::GetChildTypes(type));
149: 	default:
150: 		throw NotImplementedException("Unimplemented CompareValAndAdvance for type %s", type.ToString());
151: 	}
152: }
153: 
154: template <class T>
155: int Comparators::TemplatedCompareAndAdvance(data_ptr_t &left_ptr, data_ptr_t &right_ptr) {
156: 	auto result = TemplatedCompareVal<T>(left_ptr, right_ptr);
157: 	left_ptr += sizeof(T);
158: 	right_ptr += sizeof(T);
159: 	return result;
160: }
161: 
162: int Comparators::CompareStringAndAdvance(data_ptr_t &left_ptr, data_ptr_t &right_ptr) {
163: 	// Construct the string_t
164: 	uint32_t left_string_size = Load<uint32_t>(left_ptr);
165: 	uint32_t right_string_size = Load<uint32_t>(right_ptr);
166: 	left_ptr += sizeof(uint32_t);
167: 	right_ptr += sizeof(uint32_t);
168: 	string_t left_val((const char *)left_ptr, left_string_size);
169: 	string_t right_val((const char *)right_ptr, right_string_size);
170: 	left_ptr += left_string_size;
171: 	right_ptr += right_string_size;
172: 	// Compare
173: 	return TemplatedCompareVal<string_t>((data_ptr_t)&left_val, (data_ptr_t)&right_val);
174: }
175: 
176: int Comparators::CompareStructAndAdvance(data_ptr_t &left_ptr, data_ptr_t &right_ptr,
177:                                          const child_list_t<LogicalType> &types) {
178: 	idx_t count = types.size();
179: 	// Load validity masks
180: 	ValidityBytes left_validity(left_ptr);
181: 	ValidityBytes right_validity(right_ptr);
182: 	left_ptr += (count + 7) / 8;
183: 	right_ptr += (count + 7) / 8;
184: 	// Initialize variables
185: 	bool left_valid;
186: 	bool right_valid;
187: 	idx_t entry_idx;
188: 	idx_t idx_in_entry;
189: 	// Compare
190: 	int comp_res = 0;
191: 	for (idx_t i = 0; i < count; i++) {
192: 		ValidityBytes::GetEntryIndex(i, entry_idx, idx_in_entry);
193: 		left_valid = left_validity.RowIsValid(left_validity.GetValidityEntry(entry_idx), idx_in_entry);
194: 		right_valid = right_validity.RowIsValid(right_validity.GetValidityEntry(entry_idx), idx_in_entry);
195: 		auto &type = types[i].second;
196: 		if ((left_valid && right_valid) || TypeIsConstantSize(type.InternalType())) {
197: 			comp_res = CompareValAndAdvance(left_ptr, right_ptr, types[i].second);
198: 		}
199: 		if (!left_valid && !right_valid) {
200: 			comp_res = 0;
201: 		} else if (!left_valid) {
202: 			comp_res = 1;
203: 		} else if (!right_valid) {
204: 			comp_res = -1;
205: 		}
206: 		if (comp_res != 0) {
207: 			break;
208: 		}
209: 	}
210: 	return comp_res;
211: }
212: 
213: int Comparators::CompareListAndAdvance(data_ptr_t &left_ptr, data_ptr_t &right_ptr, const LogicalType &type) {
214: 	// Load list lengths
215: 	auto left_len = Load<idx_t>(left_ptr);
216: 	auto right_len = Load<idx_t>(right_ptr);
217: 	left_ptr += sizeof(idx_t);
218: 	right_ptr += sizeof(idx_t);
219: 	// Load list validity masks
220: 	ValidityBytes left_validity(left_ptr);
221: 	ValidityBytes right_validity(right_ptr);
222: 	left_ptr += (left_len + 7) / 8;
223: 	right_ptr += (right_len + 7) / 8;
224: 	// Compare
225: 	int comp_res = 0;
226: 	idx_t count = MinValue(left_len, right_len);
227: 	if (TypeIsConstantSize(type.InternalType())) {
228: 		// Templated code for fixed-size types
229: 		switch (type.InternalType()) {
230: 		case PhysicalType::BOOL:
231: 		case PhysicalType::INT8:
232: 			comp_res = TemplatedCompareListLoop<int8_t>(left_ptr, right_ptr, left_validity, right_validity, count);
233: 			break;
234: 		case PhysicalType::INT16:
235: 			comp_res = TemplatedCompareListLoop<int16_t>(left_ptr, right_ptr, left_validity, right_validity, count);
236: 			break;
237: 		case PhysicalType::INT32:
238: 			comp_res = TemplatedCompareListLoop<int32_t>(left_ptr, right_ptr, left_validity, right_validity, count);
239: 			break;
240: 		case PhysicalType::INT64:
241: 			comp_res = TemplatedCompareListLoop<int64_t>(left_ptr, right_ptr, left_validity, right_validity, count);
242: 			break;
243: 		case PhysicalType::UINT8:
244: 			comp_res = TemplatedCompareListLoop<uint8_t>(left_ptr, right_ptr, left_validity, right_validity, count);
245: 			break;
246: 		case PhysicalType::UINT16:
247: 			comp_res = TemplatedCompareListLoop<uint16_t>(left_ptr, right_ptr, left_validity, right_validity, count);
248: 			break;
249: 		case PhysicalType::UINT32:
250: 			comp_res = TemplatedCompareListLoop<uint32_t>(left_ptr, right_ptr, left_validity, right_validity, count);
251: 			break;
252: 		case PhysicalType::UINT64:
253: 			comp_res = TemplatedCompareListLoop<uint64_t>(left_ptr, right_ptr, left_validity, right_validity, count);
254: 			break;
255: 		case PhysicalType::INT128:
256: 			comp_res = TemplatedCompareListLoop<hugeint_t>(left_ptr, right_ptr, left_validity, right_validity, count);
257: 			break;
258: 		case PhysicalType::FLOAT:
259: 			comp_res = TemplatedCompareListLoop<float>(left_ptr, right_ptr, left_validity, right_validity, count);
260: 			break;
261: 		case PhysicalType::DOUBLE:
262: 			comp_res = TemplatedCompareListLoop<double>(left_ptr, right_ptr, left_validity, right_validity, count);
263: 			break;
264: 		case PhysicalType::INTERVAL:
265: 			comp_res = TemplatedCompareListLoop<interval_t>(left_ptr, right_ptr, left_validity, right_validity, count);
266: 			break;
267: 		default:
268: 			throw NotImplementedException("CompareListAndAdvance for fixed-size type %s", type.ToString());
269: 		}
270: 	} else {
271: 		// Variable-sized list entries
272: 		bool left_valid;
273: 		bool right_valid;
274: 		idx_t entry_idx;
275: 		idx_t idx_in_entry;
276: 		// Size (in bytes) of all variable-sizes entries is stored before the entries begin,
277: 		// to make deserialization easier. We need to skip over them
278: 		left_ptr += left_len * sizeof(idx_t);
279: 		right_ptr += right_len * sizeof(idx_t);
280: 		for (idx_t i = 0; i < count; i++) {
281: 			ValidityBytes::GetEntryIndex(i, entry_idx, idx_in_entry);
282: 			left_valid = left_validity.RowIsValid(left_validity.GetValidityEntry(entry_idx), idx_in_entry);
283: 			right_valid = right_validity.RowIsValid(right_validity.GetValidityEntry(entry_idx), idx_in_entry);
284: 			if (left_valid && right_valid) {
285: 				switch (type.InternalType()) {
286: 				case PhysicalType::LIST:
287: 					comp_res = CompareListAndAdvance(left_ptr, right_ptr, ListType::GetChildType(type));
288: 					break;
289: 				case PhysicalType::VARCHAR:
290: 					comp_res = CompareStringAndAdvance(left_ptr, right_ptr);
291: 					break;
292: 				case PhysicalType::STRUCT:
293: 					comp_res = CompareStructAndAdvance(left_ptr, right_ptr, StructType::GetChildTypes(type));
294: 					break;
295: 				default:
296: 					throw NotImplementedException("CompareListAndAdvance for variable-size type %s", type.ToString());
297: 				}
298: 			} else if (!left_valid && !right_valid) {
299: 				comp_res = 0;
300: 			} else if (left_valid) {
301: 				comp_res = -1;
302: 			} else {
303: 				comp_res = 1;
304: 			}
305: 			if (comp_res != 0) {
306: 				break;
307: 			}
308: 		}
309: 	}
310: 	// All values that we looped over were equal
311: 	if (comp_res == 0 && left_len != right_len) {
312: 		// Smaller lists first
313: 		if (left_len < right_len) {
314: 			comp_res = -1;
315: 		} else {
316: 			comp_res = 1;
317: 		}
318: 	}
319: 	return comp_res;
320: }
321: 
322: template <class T>
323: int Comparators::TemplatedCompareListLoop(data_ptr_t &left_ptr, data_ptr_t &right_ptr,
324:                                           const ValidityBytes &left_validity, const ValidityBytes &right_validity,
325:                                           const idx_t &count) {
326: 	int comp_res = 0;
327: 	bool left_valid;
328: 	bool right_valid;
329: 	idx_t entry_idx;
330: 	idx_t idx_in_entry;
331: 	for (idx_t i = 0; i < count; i++) {
332: 		ValidityBytes::GetEntryIndex(i, entry_idx, idx_in_entry);
333: 		left_valid = left_validity.RowIsValid(left_validity.GetValidityEntry(entry_idx), idx_in_entry);
334: 		right_valid = right_validity.RowIsValid(right_validity.GetValidityEntry(entry_idx), idx_in_entry);
335: 		comp_res = TemplatedCompareAndAdvance<T>(left_ptr, right_ptr);
336: 		if (!left_valid && !right_valid) {
337: 			comp_res = 0;
338: 		} else if (!left_valid) {
339: 			comp_res = 1;
340: 		} else if (!right_valid) {
341: 			comp_res = -1;
342: 		}
343: 		if (comp_res != 0) {
344: 			break;
345: 		}
346: 	}
347: 	return comp_res;
348: }
349: 
350: void Comparators::UnswizzleSingleValue(data_ptr_t data_ptr, const data_ptr_t &heap_ptr, const LogicalType &type) {
351: 	if (type.InternalType() == PhysicalType::VARCHAR) {
352: 		data_ptr += sizeof(uint32_t) + string_t::PREFIX_LENGTH;
353: 	}
354: 	Store<data_ptr_t>(heap_ptr + Load<idx_t>(data_ptr), data_ptr);
355: }
356: 
357: void Comparators::SwizzleSingleValue(data_ptr_t data_ptr, const data_ptr_t &heap_ptr, const LogicalType &type) {
358: 	if (type.InternalType() == PhysicalType::VARCHAR) {
359: 		data_ptr += sizeof(uint32_t) + string_t::PREFIX_LENGTH;
360: 	}
361: 	Store<idx_t>(Load<data_ptr_t>(data_ptr) - heap_ptr, data_ptr);
362: }
363: 
364: } // namespace duckdb
[end of src/common/sort/comparators.cpp]
[start of src/function/aggregate/distributive/first.cpp]
1: #include "duckdb/function/aggregate/distributive_functions.hpp"
2: #include "duckdb/common/exception.hpp"
3: #include "duckdb/common/vector_operations/vector_operations.hpp"
4: #include "duckdb/planner/expression.hpp"
5: 
6: namespace duckdb {
7: 
8: template <class T>
9: struct FirstState {
10: 	T value;
11: 	bool is_set;
12: 	bool is_null;
13: };
14: 
15: struct FirstFunctionBase {
16: 	template <class STATE>
17: 	static void Initialize(STATE *state) {
18: 		state->is_set = false;
19: 		state->is_null = false;
20: 	}
21: 
22: 	static bool IgnoreNull() {
23: 		return false;
24: 	}
25: };
26: 
27: template <bool LAST, bool SKIP_NULLS>
28: struct FirstFunction : public FirstFunctionBase {
29: 	template <class INPUT_TYPE, class STATE, class OP>
30: 	static void Operation(STATE *state, AggregateInputData &, INPUT_TYPE *input, ValidityMask &mask, idx_t idx) {
31: 		if (LAST || !state->is_set) {
32: 			if (!mask.RowIsValid(idx)) {
33: 				if (!SKIP_NULLS) {
34: 					state->is_set = true;
35: 				}
36: 				state->is_null = true;
37: 			} else {
38: 				state->is_set = true;
39: 				state->is_null = false;
40: 				state->value = input[idx];
41: 			}
42: 		}
43: 	}
44: 
45: 	template <class INPUT_TYPE, class STATE, class OP>
46: 	static void ConstantOperation(STATE *state, AggregateInputData &aggr_input_data, INPUT_TYPE *input,
47: 	                              ValidityMask &mask, idx_t count) {
48: 		Operation<INPUT_TYPE, STATE, OP>(state, aggr_input_data, input, mask, 0);
49: 	}
50: 
51: 	template <class STATE, class OP>
52: 	static void Combine(const STATE &source, STATE *target, AggregateInputData &) {
53: 		if (!target->is_set) {
54: 			*target = source;
55: 		}
56: 	}
57: 
58: 	template <class T, class STATE>
59: 	static void Finalize(Vector &result, AggregateInputData &, STATE *state, T *target, ValidityMask &mask, idx_t idx) {
60: 		if (!state->is_set || state->is_null) {
61: 			mask.SetInvalid(idx);
62: 		} else {
63: 			target[idx] = state->value;
64: 		}
65: 	}
66: };
67: 
68: template <bool LAST, bool SKIP_NULLS>
69: struct FirstFunctionString : public FirstFunctionBase {
70: 	template <class STATE>
71: 	static void SetValue(STATE *state, string_t value, bool is_null) {
72: 		if (is_null) {
73: 			if (!SKIP_NULLS) {
74: 				state->is_set = true;
75: 				state->is_null = true;
76: 			}
77: 		} else {
78: 			state->is_set = true;
79: 			if (value.IsInlined()) {
80: 				state->value = value;
81: 			} else {
82: 				// non-inlined string, need to allocate space for it
83: 				auto len = value.GetSize();
84: 				auto ptr = new char[len];
85: 				memcpy(ptr, value.GetDataUnsafe(), len);
86: 
87: 				state->value = string_t(ptr, len);
88: 			}
89: 		}
90: 	}
91: 
92: 	template <class INPUT_TYPE, class STATE, class OP>
93: 	static void Operation(STATE *state, AggregateInputData &, INPUT_TYPE *input, ValidityMask &mask, idx_t idx) {
94: 		if (LAST || !state->is_set) {
95: 			SetValue(state, input[idx], !mask.RowIsValid(idx));
96: 		}
97: 	}
98: 
99: 	template <class INPUT_TYPE, class STATE, class OP>
100: 	static void ConstantOperation(STATE *state, AggregateInputData &aggr_input_data, INPUT_TYPE *input,
101: 	                              ValidityMask &mask, idx_t count) {
102: 		Operation<INPUT_TYPE, STATE, OP>(state, aggr_input_data, input, mask, 0);
103: 	}
104: 
105: 	template <class STATE, class OP>
106: 	static void Combine(const STATE &source, STATE *target, AggregateInputData &) {
107: 		if (source.is_set && (LAST || !target->is_set)) {
108: 			SetValue(target, source.value, source.is_null);
109: 		}
110: 	}
111: 
112: 	template <class T, class STATE>
113: 	static void Finalize(Vector &result, AggregateInputData &, STATE *state, T *target, ValidityMask &mask, idx_t idx) {
114: 		if (!state->is_set || state->is_null) {
115: 			mask.SetInvalid(idx);
116: 		} else {
117: 			target[idx] = StringVector::AddStringOrBlob(result, state->value);
118: 		}
119: 	}
120: 
121: 	template <class STATE>
122: 	static void Destroy(STATE *state) {
123: 		if (state->is_set && !state->is_null && !state->value.IsInlined()) {
124: 			delete[] state->value.GetDataUnsafe();
125: 		}
126: 	}
127: };
128: 
129: struct FirstStateVector {
130: 	Vector *value;
131: };
132: 
133: template <bool LAST, bool SKIP_NULLS>
134: struct FirstVectorFunction {
135: 	template <class STATE>
136: 	static void Initialize(STATE *state) {
137: 		state->value = nullptr;
138: 	}
139: 
140: 	template <class STATE>
141: 	static void Destroy(STATE *state) {
142: 		if (state->value) {
143: 			delete state->value;
144: 		}
145: 	}
146: 	static bool IgnoreNull() {
147: 		return SKIP_NULLS;
148: 	}
149: 
150: 	template <class STATE>
151: 	static void SetValue(STATE *state, Vector &input, const idx_t idx) {
152: 		if (!state->value) {
153: 			state->value = new Vector(input.GetType());
154: 			state->value->SetVectorType(VectorType::CONSTANT_VECTOR);
155: 		}
156: 		sel_t selv = idx;
157: 		SelectionVector sel(&selv);
158: 		VectorOperations::Copy(input, *state->value, sel, 1, 0, 0);
159: 	}
160: 
161: 	static void Update(Vector inputs[], AggregateInputData &, idx_t input_count, Vector &state_vector, idx_t count) {
162: 		auto &input = inputs[0];
163: 		UnifiedVectorFormat idata;
164: 		input.ToUnifiedFormat(count, idata);
165: 
166: 		UnifiedVectorFormat sdata;
167: 		state_vector.ToUnifiedFormat(count, sdata);
168: 
169: 		auto states = (FirstStateVector **)sdata.data;
170: 		for (idx_t i = 0; i < count; i++) {
171: 			const auto idx = idata.sel->get_index(i);
172: 			if (SKIP_NULLS && !idata.validity.RowIsValid(idx)) {
173: 				continue;
174: 			}
175: 			auto state = states[sdata.sel->get_index(i)];
176: 			if (LAST || !state->value) {
177: 				SetValue(state, input, i);
178: 			}
179: 		}
180: 	}
181: 
182: 	template <class STATE, class OP>
183: 	static void Combine(const STATE &source, STATE *target, AggregateInputData &) {
184: 		if (source.value && (LAST || !target->value)) {
185: 			SetValue(target, *source.value, 0);
186: 		}
187: 	}
188: 
189: 	template <class T, class STATE>
190: 	static void Finalize(Vector &result, AggregateInputData &, STATE *state, T *target, ValidityMask &mask, idx_t idx) {
191: 		if (!state->value) {
192: 			// we need to use FlatVector::SetNull here
193: 			// since for STRUCT columns only setting the validity mask of the struct is incorrect
194: 			// as for a struct column, we need to also set ALL child columns to NULL
195: 			if (result.GetVectorType() == VectorType::CONSTANT_VECTOR) {
196: 				ConstantVector::SetNull(result, true);
197: 			} else {
198: 				FlatVector::SetNull(result, idx, true);
199: 			}
200: 		} else {
201: 			VectorOperations::Copy(*state->value, result, 1, 0, idx);
202: 		}
203: 	}
204: 
205: 	static unique_ptr<FunctionData> Bind(ClientContext &context, AggregateFunction &function,
206: 	                                     vector<unique_ptr<Expression>> &arguments) {
207: 		function.arguments[0] = arguments[0]->return_type;
208: 		function.return_type = arguments[0]->return_type;
209: 		return nullptr;
210: 	}
211: };
212: 
213: template <class T, bool LAST, bool SKIP_NULLS>
214: static AggregateFunction GetFirstAggregateTemplated(LogicalType type) {
215: 	return AggregateFunction::UnaryAggregate<FirstState<T>, T, T, FirstFunction<LAST, SKIP_NULLS>>(type, type);
216: }
217: 
218: template <bool LAST, bool SKIP_NULLS>
219: static AggregateFunction GetFirstFunction(const LogicalType &type);
220: 
221: template <bool LAST, bool SKIP_NULLS>
222: AggregateFunction GetDecimalFirstFunction(const LogicalType &type) {
223: 	D_ASSERT(type.id() == LogicalTypeId::DECIMAL);
224: 	switch (type.InternalType()) {
225: 	case PhysicalType::INT16:
226: 		return GetFirstFunction<LAST, SKIP_NULLS>(LogicalType::SMALLINT);
227: 	case PhysicalType::INT32:
228: 		return GetFirstFunction<LAST, SKIP_NULLS>(LogicalType::INTEGER);
229: 	case PhysicalType::INT64:
230: 		return GetFirstFunction<LAST, SKIP_NULLS>(LogicalType::BIGINT);
231: 	default:
232: 		return GetFirstFunction<LAST, SKIP_NULLS>(LogicalType::HUGEINT);
233: 	}
234: }
235: 
236: template <bool LAST, bool SKIP_NULLS>
237: static AggregateFunction GetFirstFunction(const LogicalType &type) {
238: 	switch (type.id()) {
239: 	case LogicalTypeId::BOOLEAN:
240: 		return GetFirstAggregateTemplated<int8_t, LAST, SKIP_NULLS>(type);
241: 	case LogicalTypeId::TINYINT:
242: 		return GetFirstAggregateTemplated<int8_t, LAST, SKIP_NULLS>(type);
243: 	case LogicalTypeId::SMALLINT:
244: 		return GetFirstAggregateTemplated<int16_t, LAST, SKIP_NULLS>(type);
245: 	case LogicalTypeId::INTEGER:
246: 	case LogicalTypeId::DATE:
247: 		return GetFirstAggregateTemplated<int32_t, LAST, SKIP_NULLS>(type);
248: 	case LogicalTypeId::BIGINT:
249: 	case LogicalTypeId::TIME:
250: 	case LogicalTypeId::TIMESTAMP:
251: 	case LogicalTypeId::TIME_TZ:
252: 	case LogicalTypeId::TIMESTAMP_TZ:
253: 		return GetFirstAggregateTemplated<int64_t, LAST, SKIP_NULLS>(type);
254: 	case LogicalTypeId::UTINYINT:
255: 		return GetFirstAggregateTemplated<uint8_t, LAST, SKIP_NULLS>(type);
256: 	case LogicalTypeId::USMALLINT:
257: 		return GetFirstAggregateTemplated<uint16_t, LAST, SKIP_NULLS>(type);
258: 	case LogicalTypeId::UINTEGER:
259: 		return GetFirstAggregateTemplated<uint32_t, LAST, SKIP_NULLS>(type);
260: 	case LogicalTypeId::UBIGINT:
261: 		return GetFirstAggregateTemplated<uint64_t, LAST, SKIP_NULLS>(type);
262: 	case LogicalTypeId::HUGEINT:
263: 		return GetFirstAggregateTemplated<hugeint_t, LAST, SKIP_NULLS>(type);
264: 	case LogicalTypeId::FLOAT:
265: 		return GetFirstAggregateTemplated<float, LAST, SKIP_NULLS>(type);
266: 	case LogicalTypeId::DOUBLE:
267: 		return GetFirstAggregateTemplated<double, LAST, SKIP_NULLS>(type);
268: 	case LogicalTypeId::INTERVAL:
269: 		return GetFirstAggregateTemplated<interval_t, LAST, SKIP_NULLS>(type);
270: 	case LogicalTypeId::VARCHAR:
271: 	case LogicalTypeId::BLOB:
272: 		return AggregateFunction::UnaryAggregateDestructor<FirstState<string_t>, string_t, string_t,
273: 		                                                   FirstFunctionString<LAST, SKIP_NULLS>>(type, type);
274: 	case LogicalTypeId::DECIMAL: {
275: 		type.Verify();
276: 		AggregateFunction function = GetDecimalFirstFunction<LAST, SKIP_NULLS>(type);
277: 		function.arguments[0] = type;
278: 		function.return_type = type;
279: 		// TODO set_key here?
280: 		return function;
281: 	}
282: 	default: {
283: 		using OP = FirstVectorFunction<LAST, SKIP_NULLS>;
284: 		return AggregateFunction({type}, type, AggregateFunction::StateSize<FirstStateVector>,
285: 		                         AggregateFunction::StateInitialize<FirstStateVector, OP>, OP::Update,
286: 		                         AggregateFunction::StateCombine<FirstStateVector, OP>,
287: 		                         AggregateFunction::StateFinalize<FirstStateVector, void, OP>, nullptr, OP::Bind,
288: 		                         AggregateFunction::StateDestroy<FirstStateVector, OP>, nullptr, nullptr);
289: 	}
290: 	}
291: }
292: 
293: AggregateFunction FirstFun::GetFunction(const LogicalType &type) {
294: 	auto fun = GetFirstFunction<false, false>(type);
295: 	fun.name = "first";
296: 	return fun;
297: }
298: 
299: template <bool LAST, bool SKIP_NULLS>
300: unique_ptr<FunctionData> BindDecimalFirst(ClientContext &context, AggregateFunction &function,
301:                                           vector<unique_ptr<Expression>> &arguments) {
302: 	auto decimal_type = arguments[0]->return_type;
303: 	function = GetFirstFunction<LAST, SKIP_NULLS>(decimal_type);
304: 	function.name = "first";
305: 	function.return_type = decimal_type;
306: 	return nullptr;
307: }
308: 
309: template <bool LAST, bool SKIP_NULLS>
310: static AggregateFunction GetFirstOperator(const LogicalType &type) {
311: 	if (type.id() == LogicalTypeId::DECIMAL) {
312: 		throw InternalException("FIXME: this shouldn't happen...");
313: 	}
314: 	return GetFirstFunction<LAST, SKIP_NULLS>(type);
315: }
316: 
317: template <bool LAST, bool SKIP_NULLS>
318: unique_ptr<FunctionData> BindFirst(ClientContext &context, AggregateFunction &function,
319:                                    vector<unique_ptr<Expression>> &arguments) {
320: 	auto input_type = arguments[0]->return_type;
321: 	auto name = move(function.name);
322: 	function = GetFirstOperator<LAST, SKIP_NULLS>(input_type);
323: 	function.name = move(name);
324: 	if (function.bind) {
325: 		return function.bind(context, function, arguments);
326: 	} else {
327: 		return nullptr;
328: 	}
329: }
330: 
331: template <bool LAST, bool SKIP_NULLS>
332: static void AddFirstOperator(AggregateFunctionSet &set) {
333: 	set.AddFunction(AggregateFunction({LogicalTypeId::DECIMAL}, LogicalTypeId::DECIMAL, nullptr, nullptr, nullptr,
334: 	                                  nullptr, nullptr, nullptr, BindDecimalFirst<LAST, SKIP_NULLS>));
335: 	set.AddFunction(AggregateFunction({LogicalType::ANY}, LogicalType::ANY, nullptr, nullptr, nullptr, nullptr, nullptr,
336: 	                                  nullptr, BindFirst<LAST, SKIP_NULLS>));
337: }
338: 
339: void FirstFun::RegisterFunction(BuiltinFunctions &set) {
340: 	AggregateFunctionSet first("first");
341: 	AggregateFunctionSet last("last");
342: 	AggregateFunctionSet any_value("any_value");
343: 
344: 	AddFirstOperator<false, false>(first);
345: 	AddFirstOperator<true, false>(last);
346: 	AddFirstOperator<false, true>(any_value);
347: 
348: 	set.AddFunction(first);
349: 	first.name = "arbitrary";
350: 	set.AddFunction(first);
351: 
352: 	set.AddFunction(last);
353: 
354: 	set.AddFunction(any_value);
355: }
356: 
357: } // namespace duckdb
[end of src/function/aggregate/distributive/first.cpp]
[start of src/include/duckdb/common/operator/comparison_operators.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/common/operator/comparison_operators.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/common/types/string_type.hpp"
12: #include "duckdb/common/types.hpp"
13: #include "duckdb/common/types/hugeint.hpp"
14: #include "duckdb/common/types/interval.hpp"
15: #include "duckdb/common/helper.hpp"
16: 
17: #include <cstring>
18: 
19: namespace duckdb {
20: 
21: //===--------------------------------------------------------------------===//
22: // Comparison Operations
23: //===--------------------------------------------------------------------===//
24: struct Equals {
25: 	template <class T>
26: 	DUCKDB_API static inline bool Operation(T left, T right) {
27: 		return left == right;
28: 	}
29: };
30: struct NotEquals {
31: 	template <class T>
32: 	DUCKDB_API static inline bool Operation(T left, T right) {
33: 		return !Equals::Operation(left, right);
34: 	}
35: };
36: 
37: struct GreaterThan {
38: 	template <class T>
39: 	DUCKDB_API static inline bool Operation(T left, T right) {
40: 		return left > right;
41: 	}
42: };
43: 
44: struct GreaterThanEquals {
45: 	template <class T>
46: 	DUCKDB_API static inline bool Operation(T left, T right) {
47: 		return left >= right;
48: 	}
49: };
50: 
51: struct LessThan {
52: 	template <class T>
53: 	DUCKDB_API static inline bool Operation(T left, T right) {
54: 		return GreaterThan::Operation(right, left);
55: 	}
56: };
57: 
58: struct LessThanEquals {
59: 	template <class T>
60: 	DUCKDB_API static inline bool Operation(T left, T right) {
61: 		return GreaterThanEquals::Operation(right, left);
62: 	}
63: };
64: 
65: template <>
66: DUCKDB_API bool Equals::Operation(float left, float right);
67: template <>
68: DUCKDB_API bool Equals::Operation(double left, double right);
69: 
70: template <>
71: DUCKDB_API bool GreaterThan::Operation(float left, float right);
72: template <>
73: DUCKDB_API bool GreaterThan::Operation(double left, double right);
74: 
75: template <>
76: DUCKDB_API bool GreaterThanEquals::Operation(float left, float right);
77: template <>
78: DUCKDB_API bool GreaterThanEquals::Operation(double left, double right);
79: 
80: // Distinct semantics are from Postgres record sorting. NULL = NULL and not-NULL < NULL
81: // Deferring to the non-distinct operations removes the need for further specialisation.
82: // TODO: To reverse the semantics, swap left_null and right_null for comparisons
83: struct DistinctFrom {
84: 	template <class T>
85: 	static inline bool Operation(T left, T right, bool left_null, bool right_null) {
86: 		return (left_null != right_null) || (!left_null && !right_null && NotEquals::Operation(left, right));
87: 	}
88: };
89: 
90: struct NotDistinctFrom {
91: 	template <class T>
92: 	static inline bool Operation(T left, T right, bool left_null, bool right_null) {
93: 		return (left_null && right_null) || (!left_null && !right_null && Equals::Operation(left, right));
94: 	}
95: };
96: 
97: struct DistinctGreaterThan {
98: 	template <class T>
99: 	static inline bool Operation(T left, T right, bool left_null, bool right_null) {
100: 		return GreaterThan::Operation(left_null, right_null) ||
101: 		       (!left_null && !right_null && GreaterThan::Operation(left, right));
102: 	}
103: };
104: 
105: struct DistinctGreaterThanNullsFirst {
106: 	template <class T>
107: 	static inline bool Operation(T left, T right, bool left_null, bool right_null) {
108: 		return GreaterThan::Operation(right_null, left_null) ||
109: 		       (!left_null && !right_null && GreaterThan::Operation(left, right));
110: 	}
111: };
112: 
113: struct DistinctGreaterThanEquals {
114: 	template <class T>
115: 	static inline bool Operation(T left, T right, bool left_null, bool right_null) {
116: 		return left_null || (!left_null && !right_null && GreaterThanEquals::Operation(left, right));
117: 	}
118: };
119: 
120: struct DistinctLessThan {
121: 	template <class T>
122: 	static inline bool Operation(T left, T right, bool left_null, bool right_null) {
123: 		return LessThan::Operation(left_null, right_null) ||
124: 		       (!left_null && !right_null && LessThan::Operation(left, right));
125: 	}
126: };
127: 
128: struct DistinctLessThanNullsFirst {
129: 	template <class T>
130: 	static inline bool Operation(T left, T right, bool left_null, bool right_null) {
131: 		return LessThan::Operation(right_null, left_null) ||
132: 		       (!left_null && !right_null && LessThan::Operation(left, right));
133: 	}
134: };
135: 
136: struct DistinctLessThanEquals {
137: 	template <class T>
138: 	static inline bool Operation(T left, T right, bool left_null, bool right_null) {
139: 		return right_null || (!left_null && !right_null && LessThanEquals::Operation(left, right));
140: 	}
141: };
142: 
143: //===--------------------------------------------------------------------===//
144: // Specialized Boolean Comparison Operators
145: //===--------------------------------------------------------------------===//
146: template <>
147: inline bool GreaterThan::Operation(bool left, bool right) {
148: 	return !right && left;
149: }
150: template <>
151: inline bool LessThan::Operation(bool left, bool right) {
152: 	return !left && right;
153: }
154: //===--------------------------------------------------------------------===//
155: // Specialized String Comparison Operations
156: //===--------------------------------------------------------------------===//
157: struct StringComparisonOperators {
158: 	template <bool INVERSE>
159: 	static inline bool EqualsOrNot(const string_t a, const string_t b) {
160: 		if (a.IsInlined()) {
161: 			// small string: compare entire string
162: 			if (memcmp(&a, &b, sizeof(string_t)) == 0) {
163: 				// entire string is equal
164: 				return INVERSE ? false : true;
165: 			}
166: 		} else {
167: 			// large string: first check prefix and length
168: 			if (memcmp(&a, &b, sizeof(uint32_t) + string_t::PREFIX_LENGTH) == 0) {
169: 				// prefix and length are equal: check main string
170: 				if (memcmp(a.value.pointer.ptr, b.value.pointer.ptr, a.GetSize()) == 0) {
171: 					// entire string is equal
172: 					return INVERSE ? false : true;
173: 				}
174: 			}
175: 		}
176: 		// not equal
177: 		return INVERSE ? true : false;
178: 	}
179: };
180: 
181: template <>
182: inline bool Equals::Operation(string_t left, string_t right) {
183: 	return StringComparisonOperators::EqualsOrNot<false>(left, right);
184: }
185: template <>
186: inline bool NotEquals::Operation(string_t left, string_t right) {
187: 	return StringComparisonOperators::EqualsOrNot<true>(left, right);
188: }
189: 
190: template <>
191: inline bool NotDistinctFrom::Operation(string_t left, string_t right, bool left_null, bool right_null) {
192: 	return (left_null && right_null) ||
193: 	       (!left_null && !right_null && StringComparisonOperators::EqualsOrNot<false>(left, right));
194: }
195: template <>
196: inline bool DistinctFrom::Operation(string_t left, string_t right, bool left_null, bool right_null) {
197: 	return (left_null != right_null) ||
198: 	       (!left_null && !right_null && StringComparisonOperators::EqualsOrNot<true>(left, right));
199: }
200: 
201: // compare up to shared length. if still the same, compare lengths
202: template <class OP>
203: static bool templated_string_compare_op(string_t left, string_t right) {
204: 	auto memcmp_res =
205: 	    memcmp(left.GetDataUnsafe(), right.GetDataUnsafe(), MinValue<idx_t>(left.GetSize(), right.GetSize()));
206: 	auto final_res = memcmp_res == 0 ? OP::Operation(left.GetSize(), right.GetSize()) : OP::Operation(memcmp_res, 0);
207: 	return final_res;
208: }
209: 
210: template <>
211: inline bool GreaterThan::Operation(string_t left, string_t right) {
212: 	return templated_string_compare_op<GreaterThan>(left, right);
213: }
214: 
215: template <>
216: inline bool GreaterThanEquals::Operation(string_t left, string_t right) {
217: 	return templated_string_compare_op<GreaterThanEquals>(left, right);
218: }
219: 
220: template <>
221: inline bool LessThan::Operation(string_t left, string_t right) {
222: 	return templated_string_compare_op<LessThan>(left, right);
223: }
224: 
225: template <>
226: inline bool LessThanEquals::Operation(string_t left, string_t right) {
227: 	return templated_string_compare_op<LessThanEquals>(left, right);
228: }
229: //===--------------------------------------------------------------------===//
230: // Specialized Interval Comparison Operators
231: //===--------------------------------------------------------------------===//
232: template <>
233: inline bool Equals::Operation(interval_t left, interval_t right) {
234: 	return Interval::Equals(left, right);
235: }
236: template <>
237: inline bool NotEquals::Operation(interval_t left, interval_t right) {
238: 	return !Equals::Operation(left, right);
239: }
240: template <>
241: inline bool GreaterThan::Operation(interval_t left, interval_t right) {
242: 	return Interval::GreaterThan(left, right);
243: }
244: template <>
245: inline bool GreaterThanEquals::Operation(interval_t left, interval_t right) {
246: 	return Interval::GreaterThanEquals(left, right);
247: }
248: template <>
249: inline bool LessThan::Operation(interval_t left, interval_t right) {
250: 	return GreaterThan::Operation(right, left);
251: }
252: template <>
253: inline bool LessThanEquals::Operation(interval_t left, interval_t right) {
254: 	return GreaterThanEquals::Operation(right, left);
255: }
256: 
257: template <>
258: inline bool NotDistinctFrom::Operation(interval_t left, interval_t right, bool left_null, bool right_null) {
259: 	return (left_null && right_null) || (!left_null && !right_null && Interval::Equals(left, right));
260: }
261: template <>
262: inline bool DistinctFrom::Operation(interval_t left, interval_t right, bool left_null, bool right_null) {
263: 	return (left_null != right_null) || (!left_null && !right_null && !Equals::Operation(left, right));
264: }
265: inline bool operator<(const interval_t &lhs, const interval_t &rhs) {
266: 	return LessThan::Operation(lhs, rhs);
267: }
268: 
269: //===--------------------------------------------------------------------===//
270: // Specialized Hugeint Comparison Operators
271: //===--------------------------------------------------------------------===//
272: template <>
273: inline bool Equals::Operation(hugeint_t left, hugeint_t right) {
274: 	return Hugeint::Equals(left, right);
275: }
276: template <>
277: inline bool NotEquals::Operation(hugeint_t left, hugeint_t right) {
278: 	return Hugeint::NotEquals(left, right);
279: }
280: template <>
281: inline bool GreaterThan::Operation(hugeint_t left, hugeint_t right) {
282: 	return Hugeint::GreaterThan(left, right);
283: }
284: template <>
285: inline bool GreaterThanEquals::Operation(hugeint_t left, hugeint_t right) {
286: 	return Hugeint::GreaterThanEquals(left, right);
287: }
288: template <>
289: inline bool LessThan::Operation(hugeint_t left, hugeint_t right) {
290: 	return Hugeint::LessThan(left, right);
291: }
292: template <>
293: inline bool LessThanEquals::Operation(hugeint_t left, hugeint_t right) {
294: 	return Hugeint::LessThanEquals(left, right);
295: }
296: } // namespace duckdb
[end of src/include/duckdb/common/operator/comparison_operators.hpp]
[start of src/include/duckdb/common/types/string_type.hpp]
1: //===----------------------------------------------------------------------===//
2: //                         DuckDB
3: //
4: // duckdb/common/types/string_type.hpp
5: //
6: //
7: //===----------------------------------------------------------------------===//
8: 
9: #pragma once
10: 
11: #include "duckdb/common/assert.hpp"
12: #include "duckdb/common/constants.hpp"
13: 
14: #include <cstring>
15: 
16: namespace duckdb {
17: 
18: struct string_t {
19: 	friend struct StringComparisonOperators;
20: 	friend class StringSegment;
21: 
22: public:
23: 	static constexpr idx_t PREFIX_LENGTH = 4 * sizeof(char);
24: 	static constexpr idx_t INLINE_LENGTH = 12;
25: 
26: 	string_t() = default;
27: 	explicit string_t(uint32_t len) {
28: 		value.inlined.length = len;
29: 	}
30: 	string_t(const char *data, uint32_t len) {
31: 		value.inlined.length = len;
32: 		D_ASSERT(data || GetSize() == 0);
33: 		if (IsInlined()) {
34: 			// zero initialize the prefix first
35: 			// this makes sure that strings with length smaller than 4 still have an equal prefix
36: 			memset(value.inlined.inlined, 0, INLINE_LENGTH);
37: 			if (GetSize() == 0) {
38: 				return;
39: 			}
40: 			// small string: inlined
41: 			memcpy(value.inlined.inlined, data, GetSize());
42: 		} else {
43: 			// large string: store pointer
44: 			memcpy(value.pointer.prefix, data, PREFIX_LENGTH);
45: 			value.pointer.ptr = (char *)data;
46: 		}
47: 	}
48: 	string_t(const char *data) : string_t(data, strlen(data)) { // NOLINT: Allow implicit conversion from `const char*`
49: 	}
50: 	string_t(const string &value)
51: 	    : string_t(value.c_str(), value.size()) { // NOLINT: Allow implicit conversion from `const char*`
52: 	}
53: 
54: 	bool IsInlined() const {
55: 		return GetSize() <= INLINE_LENGTH;
56: 	}
57: 
58: 	//! this is unsafe since the string will not be terminated at the end
59: 	const char *GetDataUnsafe() const {
60: 		return IsInlined() ? (const char *)value.inlined.inlined : value.pointer.ptr;
61: 	}
62: 
63: 	char *GetDataWriteable() const {
64: 		return IsInlined() ? (char *)value.inlined.inlined : value.pointer.ptr;
65: 	}
66: 
67: 	const char *GetPrefix() const {
68: 		return value.pointer.prefix;
69: 	}
70: 
71: 	idx_t GetSize() const {
72: 		return value.inlined.length;
73: 	}
74: 
75: 	string GetString() const {
76: 		return string(GetDataUnsafe(), GetSize());
77: 	}
78: 
79: 	explicit operator string() const {
80: 		return GetString();
81: 	}
82: 
83: 	void Finalize() {
84: 		// set trailing NULL byte
85: 		auto dataptr = (char *)GetDataUnsafe();
86: 		if (GetSize() <= INLINE_LENGTH) {
87: 			// fill prefix with zeros if the length is smaller than the prefix length
88: 			for (idx_t i = GetSize(); i < INLINE_LENGTH; i++) {
89: 				value.inlined.inlined[i] = '\0';
90: 			}
91: 		} else {
92: 			// copy the data into the prefix
93: 			memcpy(value.pointer.prefix, dataptr, PREFIX_LENGTH);
94: 		}
95: 	}
96: 
97: 	void Verify() const;
98: 	void VerifyNull() const;
99: 	bool operator<(const string_t &r) const {
100: 		auto this_str = this->GetString();
101: 		auto r_str = r.GetString();
102: 		return this_str < r_str;
103: 	}
104: 
105: private:
106: 	union {
107: 		struct {
108: 			uint32_t length;
109: 			char prefix[4];
110: 			char *ptr;
111: 		} pointer;
112: 		struct {
113: 			uint32_t length;
114: 			char inlined[12];
115: 		} inlined;
116: 	} value;
117: };
118: 
119: } // namespace duckdb
[end of src/include/duckdb/common/types/string_type.hpp]
</code>
Here is an example of a patch file. It consists of changes to the code base. It specifies the file names, the line numbers of each change, and the removed and added lines. A single patch file can contain changes to multiple files.
<patch>
--- a/file.cpp
+++ b/file.cpp
@@ -3,35 +3,44 @@
 #include <cstdlib>
 
 int euclidean(int a, int b) {
-    while (b) {
-        int temp = b;
-        b = a % b;
-        a = temp;
+    if (b == 0) {
+        return a;
     }
-    return a;
+    return euclidean(b, a % b);
 }
 
 std::vector<std::pair<int, int>> bresenham(int x0, int y0, int x1, int y1) {
     std::vector<std::pair<int, int>> points;
     int dx = abs(x1 - x0);
     int dy = abs(y1 - y0);
+    int x = x0, y = y0;
     int sx = (x0 < x1) ? 1 : -1;
     int sy = (y0 < y1) ? 1 : -1;
-    int err = dx - dy;
 
-    while (true) {
-        points.emplace_back(x0, y0);
-        if (x0 == x1 && y0 == y1) break;
-        int e2 = 2 * err;
-        if (e2 > -dy) {
+    if (dx > dy) {
+        int err = dx / 2;
+        while (x != x1) {
+            points.emplace_back(x, y);
             err -= dy;
-            x0 += sx;
+            if (err < 0) {
+                y += sy;
+                err += dx;
+            }
+            x += sx;
         }
-        if (e2 < dx) {
-            err += dx;
-            y0 += sy;
+    } else {
+        int err = dy / 2;
+        while (y != y1) {
+            points.emplace_back(x, y);
+            err -= dx;
+            if (err < 0) {
+                x += sx;
+                err += dy;
+            }
+            y += sy;
         }
     }
 
+    points.emplace_back(x, y);
     return points;
 }

</patch>

I need you to solve the provided issue by generating a single patch file that I can apply directly to this repository using git apply.
Please respond with a single patch file in the format shown above.
Make sure to only include the patch file contents so that the contents of your output can be copied into a patch file and applied directly

Respond below: