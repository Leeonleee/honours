{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 2783,
  "instance_id": "dragonflydb__dragonfly-2783",
  "issue_numbers": [
    "2771"
  ],
  "base_commit": "ad13cc6b9c3e414a00c01650f428058761d4149a",
  "patch": "diff --git a/src/server/db_slice.cc b/src/server/db_slice.cc\nindex 9f19ba6f7a2b..409ca82644eb 100644\n--- a/src/server/db_slice.cc\n+++ b/src/server/db_slice.cc\n@@ -409,12 +409,17 @@ OpResult<DbSlice::ItAndUpdater> DbSlice::FindMutableInternal(const Context& cntx\n   }\n \n   PreUpdate(cntx.db_index, res->it);\n-  return {{res->it, res->exp_it,\n-           AutoUpdater({.action = AutoUpdater::DestructorAction::kRun,\n-                        .db_slice = this,\n-                        .db_ind = cntx.db_index,\n-                        .it = res->it,\n-                        .key = key})}};\n+  // PreUpdate() might have caused a deletion of `it`\n+  if (res->it.IsOccupied()) {\n+    return {{res->it, res->exp_it,\n+             AutoUpdater({.action = AutoUpdater::DestructorAction::kRun,\n+                          .db_slice = this,\n+                          .db_ind = cntx.db_index,\n+                          .it = res->it,\n+                          .key = key})}};\n+  } else {\n+    return OpStatus::KEY_NOTFOUND;\n+  }\n }\n \n DbSlice::ItAndExpConst DbSlice::FindReadOnly(const Context& cntx, std::string_view key) {\n@@ -577,15 +582,20 @@ OpResult<DbSlice::AddOrFindResult> DbSlice::AddOrFindInternal(const Context& cnt\n \n   if (res.ok()) {\n     PreUpdate(cntx.db_index, res->it);\n-    return DbSlice::AddOrFindResult{\n-        .it = res->it,\n-        .exp_it = res->exp_it,\n-        .is_new = false,\n-        .post_updater = AutoUpdater({.action = AutoUpdater::DestructorAction::kRun,\n-                                     .db_slice = this,\n-                                     .db_ind = cntx.db_index,\n-                                     .it = res->it,\n-                                     .key = key})};\n+    // PreUpdate() might have caused a deletion of `it`\n+    if (res->it.IsOccupied()) {\n+      return DbSlice::AddOrFindResult{\n+          .it = res->it,\n+          .exp_it = res->exp_it,\n+          .is_new = false,\n+          .post_updater = AutoUpdater({.action = AutoUpdater::DestructorAction::kRun,\n+                                       .db_slice = this,\n+                                       .db_ind = cntx.db_index,\n+                                       .it = res->it,\n+                                       .key = key})};\n+    } else {\n+      res = OpStatus::KEY_NOTFOUND;\n+    }\n   }\n   auto status = res.status();\n   CHECK(status == OpStatus::KEY_NOTFOUND || status == OpStatus::OUT_OF_MEMORY) << status;\n@@ -706,7 +716,8 @@ void DbSlice::FlushSlotsFb(const SlotSet& slot_ids) {\n   // Slot deletion can take time as it traverses all the database, hence it runs in fiber.\n   // We want to flush all the data of a slot that was added till the time the call to FlushSlotsFb\n   // was made. Therefore we delete slots entries with version < next_version\n-  uint64_t next_version = NextVersion();\n+  uint64_t next_version = 0;\n+\n   std::string tmp;\n   auto del_entry_cb = [&](PrimeTable::iterator it) {\n     std::string_view key = it->first.GetSlice(&tmp);\n@@ -717,6 +728,33 @@ void DbSlice::FlushSlotsFb(const SlotSet& slot_ids) {\n     return true;\n   };\n \n+  auto on_change = [&](DbIndex db_index, const ChangeReq& req) {\n+    FiberAtomicGuard fg;\n+    PrimeTable* table = GetTables(db_index).first;\n+\n+    auto iterate_bucket = [&](DbIndex db_index, PrimeTable::bucket_iterator it) {\n+      while (!it.is_done()) {\n+        del_entry_cb(it);\n+        ++it;\n+      }\n+    };\n+\n+    if (const PrimeTable::bucket_iterator* bit = req.update()) {\n+      if (bit->GetVersion() < next_version) {\n+        iterate_bucket(db_index, *bit);\n+      }\n+    } else {\n+      string_view key = get<string_view>(req.change);\n+      table->CVCUponInsert(\n+          next_version, key,\n+          [this, db_index, next_version, iterate_bucket](PrimeTable::bucket_iterator it) {\n+            DCHECK_LT(it.GetVersion(), next_version);\n+            iterate_bucket(db_index, it);\n+          });\n+    }\n+  };\n+  next_version = RegisterOnChange(std::move(on_change));\n+\n   ServerState& etl = *ServerState::tlocal();\n   PrimeTable* pt = &db_arr_[0]->prime;\n   PrimeTable::Cursor cursor;\n@@ -730,6 +768,9 @@ void DbSlice::FlushSlotsFb(const SlotSet& slot_ids) {\n     }\n \n   } while (cursor && etl.gstate() != GlobalState::SHUTTING_DOWN);\n+\n+  UnregisterOnChange(next_version);\n+\n   etl.DecommitMemory(ServerState::kDataHeap);\n }\n \n",
  "test_patch": "diff --git a/src/server/cluster/cluster_family_test.cc b/src/server/cluster/cluster_family_test.cc\nindex 7580107195ba..62c20825ebdc 100644\n--- a/src/server/cluster/cluster_family_test.cc\n+++ b/src/server/cluster/cluster_family_test.cc\n@@ -36,6 +36,28 @@ class ClusterFamilyTest : public BaseFamilyTest {\n   string GetMyId() {\n     return RunPrivileged({\"dflycluster\", \"myid\"}).GetString();\n   }\n+\n+  void ConfigSingleNodeCluster(string id) {\n+    string config_template = R\"json(\n+      [\n+        {\n+          \"slot_ranges\": [\n+            {\n+              \"start\": 0,\n+              \"end\": 16383\n+            }\n+          ],\n+          \"master\": {\n+            \"id\": \"$0\",\n+            \"ip\": \"10.0.0.1\",\n+            \"port\": 7000\n+          },\n+          \"replicas\": []\n+        }\n+      ])json\";\n+    string config = absl::Substitute(config_template, id);\n+    EXPECT_EQ(RunPrivileged({\"dflycluster\", \"config\", config}), \"OK\");\n+  }\n };\n \n TEST_F(ClusterFamilyTest, ClusterConfigInvalidJSON) {\n@@ -136,25 +158,7 @@ TEST_F(ClusterFamilyTest, ClusterConfigInvalidOverlappingSlots) {\n }\n \n TEST_F(ClusterFamilyTest, ClusterConfigNoReplicas) {\n-  EXPECT_EQ(RunPrivileged({\"dflycluster\", \"config\", R\"json(\n-      [\n-        {\n-          \"slot_ranges\": [\n-            {\n-              \"start\": 0,\n-              \"end\": 16383\n-            }\n-          ],\n-          \"master\": {\n-            \"id\": \"abcd1234\",\n-            \"ip\": \"10.0.0.1\",\n-            \"port\": 7000\n-          },\n-          \"replicas\": []\n-        }\n-      ])json\"}),\n-            \"OK\");\n-\n+  ConfigSingleNodeCluster(\"abcd1234\");\n   string cluster_info = Run({\"cluster\", \"info\"}).GetString();\n   EXPECT_THAT(cluster_info, HasSubstr(\"cluster_state:ok\"));\n   EXPECT_THAT(cluster_info, HasSubstr(\"cluster_slots_assigned:16384\"));\n@@ -422,26 +426,7 @@ TEST_F(ClusterFamilyTest, ClusterGetSlotInfoInvalid) {\n }\n \n TEST_F(ClusterFamilyTest, ClusterGetSlotInfo) {\n-  string config_template = R\"json(\n-      [\n-        {\n-          \"slot_ranges\": [\n-            {\n-              \"start\": 0,\n-              \"end\": 16383\n-            }\n-          ],\n-          \"master\": {\n-            \"id\": \"$0\",\n-            \"ip\": \"10.0.0.1\",\n-            \"port\": 7000\n-          },\n-          \"replicas\": []\n-        }\n-      ])json\";\n-  string config = absl::Substitute(config_template, GetMyId());\n-\n-  EXPECT_EQ(RunPrivileged({\"dflycluster\", \"config\", config}), \"OK\");\n+  ConfigSingleNodeCluster(GetMyId());\n \n   constexpr string_view kKey = \"some-key\";\n   const SlotId slot = ClusterConfig::KeySlot(kKey);\n@@ -480,26 +465,7 @@ TEST_F(ClusterFamilyTest, ClusterGetSlotInfo) {\n }\n \n TEST_F(ClusterFamilyTest, ClusterSlotsPopulate) {\n-  string config_template = R\"json(\n-      [\n-        {\n-          \"slot_ranges\": [\n-            {\n-              \"start\": 0,\n-              \"end\": 16383\n-            }\n-          ],\n-          \"master\": {\n-            \"id\": \"$0\",\n-            \"ip\": \"10.0.0.1\",\n-            \"port\": 7000\n-          },\n-          \"replicas\": []\n-        }\n-      ])json\";\n-  string config = absl::Substitute(config_template, GetMyId());\n-\n-  EXPECT_EQ(RunPrivileged({\"dflycluster\", \"config\", config}), \"OK\");\n+  ConfigSingleNodeCluster(GetMyId());\n \n   Run({\"debug\", \"populate\", \"10000\", \"key\", \"4\", \"SLOTS\", \"0\", \"1000\"});\n \n@@ -515,26 +481,7 @@ TEST_F(ClusterFamilyTest, ClusterSlotsPopulate) {\n }\n \n TEST_F(ClusterFamilyTest, ClusterConfigDeleteSlots) {\n-  string config_template = R\"json(\n-      [\n-        {\n-          \"slot_ranges\": [\n-            {\n-              \"start\": 0,\n-              \"end\": 16383\n-            }\n-          ],\n-          \"master\": {\n-            \"id\": \"$0\",\n-            \"ip\": \"10.0.0.1\",\n-            \"port\": 7000\n-          },\n-          \"replicas\": []\n-        }\n-      ])json\";\n-  string config = absl::Substitute(config_template, GetMyId());\n-\n-  EXPECT_EQ(RunPrivileged({\"dflycluster\", \"config\", config}), \"OK\");\n+  ConfigSingleNodeCluster(GetMyId());\n \n   Run({\"debug\", \"populate\", \"100000\"});\n \n@@ -546,8 +493,7 @@ TEST_F(ClusterFamilyTest, ClusterConfigDeleteSlots) {\n           RespArray(ElementsAre(IntArg(2), \"key_count\", Not(IntArg(0)), \"total_reads\", IntArg(0),\n                                 \"total_writes\", Not(IntArg(0)), \"memory_bytes\", IntArg(0))))));\n \n-  config = absl::Substitute(config_template, \"abc\");\n-  EXPECT_EQ(RunPrivileged({\"dflycluster\", \"config\", config}), \"OK\");\n+  ConfigSingleNodeCluster(\"abc\");\n \n   ExpectConditionWithinTimeout([&]() { return CheckedInt({\"dbsize\"}) == 0; });\n \n@@ -562,26 +508,7 @@ TEST_F(ClusterFamilyTest, ClusterConfigDeleteSlots) {\n \n // Test issue #1302\n TEST_F(ClusterFamilyTest, ClusterConfigDeleteSlotsNoCrashOnShutdown) {\n-  string config_template = R\"json(\n-      [\n-        {\n-          \"slot_ranges\": [\n-            {\n-              \"start\": 0,\n-              \"end\": 16383\n-            }\n-          ],\n-          \"master\": {\n-            \"id\": \"$0\",\n-            \"ip\": \"10.0.0.1\",\n-            \"port\": 7000\n-          },\n-          \"replicas\": []\n-        }\n-      ])json\";\n-  string config = absl::Substitute(config_template, GetMyId());\n-\n-  EXPECT_EQ(RunPrivileged({\"dflycluster\", \"config\", config}), \"OK\");\n+  ConfigSingleNodeCluster(GetMyId());\n \n   Run({\"debug\", \"populate\", \"100000\"});\n \n@@ -593,10 +520,9 @@ TEST_F(ClusterFamilyTest, ClusterConfigDeleteSlotsNoCrashOnShutdown) {\n           RespArray(ElementsAre(IntArg(2), \"key_count\", Not(IntArg(0)), \"total_reads\", IntArg(0),\n                                 \"total_writes\", Not(IntArg(0)), \"memory_bytes\", IntArg(0))))));\n \n-  config = absl::Substitute(config_template, \"abc\");\n   // After running the new config we start a fiber that removes all slots from current instance\n   // we immediately shut down to test that we do not crash.\n-  EXPECT_EQ(RunPrivileged({\"dflycluster\", \"config\", config}), \"OK\");\n+  ConfigSingleNodeCluster(\"abc\");\n }\n \n TEST_F(ClusterFamilyTest, ClusterConfigDeleteSomeSlots) {\n@@ -674,24 +600,7 @@ TEST_F(ClusterFamilyTest, ClusterFirstConfigCallDropsEntriesNotOwnedByNode) {\n   EXPECT_EQ(Run({\"debug\", \"load\", save_info.file_name}), \"OK\");\n   EXPECT_EQ(CheckedInt({\"dbsize\"}), 50000);\n \n-  EXPECT_EQ(RunPrivileged({\"dflycluster\", \"config\", R\"json(\n-      [\n-        {\n-          \"slot_ranges\": [\n-            {\n-              \"start\": 0,\n-              \"end\": 16383\n-            }\n-          ],\n-          \"master\": {\n-            \"id\": \"abcd1234\",\n-            \"ip\": \"10.0.0.1\",\n-            \"port\": 7000\n-          },\n-          \"replicas\": []\n-        }\n-      ])json\"}),\n-            \"OK\");\n+  ConfigSingleNodeCluster(\"abcd1234\");\n \n   // Make sure `dbsize` all slots were removed\n   ExpectConditionWithinTimeout([&]() { return CheckedInt({\"dbsize\"}) == 0; });\n@@ -739,27 +648,36 @@ TEST_F(ClusterFamilyTest, FlushSlots) {\n                                                   _, \"total_writes\", _, \"memory_bytes\", _)))));\n }\n \n+TEST_F(ClusterFamilyTest, FlushSlotsAndImmediatelySetValue) {\n+  for (int count : {1, 10, 100, 1000, 10000, 100000}) {\n+    ConfigSingleNodeCluster(GetMyId());\n+\n+    EXPECT_EQ(Run({\"debug\", \"populate\", absl::StrCat(count), \"key\", \"4\"}), \"OK\");\n+    EXPECT_EQ(Run({\"get\", \"key:0\"}), \"xxxx\");\n+\n+    EXPECT_THAT(Run({\"cluster\", \"keyslot\", \"key:0\"}), IntArg(2592));\n+    EXPECT_THAT(Run({\"dbsize\"}), IntArg(count));\n+    auto slot_size_response = Run({\"dflycluster\", \"getslotinfo\", \"slots\", \"2592\"});\n+    EXPECT_THAT(slot_size_response, RespArray(ElementsAre(_, \"key_count\", _, \"total_reads\", _,\n+                                                          \"total_writes\", _, \"memory_bytes\", _)));\n+    auto slot_size = slot_size_response.GetVec()[2].GetInt();\n+    EXPECT_TRUE(slot_size.has_value());\n+\n+    EXPECT_EQ(Run({\"dflycluster\", \"flushslots\", \"2592\", \"2592\"}), \"OK\");\n+    // key:0 should have been removed, so APPEND will end up with key:0 == ZZZZ\n+    EXPECT_THAT(Run({\"append\", \"key:0\", \"ZZZZ\"}), IntArg(4));\n+    EXPECT_EQ(Run({\"get\", \"key:0\"}), \"ZZZZ\");\n+    // db size should be count - (size of slot 2592) + 1, where 1 is for 'key:0'\n+    ExpectConditionWithinTimeout(\n+        [&]() { return CheckedInt({\"dbsize\"}) == (count - *slot_size + 1); });\n+\n+    ResetService();\n+  }\n+}\n+\n TEST_F(ClusterFamilyTest, ClusterCrossSlot) {\n-  string config_template = R\"json(\n-      [\n-        {\n-          \"slot_ranges\": [\n-            {\n-              \"start\": 0,\n-              \"end\": 16383\n-            }\n-          ],\n-          \"master\": {\n-            \"id\": \"$0\",\n-            \"ip\": \"10.0.0.1\",\n-            \"port\": 7000\n-          },\n-          \"replicas\": []\n-        }\n-      ])json\";\n-  string config = absl::Substitute(config_template, GetMyId());\n+  ConfigSingleNodeCluster(GetMyId());\n \n-  EXPECT_EQ(RunPrivileged({\"dflycluster\", \"config\", config}), \"OK\");\n   EXPECT_EQ(Run({\"SET\", \"key\", \"value\"}), \"OK\");\n   EXPECT_EQ(Run({\"GET\", \"key\"}), \"value\");\n \n",
  "problem_statement": "FLUSHSLOTS bug\nWhen running DFLYCLUSTER FLUSHSLOTS <range_start> <range_end> we want to delete all the slots data in given range.\r\nTo do this we create a fiber which will traverse the dash table and if the key belong to this slot and the bucket version is <= version time of the command it will be deleted.\r\nThe problem with this implementation is that if while yielding from this fiber we insert new entry to a bucket in which there is a key to be removed as it is in the flush slot range we will update the bucket version hence when we will get to this bucket in the traverse we will not delete the slot data.\r\n\n",
  "hints_text": "The fix is simple, imho. We do something similar in snapshotting by traversing the physical bucket for other entries.\n@romange I dont think it is related to traversing the physical bucket. \r\nWhen we insert to some bucket we update this bucket version. This is a bit similar to preupdate regiter when snapshoting where we serialise before we update the bucket. We need to delete the slots data in this bucket before we insert to the bucket and update it snapshot version",
  "created_at": "2024-03-28T10:01:10Z",
  "modified_files": [
    "src/server/db_slice.cc"
  ],
  "modified_test_files": [
    "src/server/cluster/cluster_family_test.cc"
  ]
}