{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 1635,
  "instance_id": "dragonflydb__dragonfly-1635",
  "issue_numbers": [
    "1618"
  ],
  "base_commit": "8040bed10fe744688a38d7140608d358eccc75d5",
  "patch": "diff --git a/src/core/compact_object.cc b/src/core/compact_object.cc\nindex e77acc752363..362be2408d87 100644\n--- a/src/core/compact_object.cc\n+++ b/src/core/compact_object.cc\n@@ -198,7 +198,6 @@ size_t RobjWrapper::MallocUsed() const {\n \n   switch (type_) {\n     case OBJ_STRING:\n-      DVLOG(2) << \"Freeing string object\";\n       CHECK_EQ(OBJ_ENCODING_RAW, encoding_);\n       return InnerObjMallocUsed();\n     case OBJ_LIST:\n@@ -256,6 +255,18 @@ size_t RobjWrapper::Size() const {\n         default:\n           LOG(FATAL) << \"Unexpected encoding \" << encoding_;\n       };\n+    case OBJ_HASH:\n+      switch (encoding_) {\n+        case kEncodingListPack: {\n+          uint8_t* lp = (uint8_t*)inner_obj_;\n+          return lpLength(lp) / 2;\n+        } break;\n+\n+        case kEncodingStrMap2: {\n+          StringMap* sm = (StringMap*)inner_obj_;\n+          return sm->Size();\n+        }\n+      }\n     default:;\n   }\n   return 0;\ndiff --git a/src/server/debugcmd.cc b/src/server/debugcmd.cc\nindex ad44fa8b2ff1..cae152ddf8ca 100644\n--- a/src/server/debugcmd.cc\n+++ b/src/server/debugcmd.cc\n@@ -11,7 +11,9 @@\n \n #include \"base/flags.h\"\n #include \"base/logging.h\"\n+#include \"core/string_map.h\"\n #include \"server/blocking_controller.h\"\n+#include \"server/container_utils.h\"\n #include \"server/engine_shard_set.h\"\n #include \"server/error.h\"\n #include \"server/main_service.h\"\n@@ -36,6 +38,7 @@ using absl::GetFlag;\n using absl::StrAppend;\n using absl::StrCat;\n \n+namespace {\n struct PopulateBatch {\n   DbIndex dbid;\n   uint64_t index[32];\n@@ -87,6 +90,128 @@ void DoPopulateBatch(std::string_view prefix, size_t val_size, bool random_value\n   }\n }\n \n+struct ObjHist {\n+  base::Histogram key_len;\n+  base::Histogram val_len;    // overall size for the value.\n+  base::Histogram card;       // for sets, hashmaps etc - it's number of entries.\n+  base::Histogram entry_len;  // for sets, hashmaps etc - it's the length of each entry.\n+};\n+\n+// Returns number of O(1) steps executed.\n+unsigned AddObjHist(PrimeIterator it, ObjHist* hist) {\n+  using namespace container_utils;\n+  const PrimeValue& pv = it->second;\n+  size_t val_len = 0;\n+  unsigned steps = 1;\n+\n+  auto per_entry_cb = [&](ContainerEntry entry) {\n+    if (entry.value) {\n+      val_len += entry.length;\n+      hist->entry_len.Add(entry.length);\n+    } else {\n+      val_len += 8;  // size of long\n+    }\n+    ++steps;\n+    return true;\n+  };\n+\n+  hist->key_len.Add(it->first.Size());\n+\n+  if (pv.ObjType() == OBJ_LIST) {\n+    IterateList(pv, per_entry_cb, 0, -1);\n+  } else if (pv.ObjType() == OBJ_ZSET) {\n+    IterateSortedSet(pv.GetRobjWrapper(),\n+                     [&](ContainerEntry entry, double) { return per_entry_cb(entry); });\n+  } else if (pv.ObjType() == OBJ_SET) {\n+    IterateSet(pv, per_entry_cb);\n+  } else if (pv.ObjType() == OBJ_HASH) {\n+    if (pv.Encoding() == kEncodingListPack) {\n+      uint8_t intbuf[LP_INTBUF_SIZE];\n+      uint8_t* lp = (uint8_t*)pv.RObjPtr();\n+      uint8_t* fptr = lpFirst(lp);\n+      while (fptr) {\n+        size_t entry_len = 0;\n+        // field\n+        string_view sv = LpGetView(fptr, intbuf);\n+        entry_len += sv.size();\n+\n+        // value\n+        fptr = lpNext(lp, fptr);\n+        entry_len += sv.size();\n+        fptr = lpNext(lp, fptr);\n+        hist->entry_len.Add(entry_len);\n+        steps += 2;\n+      }\n+      val_len = lpBytes(lp);\n+    } else {\n+      StringMap* sm = static_cast<StringMap*>(pv.RObjPtr());\n+      for (const auto& k_v : *sm) {\n+        hist->entry_len.Add(sdslen(k_v.first) + sdslen(k_v.second) + 2);\n+        ++steps;\n+      }\n+      val_len = sm->ObjMallocUsed() + sm->SetMallocUsed();\n+    }\n+  }\n+  // TODO: streams\n+\n+  if (val_len == 0) {\n+    // Fallback\n+    val_len = pv.MallocUsed();\n+  }\n+\n+  hist->val_len.Add(val_len);\n+\n+  if (pv.ObjType() != OBJ_STRING && pv.ObjType() != OBJ_JSON)\n+    hist->card.Add(pv.Size());\n+\n+  return steps;\n+}\n+\n+using ObjHistMap = absl::flat_hash_map<unsigned, unique_ptr<ObjHist>>;\n+\n+void MergeObjHistMap(ObjHistMap&& src, ObjHistMap* dest) {\n+  for (auto& [obj_type, src_hist] : src) {\n+    auto& dest_hist = (*dest)[obj_type];\n+    if (!dest_hist) {\n+      dest_hist = std::move(src_hist);\n+    } else {\n+      dest_hist->key_len.Merge(src_hist->key_len);\n+      dest_hist->val_len.Merge(src_hist->val_len);\n+      dest_hist->card.Merge(src_hist->card);\n+      dest_hist->entry_len.Merge(src_hist->entry_len);\n+    }\n+  }\n+}\n+\n+void DoBuildObjHist(EngineShard* shard, ObjHistMap* obj_hist_map) {\n+  auto& db_slice = shard->db_slice();\n+  unsigned steps = 0;\n+\n+  for (unsigned i = 0; i < db_slice.db_array_size(); ++i) {\n+    DbTable* dbt = db_slice.GetDBTable(i);\n+    if (dbt == nullptr)\n+      continue;\n+    PrimeTable::Cursor cursor;\n+    do {\n+      cursor = dbt->prime.Traverse(cursor, [&](PrimeIterator it) {\n+        unsigned obj_type = it->second.ObjType();\n+        auto& hist_ptr = (*obj_hist_map)[obj_type];\n+        if (!hist_ptr) {\n+          hist_ptr.reset(new ObjHist);\n+        }\n+        steps += AddObjHist(it, hist_ptr.get());\n+      });\n+\n+      if (steps >= 20000) {\n+        steps = 0;\n+        ThisFiber::Yield();\n+      }\n+    } while (cursor);\n+  }\n+}\n+\n+}  // namespace\n+\n DebugCmd::DebugCmd(ServerFamily* owner, ConnectionContext* cntx) : sf_(*owner), cntx_(cntx) {\n }\n \n@@ -117,6 +242,8 @@ void DebugCmd::Run(CmdArgList args) {\n         \"    to meet value size.\",\n         \"    If RAND is specified then value will be set to random hex string in specified size.\",\n         \"    If SLOTS is specified then create keys only in given slots range.\"\n+        \"OBJHIST\",\n+        \"    Prints histogram of object sizes.\",\n         \"HELP\",\n         \"    Prints this help.\",\n     };\n@@ -153,7 +280,9 @@ void DebugCmd::Run(CmdArgList args) {\n   if (subcmd == \"TRANSACTION\") {\n     return TxAnalysis();\n   }\n-\n+  if (subcmd == \"OBJHIST\") {\n+    return ObjHist();\n+  }\n   string reply = UnknownSubCmd(subcmd, \"DEBUG\");\n   return (*cntx_)->SendError(reply, kSyntaxErrType);\n }\n@@ -570,4 +699,30 @@ void DebugCmd::TxAnalysis() {\n                                           \"armed: \", armed_cnt.load(), \" free:\", free_cnt.load()));\n }\n \n+void DebugCmd::ObjHist() {\n+  vector<ObjHistMap> obj_hist_map_arr(shard_set->size());\n+\n+  shard_set->RunBlockingInParallel(\n+      [&](EngineShard* shard) { DoBuildObjHist(shard, &obj_hist_map_arr[shard->shard_id()]); });\n+\n+  for (size_t i = shard_set->size() - 1; i > 0; --i) {\n+    MergeObjHistMap(std::move(obj_hist_map_arr[i]), &obj_hist_map_arr[0]);\n+  }\n+\n+  string result;\n+  absl::StrAppend(&result, \"___begin object histogram___\\n\\n\");\n+\n+  for (auto& [obj_type, hist_ptr] : obj_hist_map_arr[0]) {\n+    StrAppend(&result, \"OBJECT:\", ObjTypeName(obj_type), \"\\n\");\n+    StrAppend(&result, \"________________________________________________________________\\n\");\n+    StrAppend(&result, \"Key length histogram:\\n\", hist_ptr->key_len.ToString(), \"\\n\");\n+    StrAppend(&result, \"Value length histogram:\\n\", hist_ptr->val_len.ToString(), \"\\n\");\n+    StrAppend(&result, \"Cardinality histogram:\\n\", hist_ptr->card.ToString(), \"\\n\");\n+    StrAppend(&result, \"Entry length histogram:\\n\", hist_ptr->entry_len.ToString(), \"\\n\");\n+  }\n+\n+  absl::StrAppend(&result, \"___end object histogram___\\n\");\n+  (*cntx_)->SendBulkString(result);\n+}\n+\n }  // namespace dfly\ndiff --git a/src/server/debugcmd.h b/src/server/debugcmd.h\nindex cb6c318ec068..bfb45e46ee22 100644\n--- a/src/server/debugcmd.h\n+++ b/src/server/debugcmd.h\n@@ -38,6 +38,7 @@ class DebugCmd {\n   void Inspect(std::string_view key);\n   void Watched();\n   void TxAnalysis();\n+  void ObjHist();\n \n   ServerFamily& sf_;\n   ConnectionContext* cntx_;\ndiff --git a/src/server/table.h b/src/server/table.h\nindex 444b8df0033f..9e3e0667d66a 100644\n--- a/src/server/table.h\n+++ b/src/server/table.h\n@@ -80,7 +80,6 @@ struct DbTable : boost::intrusive_ref_counter<DbTable, boost::thread_unsafe_coun\n   mutable DbTableStats stats;\n   std::vector<SlotStats> slots_stats;\n   ExpireTable::Cursor expire_cursor;\n-  PrimeTable::Cursor prime_cursor;\n \n   TopKeys top_keys;\n \n",
  "test_patch": "diff --git a/src/core/compact_object_test.cc b/src/core/compact_object_test.cc\nindex d582ff665c9d..a90247db6033 100644\n--- a/src/core/compact_object_test.cc\n+++ b/src/core/compact_object_test.cc\n@@ -109,6 +109,7 @@ class CompactObjectTest : public ::testing::Test {\n };\n \n TEST_F(CompactObjectTest, WastedMemoryDetection) {\n+  GTEST_SKIP() << \"TODO: this test is unreliable and must be revisited\";\n   mi_option_set(mi_option_decommit_delay, 0);\n \n   size_t allocated = 0, commited = 0, wasted = 0;\n@@ -183,6 +184,8 @@ TEST_F(CompactObjectTest, WastedMemoryDetection) {\n }\n \n TEST_F(CompactObjectTest, WastedMemoryDontCount) {\n+  GTEST_SKIP() << \"TODO: this test is unreliable and must be revisited\";\n+\n   // The commited memory per blocks are:\n   // 64bit => 4K\n   // 128bit => 8k\n@@ -383,6 +386,15 @@ TEST_F(CompactObjectTest, ZSet) {\n   EXPECT_EQ(OBJ_ENCODING_LISTPACK, cobj_.Encoding());\n }\n \n+TEST_F(CompactObjectTest, Hash) {\n+  uint8_t* lp = lpNew(0);\n+  lp = lpAppend(lp, reinterpret_cast<const uint8_t*>(\"foo\"), 3);\n+  lp = lpAppend(lp, reinterpret_cast<const uint8_t*>(\"barrr\"), 5);\n+  cobj_.InitRobj(OBJ_HASH, kEncodingListPack, lp);\n+  EXPECT_EQ(OBJ_HASH, cobj_.ObjType());\n+  EXPECT_EQ(1, cobj_.Size());\n+}\n+\n #if 0\n TEST_F(CompactObjectTest, FlatSet) {\n   size_t allocated1, resident1, active1;\n",
  "problem_statement": "DEBUG OBJHIST\nWe often need a way to learn about user's workload without leaking datastore PII data.\r\n\r\n#712 is one way to do but it's not done yet and frankly it's not enough.\r\n\r\nInstead, we could introduce the command \"DEBUG OBJHIST\" which will produce the following report:\r\n1. Per dataset/type report  (db0..dbn)/(strings, sets, hash maps etc)\r\n2. For each type print:\r\n   a. histogram of its key lengths\r\n   b. histogram of its total value lengths (so for hashmaps it would be the total length of its fields/values). As close to MallocUsed for values as possible.\r\n   c. for sets/maps/zsets: histogram of their cardinalities (zcard etc), total histogram of their member field length, member value length\r\n\r\nThe command does not have to be transactional meaning it can use `shard_set->RunBlockingInParallel` to run a fiber function that gradually crawls each shard. The function should yield after a predefined number of O(1) steps to allow smooth execution for the rest of the backend. At the end, all the histograms should be merged and printed nicely by the main command. \n",
  "hints_text": "",
  "created_at": "2023-08-03T11:48:03Z",
  "modified_files": [
    "src/core/compact_object.cc",
    "src/server/debugcmd.cc",
    "src/server/debugcmd.h",
    "src/server/table.h"
  ],
  "modified_test_files": [
    "src/core/compact_object_test.cc"
  ]
}