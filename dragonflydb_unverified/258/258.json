{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 258,
  "instance_id": "dragonflydb__dragonfly-258",
  "issue_numbers": [
    "224"
  ],
  "base_commit": "c49e88899b4d1266574e98f2a146c3fca92f8c4d",
  "patch": "diff --git a/src/core/dash.h b/src/core/dash.h\nindex 0106509f465b..4add42dbc349 100644\n--- a/src/core/dash.h\n+++ b/src/core/dash.h\n@@ -69,7 +69,7 @@ class DashTable : public detail::DashTableBase {\n \n   using const_bucket_iterator = Iterator<true, true>;\n   using bucket_iterator = Iterator<false, true>;\n-  using cursor = detail::DashCursor;\n+  using Cursor = detail::DashCursor;\n \n   struct HotspotBuckets {\n     static constexpr size_t kRegularBuckets = 4;\n@@ -193,6 +193,11 @@ class DashTable : public detail::DashTableBase {\n     return unique_segments_ * SegmentType::capacity();\n   }\n \n+  // Overall capacity of the table (including stash buckets).\n+  size_t capacity() const {\n+    return bucket_count();\n+  }\n+\n   double load_factor() const {\n     return double(size()) / (SegmentType::capacity() * unique_segments());\n   }\n@@ -206,17 +211,27 @@ class DashTable : public detail::DashTableBase {\n   // during the traversal, then Traverse() will eventually reach it even when the\n   // table shrinks or grows.\n   // Returns: cursor that is guaranteed to be less than 2^40.\n-  template <typename Cb> cursor Traverse(cursor curs, Cb&& cb);\n+  template <typename Cb> Cursor Traverse(Cursor curs, Cb&& cb);\n \n   // Takes an iterator pointing to an entry in a dash bucket and traverses all bucket's entries by\n   // calling cb(iterator) for every non-empty slot. The iteration goes over a physical bucket.\n   template <typename Cb> void TraverseBucket(const_iterator it, Cb&& cb);\n \n-  static const_bucket_iterator bucket_it(const_iterator it) {\n+  // Discards slots information.\n+  static const_bucket_iterator BucketIt(const_iterator it) {\n     return const_bucket_iterator{it.owner_, it.seg_id_, it.bucket_id_, 0};\n   }\n \n-  const_bucket_iterator CursorToBucketIt(cursor c) const {\n+  // Seeks to the first occupied slot if exists in the bucket.\n+  const_bucket_iterator BucketIt(unsigned segment_id, unsigned bucket_id) const {\n+    return const_bucket_iterator{this, segment_id, uint8_t(bucket_id)};\n+  }\n+\n+  iterator GetIterator(unsigned segment_id, unsigned bucket_id, unsigned slot_id) {\n+    return iterator{this, segment_id, uint8_t(bucket_id), uint8_t(slot_id)};\n+  }\n+\n+  const_bucket_iterator CursorToBucketIt(Cursor c) const {\n     return const_bucket_iterator{this, c.segment_id(global_depth_), c.bucket_id(), 0};\n   }\n \n@@ -240,8 +255,7 @@ class DashTable : public detail::DashTableBase {\n   // Returns true if an element was deleted i.e the rightmost slot was busy.\n   bool ShiftRight(bucket_iterator it);\n \n-  template<typename BumpPolicy>\n-  iterator BumpUp(iterator it, const BumpPolicy& bp) {\n+  template <typename BumpPolicy> iterator BumpUp(iterator it, const BumpPolicy& bp) {\n     SegmentIterator seg_it =\n         segment_[it.seg_id_]->BumpUp(it.bucket_id_, it.slot_id_, DoHash(it->first), bp);\n \n@@ -642,12 +656,12 @@ template <typename _Key, typename _Value, typename Policy>\n template <typename U>\n auto DashTable<_Key, _Value, Policy>::Find(U&& key) -> iterator {\n   uint64_t key_hash = DoHash(key);\n-  size_t x = SegmentId(key_hash);\n-  const auto* target = segment_[x];\n+  uint32_t segid = SegmentId(key_hash);\n+  const auto* target = segment_[segid];\n \n   auto seg_it = target->FindIt(key, key_hash, EqPred());\n   if (seg_it.found()) {\n-    return iterator{this, uint32_t(x), seg_it.index, seg_it.slot};\n+    return iterator{this, segid, seg_it.index, seg_it.slot};\n   }\n   return iterator{};\n }\n@@ -839,7 +853,7 @@ void DashTable<_Key, _Value, Policy>::Split(uint32_t seg_id) {\n \n template <typename _Key, typename _Value, typename Policy>\n template <typename Cb>\n-auto DashTable<_Key, _Value, Policy>::Traverse(cursor curs, Cb&& cb) -> cursor {\n+auto DashTable<_Key, _Value, Policy>::Traverse(Cursor curs, Cb&& cb) -> Cursor {\n   if (curs.bucket_id() >= kLogicalBucketNum)  // sanity.\n     return 0;\n \n@@ -868,7 +882,7 @@ auto DashTable<_Key, _Value, Policy>::Traverse(cursor curs, Cb&& cb) -> cursor {\n     }\n   } while (!fetched);\n \n-  return cursor{global_depth_, sid, bid};\n+  return Cursor{global_depth_, sid, bid};\n }\n \n template <typename _Key, typename _Value, typename Policy>\ndiff --git a/src/core/dash_internal.h b/src/core/dash_internal.h\nindex a8bd045a1dd9..92632c794924 100644\n--- a/src/core/dash_internal.h\n+++ b/src/core/dash_internal.h\n@@ -174,6 +174,10 @@ template <unsigned NUM_SLOTS, unsigned NUM_STASH_FPS> class BucketBase {\n     return slotb_.GetBusy();\n   }\n \n+  bool IsBusy(unsigned slot) const {\n+    return (GetBusy() & (1u << slot)) != 0;\n+  }\n+\n   // mask is saying which slots needs to be freed (1 - should clear).\n   void ClearSlots(uint32_t mask) {\n     slotb_.ClearSlots(mask);\n@@ -664,8 +668,8 @@ class DashCursor {\n   // | segment_id......| bucket_id\n   // 40                8          0\n   // By using depth we take most significant bits of segment_id if depth has decreased\n-  // since the cursort was created, or extend the least significant bits with zeros if\n-  // depth has increased.\n+  // since the cursor has been created, or extend the least significant bits with zeros,\n+  // if depth was increased.\n   uint32_t segment_id(uint8_t depth) {\n     return val_ >> (40 - depth);\n   }\ndiff --git a/src/server/db_slice.cc b/src/server/db_slice.cc\nindex f972b45a98bc..31786dd4abc9 100644\n--- a/src/server/db_slice.cc\n+++ b/src/server/db_slice.cc\n@@ -44,13 +44,27 @@ void UpdateStatsOnDeletion(PrimeIterator it, DbTableStats* stats) {\n     stats->strval_memory_usage -= value_heap_size;\n }\n \n+void EvictItemFun(PrimeIterator del_it, DbTable* table) {\n+  if (del_it->second.HasExpire()) {\n+    CHECK_EQ(1u, table->expire.Erase(del_it->first));\n+  }\n+\n+  UpdateStatsOnDeletion(del_it, &table->stats);\n+\n+  DVLOG(2) << \"Evicted from bucket \" << del_it.bucket_id() << \" \" << del_it->first.ToString();\n+\n+  table->prime.Erase(del_it);\n+};\n+\n class PrimeEvictionPolicy {\n  public:\n   static constexpr bool can_evict = true;  // we implement eviction functionality.\n   static constexpr bool can_gc = true;\n \n-  PrimeEvictionPolicy(DbIndex db_indx, bool can_evict, DbSlice* db_slice, int64_t mem_budget)\n-      : db_slice_(db_slice), mem_budget_(mem_budget), db_indx_(db_indx), can_evict_(can_evict) {\n+  PrimeEvictionPolicy(DbIndex db_indx, bool can_evict, ssize_t mem_budget, ssize_t soft_limit,\n+                      DbSlice* db_slice)\n+      : db_slice_(db_slice), mem_budget_(mem_budget), soft_limit_(soft_limit), db_indx_(db_indx),\n+        can_evict_(can_evict) {\n   }\n \n   void RecordSplit(PrimeTable::Segment_t* segment) {\n@@ -58,14 +72,12 @@ class PrimeEvictionPolicy {\n     DVLOG(1) << \"split: \" << segment->SlowSize() << \"/\" << segment->capacity();\n   }\n \n-  bool CanGrow(const PrimeTable& tbl) const {\n-    return mem_budget_ > int64_t(PrimeTable::kSegBytes);\n-  }\n+  bool CanGrow(const PrimeTable& tbl) const;\n \n   unsigned GarbageCollect(const PrimeTable::HotspotBuckets& eb, PrimeTable* me);\n   unsigned Evict(const PrimeTable::HotspotBuckets& eb, PrimeTable* me);\n \n-  int64_t mem_budget() const {\n+  ssize_t mem_budget() const {\n     return mem_budget_;\n   }\n \n@@ -79,7 +91,8 @@ class PrimeEvictionPolicy {\n \n  private:\n   DbSlice* db_slice_;\n-  int64_t mem_budget_;\n+  ssize_t mem_budget_;\n+  ssize_t soft_limit_ = 0;\n   unsigned evicted_ = 0;\n   unsigned checked_ = 0;\n   const DbIndex db_indx_;\n@@ -90,13 +103,26 @@ class PrimeEvictionPolicy {\n };\n \n class PrimeBumpPolicy {\n-public:\n+ public:\n   // returns true if key can be made less important for eviction (opposite of bump up)\n   bool CanBumpDown(const CompactObj& key) const {\n     return !key.IsSticky();\n   }\n };\n \n+bool PrimeEvictionPolicy::CanGrow(const PrimeTable& tbl) const {\n+  if (mem_budget_ > soft_limit_)\n+    return true;\n+\n+  DCHECK_LT(tbl.size(), tbl.capacity());\n+\n+  // We take a conservative stance here -\n+  // we estimate how much memory we will take with the current capacity\n+  // even though we may currently use less memory.\n+  // see https://github.com/dragonflydb/dragonfly/issues/256#issuecomment-1227095503\n+  size_t available = tbl.capacity() - tbl.size();\n+  return mem_budget_ > int64_t(PrimeTable::kSegBytes + db_slice_->bytes_per_object() * available);\n+}\n \n unsigned PrimeEvictionPolicy::GarbageCollect(const PrimeTable::HotspotBuckets& eb, PrimeTable* me) {\n   unsigned res = 0;\n@@ -136,14 +162,12 @@ unsigned PrimeEvictionPolicy::Evict(const PrimeTable::HotspotBuckets& eb, PrimeT\n     if (last_slot_it->first.IsSticky()) {\n       return 0;\n     }\n-    if (last_slot_it->second.HasExpire()) {\n-      ExpireTable* expire_tbl = db_slice_->GetTables(db_indx_).second;\n-      CHECK_EQ(1u, expire_tbl->Erase(last_slot_it->first));\n-    }\n-    UpdateStatsOnDeletion(last_slot_it, db_slice_->MutableStats(db_indx_));\n+\n+    DbTable* table = db_slice_->GetDBTable(db_indx_);\n+    EvictItemFun(last_slot_it, table);\n+    ++evicted_;\n   }\n-  CHECK(me->ShiftRight(bucket_it));\n-  ++evicted_;\n+  me->ShiftRight(bucket_it);\n \n   return 1;\n }\n@@ -167,9 +191,10 @@ DbStats& DbStats::operator+=(const DbStats& o) {\n }\n \n SliceEvents& SliceEvents::operator+=(const SliceEvents& o) {\n-  static_assert(sizeof(SliceEvents) == 48, \"You should update this function with new fields\");\n+  static_assert(sizeof(SliceEvents) == 56, \"You should update this function with new fields\");\n \n   ADD(evicted_keys);\n+  ADD(hard_evictions);\n   ADD(expired_keys);\n   ADD(garbage_collected);\n   ADD(stash_unloaded);\n@@ -186,6 +211,7 @@ DbSlice::DbSlice(uint32_t index, bool caching_mode, EngineShard* owner)\n   db_arr_.emplace_back();\n   CreateDb(0);\n   expire_base_[0] = expire_base_[1] = 0;\n+  soft_budget_limit_ = (0.1 * max_memory_limit / shard_set->size());\n }\n \n DbSlice::~DbSlice() {\n@@ -299,11 +325,11 @@ pair<PrimeIterator, bool> DbSlice::AddOrFind(DbIndex db_index, string_view key)\n   return make_pair(get<0>(res), get<2>(res));\n }\n \n-tuple<PrimeIterator, ExpireIterator, bool> DbSlice::AddOrFind2(\n-    DbIndex db_index, string_view key) noexcept(false) {\n+tuple<PrimeIterator, ExpireIterator, bool> DbSlice::AddOrFind2(DbIndex db_index,\n+                                                               string_view key) noexcept(false) {\n   DCHECK(IsDbValid(db_index));\n \n-  auto& db = db_arr_[db_index];\n+  DbTable& db = *db_arr_[db_index];\n \n   // If we have some registered onchange callbacks, we must know in advance whether its Find or Add.\n   if (!change_cb_.empty()) {\n@@ -319,8 +345,13 @@ tuple<PrimeIterator, ExpireIterator, bool> DbSlice::AddOrFind2(\n     }\n   }\n \n-  PrimeEvictionPolicy evp{db_index, bool(caching_mode_), this,\n-                          int64_t(memory_budget_ - key.size())};\n+  PrimeEvictionPolicy evp{db_index, bool(caching_mode_), int64_t(memory_budget_ - key.size()),\n+                          ssize_t(soft_budget_limit_), this};\n+\n+  // If we are over limit in non-cache scenario, just be conservative and throw.\n+  if (!caching_mode_ && evp.mem_budget() < 0) {\n+    throw bad_alloc();\n+  }\n \n   // Fast-path if change_cb_ is empty so we Find or Add using\n   // the insert operation: twice more efficient.\n@@ -330,22 +361,31 @@ tuple<PrimeIterator, ExpireIterator, bool> DbSlice::AddOrFind2(\n \n   // I try/catch just for sake of having a convenient place to set a breakpoint.\n   try {\n-    tie(it, inserted) = db->prime.Insert(std::move(co_key), PrimeValue{}, evp);\n+    tie(it, inserted) = db.prime.Insert(std::move(co_key), PrimeValue{}, evp);\n   } catch (bad_alloc& e) {\n     throw e;\n   }\n \n+  size_t evicted_obj_bytes = 0;\n+\n+  // We may still reach the state when our memory usage is above the limit even if we\n+  // do not add new segments. For example, we have half full segments\n+  // and we add new objects or update the existing ones and our memory usage grows.\n+  if (evp.mem_budget() < 0) {\n+    evicted_obj_bytes = EvictObjects(-evp.mem_budget(), it, &db);\n+  }\n+\n   if (inserted) {  // new entry\n-    db->stats.inline_keys += it->first.IsInline();\n-    db->stats.obj_memory_usage += it->first.MallocUsed();\n+    db.stats.inline_keys += it->first.IsInline();\n+    db.stats.obj_memory_usage += it->first.MallocUsed();\n \n-    events_.garbage_collected = db->prime.garbage_collected();\n-    events_.stash_unloaded = db->prime.stash_unloaded();\n+    events_.garbage_collected = db.prime.garbage_collected();\n+    events_.stash_unloaded = db.prime.stash_unloaded();\n     events_.evicted_keys += evp.evicted();\n     events_.garbage_checked += evp.checked();\n \n     it.SetVersion(NextVersion());\n-    memory_budget_ = evp.mem_budget();\n+    memory_budget_ = evp.mem_budget() + evicted_obj_bytes;\n \n     return make_tuple(it, ExpireIterator{}, true);\n   }\n@@ -354,9 +394,11 @@ tuple<PrimeIterator, ExpireIterator, bool> DbSlice::AddOrFind2(\n \n   DCHECK(IsValid(existing));\n \n+  memory_budget_ += evicted_obj_bytes;\n+\n   ExpireIterator expire_it;\n   if (existing->second.HasExpire()) {\n-    expire_it = db->expire.Find(existing->first);\n+    expire_it = db.expire.Find(existing->first);\n     CHECK(IsValid(expire_it));\n \n     // TODO: to implement the incremental update of expiry values using multi-generation\n@@ -364,17 +406,17 @@ tuple<PrimeIterator, ExpireIterator, bool> DbSlice::AddOrFind2(\n     uint64_t delta_ms = now_ms_ - expire_base_[0];\n \n     if (expire_it->second.duration_ms() <= delta_ms) {\n-      db->expire.Erase(expire_it);\n+      db.expire.Erase(expire_it);\n \n       if (existing->second.HasFlag()) {\n-        db->mcflag.Erase(existing->first);\n+        db.mcflag.Erase(existing->first);\n       }\n \n       // Keep the entry but reset the object.\n       size_t value_heap_size = existing->second.MallocUsed();\n-      db->stats.obj_memory_usage -= value_heap_size;\n+      db.stats.obj_memory_usage -= value_heap_size;\n       if (existing->second.ObjType() == OBJ_STRING)\n-        db->stats.obj_memory_usage -= value_heap_size;\n+        db.stats.obj_memory_usage -= value_heap_size;\n \n       existing->second.Reset();\n       events_.expired_keys++;\n@@ -392,13 +434,6 @@ void DbSlice::ActivateDb(DbIndex db_ind) {\n   CreateDb(db_ind);\n }\n \n-void DbSlice::CreateDb(DbIndex index) {\n-  auto& db = db_arr_[index];\n-  if (!db) {\n-    db.reset(new DbTable{owner_->memory_resource()});\n-  }\n-}\n-\n bool DbSlice::Del(DbIndex db_ind, PrimeIterator it) {\n   if (!IsValid(it)) {\n     return false;\n@@ -490,14 +525,14 @@ uint32_t DbSlice::GetMCFlag(DbIndex db_ind, const PrimeKey& key) const {\n \n PrimeIterator DbSlice::AddNew(DbIndex db_ind, string_view key, PrimeValue obj,\n                               uint64_t expire_at_ms) noexcept(false) {\n-  auto [it, added] = AddOrFind(db_ind, key, std::move(obj), expire_at_ms);\n+  auto [it, added] = AddEntry(db_ind, key, std::move(obj), expire_at_ms);\n   CHECK(added);\n \n   return it;\n }\n \n-pair<PrimeIterator, bool> DbSlice::AddOrFind(DbIndex db_ind, string_view key, PrimeValue obj,\n-                                             uint64_t expire_at_ms) noexcept(false) {\n+pair<PrimeIterator, bool> DbSlice::AddEntry(DbIndex db_ind, string_view key, PrimeValue obj,\n+                                            uint64_t expire_at_ms) noexcept(false) {\n   DCHECK_LT(db_ind, db_arr_.size());\n   DCHECK(!obj.IsRef());\n \n@@ -666,7 +701,7 @@ void DbSlice::UnregisterOnChange(uint64_t id) {\n   LOG(DFATAL) << \"Could not find \" << id << \" to unregister\";\n }\n \n-auto DbSlice::DeleteExpired(DbIndex db_ind, unsigned count) -> DeleteExpiredStats {\n+auto DbSlice::DeleteExpiredStep(DbIndex db_ind, unsigned count) -> DeleteExpiredStats {\n   auto& db = *db_arr_[db_ind];\n   DeleteExpiredStats result;\n \n@@ -698,4 +733,100 @@ auto DbSlice::DeleteExpired(DbIndex db_ind, unsigned count) -> DeleteExpiredStat\n   return result;\n }\n \n+// TODO: Design a better background evicting heuristic.\n+void DbSlice::FreeMemWithEvictionStep(DbIndex db_ind, size_t increase_goal_bytes) {\n+  if (!caching_mode_)\n+    return;\n+}\n+\n+void DbSlice::CreateDb(DbIndex db_ind) {\n+  auto& db = db_arr_[db_ind];\n+  if (!db) {\n+    db.reset(new DbTable{owner_->memory_resource()});\n+  }\n+}\n+\n+// \"it\" is the iterator that we just added/updated and it should not be deleted.\n+// \"table\" is the instance where we should delete the objects from.\n+size_t DbSlice::EvictObjects(size_t memory_to_free, PrimeIterator it, DbTable* table) {\n+  PrimeTable::Segment_t* segment = table->prime.GetSegment(it.segment_id());\n+  DCHECK(segment);\n+\n+  constexpr unsigned kNumStashBuckets =\n+      PrimeTable::Segment_t::kTotalBuckets - PrimeTable::Segment_t::kNumBuckets;\n+\n+  PrimeTable::bucket_iterator it2(it);\n+  unsigned evicted = 0;\n+  bool evict_succeeded = false;\n+\n+  EngineShard* shard = owner_;\n+  size_t used_memory_start = shard->UsedMemory();\n+\n+  auto freed_memory_fun = [&] {\n+    size_t current = shard->UsedMemory();\n+    return current < used_memory_start ? used_memory_start - current : 0;\n+  };\n+\n+  for (unsigned i = 0; !evict_succeeded && i < kNumStashBuckets; ++i) {\n+    unsigned stash_bid = i + PrimeTable::Segment_t::kNumBuckets;\n+    const auto& bucket = segment->GetBucket(stash_bid);\n+    if (bucket.IsEmpty())\n+      continue;\n+\n+    for (int slot_id = PrimeTable::Segment_t::kNumSlots - 1; slot_id >= 0; --slot_id) {\n+      if (!bucket.IsBusy(slot_id))\n+        continue;\n+\n+      auto evict_it = table->prime.GetIterator(it.segment_id(), stash_bid, slot_id);\n+      // skip the iterator that we must keep or the sticky items.\n+      if (evict_it == it || evict_it->first.IsSticky())\n+        continue;\n+\n+      EvictItemFun(evict_it, table);\n+      ++evicted;\n+      if (freed_memory_fun() > memory_to_free) {\n+        evict_succeeded = true;\n+        break;\n+      }\n+    }\n+  }\n+\n+  if (evicted) {\n+    DVLOG(1) << \"Evicted \" << evicted << \" stashed items, freed \" << freed_memory_fun() << \" bytes\";\n+  }\n+\n+  // Try normal buckets now. We iterate from largest slot to smallest across the whole segment.\n+  for (int slot_id = PrimeTable::Segment_t::kNumSlots - 1; !evict_succeeded && slot_id >= 0;\n+       --slot_id) {\n+    for (unsigned i = 0; i < PrimeTable::Segment_t::kNumBuckets; ++i) {\n+      unsigned bid = (it.bucket_id() + i) % PrimeTable::Segment_t::kNumBuckets;\n+      const auto& bucket = segment->GetBucket(bid);\n+      if (!bucket.IsBusy(slot_id))\n+        continue;\n+\n+      auto evict_it = table->prime.GetIterator(it.segment_id(), bid, slot_id);\n+      if (evict_it == it || evict_it->first.IsSticky())\n+        continue;\n+\n+      EvictItemFun(evict_it, table);\n+      ++evicted;\n+\n+      if (freed_memory_fun() > memory_to_free) {\n+        evict_succeeded = true;\n+        break;\n+      }\n+    }\n+  }\n+\n+  if (evicted) {\n+    DVLOG(1) << \"Evicted total: \" << evicted << \" items, freed \" << freed_memory_fun() << \" bytes \"\n+             << \"success: \" << evict_succeeded;\n+\n+    events_.evicted_keys += evicted;\n+    events_.hard_evictions += evicted;\n+  }\n+\n+  return freed_memory_fun();\n+};\n+\n }  // namespace dfly\ndiff --git a/src/server/db_slice.h b/src/server/db_slice.h\nindex 362d6c4d2f89..ccab1c6b1cce 100644\n--- a/src/server/db_slice.h\n+++ b/src/server/db_slice.h\n@@ -40,6 +40,9 @@ struct DbStats : public DbTableStats {\n struct SliceEvents {\n   // Number of eviction events.\n   size_t evicted_keys = 0;\n+\n+  // evictions that were performed when we have a negative memory budget.\n+  size_t hard_evictions = 0;\n   size_t expired_keys = 0;\n   size_t garbage_checked = 0;\n   size_t garbage_collected = 0;\n@@ -83,6 +86,7 @@ class DbSlice {\n   // Activates `db_ind` database if it does not exist (see ActivateDb below).\n   void Reserve(DbIndex db_ind, size_t key_size);\n \n+  // Returns statistics for the whole db slice. A bit heavy operation.\n   Stats GetStats() const;\n \n   //! UpdateExpireClock updates the expire clock for this db slice.\n@@ -95,14 +99,21 @@ class DbSlice {\n     expire_base_[generation & 1] = now;\n   }\n \n-  void SetMemoryBudget(int64_t budget) {\n+  // From time to time DbSlice is set with a new set of params needed to estimate its\n+  // memory usage.\n+  void SetCachedParams(int64_t budget, size_t bytes_per_object) {\n     memory_budget_ = budget;\n+    bytes_per_object_ = bytes_per_object;\n   }\n \n   ssize_t memory_budget() const {\n     return memory_budget_;\n   }\n \n+  size_t bytes_per_object() const {\n+    return bytes_per_object_;\n+  }\n+\n   // returns absolute time of the expiration.\n   time_t ExpireTime(ExpireIterator it) const {\n     return it.is_done() ? 0 : expire_base_[0] + it->second.duration_ms();\n@@ -136,8 +147,14 @@ class DbSlice {\n   // Returns second=true if insertion took place, false otherwise.\n   // expire_at_ms equal to 0 - means no expiry.\n   // throws: bad_alloc is insertion could not happen due to out of memory.\n-  std::pair<PrimeIterator, bool> AddOrFind(DbIndex db_ind, std::string_view key, PrimeValue obj,\n-                                           uint64_t expire_at_ms) noexcept(false);\n+  std::pair<PrimeIterator, bool> AddEntry(DbIndex db_ind, std::string_view key, PrimeValue obj,\n+                                          uint64_t expire_at_ms) noexcept(false);\n+\n+  // Adds a new entry. Requires: key does not exist in this slice.\n+  // Returns the iterator to the newly added entry.\n+  // throws: bad_alloc is insertion could not happen due to out of memory.\n+  PrimeIterator AddNew(DbIndex db_ind, std::string_view key, PrimeValue obj,\n+                       uint64_t expire_at_ms) noexcept(false);\n \n   // Either adds or removes (if at == 0) expiry. Returns true if a change was made.\n   // Does not change expiry if at != 0 and expiry already exists.\n@@ -146,12 +163,6 @@ class DbSlice {\n   void SetMCFlag(DbIndex db_ind, PrimeKey key, uint32_t flag);\n   uint32_t GetMCFlag(DbIndex db_ind, const PrimeKey& key) const;\n \n-  // Adds a new entry. Requires: key does not exist in this slice.\n-  // Returns the iterator to the newly added entry.\n-  // throws: bad_alloc is insertion could not happen due to out of memory.\n-  PrimeIterator AddNew(DbIndex db_ind, std::string_view key, PrimeValue obj,\n-                       uint64_t expire_at_ms) noexcept(false);\n-\n   // Creates a database with index `db_ind`. If such database exists does nothing.\n   void ActivateDb(DbIndex db_ind);\n \n@@ -193,6 +204,10 @@ class DbSlice {\n     return id < db_arr_.size() && bool(db_arr_[id]);\n   }\n \n+  DbTable* GetDBTable(DbIndex id) {\n+    return db_arr_[id].get();\n+  }\n+\n   std::pair<PrimeTable*, ExpireTable*> GetTables(DbIndex id) {\n     return std::pair<PrimeTable*, ExpireTable*>(&db_arr_[id]->prime, &db_arr_[id]->expire);\n   }\n@@ -235,7 +250,8 @@ class DbSlice {\n   };\n \n   // Deletes some amount of possible expired items.\n-  DeleteExpiredStats DeleteExpired(DbIndex db_indx, unsigned count);\n+  DeleteExpiredStats DeleteExpiredStep(DbIndex db_indx, unsigned count);\n+  void FreeMemWithEvictionStep(DbIndex db_indx, size_t increase_goal_bytes);\n \n   const DbTableArray& databases() const {\n     return db_arr_;\n@@ -247,6 +263,7 @@ class DbSlice {\n \n  private:\n   void CreateDb(DbIndex index);\n+  size_t EvictObjects(size_t memory_to_free, PrimeIterator it, DbTable* table);\n \n   uint64_t NextVersion() {\n     return version_++;\n@@ -262,6 +279,8 @@ class DbSlice {\n \n   uint64_t version_ = 1;  // Used to version entries in the PrimeTable.\n   ssize_t memory_budget_ = SSIZE_MAX;\n+  size_t bytes_per_object_ = 0;\n+  size_t soft_budget_limit_ = 0;\n \n   mutable SliceEvents events_;  // we may change this even for const operations.\n \ndiff --git a/src/server/engine_shard_set.cc b/src/server/engine_shard_set.cc\nindex 273be74d3ac5..3a2f8c1c793d 100644\n--- a/src/server/engine_shard_set.cc\n+++ b/src/server/engine_shard_set.cc\n@@ -289,25 +289,37 @@ void EngineShard::Heartbeat() {\n \n   if (task_iters_++ % 8 == 0) {\n     CacheStats();\n+    constexpr double kTtlDeleteLimit = 200;\n+    constexpr double kRedLimitFactor = 0.1;\n \n     uint32_t traversed = GetMovingSum6(TTL_TRAVERSE);\n     uint32_t deleted = GetMovingSum6(TTL_DELETE);\n-    unsigned count = 5;\n+    unsigned ttl_delete_target = 5;\n+\n     if (deleted > 10) {\n-      // deleted should leq than traversed.\n-      // hence we map our delete/traversed ration into a range [0, 100).\n-      count = 200.0 * double(deleted) / (double(traversed) + 10);\n+      // deleted should be <= traversed.\n+      // hence we map our delete/traversed ratio into a range [0, kTtlDeleteLimit).\n+      // The higher t\n+      ttl_delete_target = kTtlDeleteLimit * double(deleted) / (double(traversed) + 10);\n     }\n \n+    ssize_t redline = (max_memory_limit * kRedLimitFactor) / shard_set->size();\n+\n     for (unsigned i = 0; i < db_slice_.db_array_size(); ++i) {\n-      if (db_slice_.IsDbValid(i)) {\n-        auto [pt, expt] = db_slice_.GetTables(i);\n-        if (expt->size() > pt->size() / 4) {\n-          DbSlice::DeleteExpiredStats stats = db_slice_.DeleteExpired(i, count);\n-\n-          counter_[TTL_TRAVERSE].IncBy(stats.traversed);\n-          counter_[TTL_DELETE].IncBy(stats.deleted);\n-        }\n+      if (!db_slice_.IsDbValid(i))\n+        continue;\n+\n+      auto [pt, expt] = db_slice_.GetTables(i);\n+      if (expt->size() > pt->size() / 4) {\n+        DbSlice::DeleteExpiredStats stats = db_slice_.DeleteExpiredStep(i, ttl_delete_target);\n+\n+        counter_[TTL_TRAVERSE].IncBy(stats.traversed);\n+        counter_[TTL_DELETE].IncBy(stats.deleted);\n+      }\n+\n+      // if our budget is below the limit\n+      if (db_slice_.memory_budget() < redline) {\n+        db_slice_.FreeMemWithEvictionStep(i, redline - db_slice_.memory_budget());\n       }\n     }\n   }\n@@ -317,13 +329,24 @@ void EngineShard::CacheStats() {\n   // mi_heap_visit_blocks(tlh, false /* visit all blocks*/, visit_cb, &sum);\n   mi_stats_merge();\n \n+  // Used memory for this shard.\n   size_t used_mem = UsedMemory();\n   cached_stats[db_slice_.shard_id()].used_memory.store(used_mem, memory_order_relaxed);\n   ssize_t free_mem = max_memory_limit - used_mem_current.load(memory_order_relaxed);\n-  if (free_mem < 0)\n-    free_mem = 0;\n \n-  db_slice_.SetMemoryBudget(free_mem / shard_set->size());\n+  size_t entries = 0;\n+  size_t table_memory = 0;\n+  for (size_t i = 0; i < db_slice_.db_array_size(); ++i) {\n+    DbTable* table = db_slice_.GetDBTable(i);\n+    if (table) {\n+      entries += table->prime.size();\n+      table_memory += (table->prime.mem_usage() + table->expire.mem_usage());\n+    }\n+  }\n+  size_t obj_memory = table_memory <= used_mem ? used_mem - table_memory : 0;\n+\n+  size_t bytes_per_obj = entries > 0 ? obj_memory / entries : 0;\n+  db_slice_.SetCachedParams(free_mem / shard_set->size(), bytes_per_obj);\n }\n \n size_t EngineShard::UsedMemory() const {\ndiff --git a/src/server/generic_family.cc b/src/server/generic_family.cc\nindex 7b99a30d8bff..c772598947b5 100644\n--- a/src/server/generic_family.cc\n+++ b/src/server/generic_family.cc\n@@ -218,7 +218,7 @@ void OpScan(const OpArgs& op_args, const ScanOpts& scan_opts, uint64_t* cursor,\n   VLOG(1) << \"PrimeTable \" << db_slice.shard_id() << \"/\" << op_args.db_ind << \" has \"\n           << db_slice.DbSize(op_args.db_ind);\n \n-  PrimeTable::cursor cur = *cursor;\n+  PrimeTable::Cursor cur = *cursor;\n   auto [prime_table, expire_table] = db_slice.GetTables(op_args.db_ind);\n   do {\n     cur = prime_table->Traverse(\ndiff --git a/src/server/rdb_load.cc b/src/server/rdb_load.cc\nindex 30384d57d671..926662d3d710 100644\n--- a/src/server/rdb_load.cc\n+++ b/src/server/rdb_load.cc\n@@ -1214,7 +1214,7 @@ void RdbLoader::LoadItemsBuffer(DbIndex db_ind, const ItemsBuf& ib) {\n       break;\n     }\n \n-    auto [it, added] = db_slice.AddOrFind(db_ind, key, std::move(pv), item.expire_ms);\n+    auto [it, added] = db_slice.AddEntry(db_ind, key, std::move(pv), item.expire_ms);\n \n     if (!added) {\n       LOG(WARNING) << \"RDB has duplicated key '\" << key << \"' in DB \" << db_ind;\ndiff --git a/src/server/server_family.cc b/src/server/server_family.cc\nindex 9dabf777e96a..0db8811cdfe3 100644\n--- a/src/server/server_family.cc\n+++ b/src/server/server_family.cc\n@@ -165,6 +165,9 @@ void ServerFamily::Init(util::AcceptServer* acceptor, util::ListenerInterface* m\n   dfly_cmd_.reset(new DflyCmd(main_listener, journal_.get()));\n \n   pb_task_ = shard_set->pool()->GetNextProactor();\n+\n+  // Unlike EngineShard::Heartbeat that runs independently in each shard thread,\n+  // this callback runs in a single thread and it aggregates globally stats from all the shards.\n   auto cache_cb = [] {\n     uint64_t sum = 0;\n     const auto& stats = EngineShardSet::GetCachedStats();\n@@ -864,6 +867,7 @@ void ServerFamily::Info(CmdArgList args, ConnectionContext* cntx) {\n     append(\"rejected_connections\", -1);\n     append(\"expired_keys\", m.events.expired_keys);\n     append(\"evicted_keys\", m.events.evicted_keys);\n+    append(\"hard_evictions\", m.events.hard_evictions);\n     append(\"garbage_checked\", m.events.garbage_checked);\n     append(\"garbage_collected\", m.events.garbage_collected);\n     append(\"bump_ups\", m.events.bumpups);\ndiff --git a/src/server/snapshot.cc b/src/server/snapshot.cc\nindex fdffb6478865..a6643a7592fc 100644\n--- a/src/server/snapshot.cc\n+++ b/src/server/snapshot.cc\n@@ -75,7 +75,7 @@ void SliceSnapshot::SerializeSingleEntry(DbIndex db_indx, const PrimeKey& pk, co\n void SliceSnapshot::FiberFunc() {\n   this_fiber::properties<FiberProps>().set_name(\n       absl::StrCat(\"SliceSnapshot\", ProactorBase::GetIndex()));\n-  PrimeTable::cursor cursor;\n+  PrimeTable::Cursor cursor;\n \n   for (DbIndex db_indx = 0; db_indx < db_array_.size(); ++db_indx) {\n     if (!db_array_[db_indx])\n@@ -90,7 +90,7 @@ void SliceSnapshot::FiberFunc() {\n     mu_.unlock();\n \n     do {\n-      PrimeTable::cursor next = pt->Traverse(cursor, [this](auto it) { this->SaveCb(move(it)); });\n+      PrimeTable::Cursor next = pt->Traverse(cursor, [this](auto it) { this->SaveCb(move(it)); });\n \n       cursor = next;\n \ndiff --git a/src/server/table.h b/src/server/table.h\nindex 7960e5c3c852..898a649d2c4b 100644\n--- a/src/server/table.h\n+++ b/src/server/table.h\n@@ -65,7 +65,8 @@ struct DbTable : boost::intrusive_ref_counter<DbTable, boost::thread_unsafe_coun\n   LockTable trans_locks;\n \n   mutable DbTableStats stats;\n-  ExpireTable::cursor expire_cursor;\n+  ExpireTable::Cursor expire_cursor;\n+  PrimeTable::Cursor prime_cursor;\n \n   explicit DbTable(std::pmr::memory_resource* mr);\n   ~DbTable();\ndiff --git a/src/server/tiered_storage.cc b/src/server/tiered_storage.cc\nindex 8cab2d2e0dee..bf5c30215845 100644\n--- a/src/server/tiered_storage.cc\n+++ b/src/server/tiered_storage.cc\n@@ -329,7 +329,7 @@ void TieredStorage::FlushPending() {\n   for (size_t i = 0; i < canonic_req.size(); ++i) {\n     DbIndex db_ind = canonic_req[i].first;\n     uint64_t cursor_val = canonic_req[i].second;\n-    PrimeTable::cursor curs(cursor_val);\n+    PrimeTable::Cursor curs(cursor_val);\n     db_slice_.GetTables(db_ind).first->Traverse(curs, tr_cb);\n \n     for (unsigned j = 0; j < batch_len; ++j) {\n",
  "test_patch": "diff --git a/src/core/dash_test.cc b/src/core/dash_test.cc\nindex 8435fb434f5f..c00ba575b6a1 100644\n--- a/src/core/dash_test.cc\n+++ b/src/core/dash_test.cc\n@@ -512,7 +512,7 @@ TEST_F(DashTest, Traverse) {\n     dt_.Insert(i, i);\n   }\n \n-  Dash64::cursor cursor;\n+  Dash64::Cursor cursor;\n   vector<unsigned> nums;\n   auto tr_cb = [&](Dash64::iterator it) {\n     nums.push_back(it->first);\n@@ -536,7 +536,7 @@ TEST_F(DashTest, Bucket) {\n   }\n   std::vector<uint64_t> s;\n   auto it = dt_.begin();\n-  auto bucket_it = Dash64::bucket_it(it);\n+  auto bucket_it = Dash64::BucketIt(it);\n \n   dt_.TraverseBucket(it, [&](auto i) { s.push_back(i->first); });\n \ndiff --git a/src/facade/facade_test.h b/src/facade/facade_test.h\nindex baa0342d2268..f6999999a7f3 100644\n--- a/src/facade/facade_test.h\n+++ b/src/facade/facade_test.h\n@@ -74,6 +74,14 @@ inline bool operator!=(const RespExpr& left, std::string_view s) {\n   return !(left == s);\n }\n \n+inline bool operator==(std::string_view s, const RespExpr& right) {\n+  return right == s;\n+}\n+\n+inline bool operator!=(std::string_view s, const RespExpr& right) {\n+  return !(right == s);\n+}\n+\n void PrintTo(const RespExpr::Vec& vec, std::ostream* os);\n \n }  // namespace facade\ndiff --git a/src/server/dragonfly_test.cc b/src/server/dragonfly_test.cc\nindex 0dd6e978c06b..7caefa3a05b4 100644\n--- a/src/server/dragonfly_test.cc\n+++ b/src/server/dragonfly_test.cc\n@@ -502,20 +502,26 @@ TEST_F(DflyEngineTest, Bug207) {\n TEST_F(DflyEngineTest, StickyEviction) {\n   shard_set->TEST_EnableHeartBeat();\n   shard_set->TEST_EnableCacheMode();\n-  max_memory_limit = 0;\n+  max_memory_limit = 300000;\n \n   string tmp_val(100, '.');\n \n   ssize_t failed = -1;\n   for (ssize_t i = 0; i < 5000; ++i) {\n-    auto set_resp = Run({\"set\", StrCat(\"key\", i), tmp_val});\n-    auto stick_resp = Run({\"stick\", StrCat(\"key\", i)});\n+    string key = StrCat(\"volatile\", i);\n+    ASSERT_EQ(\"OK\", Run({\"set\", key, tmp_val}));\n+  }\n+\n+  for (ssize_t i = 0; i < 5000; ++i) {\n+    string key = StrCat(\"key\", i);\n+    auto set_resp = Run({\"set\", key, tmp_val});\n+    auto stick_resp = Run({\"stick\", key});\n \n     if (set_resp != \"OK\") {\n       failed = i;\n       break;\n     }\n-    ASSERT_THAT(stick_resp, IntArg(1));\n+    ASSERT_THAT(stick_resp, IntArg(1)) << i;\n   }\n \n   ASSERT_GE(failed, 0);\n",
  "problem_statement": "Dragonfly does not respect maxmemory limit\nOriginally reported by @anosulchik\r\n\r\nFollowing on #210 and #207, it seems that Dragonfly can grow beyond the specified limit.\r\n\r\nthe API is mostly `setex` command. \r\n\r\nI have a working theory why it happens but I would like to understand more about the write pattern of the system. \r\n\r\nwhat's the average value size?\r\nDoes it mostly write new keys or update the existing keys? what's the ttl of the stored items?\n",
  "hints_text": "I easily succeeded to reproduce this when using large values with:\r\n\r\n`memtier_benchmark  --ratio 1:0 -c 1 -d 32768 --hide-histogram --distinct-client-seed -n 1000`\r\nby playing with `n`, `c` it is possible to cause dragonfly to be far from reaching its current dashtable capacity but still cross the memory limit due to large values. Possible solution - we should also evict items with segments that are not full.",
  "created_at": "2022-08-25T20:29:19Z",
  "modified_files": [
    "src/core/dash.h",
    "src/core/dash_internal.h",
    "src/server/db_slice.cc",
    "src/server/db_slice.h",
    "src/server/engine_shard_set.cc",
    "src/server/generic_family.cc",
    "src/server/rdb_load.cc",
    "src/server/server_family.cc",
    "src/server/snapshot.cc",
    "src/server/table.h",
    "src/server/tiered_storage.cc"
  ],
  "modified_test_files": [
    "src/core/dash_test.cc",
    "src/facade/facade_test.h",
    "src/server/dragonfly_test.cc"
  ]
}