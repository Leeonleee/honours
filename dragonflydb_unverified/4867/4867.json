{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 4867,
  "instance_id": "dragonflydb__dragonfly-4867",
  "issue_numbers": [
    "4858"
  ],
  "base_commit": "ca4135ee12edd74d5f0dc3f27a7cb20f0963e1e0",
  "patch": "diff --git a/src/server/snapshot.cc b/src/server/snapshot.cc\nindex 28dbedd96471..54a964c3c5fe 100644\n--- a/src/server/snapshot.cc\n+++ b/src/server/snapshot.cc\n@@ -201,8 +201,8 @@ void SliceSnapshot::IterateBucketsFb(bool send_full_sync_cut) {\n   }\n \n   // serialized + side_saved must be equal to the total saved.\n-  VLOG(1) << \"Exit SnapshotSerializer (loop_serialized/side_saved/cbcalls): \"\n-          << stats_.loop_serialized << \"/\" << stats_.side_saved << \"/\" << stats_.savecb_calls;\n+  VLOG(1) << \"Exit SnapshotSerializer loop_serialized: \" << stats_.loop_serialized\n+          << \", side_saved \" << stats_.side_saved << \", cbcalls \" << stats_.savecb_calls;\n }\n \n void SliceSnapshot::SwitchIncrementalFb(LSN lsn) {\n",
  "test_patch": "diff --git a/tests/dragonfly/cluster_test.py b/tests/dragonfly/cluster_test.py\nindex 5fba77a9a8d1..52bac006ae0c 100644\n--- a/tests/dragonfly/cluster_test.py\n+++ b/tests/dragonfly/cluster_test.py\n@@ -227,12 +227,6 @@ def stop_and_get_restore_log(instance):\n     return line\n \n \n-def extract_int_after_prefix(prefix, line):\n-    match = re.search(prefix + \"(\\\\d+)\", line)\n-    assert match\n-    return int(match.group(1))\n-\n-\n @dfly_args({})\n class TestNotEmulated:\n     async def test_cluster_commands_fails_when_not_emulate(self, async_client: aioredis.Redis):\ndiff --git a/tests/dragonfly/replication_test.py b/tests/dragonfly/replication_test.py\nindex 9e78df5f43c0..87be90a26c17 100644\n--- a/tests/dragonfly/replication_test.py\n+++ b/tests/dragonfly/replication_test.py\n@@ -2988,3 +2988,51 @@ async def test_bug_in_json_memory_tracking(df_factory: DflyInstanceFactory):\n         await wait_for_replicas_state(*c_replicas)\n \n     await fill_task\n+\n+\n+async def test_replica_snapshot_with_big_values_while_seeding(df_factory: DflyInstanceFactory):\n+    proactors = 4\n+    master = df_factory.create(proactor_threads=proactors, dbfilename=\"\")\n+    replica = df_factory.create(proactor_threads=proactors, dbfilename=\"\")\n+    df_factory.start_all([master, replica])\n+    c_master = master.client()\n+    c_replica = replica.client()\n+\n+    # 50% big values\n+    seeder_config = dict(key_target=20_000, huge_value_target=10000)\n+    # Fill instance with test data\n+    seeder = SeederV2(**seeder_config)\n+    await seeder.run(c_master, target_deviation=0.01)\n+\n+    assert await c_replica.execute_command(f\"REPLICAOF localhost {master.port}\")\n+    async with async_timeout.timeout(60):\n+        await wait_for_replicas_state(c_replica)\n+\n+    # Start data stream\n+    stream_task = asyncio.create_task(seeder.run(c_master))\n+    await asyncio.sleep(1)\n+\n+    file_name = tmp_file_name()\n+    assert await c_replica.execute_command(f\"SAVE DF {file_name}\") == \"OK\"\n+    await seeder.stop(c_master)\n+    await stream_task\n+\n+    # Check that everything is in sync\n+    hashes = await asyncio.gather(*(SeederV2.capture(c) for c in [c_master, c_replica]))\n+    assert len(set(hashes)) == 1\n+\n+    replica.stop()\n+    lines = replica.find_in_logs(\"Exit SnapshotSerializer\")\n+    assert len(lines) == (proactors - 1)\n+    for line in lines:\n+        # We test the serializtion path of command execution\n+        side_saved = extract_int_after_prefix(\"side_saved \", line)\n+        assert side_saved > 0\n+\n+    # Check that the produced rdb is loaded correctly\n+    node = df_factory.create(dbfilename=file_name)\n+    node.start()\n+    c_node = node.client()\n+    await wait_available_async(c_node)\n+    assert await c_node.execute_command(\"dbsize\") > 0\n+    await c_node.execute_command(\"FLUSHALL\")\ndiff --git a/tests/dragonfly/utility.py b/tests/dragonfly/utility.py\nindex 5b5195e7496f..bfaec24193dc 100644\n--- a/tests/dragonfly/utility.py\n+++ b/tests/dragonfly/utility.py\n@@ -17,6 +17,7 @@\n import fakeredis\n from typing import Iterable, Union\n from enum import Enum\n+import re\n \n \n def tmp_file_name():\n@@ -781,3 +782,9 @@ async def wait_until_n_inserts(self, count):\n \n     def stop(self):\n         self.stop_flag = True\n+\n+\n+def extract_int_after_prefix(prefix, line):\n+    match = re.search(prefix + \"(\\\\d+)\", line)\n+    assert match\n+    return int(match.group(1))\n",
  "problem_statement": "Test snapshoting big values in replica\nAdd a python test to check replica running save while seeding master, make sure that the replica has big values to serialize\n",
  "hints_text": "",
  "created_at": "2025-03-31T12:29:14Z",
  "modified_files": [
    "src/server/snapshot.cc"
  ],
  "modified_test_files": [
    "tests/dragonfly/cluster_test.py",
    "tests/dragonfly/replication_test.py",
    "tests/dragonfly/utility.py"
  ]
}