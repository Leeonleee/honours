{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 4907,
  "instance_id": "dragonflydb__dragonfly-4907",
  "issue_numbers": [
    "4840"
  ],
  "base_commit": "7adb071f2a91d6175331ae6d146f44328d16b6cc",
  "patch": "diff --git a/src/server/server_family.cc b/src/server/server_family.cc\nindex d022a233cb42..73cac4598ff8 100644\n--- a/src/server/server_family.cc\n+++ b/src/server/server_family.cc\n@@ -927,9 +927,11 @@ void ServerFamily::LoadFromSnapshot() {\n     if (std::error_code(load_path_result.error()) == std::errc::no_such_file_or_directory) {\n       LOG(WARNING) << \"Load snapshot: No snapshot found\";\n     } else {\n-      util::fb2::LockGuard lk{loading_stats_mu_};\n+      loading_stats_mu_.lock();\n       loading_stats_.failed_restore_count++;\n-      LOG(ERROR) << \"Failed to load snapshot: \" << load_path_result.error().Format();\n+      loading_stats_mu_.unlock();\n+      LOG(ERROR) << \"Failed to load snapshot with error: \" << load_path_result.error().Format();\n+      exit(1);\n     }\n   }\n }\n",
  "test_patch": "diff --git a/tests/dragonfly/snapshot_test.py b/tests/dragonfly/snapshot_test.py\nindex 7f34979fb1a6..fb0e5a3e2b2d 100644\n--- a/tests/dragonfly/snapshot_test.py\n+++ b/tests/dragonfly/snapshot_test.py\n@@ -326,6 +326,24 @@ def delete_s3_objects(bucket, prefix):\n     )\n \n \n+# If DRAGONFLY_S3_BUCKET is configured, AWS credentials must also be\n+# configured.\n+@pytest.mark.skipif(\n+    \"DRAGONFLY_S3_BUCKET\" not in os.environ or os.environ[\"DRAGONFLY_S3_BUCKET\"] == \"\",\n+    reason=\"AWS S3 snapshots bucket is not configured\",\n+)\n+async def test_exit_on_s3_snapshot_load_err(df_factory):\n+    invalid_s3_dir = \"s3://{DRAGONFLY_S3_BUCKET}\" + \"_invalid_bucket_\"\n+    df_server = df_factory.create(\n+        dir=invalid_s3_dir, dbfilename=\"db\", exit_on_cloud_dir_snapshot_load_err=True\n+    )\n+    df_server.start()\n+    # Let's wait so that process exit\n+    await asyncio.sleep(2)\n+    with pytest.raises(Exception):\n+        df_server._check_status()\n+\n+\n # If DRAGONFLY_S3_BUCKET is configured, AWS credentials must also be\n # configured.\n @pytest.mark.skipif(\n",
  "problem_statement": "Instance starts with empty state when loading of snapshot from S3 fails\n**Describe the bug**\nWe use S3 (MinIO) to store snapshots. I noticed that when Dragonfly couldn't load the snapshot on startup, due to temporary access denied errors returned by MinIO, it continued startup with an empty state. The temporary access denied problem was likely caused by the fact that a node was lost and MinIO was recovering.\n\nI'm not sure if this is expected behaviour. In our case it led to data loss \u2013 unfortunately a 3rd party system that we host uses redis as a persistent data store.\n\nI'm also not sure if this is the only case, or would a similar problem show up if there was a network error or something similar.\n\n**To Reproduce**\nSteps to reproduce the behavior (not yet validated in a clean environment):\n1. Set up Dragonfly with snapshotting to S3/MinIO\n2. Write some data\n3. Let at least one snapshot happen\n4. Temporarily revoke access to the bucket for the credentials given to Dragonfly\n5. Restart Dragonfly\n6. Give back access to the credentials\n7. The written data was lost and Dragonfly is not writing new snapshots that do not include it\n\n**Expected behavior**\nNo data loss.\n\nI see a couple of options:\n1. Make Dragonfly fail on startup if there are any connection/access problems. Do not fail if it's able to connect to the bucket, and the bucket is empty\n2. Add flag that forces snapshot loading and fail on startup no matter what the reason of not being able to load the snapshot is. Could be a bit safer for mission critical data, but then the bucket outright losing data does not seem likely.\n\n**Screenshots**\nI do not have full logs at the moment, would have after repro. But they were something along these lines:\n```\nsnapshot_storage.cc:379] Creating AWS S3 client; region=us-east-1; https=true; endpoint=[redacted]\ncredentials_provider_chain.cc:28] aws: disabled EC2 metadata\ncredentials_provider_chain.cc:36] aws: loaded credentials; provider=environment\nsnapshot_storage.cc:430] Load snapshot: Searching for snapshot in S3 path: s3://[redacted]/\n<the access denied log line, I _think_ it was from server_family.cc>\nlistener_interface.cc:101] sock[7] AcceptServer - listening on port 9999\nlistener_interface.cc:101] sock[8] AcceptServer - listening on port 6379\n```\n\n**Environment (please complete the following information):**\n - OS: NixOS 24.11\n - Kernel: 6.6.76\n - Containerized?: Kubernetes\n - Dragonfly Version: v1.26.1\n\n**Reproducible Code Snippet**\nI could try providing a docker compose setup later.\n\n**Additional context**\nOriginally started as a discussion: https://github.com/dragonflydb/dragonfly/discussions/4839\n\n",
  "hints_text": "Hi @mlazowik , thanks for reporting this.\nI think we can add some flag for your case.",
  "created_at": "2025-04-09T09:05:07Z",
  "modified_files": [
    "src/server/server_family.cc"
  ],
  "modified_test_files": [
    "tests/dragonfly/snapshot_test.py"
  ]
}