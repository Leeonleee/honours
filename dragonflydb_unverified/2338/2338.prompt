You will be provided with a partial code base and an issue statement explaining a problem to resolve.

<issue>
During the load snapshot process, should the REPLICAOF or SLAVEOF command be allowed to be executed?
**Describe the bug**
  When starting a stopped old instance as a replica of a master instance without data, after starting the replica instance, the most recent snapshot will be loaded first. When the load process is not completed, the replicateaof command is executed to establish the master-slave with the master without data. Relationship, since the main library does not have data, the `full sync ` process will be very fast. When the synchronization state reaches `stable sync`, a problem occurs. The process of replica loading the old snapshot has not ended yet, which ultimately leads to inconsistency between the master and slave data. question.

**Environment (please complete the following information):**
 - OS: [Debian GNU/Linux 11]
 - Kernel:  #1 SMP Debian 5.10.178-3 (2023-04-22) x86_64 GNU/Linux
 - Containerized?: [Physical machine environment]
 - Dragonfly Version: [v 1.3.0]

**Expected behavior**
After the slave executes the `replicaof` or `slaveof` command, the data in the master library and the slave library should be completely consistent.

**Logs and Screenshots of process recurrence**

- Background description
  masterï¼š192.168.1.10:6380
  replica:   192.168.1.10:6381
  1.  The master has no data
  2. The slave has many snapshots after bgsave of the previous instance.

- Reproduction steps
  1. Start the slave instance
  2. Execute `replicaof 192.168.1.10 6380` or `slaveof 192.168.1.10 6380`
  3. Since the master has no data, the slave synchronization state quickly changes from the full sync state to the stable sync state, and starts replicating the relationship.
  4. There is a huge data inconsistency between master and slave
  5. Execute REPLICAOF no one in the slave library to disconnect the master-slave replication
  6. Execute `replicaof 192.168.1.10 6380` or `slaveof 192.168.1.10 6380` again 
  7. After reaching the stable sync state again, the data is consistent

- Important log display
```
I20231226 15:32:25.121160 1434315 init.cc:70] dragonfly running in opt mode.
I20231226 15:32:25.121472 1434315 dfly_main.cc:800] Starting dragonfly df-v1.13.0-f39eac5bcaf7c8ffe5c433a0e8e15747391199d9
I20231226 15:32:25.121649 1434315 dfly_main.cc:863] Max memory limit is: 14.00GiB
I20231226 15:32:25.199597 1434315 proactor_pool.cc:146] Running 56 io threads
I20231226 15:32:25.200731 1434315 main_service.cc:2470] Multi-key commands are: 
I20231226 15:32:25.200749 1434315 main_service.cc:2478]     SINTERSTORE: with unlimited keys
...
I20231226 15:32:25.202522 1434315 main_service.cc:2485]     REPLICAOF
I20231226 15:32:25.202529 1434315 main_service.cc:2485]     LTRIM
I20231226 15:32:25.202536 1434315 main_service.cc:2485]     HSTRLEN
I20231226 15:32:25.204681 1434315 dfly_main.cc:437] Listening on admin socket 192.168.1.11:16381
I20231226 15:32:25.279189 1434315 snapshot_storage.cc:106] Load snapshot: Searching for snapshot in directory: "/home/dba/dragonfly/dragonfly6381"
I20231226 15:32:25.280342 1434315 server_family.cc:673] Loading /home/dba/dragonfly/dragonfly6381/dump-2023-09-06T17:07:32-summary.dfs
I20231226 15:32:25.280357 1434315 main_service.cc:2295] Switching state from ACTIVE to LOADING
I20231226 15:32:25.296355 1434318 listener_interface.cc:101] sock[117] AcceptServer - listening on port 6381
I20231226 15:32:25.296356 1434317 listener_interface.cc:101] sock[116] AcceptServer - listening on port 16381
I20231226 15:32:52.904044 1434316 main_service.cc:1063] Got (1): [REPLICAOF,192.168.1.10,6380] in dbid=0
I20231226 15:32:53.315989 1434316 server_family.cc:1937] Replicating 192.168.1.10:6380
I20231226 15:32:53.417805 1434316 replica.cc:515] Started full sync with 192.168.1.10:6380
I20231226 15:32:53.421008 1434316 replica.cc:535] full sync finished in 89 ms
I20231226 15:32:53.425195 1434316 main_service.cc:2295] Switching state from LOADING to ACTIVE
I20231226 15:32:53.425483 1434316 replica.cc:612] Transitioned into stable sync
I20231226 15:32:57.308971 1434316 main_service.cc:1063] Got (1): [INFO] in dbid=0
...
I20231226 15:34:19.674978 1434317 main_service.cc:1063] Got (2): [INFO] in dbid=0
I20231226 15:34:47.527698 1434320 server_family.cc:727] Load finished, num keys read: 174767542
I20231226 15:34:52.395077 1434318 main_service.cc:1063] Got (3): [COMMAND] in dbid=0
I20231226 15:34:53.693976 1434318 main_service.cc:1063] Got (3): [INFO] in dbid=0
...
I20231226 15:53:15.552983 1434320 main_service.cc:1063] Got (5): [REPLICAOF,no,one] in dbid=0
I20231226 15:53:15.553061 1434320 server_family.cc:1937] Replicating no:one
I20231226 15:53:15.557498 1434316 replica.cc:636] Exit stable sync
W20231226 15:53:15.557523 1434316 replica.cc:237] Error stable sync with 192.168.1.10:6380 generic:125 Operation canceled
...
I20231226 15:53:25.385007 1434320 main_service.cc:1063] Got (5): [REPLICAOF,192.168.1.10,6380] in dbid=0
I20231226 15:53:27.321966 1434320 server_family.cc:1937] Replicating 192.168.1.10:6380
I20231226 15:53:27.322014 1434320 main_service.cc:2295] Switching state from ACTIVE to LOADING
I20231226 15:53:27.386029 1434320 replica.cc:515] Started full sync with 192.168.1.10:6380
I20231226 15:53:27.387676 1434320 replica.cc:535] full sync finished in 64 ms
I20231226 15:53:27.387760 1434320 main_service.cc:2295] Switching state from LOADING to ACTIVE
I20231226 15:53:27.387941 1434320 replica.cc:612] Transitioned into stable sync
``` 

**Additional context**
This is how I think about it. This should not happen with redis, because the `replicaof` or `slaveof` commands cannot be executed during the load snapshot process. Due to the single-threaded design, they will be blocked. Due to its multi-threaded shared-nothing design mode, dragonfly will not block the `replicaof` or `slaveof` commands. However, the problem caused by this is that the master-slave instance data is inconsistent. The slave library has a lot more data from previous snapshots than the main library, thus resulting in subsequent use risks. For example, the memory usage of the main library is 50%, but the memory usage of the slave library is 90%, and the data is not easy to clean after a period of use.

**My advice**
So my question is, how to solve this problem in dragonfly's architecture. I have two personal thoughts:
1. Should the execution of `replicaof` and `slaveof` commands be prohibited during the load snapshot phase and a prompt given?
2. If the execution of the `replicaof` and `slaveof` commands is not blocked, immediately after executing the command, all scheduling of the load snapshot process will be interrupted, and flushall async will be executed, and then go to the master to pull the snapshot, ultimately achieving consistency of the master-slave data.
</issue>

I need you to solve the provided issue by generating a code fix that can be applied directly to the repository

Respond below:
