{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 1388,
  "instance_id": "dragonflydb__dragonfly-1388",
  "issue_numbers": [
    "1313"
  ],
  "base_commit": "16454c1e176c081332c6398f37e9c6a55dbcf086",
  "patch": "diff --git a/src/facade/dragonfly_connection.cc b/src/facade/dragonfly_connection.cc\nindex 0252309d3da2..9697829d9bdd 100644\n--- a/src/facade/dragonfly_connection.cc\n+++ b/src/facade/dragonfly_connection.cc\n@@ -837,6 +837,10 @@ void Connection::ShutdownThreadLocal() {\n   pipeline_req_pool_.clear();\n }\n \n+bool Connection::IsCurrentlyDispatching() const {\n+  return cc_->async_dispatch || cc_->sync_dispatch;\n+}\n+\n void RespToArgList(const RespVec& src, CmdArgVec* dest) {\n   dest->resize(src.size());\n   for (size_t i = 0; i < src.size(); ++i) {\ndiff --git a/src/facade/dragonfly_connection.h b/src/facade/dragonfly_connection.h\nindex c194a10d8212..20a1e0fde12f 100644\n--- a/src/facade/dragonfly_connection.h\n+++ b/src/facade/dragonfly_connection.h\n@@ -138,6 +138,8 @@ class Connection : public util::Connection {\n \n   static void ShutdownThreadLocal();\n \n+  bool IsCurrentlyDispatching() const;\n+\n   std::string GetClientInfo(unsigned thread_id) const;\n   std::string RemoteEndpointStr() const;\n   std::string RemoteEndpointAddress() const;\ndiff --git a/src/facade/dragonfly_listener.cc b/src/facade/dragonfly_listener.cc\nindex ae3a48a49d26..5d5560dc200a 100644\n--- a/src/facade/dragonfly_listener.cc\n+++ b/src/facade/dragonfly_listener.cc\n@@ -180,6 +180,37 @@ void Listener::PreAcceptLoop(util::ProactorBase* pb) {\n }\n \n void Listener::PreShutdown() {\n+  // Iterate on all connections and allow them to finish their commands for\n+  // a short period.\n+  // Executed commands can be visible in snapshots or replicas, but if we close the client\n+  // connections too fast we might not send the acknowledgment for those commands.\n+  // This shouldn't take a long time: All clients should reject incoming commands\n+  // at this stage since we're in SHUTDOWN mode.\n+  // If a command is running for too long we give up and proceed.\n+  const absl::Duration kDispatchShutdownTimeout = absl::Milliseconds(10);\n+  absl::Time start = absl::Now();\n+\n+  bool success = false;\n+  while (absl::Now() - start < kDispatchShutdownTimeout) {\n+    std::atomic<bool> any_connection_dispatching = false;\n+    auto cb = [&any_connection_dispatching](unsigned thread_index, util::Connection* conn) {\n+      if (static_cast<Connection*>(conn)->IsCurrentlyDispatching()) {\n+        any_connection_dispatching.store(true);\n+      }\n+    };\n+    this->TraverseConnections(cb);\n+    if (!any_connection_dispatching.load()) {\n+      success = true;\n+      break;\n+    }\n+    VLOG(1) << \"A command is still dispatching, let's wait for it\";\n+    ThisFiber::SleepFor(100us);\n+  }\n+\n+  if (!success) {\n+    LOG(WARNING) << \"Some commands are still being dispatched but didn't conclude in time. \"\n+                    \"Proceeding in shutdown.\";\n+  }\n }\n \n void Listener::PostShutdown() {\ndiff --git a/src/server/server_family.cc b/src/server/server_family.cc\nindex 10d83a2c296c..924ba7766b92 100644\n--- a/src/server/server_family.cc\n+++ b/src/server/server_family.cc\n@@ -2069,6 +2069,9 @@ void ServerFamily::_Shutdown(CmdArgList args, ConnectionContext* cntx) {\n     }\n   }\n \n+  service_.proactor_pool().AwaitFiberOnAll(\n+      [](ProactorBase* pb) { ServerState::tlocal()->EnterLameDuck(); });\n+\n   CHECK_NOTNULL(acceptor_)->Stop();\n   (*cntx)->SendOk();\n }\n",
  "test_patch": "diff --git a/tests/dragonfly/shutdown_test.py b/tests/dragonfly/shutdown_test.py\nnew file mode 100644\nindex 000000000000..90c0e7774021\n--- /dev/null\n+++ b/tests/dragonfly/shutdown_test.py\n@@ -0,0 +1,48 @@\n+import pytest\n+import asyncio\n+import redis\n+from redis import asyncio as aioredis\n+from pathlib import Path\n+\n+from . import dfly_args\n+\n+BASIC_ARGS = {\"dir\": \"{DRAGONFLY_TMP}/\"}\n+\n+\n+@dfly_args({\"proactor_threads\": \"4\"})\n+class TestDflyAutoLoadSnapshot():\n+    \"\"\"Test automatic loading of dump files on startup with timestamp\"\"\"\n+\n+    @pytest.mark.asyncio\n+    async def test_gracefull_shutdown(self, df_local_factory):\n+        df_args = {\"dbfilename\": \"dump\", **BASIC_ARGS, \"port\": 1111}\n+\n+        df_server = df_local_factory.create(**df_args)\n+        df_server.start()\n+        client = aioredis.Redis(port=df_server.port)\n+\n+        async def counter(key):\n+            value = 0\n+            await client.execute_command(f\"SET {key} 0\")\n+            while True:\n+                try:\n+                    value = await client.execute_command(f\"INCR {key}\")\n+                except (redis.exceptions.ConnectionError, redis.exceptions.ResponseError) as e:\n+                    break\n+            return key, value\n+\n+        async def delayed_takeover():\n+            await asyncio.sleep(1)\n+            await client.execute_command(\"SHUTDOWN\")\n+            await client.connection_pool.disconnect()\n+\n+        _, *results = await asyncio.gather(delayed_takeover(), *[counter(f\"key{i}\") for i in range(16)])\n+\n+        df_server.start()\n+        client = aioredis.Redis(port=df_server.port)\n+\n+        for key, acknowleged_value in results:\n+            value_from_snapshot = await client.get(key)\n+            assert acknowleged_value == int(value_from_snapshot)\n+\n+        await client.connection_pool.disconnect()\n",
  "problem_statement": "Shutdown closes sockets too early.\nVery fragile test case:\r\n\r\n```bash\r\nsh -c \"./dragonfly & sleep 3 && redis-cli shutdown\" & sleep 1\r\nwhile true; do redis-cli incr key && continue; break; done\r\n./dragonfly & sleep 1 # Restores from snapshot\r\nredis-cli get key\r\nkillall dragonfly\r\n```\r\n\r\nAfter running it a few times, you can get this:\r\n```\r\n(integer) 30643\r\n(integer) 30644\r\n(integer) 30645\r\nError: Server closed the connection\r\nOK\r\n[2]+  Done                    sh -c \"./dragonfly & sleep 3 && redis-cli shutdown\"\r\n[1] 361833\r\n\"30646\"\r\n```\r\nSo the last `INCR` was executed and written to the snapshot but didn't reach the client.\r\n\r\nTechnically this is conforming, since clients cannot assume a command has not been executed if the socket is terminated, but in this case we could probably increase the reliability by improving how we do shutdown.\n",
  "hints_text": "A more detailed trace of the issue:\r\n\r\n```\r\nI20230604 16:05:41.877667 116888 listener_interface.cc:182] sock[15] Running connection \r\nI20230604 16:05:41.877696 116888 dragonfly_listener.cc:193] Opening connection 27\r\nI20230604 16:05:41.877734 116888 uring_socket.cc:335] sock[15] Recv [15] 0\r\nI20230604 16:05:41.877759 116887 uring_proactor.cc:574] Switching to DflyConnection\r\nI20230604 16:05:41.877792 116888 uring_proactor.cc:574] Switching to DflyConnection\r\nI20230604 16:05:41.877923 116887 dragonfly_connection.cc:578] Got Args with first token shutdown\r\nI20230604 16:05:41.877948 116888 uring_proactor.cc:574] Switching to DflyConnection\r\nI20230604 16:05:41.877969 116887 main_service.cc:789] Got (26): [SHUTDOWN] in dbid=0\r\nI20230604 16:05:41.878095 116887 accept_server.cc:56] AcceptServer::Stop\r\nI20230604 16:05:41.878156 116888 dragonfly_connection.cc:578] Got Args with first token incr\r\nI20230604 16:05:41.878180 116887 accept_server.cc:171] AcceptServer::BreakListeners finished\r\nI20230604 16:05:41.878196 116888 main_service.cc:789] Got (27): [INCR,key] in dbid=0\r\nI20230604 16:05:41.878207 116887 reply_builder.cc:75] Writing 5 bytes of len 3\r\nI20230604 16:05:41.878244 116887 uring_socket.cc:159] sock[14] WriteSome [14] 3\r\nI20230604 16:05:41.878348 116887 uring_proactor.cc:574] Switching to DflyConnection\r\nI20230604 16:05:41.878343 116888 scheduler.cc:518] ScheduleFromRemote shard_queue1\r\nI20230604 16:05:41.878413 116888 transaction.cc:707] ScheduleSingleHop before Wait INCR@0/1 (2782) 1\r\nI20230604 16:05:41.878556 116887 uring_socket.cc:335] sock[14] Recv [14] 0\r\nI20230604 16:05:41.878577 116888 scheduler.cc:601] timeout for shard_periodic2\r\nI20230604 16:05:41.878623 116888 uring_proactor.cc:574] Switching to Dispatched\r\nI20230604 16:05:41.878661 116888 fiber_interface.cc:155] Terminating Dispatched\r\nI20230604 16:05:41.878710 116887 scheduler.cc:578] set ready shard_queue1\r\nI20230604 16:05:41.878739 116888 uring_proactor.cc:574] Switching to AcceptLoop\r\nI20230604 16:05:41.878754 116887 uring_proactor.cc:574] Switching to shard_queue1\r\nI20230604 16:05:41.878801 116888 listener_interface.cc:113] Exit AcceptLoop with ec=generic:103\r\nI20230604 16:05:41.878818 116887 transaction.cc:888] RunQuickSingle INCR@0/1 (2782) 1\r\nI20230604 16:05:41.878875 116887 db_slice.cc:808] Running callbacks in dbid 0\r\nI20230604 16:05:41.878998 116887 scheduler.cc:518] ScheduleFromRemote DflyConnection\r\nI20230604 16:05:41.878993 116886 uring_proactor.cc:217] PRO[0] Wakeup 8/0\r\nI20230604 16:05:41.878993 116888 uring_proactor.cc:574] Switching to \r\nI20230604 16:05:41.879005 116889 uring_proactor.cc:217] PRO[3] Wakeup 8/0\r\nI20230604 16:05:41.879071 116886 uring_proactor.cc:574] Switching to \r\nI20230604 16:05:41.879086 116889 uring_proactor.cc:574] Switching to \r\nI20230604 16:05:41.879107 116886 fiber_interface.cc:155] Terminating \r\nI20230604 16:05:41.879122 116887 uring_proactor.cc:574] Switching to \r\nI20230604 16:05:41.879117 116889 fiber_interface.cc:155] Terminating \r\nI20230604 16:05:41.879115 116888 dragonfly_connection.cc:252] Connection::OnShutdown\r\nI20230604 16:05:41.879165 116888 listener_interface.cc:155] sock[15] Shutdown\r\nI20230604 16:05:41.879168 116889 scheduler.cc:550] Releasing terminated \r\nI20230604 16:05:41.879158 116886 scheduler.cc:550] Releasing terminated \r\nI20230604 16:05:41.879187 116887 dragonfly_connection.cc:252] Connection::OnShutdown\r\nI20230604 16:05:41.879199 116888 fiber_interface.cc:155] Terminating \r\nI20230604 16:05:41.879207 116886 fiber_interface.cc:129] Destroying \r\nI20230604 16:05:41.879199 116889 fiber_interface.cc:129] Destroying \r\nI20230604 16:05:41.879305 116888 dragonfly_connection.cc:655] Got event 8208\r\nI20230604 16:05:41.879240 116887 listener_interface.cc:155] sock[14] Shutdown\r\nI20230604 16:05:41.879350 116886 uring_proactor.cc:625] PRO[0] wait_for_cqe 2535\r\nI20230604 16:05:41.879345 116888 scheduler.cc:578] set ready DflyConnection\r\nI20230604 16:05:41.879343 116887 scheduler.cc:518] ScheduleFromRemote AcceptLoop\r\nI20230604 16:05:41.879351 116889 uring_proactor.cc:625] PRO[3] wait_for_cqe 417\r\nI20230604 16:05:41.879411 116888 uring_proactor.cc:574] Switching to DispatchFiber\r\nI20230604 16:05:41.879424 116887 fiber_interface.cc:155] Terminating \r\nI20230604 16:05:41.879439 116888 fiber_interface.cc:155] Terminating DispatchFiber\r\nI20230604 16:05:41.879457 116887 dragonfly_connection.cc:655] Got event 8208\r\nI20230604 16:05:41.879462 116888 transaction.cc:709] ScheduleSingleHop after Wait INCR@0/1 (2782)\r\nI20230604 16:05:41.879505 116888 string_family.cc:1046] IncrByGeneric key/26\r\n```\r\n\r\nSo we \r\n1. Receive an `INCR` command\r\n2. Receive a `SHUTDOWN` command\r\n3. Schedule the `INCR` command to a different shard and wait\r\n4. Close the socket from the cleanup in `ListenerInterface::RunAcceptLoop`\r\n5. Finish the command and don't answer because the socket is closed.\r\n\r\nSo does `SHUTDOWN` need locking guarantees? Currently it's not touching the DB and the locks at all, just the accept loop. On the other hand we don't necessarily want to wait if there's some long transaction running.\n@royjacobson  seems that shutdown needs to tell all the client connections to stop accepting new commands.\r\nThere are hooks like this one: https://github.com/romange/helio/blob/0cd35814f3ce0362a8ec6be563d5c740b094fa34/util/listener_interface.cc#L133 \r\n\r\nwhere we can override, and do proper orderly shutdown sequence. i.e. here the listening socket does not accept new connections anymore, but we still process the existing ones. We could tell the existing connections to stop accepting new commands and then wait K ms for the current ones to finish. I do not think you need to do anything with database locks.\r\n  ",
  "created_at": "2023-06-11T10:38:26Z",
  "modified_files": [
    "src/facade/dragonfly_connection.cc",
    "src/facade/dragonfly_connection.h",
    "src/facade/dragonfly_listener.cc",
    "src/server/server_family.cc"
  ],
  "modified_test_files": [
    "b/tests/dragonfly/shutdown_test.py"
  ]
}