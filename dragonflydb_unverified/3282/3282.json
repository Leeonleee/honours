{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 3282,
  "instance_id": "dragonflydb__dragonfly-3282",
  "issue_numbers": [
    "3280"
  ],
  "base_commit": "fba902d0ace05593d8992c398dbcf6a38fa2b00f",
  "patch": "diff --git a/src/server/server_family.cc b/src/server/server_family.cc\nindex 341f6ba822c0..b034acf3661e 100644\n--- a/src/server/server_family.cc\n+++ b/src/server/server_family.cc\n@@ -2258,9 +2258,12 @@ void ServerFamily::Info(CmdArgList args, ConnectionContext* cntx) {\n   }\n \n   if (should_enter(\"REPLICATION\")) {\n-    ServerState& etl = *ServerState::tlocal();\n-\n-    if (etl.is_master) {\n+    unique_lock lk(replicaof_mu_);\n+    // Thread local var is_master is updated under mutex replicaof_mu_ together with replica_,\n+    // ensuring eventual consistency of is_master. When determining if the server is a replica and\n+    // accessing the replica_ object, we must lock replicaof_mu_. Using is_master alone is\n+    // insufficient in this scenario.\n+    if (!replica_) {\n       append(\"role\", \"master\");\n       append(\"connected_slaves\", m.facade_stats.conn_stats.num_replicas);\n       const auto& replicas = m.replication_metrics;\n@@ -2274,10 +2277,6 @@ void ServerFamily::Info(CmdArgList args, ConnectionContext* cntx) {\n     } else {\n       append(\"role\", GetFlag(FLAGS_info_replication_valkey_compatible) ? \"slave\" : \"replica\");\n \n-      // The replica pointer can still be mutated even while master=true,\n-      // we don't want to drop the replica object in this fiber\n-      unique_lock lk{replicaof_mu_};\n-\n       auto replication_info_cb = [&](Replica::Info rinfo) {\n         append(\"master_host\", rinfo.host);\n         append(\"master_port\", rinfo.port);\n@@ -2737,8 +2736,12 @@ void ServerFamily::ReplConf(CmdArgList args, ConnectionContext* cntx) {\n \n void ServerFamily::Role(CmdArgList args, ConnectionContext* cntx) {\n   auto* rb = static_cast<RedisReplyBuilder*>(cntx->reply_builder());\n-  ServerState& etl = *ServerState::tlocal();\n-  if (etl.is_master) {\n+  unique_lock lk(replicaof_mu_);\n+  // Thread local var is_master is updated under mutex replicaof_mu_ together with replica_,\n+  // ensuring eventual consistency of is_master. When determining if the server is a replica and\n+  // accessing the replica_ object, we must lock replicaof_mu_. Using is_master alone is\n+  // insufficient in this scenario.\n+  if (!replica_) {\n     rb->StartArray(2);\n     rb->SendBulkString(\"master\");\n     auto vec = dfly_cmd_->GetReplicasRoleInfo();\n@@ -2751,7 +2754,6 @@ void ServerFamily::Role(CmdArgList args, ConnectionContext* cntx) {\n     }\n \n   } else {\n-    unique_lock lk{replicaof_mu_};\n     rb->StartArray(4 + cluster_replicas_.size() * 3);\n     rb->SendBulkString(GetFlag(FLAGS_info_replication_valkey_compatible) ? \"slave\" : \"replica\");\n \n",
  "test_patch": "diff --git a/tests/dragonfly/instance.py b/tests/dragonfly/instance.py\nindex 50ce582080b0..f2744d7c99c9 100644\n--- a/tests/dragonfly/instance.py\n+++ b/tests/dragonfly/instance.py\n@@ -336,7 +336,7 @@ def create(self, existing_port=None, **kwargs) -> DflyInstance:\n         args.setdefault(\"noversion_check\", None)\n         # MacOs does not set it automatically, so we need to set it manually\n         args.setdefault(\"maxmemory\", \"8G\")\n-        vmod = \"dragonfly_connection=1,accept_server=1,listener_interface=1,main_service=1,rdb_save=1,replica=1,cluster_family=1\"\n+        vmod = \"dragonfly_connection=1,accept_server=1,listener_interface=1,main_service=1,rdb_save=1,replica=1,cluster_family=1,dflycmd=1\"\n         args.setdefault(\"vmodule\", vmod)\n         args.setdefault(\"jsonpathv2\")\n \ndiff --git a/tests/dragonfly/replication_test.py b/tests/dragonfly/replication_test.py\nindex 3feee76cad3d..bab7d636b623 100644\n--- a/tests/dragonfly/replication_test.py\n+++ b/tests/dragonfly/replication_test.py\n@@ -1151,10 +1151,7 @@ async def test_readonly_script(df_factory):\n @pytest.mark.parametrize(\"master_threads, replica_threads\", take_over_cases)\n @pytest.mark.asyncio\n async def test_take_over_counters(df_factory, master_threads, replica_threads):\n-    master = df_factory.create(\n-        proactor_threads=master_threads,\n-        logtostderr=True,\n-    )\n+    master = df_factory.create(proactor_threads=master_threads)\n     replica1 = df_factory.create(proactor_threads=replica_threads)\n     replica2 = df_factory.create(proactor_threads=replica_threads)\n     replica3 = df_factory.create(proactor_threads=replica_threads)\n@@ -1214,11 +1211,7 @@ async def test_take_over_seeder(\n     request, df_factory, df_seeder_factory, master_threads, replica_threads\n ):\n     tmp_file_name = \"\".join(random.choices(string.ascii_letters, k=10))\n-    master = df_factory.create(\n-        proactor_threads=master_threads,\n-        dbfilename=f\"dump_{tmp_file_name}\",\n-        logtostderr=True,\n-    )\n+    master = df_factory.create(proactor_threads=master_threads, dbfilename=f\"dump_{tmp_file_name}\")\n     replica = df_factory.create(proactor_threads=replica_threads)\n     df_factory.start_all([master, replica])\n \n@@ -1229,17 +1222,27 @@ async def test_take_over_seeder(\n     await c_replica.execute_command(f\"REPLICAOF localhost {master.port}\")\n     await wait_available_async(c_replica)\n \n-    async def seed():\n-        await seeder.run(target_ops=3000)\n+    fill_task = asyncio.create_task(seeder.run())\n+\n+    stop_info = False\n \n-    fill_task = asyncio.create_task(seed())\n+    async def info_task():\n+        my_client = replica.client()\n+        while not stop_info:\n+            info = await my_client.info(\"replication\")\n+            asyncio.sleep(0.5)\n+\n+    info_task = asyncio.create_task(info_task())\n \n     # Give the seeder a bit of time.\n-    await asyncio.sleep(1)\n+    await asyncio.sleep(3)\n+    logging.debug(\"running repltakover\")\n     await c_replica.execute_command(f\"REPLTAKEOVER 5 SAVE\")\n+    logging.debug(\"after running repltakover\")\n     seeder.stop()\n \n     assert await c_replica.execute_command(\"role\") == [\"master\", []]\n+    stop_info = True\n \n     # Need to wait a bit to give time to write the shutdown snapshot\n     await asyncio.sleep(1)\n@@ -1258,10 +1261,7 @@ async def seed():\n @pytest.mark.parametrize(\"master_threads, replica_threads\", [[4, 4]])\n @pytest.mark.asyncio\n async def test_take_over_read_commands(df_factory, master_threads, replica_threads):\n-    master = df_factory.create(\n-        proactor_threads=master_threads,\n-        logtostderr=True,\n-    )\n+    master = df_factory.create(proactor_threads=master_threads)\n     replica = df_factory.create(proactor_threads=replica_threads)\n     df_factory.start_all([master, replica])\n \n",
  "problem_statement": "Server crash while running replica takeover and info replication\nThe bug:\r\ninfo replication first checks if the server is master, if not takes replica mutex and calls\r\ndfly::Replica::GetInfo()\r\nWhen running replica takeover we take the mutex finish the takeover reset the replica object and set is master to true.\r\nWith this flow when if we get the mutex after takeover is done but check is master before we will get a crash for accessing the replica object which was reset.\n",
  "hints_text": "",
  "created_at": "2024-07-07T14:43:08Z",
  "modified_files": [
    "src/server/server_family.cc"
  ],
  "modified_test_files": [
    "tests/dragonfly/instance.py",
    "tests/dragonfly/replication_test.py"
  ]
}