{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 1314,
  "instance_id": "dragonflydb__dragonfly-1314",
  "issue_numbers": [
    "1446"
  ],
  "base_commit": "aed01aa5e4e3838b6a8c2a2f30017c856dccc1ae",
  "patch": "diff --git a/src/facade/dragonfly_listener.cc b/src/facade/dragonfly_listener.cc\nindex 5d5560dc200a..6eaf24483a30 100644\n--- a/src/facade/dragonfly_listener.cc\n+++ b/src/facade/dragonfly_listener.cc\n@@ -179,35 +179,39 @@ void Listener::PreAcceptLoop(util::ProactorBase* pb) {\n   per_thread_.resize(pool()->size());\n }\n \n-void Listener::PreShutdown() {\n-  // Iterate on all connections and allow them to finish their commands for\n-  // a short period.\n-  // Executed commands can be visible in snapshots or replicas, but if we close the client\n-  // connections too fast we might not send the acknowledgment for those commands.\n-  // This shouldn't take a long time: All clients should reject incoming commands\n-  // at this stage since we're in SHUTDOWN mode.\n-  // If a command is running for too long we give up and proceed.\n-  const absl::Duration kDispatchShutdownTimeout = absl::Milliseconds(10);\n+bool Listener::AwaitDispatches(absl::Duration timeout,\n+                               const std::function<bool(util::Connection*)>& filter) {\n   absl::Time start = absl::Now();\n \n-  bool success = false;\n-  while (absl::Now() - start < kDispatchShutdownTimeout) {\n+  while (absl::Now() - start < timeout) {\n     std::atomic<bool> any_connection_dispatching = false;\n-    auto cb = [&any_connection_dispatching](unsigned thread_index, util::Connection* conn) {\n-      if (static_cast<Connection*>(conn)->IsCurrentlyDispatching()) {\n+    auto cb = [&any_connection_dispatching, &filter](unsigned thread_index,\n+                                                     util::Connection* conn) {\n+      if (filter(conn) && static_cast<Connection*>(conn)->IsCurrentlyDispatching()) {\n         any_connection_dispatching.store(true);\n       }\n     };\n     this->TraverseConnections(cb);\n     if (!any_connection_dispatching.load()) {\n-      success = true;\n-      break;\n+      return true;\n     }\n     VLOG(1) << \"A command is still dispatching, let's wait for it\";\n     ThisFiber::SleepFor(100us);\n   }\n+  return false;\n+}\n \n-  if (!success) {\n+void Listener::PreShutdown() {\n+  // Iterate on all connections and allow them to finish their commands for\n+  // a short period.\n+  // Executed commands can be visible in snapshots or replicas, but if we close the client\n+  // connections too fast we might not send the acknowledgment for those commands.\n+  // This shouldn't take a long time: All clients should reject incoming commands\n+  // at this stage since we're in SHUTDOWN mode.\n+  // If a command is running for too long we give up and proceed.\n+  const absl::Duration kDispatchShutdownTimeout = absl::Milliseconds(10);\n+\n+  if (!AwaitDispatches(kDispatchShutdownTimeout, [](util::Connection*) { return true; })) {\n     LOG(WARNING) << \"Some commands are still being dispatched but didn't conclude in time. \"\n                     \"Proceeding in shutdown.\";\n   }\ndiff --git a/src/facade/dragonfly_listener.h b/src/facade/dragonfly_listener.h\nindex d1b0ce11bdcc..ee8362ef9da5 100644\n--- a/src/facade/dragonfly_listener.h\n+++ b/src/facade/dragonfly_listener.h\n@@ -24,6 +24,11 @@ class Listener : public util::ListenerInterface {\n \n   std::error_code ConfigureServerSocket(int fd) final;\n \n+  // Wait until all connections that pass the filter have stopped dispatching or until a timeout has\n+  // run out. Returns true if the all connections have stopped dispatching.\n+  bool AwaitDispatches(absl::Duration timeout,\n+                       const std::function<bool(util::Connection*)>& filter);\n+\n  private:\n   util::Connection* NewConnection(ProactorBase* proactor) final;\n   ProactorBase* PickConnectionProactor(util::LinuxSocketBase* sock) final;\n@@ -33,7 +38,6 @@ class Listener : public util::ListenerInterface {\n   void PreAcceptLoop(ProactorBase* pb) final;\n \n   void PreShutdown() final;\n-\n   void PostShutdown() final;\n \n   std::unique_ptr<util::HttpListenerBase> http_base_;\ndiff --git a/src/facade/op_status.cc b/src/facade/op_status.cc\nindex e398bad001c0..67c208fc9f28 100644\n--- a/src/facade/op_status.cc\n+++ b/src/facade/op_status.cc\n@@ -36,6 +36,8 @@ const char* DebugString(OpStatus op) {\n       return \"ENTRIES ADDED IS TO SMALL\";\n     case OpStatus::INVALID_NUMERIC_RESULT:\n       return \"INVALID NUMERIC RESULT\";\n+    case OpStatus::CANCELLED:\n+      return \"CANCELLED\";\n   }\n   return \"Unknown Error Code\";  // we should not be here, but this is how enums works in c++\n }\ndiff --git a/src/facade/op_status.h b/src/facade/op_status.h\nindex 685ba145703c..28f838c49634 100644\n--- a/src/facade/op_status.h\n+++ b/src/facade/op_status.h\n@@ -26,6 +26,7 @@ enum class OpStatus : uint16_t {\n   STREAM_ID_SMALL,\n   ENTRIES_ADDED_SMALL,\n   INVALID_NUMERIC_RESULT,\n+  CANCELLED,\n };\n \n const char* DebugString(OpStatus op);\ndiff --git a/src/server/common.cc b/src/server/common.cc\nindex 3bc955693d48..25e5d207583d 100644\n--- a/src/server/common.cc\n+++ b/src/server/common.cc\n@@ -44,6 +44,8 @@ const char* GlobalStateName(GlobalState s) {\n       return \"SAVING\";\n     case GlobalState::SHUTTING_DOWN:\n       return \"SHUTTING DOWN\";\n+    case GlobalState::TAKEN_OVER:\n+      return \"TAKEN OVER\";\n   }\n   ABSL_UNREACHABLE();\n }\ndiff --git a/src/server/common.h b/src/server/common.h\nindex e46b16f2d168..bfe7629490cf 100644\n--- a/src/server/common.h\n+++ b/src/server/common.h\n@@ -134,6 +134,7 @@ enum class GlobalState : uint8_t {\n   LOADING,\n   SAVING,\n   SHUTTING_DOWN,\n+  TAKEN_OVER,\n };\n \n enum class TimeUnit : uint8_t { SEC, MSEC };\ndiff --git a/src/server/db_slice.cc b/src/server/db_slice.cc\nindex 93147fb4bb6a..760ac22cc1eb 100644\n--- a/src/server/db_slice.cc\n+++ b/src/server/db_slice.cc\n@@ -894,8 +894,8 @@ pair<PrimeIterator, ExpireIterator> DbSlice::ExpireIfNeeded(const Context& cntx,\n   // TODO: to employ multi-generation update of expire-base and the underlying values.\n   time_t expire_time = ExpireTime(expire_it);\n \n-  // Never do expiration on replica.\n-  if (time_t(cntx.time_now_ms) < expire_time || owner_->IsReplica())\n+  // Never do expiration on replica or if expiration is disabled.\n+  if (time_t(cntx.time_now_ms) < expire_time || owner_->IsReplica() || !expire_allowed_)\n     return make_pair(it, expire_it);\n \n   // Replicate expiry\ndiff --git a/src/server/db_slice.h b/src/server/db_slice.h\nindex b0fc47e64d90..10d87b1274ca 100644\n--- a/src/server/db_slice.h\n+++ b/src/server/db_slice.h\n@@ -324,6 +324,10 @@ class DbSlice {\n   // Resets the event counter for updates/insertions\n   void ResetUpdateEvents();\n \n+  void SetExpireAllowed(bool is_allowed) {\n+    expire_allowed_ = is_allowed;\n+  }\n+\n  private:\n   std::pair<PrimeIterator, bool> AddOrUpdateInternal(const Context& cntx, std::string_view key,\n                                                      PrimeValue obj, uint64_t expire_at_ms,\n@@ -351,6 +355,7 @@ class DbSlice {\n   EngineShard* owner_;\n \n   time_t expire_base_[2];  // Used for expire logic, represents a real clock.\n+  bool expire_allowed_ = true;\n \n   uint64_t version_ = 1;  // Used to version entries in the PrimeTable.\n   ssize_t memory_budget_ = SSIZE_MAX;\ndiff --git a/src/server/dfly_main.cc b/src/server/dfly_main.cc\nindex 08919edf12dd..aeb6bd775028 100644\n--- a/src/server/dfly_main.cc\n+++ b/src/server/dfly_main.cc\n@@ -314,12 +314,14 @@ bool RunEngine(ProactorPool* pool, AcceptServer* acceptor) {\n   auto tcp_disabled = GetFlag(FLAGS_port) == 0u;\n   Listener* main_listener = nullptr;\n \n-  if (!tcp_disabled)\n+  std::vector<facade::Listener*> listeners;\n+  if (!tcp_disabled) {\n     main_listener = new Listener{Protocol::REDIS, &service};\n+    listeners.push_back(main_listener);\n+  }\n \n   Service::InitOpts opts;\n   opts.disable_time_update = false;\n-  service.Init(acceptor, main_listener, opts);\n   const auto& bind = GetFlag(FLAGS_bind);\n   const char* bind_addr = bind.empty() ? nullptr : bind.c_str();\n   auto port = GetFlag(FLAGS_port);\n@@ -357,6 +359,7 @@ bool RunEngine(ProactorPool* pool, AcceptServer* acceptor) {\n       delete uds_listener;\n     } else {\n       LOG(INFO) << \"Listening on unix socket \" << unix_sock;\n+      listeners.push_back(uds_listener);\n       unlink_uds = true;\n     }\n   } else if (tcp_disabled) {\n@@ -381,9 +384,12 @@ bool RunEngine(ProactorPool* pool, AcceptServer* acceptor) {\n       delete admin_listener;\n     } else {\n       LOG(INFO) << \"Listening on \" << printable_addr;\n+      listeners.push_back(admin_listener);\n     }\n   }\n \n+  service.Init(acceptor, listeners, opts);\n+\n   if (!tcp_disabled) {\n     error_code ec = acceptor->AddListener(bind_addr, port, main_listener);\n \ndiff --git a/src/server/dflycmd.cc b/src/server/dflycmd.cc\nindex a2b672705660..c7fe6d25fd34 100644\n--- a/src/server/dflycmd.cc\n+++ b/src/server/dflycmd.cc\n@@ -14,10 +14,12 @@\n #include \"base/flags.h\"\n #include \"base/logging.h\"\n #include \"facade/dragonfly_connection.h\"\n+#include \"facade/dragonfly_listener.h\"\n #include \"server/engine_shard_set.h\"\n #include \"server/error.h\"\n #include \"server/journal/journal.h\"\n #include \"server/journal/streamer.h\"\n+#include \"server/main_service.h\"\n #include \"server/rdb_save.h\"\n #include \"server/script_mgr.h\"\n #include \"server/server_family.h\"\n@@ -65,15 +67,27 @@ std::string_view SyncStateName(DflyCmd::SyncState sync_state) {\n }\n \n struct TransactionGuard {\n-  constexpr static auto kEmptyCb = [](Transaction* t, EngineShard* shard) { return OpStatus::OK; };\n+  static OpStatus ExitGuardCb(Transaction* t, EngineShard* shard) {\n+    shard->db_slice().SetExpireAllowed(true);\n+    return OpStatus::OK;\n+  };\n \n-  TransactionGuard(Transaction* t) : t(t) {\n+  explicit TransactionGuard(Transaction* t, bool disable_expirations = false) : t(t) {\n     t->Schedule();\n-    t->Execute(kEmptyCb, false);\n+    t->Execute(\n+        [disable_expirations](Transaction* t, EngineShard* shard) {\n+          if (disable_expirations) {\n+            shard->db_slice().SetExpireAllowed(!disable_expirations);\n+          }\n+          return OpStatus::OK;\n+        },\n+        false);\n+    VLOG(1) << \"Transaction guard engaged\";\n   }\n \n   ~TransactionGuard() {\n-    t->Execute(kEmptyCb, true);\n+    VLOG(1) << \"Releasing transaction guard\";\n+    t->Execute(ExitGuardCb, true);\n   }\n \n   Transaction* t;\n@@ -110,6 +124,10 @@ void DflyCmd::Run(CmdArgList args, ConnectionContext* cntx) {\n     return StartStable(args, cntx);\n   }\n \n+  if (sub_cmd == \"TAKEOVER\" && args.size() == 3) {\n+    return TakeOver(args, cntx);\n+  }\n+\n   if (sub_cmd == \"EXPIRE\") {\n     return Expire(args, cntx);\n   }\n@@ -316,7 +334,6 @@ void DflyCmd::StartStable(CmdArgList args, ConnectionContext* cntx) {\n \n       StopFullSyncInThread(flow, shard);\n       status = StartStableSyncInThread(flow, &replica_ptr->cntx, shard);\n-      return OpStatus::OK;\n     };\n     shard_set->RunBlockingInParallel(std::move(cb));\n \n@@ -331,6 +348,80 @@ void DflyCmd::StartStable(CmdArgList args, ConnectionContext* cntx) {\n   return rb->SendOk();\n }\n \n+void DflyCmd::TakeOver(CmdArgList args, ConnectionContext* cntx) {\n+  RedisReplyBuilder* rb = static_cast<RedisReplyBuilder*>(cntx->reply_builder());\n+  string_view sync_id_str = ArgS(args, 2);\n+  float timeout;\n+  if (!absl::SimpleAtof(ArgS(args, 1), &timeout)) {\n+    return (*cntx)->SendError(kInvalidIntErr);\n+  }\n+  if (timeout < 0) {\n+    return (*cntx)->SendError(\"timeout is negative\");\n+  }\n+\n+  VLOG(1) << \"Got DFLY TAKEOVER \" << sync_id_str;\n+\n+  auto [sync_id, replica_ptr] = GetReplicaInfoOrReply(sync_id_str, rb);\n+  if (!sync_id)\n+    return;\n+\n+  unique_lock lk(replica_ptr->mu);\n+  if (!CheckReplicaStateOrReply(*replica_ptr, SyncState::STABLE_SYNC, rb))\n+    return;\n+\n+  LOG(INFO) << \"Takeover initiated, locking down the database.\";\n+\n+  sf_->service().SwitchState(GlobalState::ACTIVE, GlobalState::TAKEN_OVER);\n+\n+  absl::Duration timeout_dur = absl::Seconds(timeout);\n+  absl::Time start = absl::Now();\n+  AggregateStatus status;\n+\n+  // TODO: We should cancel blocking commands before awaiting all\n+  // dispatches to finish.\n+  if (!sf_->AwaitDispatches(timeout_dur, [self = cntx->owner()](util::Connection* conn) {\n+        // The only command that is currently dispatching should be the takeover command -\n+        // so we wait until this is true.\n+        return conn != self;\n+      })) {\n+    LOG(WARNING) << \"Couldn't wait for commands to finish dispatching. \" << timeout_dur;\n+    status = OpStatus::TIMED_OUT;\n+  }\n+\n+  TransactionGuard tg{cntx->transaction, /*disable_expirations=*/true};\n+\n+  if (*status == OpStatus::OK) {\n+    auto cb = [&cntx = replica_ptr->cntx, replica_ptr = replica_ptr, timeout_dur, start,\n+               &status](EngineShard* shard) {\n+      FlowInfo* flow = &replica_ptr->flows[shard->shard_id()];\n+\n+      shard->journal()->RecordEntry(0, journal::Op::PING, 0, 0, {}, true);\n+      while (flow->last_acked_lsn < shard->journal()->GetLsn()) {\n+        if (absl::Now() - start > timeout_dur) {\n+          LOG(WARNING) << \"Couldn't synchronize with replica for takeover in time.\";\n+          status = OpStatus::TIMED_OUT;\n+          return;\n+        }\n+        if (cntx.IsCancelled()) {\n+          status = OpStatus::CANCELLED;\n+          return;\n+        }\n+        ThisFiber::SleepFor(1ms);\n+      }\n+    };\n+    shard_set->RunBlockingInParallel(std::move(cb));\n+  }\n+\n+  if (*status != OpStatus::OK) {\n+    sf_->service().SwitchState(GlobalState::TAKEN_OVER, GlobalState::ACTIVE);\n+    return rb->SendError(\"Takeover failed!\");\n+  }\n+  (*cntx)->SendOk();\n+\n+  VLOG(1) << \"Takeover accepted, shutting down.\";\n+  return sf_->ShutdownCmd({}, cntx);\n+}\n+\n void DflyCmd::Expire(CmdArgList args, ConnectionContext* cntx) {\n   RedisReplyBuilder* rb = static_cast<RedisReplyBuilder*>(cntx->reply_builder());\n   cntx->transaction->ScheduleSingleHop([](Transaction* t, EngineShard* shard) {\ndiff --git a/src/server/dflycmd.h b/src/server/dflycmd.h\nindex e3ee891592b8..2f0212cbbd10 100644\n--- a/src/server/dflycmd.h\n+++ b/src/server/dflycmd.h\n@@ -99,7 +99,7 @@ class DflyCmd {\n   struct ReplicaInfo {\n     ReplicaInfo(unsigned flow_count, std::string address, uint32_t listening_port,\n                 Context::ErrHandler err_handler)\n-        : state{SyncState::PREPARATION}, cntx{std::move(err_handler)}, address{address},\n+        : state{SyncState::PREPARATION}, cntx{std::move(err_handler)}, address{std::move(address)},\n           listening_port(listening_port), flows{flow_count} {\n     }\n \n@@ -151,6 +151,10 @@ class DflyCmd {\n   // Switch to stable state replication.\n   void StartStable(CmdArgList args, ConnectionContext* cntx);\n \n+  // TAKEOVER <syncid>\n+  // Shut this master down atomically with replica promotion.\n+  void TakeOver(CmdArgList args, ConnectionContext* cntx);\n+\n   // EXPIRE\n   // Check all keys for expiry.\n   void Expire(CmdArgList args, ConnectionContext* cntx);\ndiff --git a/src/server/engine_shard_set.h b/src/server/engine_shard_set.h\nindex 174991d575d0..6226aeca799c 100644\n--- a/src/server/engine_shard_set.h\n+++ b/src/server/engine_shard_set.h\n@@ -331,6 +331,10 @@ void EngineShardSet::RunBriefInParallel(U&& func, P&& pred) const {\n \n template <typename U> void EngineShardSet::RunBlockingInParallel(U&& func) {\n   BlockingCounter bc{size()};\n+  static_assert(std::is_invocable_v<U, EngineShard*>,\n+                \"Argument must be invocable EngineShard* as argument.\");\n+  static_assert(std::is_void_v<std::invoke_result_t<U, EngineShard*>>,\n+                \"Callable must not have a return value!\");\n \n   for (uint32_t i = 0; i < size(); ++i) {\n     util::ProactorBase* dest = pp_->at(i);\ndiff --git a/src/server/journal/journal_slice.cc b/src/server/journal/journal_slice.cc\nindex cd164a616bac..852006794607 100644\n--- a/src/server/journal/journal_slice.cc\n+++ b/src/server/journal/journal_slice.cc\n@@ -114,6 +114,25 @@ error_code JournalSlice::Close() {\n \n void JournalSlice::AddLogRecord(const Entry& entry, bool await) {\n   DCHECK(ring_buffer_);\n+\n+  if (entry.opcode != Op::NOOP) {\n+    // TODO: This is preparation for AOC style journaling, currently unused.\n+    RingItem item;\n+    item.lsn = lsn_;\n+    lsn_++;\n+    item.opcode = entry.opcode;\n+    item.txid = entry.txid;\n+    VLOG(1) << \"Writing item [\" << item.lsn << \"]: \" << entry.ToString();\n+    ring_buffer_->EmplaceOrOverride(move(item));\n+\n+    if (shard_file_) {\n+      string line = absl::StrCat(item.lsn, \" \", entry.txid, \" \", entry.opcode, \"\\n\");\n+      error_code ec = shard_file_->Write(io::Buffer(line), file_offset_, 0);\n+      CHECK_EC(ec);\n+      file_offset_ += line.size();\n+    }\n+  }\n+\n   {\n     std::shared_lock lk(cb_mu_);\n     DVLOG(2) << \"AddLogRecord: run callbacks for \" << entry.ToString()\n@@ -123,26 +142,6 @@ void JournalSlice::AddLogRecord(const Entry& entry, bool await) {\n       k_v.second(entry, await);\n     }\n   }\n-\n-  if (entry.opcode == Op::NOOP)\n-    return;\n-\n-  // TODO: This is preparation for AOC style journaling, currently unused.\n-  RingItem item;\n-  item.lsn = lsn_;\n-  item.opcode = entry.opcode;\n-  item.txid = entry.txid;\n-  VLOG(1) << \"Writing item [\" << item.lsn << \"]: \" << entry.ToString();\n-  ring_buffer_->EmplaceOrOverride(move(item));\n-\n-  if (shard_file_) {\n-    string line = absl::StrCat(lsn_, \" \", entry.txid, \" \", entry.opcode, \"\\n\");\n-    error_code ec = shard_file_->Write(io::Buffer(line), file_offset_, 0);\n-    CHECK_EC(ec);\n-    file_offset_ += line.size();\n-  }\n-\n-  ++lsn_;\n }\n \n uint32_t JournalSlice::RegisterOnChange(ChangeCallback cb) {\ndiff --git a/src/server/main_service.cc b/src/server/main_service.cc\nindex 8edf56daf4d4..f148e0ca1214 100644\n--- a/src/server/main_service.cc\n+++ b/src/server/main_service.cc\n@@ -539,7 +539,7 @@ Service::~Service() {\n   shard_set = nullptr;\n }\n \n-void Service::Init(util::AcceptServer* acceptor, util::ListenerInterface* main_interface,\n+void Service::Init(util::AcceptServer* acceptor, std::vector<facade::Listener*> listeners,\n                    const InitOpts& opts) {\n   InitRedisTables();\n \n@@ -557,7 +557,7 @@ void Service::Init(util::AcceptServer* acceptor, util::ListenerInterface* main_i\n   request_latency_usec.Init(&pp_);\n   StringFamily::Init(&pp_);\n   GenericFamily::Init(&pp_);\n-  server_family_.Init(acceptor, main_interface, &cluster_family_);\n+  server_family_.Init(acceptor, std::move(listeners), &cluster_family_);\n \n   ChannelStore* cs = new ChannelStore{};\n   pp_.Await(\n@@ -695,9 +695,23 @@ bool Service::VerifyCommand(const CommandId* cid, CmdArgList args, ConnectionCon\n \n   bool is_trans_cmd = CO::IsTransKind(cid->name());\n   bool under_script = bool(dfly_cntx->conn_state.script_info);\n-  bool blocked_by_loading = !dfly_cntx->journal_emulated && etl.gstate() == GlobalState::LOADING &&\n-                            (cid->opt_mask() & CO::LOADING) == 0;\n-  if (blocked_by_loading || etl.gstate() == GlobalState::SHUTTING_DOWN) {\n+  bool allowed_by_state = true;\n+  switch (etl.gstate()) {\n+    case GlobalState::LOADING:\n+      allowed_by_state = dfly_cntx->journal_emulated || (cid->opt_mask() & CO::LOADING);\n+      break;\n+    case GlobalState::SHUTTING_DOWN:\n+      allowed_by_state = false;\n+      break;\n+    case GlobalState::TAKEN_OVER:\n+      allowed_by_state = cid->name() == \"REPLCONF\" || cid->name() == \"SAVE\";\n+      break;\n+    default:\n+      break;\n+  }\n+  if (!allowed_by_state) {\n+    VLOG(1) << \"Command \" << cid->name() << \" not executed because global state is \"\n+            << GlobalStateName(etl.gstate());\n     string err = StrCat(\"Can not execute during \", GlobalStateName(etl.gstate()));\n     (*dfly_cntx)->SendError(err);\n     return false;\ndiff --git a/src/server/main_service.h b/src/server/main_service.h\nindex bb413d0f5774..3e4c0f96268e 100644\n--- a/src/server/main_service.h\n+++ b/src/server/main_service.h\n@@ -35,7 +35,7 @@ class Service : public facade::ServiceInterface {\n   explicit Service(util::ProactorPool* pp);\n   ~Service();\n \n-  void Init(util::AcceptServer* acceptor, util::ListenerInterface* main_interface,\n+  void Init(util::AcceptServer* acceptor, std::vector<facade::Listener*> listeners,\n             const InitOpts& opts = InitOpts{});\n \n   void Shutdown();\ndiff --git a/src/server/replica.cc b/src/server/replica.cc\nindex 5923f9d68865..ccd77e70dd4f 100644\n--- a/src/server/replica.cc\n+++ b/src/server/replica.cc\n@@ -226,6 +226,21 @@ void Replica::Pause(bool pause) {\n   sock_->proactor()->Await([&] { is_paused_ = pause; });\n }\n \n+std::error_code Replica::TakeOver(std::string_view timeout) {\n+  VLOG(1) << \"Taking over\";\n+\n+  std::error_code ec;\n+  sock_->proactor()->Await(\n+      [this, &ec, timeout] { ec = SendNextPhaseRequest(absl::StrCat(\"TAKEOVER \", timeout)); });\n+\n+  if (ec) {\n+    // TODO: Handle timeout more gracefully.\n+    return cntx_.ReportError(ec);\n+  }\n+  // If we successfully taken over, return and let server_family stop us.\n+  return {};\n+}\n+\n void Replica::MainReplicationFb() {\n   VLOG(1) << \"Main replication fiber started\";\n   // Switch shard states to replication.\n@@ -608,7 +623,7 @@ error_code Replica::InitiateDflySync() {\n   RETURN_ON_ERR(cntx_.GetError());\n \n   // Send DFLY SYNC.\n-  if (auto ec = SendNextPhaseRequest(false); ec) {\n+  if (auto ec = SendNextPhaseRequest(\"SYNC\"); ec) {\n     return cntx_.ReportError(ec);\n   }\n \n@@ -624,7 +639,7 @@ error_code Replica::InitiateDflySync() {\n     return cntx_.GetError();\n \n   // Send DFLY STARTSTABLE.\n-  if (auto ec = SendNextPhaseRequest(true); ec) {\n+  if (auto ec = SendNextPhaseRequest(\"STARTSTABLE\"); ec) {\n     return cntx_.ReportError(ec);\n   }\n \n@@ -768,11 +783,10 @@ void Replica::DefaultErrorHandler(const GenericError& err) {\n   CloseSocket();\n }\n \n-error_code Replica::SendNextPhaseRequest(bool stable) {\n+error_code Replica::SendNextPhaseRequest(string_view kind) {\n   ReqSerializer serializer{sock_.get()};\n \n   // Ask master to start sending replication stream\n-  string_view kind = (stable) ? \"STARTSTABLE\"sv : \"SYNC\"sv;\n   string request = StrCat(\"DFLY \", kind, \" \", master_context_.dfly_session_id);\n \n   VLOG(1) << \"Sending: \" << request;\ndiff --git a/src/server/replica.h b/src/server/replica.h\nindex 0c32a4dd7950..a1c2ed5e7784 100644\n--- a/src/server/replica.h\n+++ b/src/server/replica.h\n@@ -115,6 +115,8 @@ class Replica {\n \n   void Pause(bool pause);\n \n+  std::error_code TakeOver(std::string_view timeout);\n+\n   std::string_view MasterId() const {\n     return master_context_.master_repl_id;\n   }\n@@ -141,8 +143,8 @@ class Replica {\n   void JoinAllFlows();                // Join all flows if possible.\n   void SetShardStates(bool replica);  // Call SetReplica(replica) on all shards.\n \n-  // Send DFLY SYNC or DFLY STARTSTABLE if stable is true.\n-  std::error_code SendNextPhaseRequest(bool stable);\n+  // Send DFLY ${kind} to the master instance.\n+  std::error_code SendNextPhaseRequest(std::string_view kind);\n \n   void DefaultErrorHandler(const GenericError& err);\n \ndiff --git a/src/server/server_family.cc b/src/server/server_family.cc\nindex ecff09d388cb..bff4ce65bf30 100644\n--- a/src/server/server_family.cc\n+++ b/src/server/server_family.cc\n@@ -493,11 +493,11 @@ ServerFamily::ServerFamily(Service* service) : service_(*service) {\n ServerFamily::~ServerFamily() {\n }\n \n-void ServerFamily::Init(util::AcceptServer* acceptor, util::ListenerInterface* main_listener,\n+void ServerFamily::Init(util::AcceptServer* acceptor, std::vector<facade::Listener*> listeners,\n                         ClusterFamily* cluster_family) {\n   CHECK(acceptor_ == nullptr);\n   acceptor_ = acceptor;\n-  main_listener_ = main_listener;\n+  listeners_ = std::move(listeners);\n   dfly_cmd_ = make_unique<DflyCmd>(this);\n   cluster_family_ = cluster_family;\n \n@@ -1054,12 +1054,13 @@ GenericError ServerFamily::DoSave(bool new_version, string_view basename, Transa\n \n   // Manage global state.\n   GlobalState new_state = service_.SwitchState(GlobalState::ACTIVE, GlobalState::SAVING);\n-  if (new_state != GlobalState::SAVING) {\n+  if (new_state != GlobalState::SAVING && new_state != GlobalState::TAKEN_OVER) {\n     return {make_error_code(errc::operation_in_progress),\n             StrCat(GlobalStateName(new_state), \" - can not save database\")};\n   }\n-  absl::Cleanup rev_state = [this] {\n-    service_.SwitchState(GlobalState::SAVING, GlobalState::ACTIVE);\n+  absl::Cleanup rev_state = [this, new_state] {\n+    if (new_state == GlobalState::SAVING)\n+      service_.SwitchState(GlobalState::SAVING, GlobalState::ACTIVE);\n   };\n \n   absl::Time start = absl::Now();\n@@ -1259,6 +1260,19 @@ void ServerFamily::BreakOnShutdown() {\n   dfly_cmd_->BreakOnShutdown();\n }\n \n+bool ServerFamily::AwaitDispatches(absl::Duration timeout,\n+                                   const std::function<bool(util::Connection*)>& filter) {\n+  auto start = absl::Now();\n+  for (auto* listener : listeners_) {\n+    absl::Duration remaining_time = timeout - (absl::Now() - start);\n+    if (remaining_time < absl::Nanoseconds(0) ||\n+        !listener->AwaitDispatches(remaining_time, filter)) {\n+      return false;\n+    }\n+  }\n+  return true;\n+}\n+\n string GetPassword() {\n   string flag = GetFlag(FLAGS_requirepass);\n   if (!flag.empty()) {\n@@ -1346,7 +1360,10 @@ void ServerFamily::Client(CmdArgList args, ConnectionContext* cntx) {\n       client_info.push_back(move(info));\n     };\n \n-    main_listener_->TraverseConnections(cb);\n+    for (auto* listener : listeners_) {\n+      listener->TraverseConnections(cb);\n+    }\n+\n     string result = absl::StrJoin(move(client_info), \"\\n\");\n     result.append(\"\\n\");\n     return (*cntx)->SendBulkString(result);\n@@ -1930,6 +1947,41 @@ void ServerFamily::ReplicaOf(CmdArgList args, ConnectionContext* cntx) {\n   }\n }\n \n+void ServerFamily::ReplTakeOver(CmdArgList args, ConnectionContext* cntx) {\n+  VLOG(1) << \"Starting take over\";\n+  VLOG(1) << \"Acquire replica lock\";\n+  unique_lock lk(replicaof_mu_);\n+\n+  float_t timeout_sec;\n+  if (!absl::SimpleAtof(ArgS(args, 0), &timeout_sec)) {\n+    return (*cntx)->SendError(kInvalidIntErr);\n+  }\n+  if (timeout_sec < 0) {\n+    return (*cntx)->SendError(\"timeout is negative\");\n+  }\n+\n+  if (ServerState::tlocal()->is_master)\n+    return (*cntx)->SendError(\"Already a master instance\");\n+  auto repl_ptr = replica_;\n+  CHECK(repl_ptr);\n+\n+  auto info = replica_->GetInfo();\n+  if (!info.full_sync_done) {\n+    return (*cntx)->SendError(\"Full sync not done\");\n+  }\n+\n+  std::error_code ec = replica_->TakeOver(ArgS(args, 0));\n+  if (ec)\n+    return (*cntx)->SendError(\"Couldn't execute takeover\");\n+\n+  LOG(INFO) << \"Takeover successful, promoting this instance to master.\";\n+  service_.proactor_pool().AwaitFiberOnAll(\n+      [&](util::ProactorBase* pb) { ServerState::tlocal()->is_master = true; });\n+  replica_->Stop();\n+  replica_.reset();\n+  return (*cntx)->SendOk();\n+}\n+\n void ServerFamily::ReplConf(CmdArgList args, ConnectionContext* cntx) {\n   if (args.size() % 2 == 1)\n     goto err;\n@@ -2080,7 +2132,7 @@ void ServerFamily::Latency(CmdArgList args, ConnectionContext* cntx) {\n   (*cntx)->SendError(kSyntaxErr);\n }\n \n-void ServerFamily::_Shutdown(CmdArgList args, ConnectionContext* cntx) {\n+void ServerFamily::ShutdownCmd(CmdArgList args, ConnectionContext* cntx) {\n   if (args.size() > 1) {\n     (*cntx)->SendError(kSyntaxErr);\n     return;\n@@ -2142,9 +2194,11 @@ void ServerFamily::Register(CommandRegistry* registry) {\n             << CI{\"LATENCY\", CO::NOSCRIPT | CO::LOADING | CO::FAST, -2, 0, 0, 0}.HFUNC(Latency)\n             << CI{\"MEMORY\", kMemOpts, -2, 0, 0, 0}.HFUNC(Memory)\n             << CI{\"SAVE\", CO::ADMIN | CO::GLOBAL_TRANS, -1, 0, 0, 0}.HFUNC(Save)\n-            << CI{\"SHUTDOWN\", CO::ADMIN | CO::NOSCRIPT | CO::LOADING, -1, 0, 0, 0}.HFUNC(_Shutdown)\n+            << CI{\"SHUTDOWN\", CO::ADMIN | CO::NOSCRIPT | CO::LOADING, -1, 0, 0, 0}.HFUNC(\n+                   ShutdownCmd)\n             << CI{\"SLAVEOF\", kReplicaOpts, 3, 0, 0, 0}.HFUNC(ReplicaOf)\n             << CI{\"REPLICAOF\", kReplicaOpts, 3, 0, 0, 0}.HFUNC(ReplicaOf)\n+            << CI{\"REPLTAKEOVER\", CO::ADMIN | CO::GLOBAL_TRANS, 2, 0, 0, 0}.HFUNC(ReplTakeOver)\n             << CI{\"REPLCONF\", CO::ADMIN | CO::LOADING, -1, 0, 0, 0}.HFUNC(ReplConf)\n             << CI{\"ROLE\", CO::LOADING | CO::FAST | CO::NOSCRIPT, 1, 0, 0, 0}.HFUNC(Role)\n             << CI{\"SLOWLOG\", CO::ADMIN | CO::FAST, -2, 0, 0, 0}.SetHandler(SlowLog)\ndiff --git a/src/server/server_family.h b/src/server/server_family.h\nindex 461bc1684cd3..a56148b64bd3 100644\n--- a/src/server/server_family.h\n+++ b/src/server/server_family.h\n@@ -8,6 +8,7 @@\n #include <string>\n \n #include \"facade/conn_context.h\"\n+#include \"facade/dragonfly_listener.h\"\n #include \"facade/redis_parser.h\"\n #include \"server/channel_store.h\"\n #include \"server/engine_shard_set.h\"\n@@ -88,11 +89,13 @@ class ServerFamily {\n   explicit ServerFamily(Service* service);\n   ~ServerFamily();\n \n-  void Init(util::AcceptServer* acceptor, util::ListenerInterface* main_listener,\n+  void Init(util::AcceptServer* acceptor, std::vector<facade::Listener*> listeners,\n             ClusterFamily* cluster_family);\n   void Register(CommandRegistry* registry);\n   void Shutdown();\n \n+  void ShutdownCmd(CmdArgList args, ConnectionContext* cntx);\n+\n   Service& service() {\n     return service_;\n   }\n@@ -153,6 +156,9 @@ class ServerFamily {\n \n   void BreakOnShutdown();\n \n+  bool AwaitDispatches(absl::Duration timeout,\n+                       const std::function<bool(util::Connection*)>& filter);\n+\n  private:\n   uint32_t shard_count() const {\n     return shard_set->size();\n@@ -173,14 +179,13 @@ class ServerFamily {\n   void Latency(CmdArgList args, ConnectionContext* cntx);\n   void Psync(CmdArgList args, ConnectionContext* cntx);\n   void ReplicaOf(CmdArgList args, ConnectionContext* cntx);\n+  void ReplTakeOver(CmdArgList args, ConnectionContext* cntx);\n   void ReplConf(CmdArgList args, ConnectionContext* cntx);\n   void Role(CmdArgList args, ConnectionContext* cntx);\n   void Save(CmdArgList args, ConnectionContext* cntx);\n   void Script(CmdArgList args, ConnectionContext* cntx);\n   void Sync(CmdArgList args, ConnectionContext* cntx);\n \n-  void _Shutdown(CmdArgList args, ConnectionContext* cntx);\n-\n   void SyncGeneric(std::string_view repl_master_id, uint64_t offs, ConnectionContext* cntx);\n \n   // Returns the number of loaded keys if successfull.\n@@ -195,7 +200,7 @@ class ServerFamily {\n   Service& service_;\n \n   util::AcceptServer* acceptor_ = nullptr;\n-  util::ListenerInterface* main_listener_ = nullptr;\n+  std::vector<facade::Listener*> listeners_;\n   util::ProactorBase* pb_task_ = nullptr;\n \n   mutable Mutex replicaof_mu_, save_mu_;\ndiff --git a/src/server/transaction.cc b/src/server/transaction.cc\nindex e6cc64371449..4d7bdd8540d9 100644\n--- a/src/server/transaction.cc\n+++ b/src/server/transaction.cc\n@@ -507,6 +507,7 @@ bool Transaction::RunInShard(EngineShard* shard, bool txq_ooo) {\n \n     if (IsGlobal()) {\n       DCHECK(!awaked_prerun && !became_suspended);  // Global transactions can not be blocking.\n+      VLOG(2) << \"Releasing shard lock\";\n       shard->shard_lock()->Release(Mode());\n     } else {  // not global.\n       largs = GetLockArgs(idx);\n@@ -572,6 +573,7 @@ void Transaction::ScheduleInternal() {\n     // Lock shards\n     auto cb = [mode](EngineShard* shard) { shard->shard_lock()->Acquire(mode); };\n     shard_set->RunBriefInParallel(std::move(cb));\n+    VLOG(1) << \"Global shard lock acquired\";\n   } else {\n     num_shards = unique_shard_cnt_;\n     DCHECK_GT(num_shards, 0u);\n@@ -893,8 +895,8 @@ void Transaction::RunQuickie(EngineShard* shard) {\n   auto& sd = shard_data_[SidToId(unique_shard_id_)];\n   DCHECK_EQ(0, sd.local_mask & (KEYLOCK_ACQUIRED | OUT_OF_ORDER));\n \n-  DVLOG(1) << \"RunQuickSingle \" << DebugId() << \" \" << shard->shard_id() << \" \" << args_[0];\n-  DCHECK(cb_ptr_) << DebugId() << \" \" << shard->shard_id() << \" \" << args_[0];\n+  DVLOG(1) << \"RunQuickSingle \" << DebugId() << \" \" << shard->shard_id();\n+  DCHECK(cb_ptr_) << DebugId() << \" \" << shard->shard_id();\n \n   // Calling the callback in somewhat safe way\n   try {\n",
  "test_patch": "diff --git a/src/server/test_utils.cc b/src/server/test_utils.cc\nindex 6fdd8f9e5889..2f334c45bbec 100644\n--- a/src/server/test_utils.cc\n+++ b/src/server/test_utils.cc\n@@ -138,7 +138,7 @@ void BaseFamilyTest::SetUp() {\n \n   Service::InitOpts opts;\n   opts.disable_time_update = true;\n-  service_->Init(nullptr, nullptr, opts);\n+  service_->Init(nullptr, {}, opts);\n \n   TEST_current_time_ms = absl::GetCurrentTimeNanos() / 1000000;\n   auto cb = [&](EngineShard* s) { s->db_slice().UpdateExpireBase(TEST_current_time_ms - 1000, 0); };\ndiff --git a/tests/dragonfly/__init__.py b/tests/dragonfly/__init__.py\nindex 3436c4bd7441..5f26746e66a6 100644\n--- a/tests/dragonfly/__init__.py\n+++ b/tests/dragonfly/__init__.py\n@@ -3,6 +3,7 @@\n import subprocess\n import aiohttp\n from prometheus_client.parser import text_string_to_metric_families\n+from redis.asyncio import Redis as RedisClient\n \n from dataclasses import dataclass\n \n@@ -32,6 +33,10 @@ def __init__(self, params: DflyParams, args):\n         self.args = args\n         self.params = params\n         self.proc = None\n+        self._client : Optional[RedisClient] = None\n+\n+    def client(self) -> RedisClient:\n+        return RedisClient(port=self.port)\n \n     def start(self):\n         self._start()\ndiff --git a/tests/dragonfly/replication_test.py b/tests/dragonfly/replication_test.py\nindex 9275bb0ce12f..1e053b6ab258 100644\n--- a/tests/dragonfly/replication_test.py\n+++ b/tests/dragonfly/replication_test.py\n@@ -937,7 +937,6 @@ async def assert_lag_condition(inst, client, condition):\n         assert False, \"Lag has never satisfied condition!\"\n \n \n-\n @dfly_args({\"proactor_threads\": 2})\n @pytest.mark.asyncio\n async def test_replication_info(df_local_factory, df_seeder_factory, n_keys=2000):\n@@ -1069,3 +1068,114 @@ async def test_readonly_script(df_local_factory):\n         assert False\n     except aioredis.ResponseError as roe:\n         assert 'READONLY ' in str(roe)\n+\n+\n+take_over_cases = [\n+    [2, 2],\n+    [2, 4],\n+    [4, 2],\n+    [8, 8],\n+]\n+\n+\n+@pytest.mark.parametrize(\"master_threads, replica_threads\", take_over_cases)\n+@pytest.mark.asyncio\n+async def test_take_over_counters(df_local_factory, master_threads, replica_threads):\n+    master = df_local_factory.create(proactor_threads=master_threads,\n+                                     port=BASE_PORT,\n+                                     #  vmodule=\"journal_slice=2,dflycmd=2,main_service=1\",\n+                                     logtostderr=True)\n+    replica1 = df_local_factory.create(\n+        port=BASE_PORT+1, proactor_threads=replica_threads)\n+    replica2 = df_local_factory.create(\n+        port=BASE_PORT+2, proactor_threads=replica_threads)\n+    replica3 = df_local_factory.create(\n+        port=BASE_PORT+3, proactor_threads=replica_threads)\n+    df_local_factory.start_all([master, replica1, replica2, replica3])\n+    async with (\n+        master.client() as c_master,\n+        replica1.client() as c1,\n+        master.client() as c_blocking,\n+        replica2.client() as c2,\n+        replica3.client() as c3,\n+    ):\n+        await c1.execute_command(f\"REPLICAOF localhost {master.port}\")\n+        await c2.execute_command(f\"REPLICAOF localhost {master.port}\")\n+        await c3.execute_command(f\"REPLICAOF localhost {master.port}\")\n+\n+        await wait_available_async(c1)\n+\n+        async def counter(key):\n+            value = 0\n+            await c_master.execute_command(f\"SET {key} 0\")\n+            start = time.time()\n+            while time.time() - start < 20:\n+                try:\n+                    value = await c_master.execute_command(f\"INCR {key}\")\n+                except (redis.exceptions.ConnectionError, redis.exceptions.ResponseError) as e:\n+                    break\n+            else:\n+                assert False, \"The incrementing loop should be exited with a connection error\"\n+            return key, value\n+\n+        async def block_during_takeover():\n+            \"Add a blocking command during takeover to make sure it doesn't block it.\"\n+            # TODO: We need to make takeover interrupt blocking commands.\n+            return\n+            try:\n+                await c_blocking.execute_command(\"BLPOP BLOCKING_KEY1 BLOCKING_KEY2 10\")\n+            except redis.exceptions.ConnectionError:\n+                pass\n+\n+        async def delayed_takeover():\n+            await asyncio.sleep(1)\n+            await c1.execute_command(f\"REPLTAKEOVER 5\")\n+\n+        _, _, *results = await asyncio.gather(delayed_takeover(), block_during_takeover(), *[counter(f\"key{i}\") for i in range(16)])\n+        assert await c1.execute_command(\"role\") == [b'master', []]\n+\n+        for key, client_value in results:\n+            replicated_value = await c1.get(key)\n+            assert client_value == int(replicated_value)\n+\n+\n+@pytest.mark.parametrize(\"master_threads, replica_threads\", take_over_cases)\n+@pytest.mark.asyncio\n+async def test_take_over_seeder(df_local_factory, df_seeder_factory, master_threads, replica_threads):\n+    master = df_local_factory.create(proactor_threads=master_threads,\n+                                     port=BASE_PORT,\n+                                     dbfilename=f\"dump_{master_threads}_{replica_threads}\",\n+                                     logtostderr=True)\n+    replica = df_local_factory.create(\n+        port=BASE_PORT+1, proactor_threads=replica_threads)\n+    df_local_factory.start_all([master, replica])\n+\n+    seeder = df_seeder_factory.create(port=master.port, keys=1000, dbcount=5, stop_on_failure=False)\n+    async with (\n+        master.client() as c_master,\n+        replica.client() as c_replica,\n+    ):\n+        await c_replica.execute_command(f\"REPLICAOF localhost {master.port}\")\n+        await wait_available_async(c_replica)\n+\n+        async def seed():\n+            await seeder.run(target_ops=3000)\n+\n+        fill_task = asyncio.create_task(seed())\n+\n+        # Give the seeder a bit of time.\n+        await asyncio.sleep(1)\n+        await c_replica.execute_command(f\"REPLTAKEOVER 5\")\n+        seeder.stop()\n+\n+        assert await c_replica.execute_command(\"role\") == [b'master', []]\n+\n+        # Need to wait a bit to give time to write the shutdown snapshot\n+        await asyncio.sleep(1)\n+        assert master.proc.poll() == 0, \"Master process did not exit correctly.\"\n+\n+        master.start()\n+        await wait_available_async(c_master)\n+\n+        capture = await seeder.capture()\n+        assert await seeder.compare(capture, port=replica.port)\ndiff --git a/tests/dragonfly/server_family_test.py b/tests/dragonfly/server_family_test.py\nindex 8151533198f6..1bf043331023 100644\n--- a/tests/dragonfly/server_family_test.py\n+++ b/tests/dragonfly/server_family_test.py\n@@ -62,10 +62,21 @@ async def test_connection_name(async_client: aioredis.Redis):\n     assert name == \"test_conn_name\"\n \n \n-'''\n-make sure that the scan command is working with python\n-'''\n+async def test_client_list(df_factory):\n+    instance = df_factory.create(port=1111, admin_port=1112)\n+    instance.start()\n+    async with (aioredis.Redis(port=instance.port) as client, aioredis.Redis(port=instance.admin_port) as admin_client):\n+        await client.ping()\n+        await admin_client.ping()\n+        assert len(await client.execute_command(\"CLIENT LIST\")) == 2\n+        assert len(await admin_client.execute_command(\"CLIENT LIST\")) == 2\n+    instance.stop()\n+\n+\n async def test_scan(async_client: aioredis.Redis):\n+    '''\n+    make sure that the scan command is working with python\n+    '''\n     def gen_test_data():\n         for i in range(10):\n             yield f\"key-{i}\", f\"value-{i}\"\ndiff --git a/tests/dragonfly/utility.py b/tests/dragonfly/utility.py\nindex ef9eb78c96d8..d62d99ac6619 100644\n--- a/tests/dragonfly/utility.py\n+++ b/tests/dragonfly/utility.py\n@@ -2,6 +2,7 @@\n import sys\n import asyncio\n from redis import asyncio as aioredis\n+import redis\n import random\n import string\n import itertools\n@@ -342,7 +343,7 @@ class DflySeeder:\n         assert await seeder.compare(capture, port=1112)\n     \"\"\"\n \n-    def __init__(self, port=6379, keys=1000, val_size=50, batch_size=100, max_multikey=5, dbcount=1, multi_transaction_probability=0.3, log_file=None, unsupported_types=[]):\n+    def __init__(self, port=6379, keys=1000, val_size=50, batch_size=100, max_multikey=5, dbcount=1, multi_transaction_probability=0.3, log_file=None, unsupported_types=[], stop_on_failure=True):\n         self.gen = CommandGenerator(\n             keys, val_size, batch_size, max_multikey, unsupported_types\n         )\n@@ -350,6 +351,7 @@ def __init__(self, port=6379, keys=1000, val_size=50, batch_size=100, max_multik\n         self.dbcount = dbcount\n         self.multi_transaction_probability = multi_transaction_probability\n         self.stop_flag = False\n+        self.stop_on_failure = stop_on_failure\n \n         self.log_file = log_file\n         if self.log_file is not None:\n@@ -496,6 +498,9 @@ async def _executor_task(self, db, queue):\n \n             try:\n                 await pipe.execute()\n+            except (redis.exceptions.ConnectionError, redis.exceptions.ResponseError) as e:\n+                if self.stop_on_failure:\n+                    raise SystemExit(e)\n             except Exception as e:\n                 raise SystemExit(e)\n             queue.task_done()\n",
  "problem_statement": "Support atomic replica takeover\n\r\nhttps://docs.google.com/document/d/1wDt_Rp4wfEX5h0cTVza1-AJOp9JrPyA5cw7CkEAjBgw/edit\n",
  "hints_text": "",
  "created_at": "2023-05-29T14:55:30Z",
  "modified_files": [
    "src/facade/dragonfly_listener.cc",
    "src/facade/dragonfly_listener.h",
    "src/facade/op_status.cc",
    "src/facade/op_status.h",
    "src/server/common.cc",
    "src/server/common.h",
    "src/server/db_slice.cc",
    "src/server/db_slice.h",
    "src/server/dfly_main.cc",
    "src/server/dflycmd.cc",
    "src/server/dflycmd.h",
    "src/server/engine_shard_set.h",
    "src/server/journal/journal_slice.cc",
    "src/server/main_service.cc",
    "src/server/main_service.h",
    "src/server/replica.cc",
    "src/server/replica.h",
    "src/server/server_family.cc",
    "src/server/server_family.h",
    "src/server/transaction.cc"
  ],
  "modified_test_files": [
    "src/server/test_utils.cc",
    "tests/dragonfly/__init__.py",
    "tests/dragonfly/replication_test.py",
    "tests/dragonfly/server_family_test.py",
    "tests/dragonfly/utility.py"
  ]
}