{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 2503,
  "instance_id": "dragonflydb__dragonfly-2503",
  "issue_numbers": [
    "2502"
  ],
  "base_commit": "1dee082f86a691c4a62d3ae349810c84c52adf10",
  "patch": "diff --git a/src/server/generic_family.cc b/src/server/generic_family.cc\nindex 8d008863e96a..380b7d33b8ed 100644\n--- a/src/server/generic_family.cc\n+++ b/src/server/generic_family.cc\n@@ -1428,6 +1428,9 @@ OpResult<void> GenericFamily::OpRen(const OpArgs& op_args, string_view from_key,\n     // from_it would be invalid. Therefore, UpdateExpire does not invalidate any iterators,\n     // therefore we can delete 'from_it'.\n     db_slice.UpdateExpire(op_args.db_cntx.db_index, to_res.it, exp_ts);\n+    to_res.it->first.SetSticky(sticky);\n+    to_res.post_updater.Run();\n+\n     from_res.post_updater.Run();\n     CHECK(db_slice.Del(op_args.db_cntx.db_index, from_res.it));\n   } else {\n@@ -1439,10 +1442,9 @@ OpResult<void> GenericFamily::OpRen(const OpArgs& op_args, string_view from_key,\n     auto op_result = db_slice.AddNew(op_args.db_cntx, to_key, std::move(from_obj), exp_ts);\n     RETURN_ON_BAD_STATUS(op_result);\n     to_res = std::move(*op_result);\n+    to_res.it->first.SetSticky(sticky);\n   }\n \n-  to_res.it->first.SetSticky(sticky);\n-\n   if (!is_prior_list && to_res.it->second.ObjType() == OBJ_LIST && es->blocking_controller()) {\n     es->blocking_controller()->AwakeWatched(op_args.db_cntx.db_index, to_key);\n   }\n",
  "test_patch": "diff --git a/src/server/generic_family_test.cc b/src/server/generic_family_test.cc\nindex 96f1e9638a90..006df7ecc357 100644\n--- a/src/server/generic_family_test.cc\n+++ b/src/server/generic_family_test.cc\n@@ -282,6 +282,15 @@ TEST_F(GenericFamilyTest, RenameSameName) {\n   EXPECT_EQ(Run({\"rename\", kKey, kKey}), \"OK\");\n }\n \n+TEST_F(GenericFamilyTest, RenameSameShard) {\n+  num_threads_ = 1;\n+  ResetService();\n+\n+  ASSERT_EQ(Run({\"set\", \"x\", \"value\"}), \"OK\");\n+  ASSERT_EQ(Run({\"set\", \"y\", \"value\"}), \"OK\");\n+  EXPECT_EQ(Run({\"rename\", \"x\", \"y\"}), \"OK\");\n+}\n+\n TEST_F(GenericFamilyTest, Stick) {\n   // check stick returns zero on non-existent keys\n   ASSERT_THAT(Run({\"stick\", \"a\", \"b\"}), IntArg(0));\n",
  "problem_statement": "Crash on replica\nI have been correcting version 1.13.0 in three nodes in high availability with Sentinel as \"vigilant\" for a long time without problems. The other day I updated 1.14.0 and obtube this message in two of the nodes:\r\n\r\n```\r\nF20240125 21: 25: 42.501004 2708194 db_slice.cc:340] Check Failed: Fields_.db_size == Fields_.db_slice-> dbsize (Fields_.db_ind) (40889 vs. 40888) Attempting to run post-update after DB was modified\r\n```\r\n\r\nThis caused the fall of the cluster.\r\n\r\nI updated 1.14.1 and I did not manage to stabilize the service, I do not know if due to the problem described above or for the haste to recover the production system.\r\n\r\nFinally, the service stabilized making a rolling at 1.13.0 and deactivating the cluster until a moment of less use, where I activated it again. In my configuration, nodes that are slaves are used to read and the master to write.\r\n\r\nThe truth is that I do not understand the error and if it has to do with version 1.14.0 and the bug that has been set at 1.14.1. Or it is a new bug.\r\n\r\nThank you very much for your help\n",
  "hints_text": "Hey @fernandomacho - is there a full stack trace after that `CHECK` failure? That could be very useful.\nI send you other full stack trace ;)\r\n\r\n```\r\nJan 25 18:38:15 ovh-innova dragonfly[3084061]: F20240125 18:38:15.791584 3084068 db_slice.cc:340] Check failed: fields_.db_size == fields_.db_slice->DbSize(fields_.db_ind) (43736 vs. 43735) Attempting to run post-update after DB was modified\r\nJan 25 18:38:15 ovh-innova dragonfly[3084061]: *** Check failure stack trace: ***\r\nJan 25 18:38:15 ovh-innova dragonfly[3084061]:     @     0x557f467129f3  google::LogMessage::SendToLog()\r\nJan 25 18:38:15 ovh-innova dragonfly[3084061]:     @     0x557f4670b1b7  google::LogMessage::Flush()\r\nJan 25 18:38:15 ovh-innova dragonfly[3084061]:     @     0x557f4670cb3f  google::LogMessageFatal::~LogMessageFatal()\r\nJan 25 18:38:15 ovh-innova dragonfly[3084061]:     @     0x557f45fdf4bc  dfly::DbSlice::AutoUpdater::Run()\r\nJan 25 18:38:15 ovh-innova dragonfly[3084061]:     @     0x557f45fdf71d  dfly::DbSlice::AutoUpdater::~AutoUpdater()\r\nJan 25 18:38:15 ovh-innova dragonfly[3084061]:     @     0x557f45d87686  dfly::GenericFamily::OpRen()\r\nJan 25 18:38:15 ovh-innova dragonfly[3084061]:     @     0x557f45d87cfb  _ZN4absl12lts_2023080219functional_internal12InvokeObjectIZN4dfly11Transaction18ScheduleSingleHopTIZNS3_13GenericFamily13RenameGenericENS0_4SpanINS7_IcEEEEbPNS3_17ConnectionContextEEUlPS4_PNS3_11EngineShardEE_EEDTclfp_fpTLDn0EEEOT_EUlSC_SE_E_NS4_14RunnableResultEJSC_SE_EEET0_NS1_7VoidPtrEDpNS1_8ForwardTIT1_E4typeE\r\nJan 25 18:38:15 ovh-innova dragonfly[3084061]:     @     0x557f4600d690  dfly::Transaction::RunQuickie()\r\nJan 25 18:38:15 ovh-innova dragonfly[3084061]:     @     0x557f4600fbe7  dfly::Transaction::ScheduleUniqueShard()\r\nJan 25 18:38:15 ovh-innova dragonfly[3084061]:     @     0x557f46012fd3  _ZNSt17_Function_handlerIFvvEZN4dfly11Transaction17ScheduleSingleHopEN4absl12lts_2023080211FunctionRefIFNS2_14RunnableResultEPS2_PNS1_11EngineShardEEEEEUlvE_E9_M_invokeERKSt9_Any_data\r\nJan 25 18:38:15 ovh-innova dragonfly[3084061]:     @     0x557f46516a8a  util::fb2::FiberQueue::Run()\r\nJan 25 18:38:15 ovh-innova dragonfly[3084061]:     @     0x557f45f3fa9e  _ZN5boost7context6detail11fiber_entryINS1_12fiber_recordINS0_5fiberENS0_21basic_fixedsize_stackINS0_12stack_traitsEEEZN4util3fb26detail15WorkerFiberImplIZN4dfly11EngineShardC4EPNS9_12ProactorBaseEP9mi_heap_sEUlvE0_JEEC4IS7_EESt17basic_string_viewIcSt11char_traitsIcEERKNS0_12preallocatedEOT_OSI_EUlOS4_E_EEEEvNS1_10transfer_tE\r\nJan 25 18:38:15 ovh-innova dragonfly[3084061]:     @     0x557f4652fdaf  make_fcontext\r\nJan 25 18:38:15 ovh-innova dragonfly[3084061]: *** SIGABRT received at time=1706204295 on cpu 3 ***\r\nJan 25 18:38:15 ovh-innova dragonfly[3084061]: PC: @     0x7f823219f00b  (unknown)  raise\r\nJan 25 18:38:22 ovh-innova systemd[1]: dragonfly.service: Main process exited, code=killed, status=6/ABRT\r\nJan 25 18:38:22 ovh-innova systemd[1]: dragonfly.service: Failed with result 'signal'.\r\n``` \nThe crash happens in `RENAME`, which indeed has some subtleties when done cross shards. I'm looking.\nI am able to reproduce the issue, it happens when both keys are actually in the same shard and both keys exist",
  "created_at": "2024-01-29T13:32:35Z",
  "modified_files": [
    "src/server/generic_family.cc"
  ],
  "modified_test_files": [
    "src/server/generic_family_test.cc"
  ]
}