{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 4273,
  "instance_id": "dragonflydb__dragonfly-4273",
  "issue_numbers": [
    "4213"
  ],
  "base_commit": "330d007d56311fc6fab2a45409350d026a9a8b53",
  "patch": "diff --git a/helio b/helio\nindex ff9b6cd35bf0..32e8c4ec830e 160000\n--- a/helio\n+++ b/helio\n@@ -1,1 +1,1 @@\n-Subproject commit ff9b6cd35bf082a9d48cf0904b0e8557cf31b6d2\n+Subproject commit 32e8c4ec830e8d4224d8a13a11c1607f357da80f\ndiff --git a/src/facade/redis_parser.cc b/src/facade/redis_parser.cc\nindex f7ebd2db4beb..2e2967761764 100644\n--- a/src/facade/redis_parser.cc\n+++ b/src/facade/redis_parser.cc\n@@ -11,6 +11,7 @@\n namespace facade {\n \n using namespace std;\n+constexpr static long kMaxBulkLen = 256 * (1ul << 20);  // 256MB.\n \n auto RedisParser::Parse(Buffer str, uint32_t* consumed, RespExpr::Vec* res) -> Result {\n   DCHECK(!str.empty());\n@@ -218,7 +219,11 @@ auto RedisParser::ParseLen(Buffer str, int64_t* res) -> ResultConsumed {\n   const char* s = reinterpret_cast<const char*>(str.data());\n   const char* pos = reinterpret_cast<const char*>(memchr(s, '\\n', str.size()));\n   if (!pos) {\n-    Result r = str.size() < 32 ? INPUT_PENDING : BAD_ARRAYLEN;\n+    Result r = INPUT_PENDING;\n+    if (str.size() >= 32) {\n+      LOG(WARNING) << \"Unexpected format \" << string_view{s, str.size()};\n+      r = BAD_ARRAYLEN;\n+    }\n     return {r, 0};\n   }\n \n@@ -227,10 +232,16 @@ auto RedisParser::ParseLen(Buffer str, int64_t* res) -> ResultConsumed {\n   }\n \n   // Skip the first character and 2 last ones (\\r\\n).\n-  bool success = absl::SimpleAtoi(std::string_view{s + 1, size_t(pos - 1 - s)}, res);\n+  string_view len_token{s + 1, size_t(pos - 1 - s)};\n+  bool success = absl::SimpleAtoi(len_token, res);\n+\n   unsigned consumed = pos - s + 1;\n+  if (success && *res >= -1) {\n+    return ResultConsumed{OK, consumed};\n+  }\n \n-  return ResultConsumed{success ? OK : BAD_ARRAYLEN, consumed};\n+  LOG(WARNING) << \"Failed to parse len \" << len_token;\n+  return ResultConsumed{BAD_ARRAYLEN, consumed};\n }\n \n auto RedisParser::ConsumeArrayLen(Buffer str) -> ResultConsumed {\n@@ -247,8 +258,8 @@ auto RedisParser::ConsumeArrayLen(Buffer str) -> ResultConsumed {\n     len *= 2;\n   }\n \n-  if (len < -1 || len > max_arr_len_) {\n-    LOG_IF(WARNING, len > max_arr_len_) << \"Multibulk len is too large \" << len;\n+  if (len > max_arr_len_) {\n+    LOG(WARNING) << \"Multibulk len is too large \" << len;\n \n     return {BAD_ARRAYLEN, res.second};\n   }\n@@ -310,15 +321,14 @@ auto RedisParser::ParseArg(Buffer str) -> ResultConsumed {\n       return res;\n     }\n \n-    if (len < -1 || len > kMaxBulkLen)\n-      return {BAD_ARRAYLEN, res.second};\n-\n     if (len == -1) {  // Resp2 NIL\n       cached_expr_->emplace_back(RespExpr::NIL);\n       cached_expr_->back().u = Buffer{};\n       HandleFinishArg();\n     } else {\n       DVLOG(1) << \"String(\" << len << \")\";\n+      LOG_IF(WARNING, len > kMaxBulkLen) << \"Large bulk len: \" << len;\n+\n       cached_expr_->emplace_back(RespExpr::STRING);\n       cached_expr_->back().u = Buffer{};\n       bulk_len_ = len;\ndiff --git a/src/facade/redis_parser.h b/src/facade/redis_parser.h\nindex f9986dd4d37e..e092be06ae98 100644\n--- a/src/facade/redis_parser.h\n+++ b/src/facade/redis_parser.h\n@@ -22,8 +22,6 @@ namespace facade {\n  */\n class RedisParser {\n  public:\n-  constexpr static long kMaxBulkLen = 256 * (1ul << 20);  // 256MB.\n-\n   enum Result : uint8_t {\n     OK,\n     INPUT_PENDING,\ndiff --git a/src/server/server_family.cc b/src/server/server_family.cc\nindex 7e9638c10bd1..632409deb461 100644\n--- a/src/server/server_family.cc\n+++ b/src/server/server_family.cc\n@@ -877,6 +877,7 @@ void ServerFamily::Init(util::AcceptServer* acceptor, std::vector<facade::Listen\n         absl::GetFlag(FLAGS_s3_ec2_metadata), absl::GetFlag(FLAGS_s3_sign_payload));\n #else\n     LOG(ERROR) << \"Compiled without AWS support\";\n+    exit(1);\n #endif\n   } else if (IsGCSPath(flag_dir)) {\n     auto gcs = std::make_shared<detail::GcsSnapshotStorage>();\n",
  "test_patch": "diff --git a/src/facade/redis_parser_test.cc b/src/facade/redis_parser_test.cc\nindex 29237ca06dae..1bb7864e4310 100644\n--- a/src/facade/redis_parser_test.cc\n+++ b/src/facade/redis_parser_test.cc\n@@ -170,7 +170,7 @@ TEST_F(RedisParserTest, Empty) {\n }\n \n TEST_F(RedisParserTest, LargeBulk) {\n-  std::string_view prefix(\"*1\\r\\n$1024\\r\\n\");\n+  string_view prefix(\"*1\\r\\n$1024\\r\\n\");\n \n   ASSERT_EQ(RedisParser::INPUT_PENDING, Parse(prefix));\n   ASSERT_EQ(prefix.size(), consumed_);\n@@ -191,6 +191,18 @@ TEST_F(RedisParserTest, LargeBulk) {\n   ASSERT_EQ(RedisParser::INPUT_PENDING, Parse(part1));\n   ASSERT_EQ(RedisParser::INPUT_PENDING, Parse(half));\n   ASSERT_EQ(RedisParser::OK, Parse(\"\\r\\n\"));\n+\n+  prefix = \"*1\\r\\n$270000000\\r\\n\";\n+  ASSERT_EQ(RedisParser::INPUT_PENDING, Parse(prefix));\n+  ASSERT_EQ(prefix.size(), consumed_);\n+  string chunk(1000000, 'a');\n+  for (unsigned i = 0; i < 270; ++i) {\n+    ASSERT_EQ(RedisParser::INPUT_PENDING, Parse(chunk));\n+    ASSERT_EQ(chunk.size(), consumed_);\n+  }\n+  ASSERT_EQ(RedisParser::OK, Parse(\"\\r\\n\"));\n+  ASSERT_THAT(args_, ElementsAre(ArgType(RespExpr::STRING)));\n+  EXPECT_EQ(270000000, args_[0].GetBuf().size());\n }\n \n TEST_F(RedisParserTest, NILs) {\n",
  "problem_statement": "can't upload db by redis-cli --pipe\n**Describe the bug**\r\n\r\n```\r\ntime redis-cli -2 --pipe < db0-31073609.resp\r\n\r\nreal\t0m4.453s\r\nuser\t0m0.355s\r\nsys\t0m2.143s\r\n```\r\n\r\n```dragonfly_connection.cc:1030] Pipeline buffer over limit: pipeline_bytes 78768428 queue_size 100001, consider increasing pipeline_buffer_limit/pipeline_queue_limit```\r\n\r\nbut in flagfile:\r\n```\r\n--pipeline_buffer_limit=7008822000\r\n--pipeline_queue_limit=100000\r\n```\r\n\r\n\r\n**Environment (please complete the following information):**\r\n - OS: Debian 12\r\n - Kernel: `Linux n02-test-podman 6.8.12-4-pve #1 SMP PREEMPT_DYNAMIC PMX 6.8.12-4 (2024-11-06T15:04Z) x86_64 GNU/Linux`\r\n - Containerized: podman\r\n - \"CreateCommand\": [\r\n               \"podman\",\r\n               \"run\",\r\n               \"-dt\",\r\n               \"--pod\",\r\n               \"new:dfly\",\r\n               \"--name\",\r\n               \"df01\",\r\n               \"-p\",\r\n               \"6379:6379\",\r\n               \"-v\",\r\n               \"/var/lib/dragonfly:/data\",\r\n               \"-v\",\r\n               \"/opt/dfly/etc:/etc/dfly\",\r\n               \"docker.dragonflydb.io/dragonflydb/dragonfly:latest\",\r\n               \"--flagfile=/etc/dfly/flagfile.conf\"\r\n          ],\r\n - Dragonfly Version: 1.25.3\n",
  "hints_text": "it's just a warning. have you actually saw it does not upload?\n@romange \r\n> it's just a warning. have you actually saw it does not upload?\r\n```\r\n# Keyspace\r\ndb0:keys=2293351,expires=0,avg_ttl=-1\r\n```\r\nresp file have 31073609 keys\nMaybe it has duplicates? Can you share the file with me?\r\nthis is what I did:\r\n```\r\nprintf \"set KEY_%d value\\n\" $(seq 0 31073609) > 1.resp\r\nredis-cli -2 --pipe < 1.resp\r\nAll data transferred. Waiting for the last reply...\r\nLast reply received from server.\r\nerrors: 0, replies: 31073610\r\n```\r\n\r\n```\r\n> dbsize\r\n(integer) 31073610\r\n```\r\n\nhave not heard from you. so far i have not seen any evidence that there is a bug. closing, please reopen if you have more info \n@romange\r\n> haven't heard from you. I haven't seen any evidence that there is a bug yet. closing, please reopen if you have more info\r\n\r\nWell, I'm not a fast Gonzalez, rather a slow Rodriguez )\r\n\r\nprintf generates a non resp file. But yes, this file is fully loaded\r\nHowever, the file dumped from keydb is not loaded in dragonfly. But it can be loaded in keydb, redis and garnet.\r\n\r\nUnfortunately, I can't provide the file itself.\r\n\r\nI also noticed that keys are scanned slowly (generated by printf):\r\n```\r\n# time redis-cli --scan | (pv -p --timer --rate --bytes )| wc -l\r\n 374MiB 0:06:05 [1.02MiB/s] [                                                    <=>                         ]\r\n31073610\r\n\r\nreal\t6m5.862s\r\nuser\t0m14.719s\r\nsys\t3m28.920s\r\n```\n> @romange\r\n> \r\n> > haven't heard from you. I haven't seen any evidence that there is a bug yet. closing, please reopen if you have more info\r\n> \r\n> Well, I'm not a fast Gonzalez, rather a slow Rodriguez )\r\n> \r\nHad to google these references to understand :)\r\n\r\n> printf generates a non resp file. But yes, this file is fully loaded However, the file dumped from keydb is not loaded in dragonfly. But it can be loaded in keydb, redis and garnet.\r\n> \r\n> Unfortunately, I can't provide the file itself.\r\n\r\nCan you please run dragonfly with `--vmodule=dragonfly_connection=1` and provide the info log after the the resp file has finished uploading?\r\n\r\n> \r\n> I also noticed that keys are scanned slowly (generated by printf):\r\n> \r\n> ```\r\n> # time redis-cli --scan | (pv -p --timer --rate --bytes )| wc -l\r\n>  374MiB 0:06:05 [1.02MiB/s] [                                                    <=>                         ]\r\n> 31073610\r\n> \r\n> real\t6m5.862s\r\n> user\t0m14.719s\r\n> sys\t3m28.920s\r\n> ```\r\n\r\n\n@romange \r\n> Can you please run dragonfly with `--vmodule=dragonfly_connection=1` and provide the info log after the the resp file has finished uploading?\r\n\r\n`--vmodule=dragonfly_connection=1`: \r\n```\r\nI20241205 15:46:12.598796    10 dragonfly_connection.cc:662] [5] HandleRequests\r\nI20241205 15:46:12.598882    10 dragonfly_connection.cc:1668] [5] LaunchDispatchFiberIfNeeded \r\nW20241205 15:46:12.702705    10 dragonfly_connection.cc:1030] Pipeline buffer over limit: pipeline_bytes 78768428 queue_size 100001, consider increasing pipeline_buffer_limit/pipeline_queue_limit\r\nI20241205 15:46:16.900218    10 dragonfly_connection.cc:984] Error parser status 2\r\nI20241205 15:46:16.900285    10 dragonfly_connection.cc:754] Closed connection for peer id=5 addr=10.88.0.1:59094 laddr=10.88.0.39:6379 fd=676 name= tid=4 irqmatch=1 age=4 idle=0 db=0 flags=t phase=preclose lib-name= lib-ver=\r\n```\r\n\r\n\r\n`--vmodule=dragonfly_connection=2`: \r\n```\r\nI20241205 15:49:09.352258     6 dragonfly_connection.cc:662] [1] HandleRequests\r\nI20241205 15:49:09.352349     6 dragonfly_connection.cc:1668] [1] LaunchDispatchFiberIfNeeded \r\nI20241205 15:49:09.352470     6 dragonfly_connection.cc:121] Grown io_buf to 512\r\nI20241205 15:49:09.352504     6 dragonfly_connection.cc:121] Grown io_buf to 1024\r\nI20241205 15:49:09.353669     6 dragonfly_connection.cc:121] Grown io_buf to 2048\r\nI20241205 15:49:09.353709     6 dragonfly_connection.cc:121] Grown io_buf to 4096\r\nW20241205 15:49:09.454347     6 dragonfly_connection.cc:1030] Pipeline buffer over limit: pipeline_bytes 78768428 queue_size 100001, consider increasing pipeline_buffer_limit/pipeline_queue_limit\r\nI20241205 15:49:09.801020     6 dragonfly_connection.cc:121] Grown io_buf to 8192\r\nI20241205 15:49:11.235170     6 dragonfly_connection.cc:121] Grown io_buf to 32768\r\nI20241205 15:49:11.620589     6 dragonfly_connection.cc:121] Grown io_buf to 65536\r\nI20241205 15:49:13.765785     6 dragonfly_connection.cc:969] Before dispatch_fb.join()\r\nI20241205 15:49:13.765923     6 dragonfly_connection.cc:971] After dispatch_fb.join()\r\nI20241205 15:49:13.768098     6 dragonfly_connection.cc:984] Error parser status 2\r\nI20241205 15:49:13.768144     6 dragonfly_connection.cc:754] Closed connection for peer id=1 addr=10.88.0.1:34728 laddr=10.88.0.40:6379 fd=676 name= tid=0 irqmatch=1 age=4 idle=0 db=0 flags=t phase=preclose lib-name= lib-ver=\r\n```\r\n\r\n\nyeah, please run dragonfly with `--max_multi_bulk_len=1000000` and tell me if it helps.\r\nI will make the warning more user friendly\n@romange `--max_multi_bulk_len=1000000` doesn't help too:\r\n```\r\nI20241205 18:26:37.683950     6 dragonfly_connection.cc:662] [1] HandleRequests\r\nI20241205 18:26:37.684032     6 dragonfly_connection.cc:1668] [1] LaunchDispatchFiberIfNeeded \r\nI20241205 18:26:37.684060     6 dragonfly_connection.cc:121] Grown io_buf to 512\r\nI20241205 18:26:37.684079     6 dragonfly_connection.cc:121] Grown io_buf to 1024\r\nI20241205 18:26:37.685305     6 dragonfly_connection.cc:121] Grown io_buf to 2048\r\nI20241205 18:26:37.685393     6 dragonfly_connection.cc:121] Grown io_buf to 4096\r\nW20241205 18:26:37.790148     6 dragonfly_connection.cc:1030] Pipeline buffer over limit: pipeline_bytes 78768428 queue_size 100001, consider increasing pipeline_buffer_limit/pipeline_queue_limit\r\nI20241205 18:26:38.147810     6 dragonfly_connection.cc:121] Grown io_buf to 8192\r\nI20241205 18:26:39.554211     6 dragonfly_connection.cc:121] Grown io_buf to 32768\r\nI20241205 18:26:39.922112     6 dragonfly_connection.cc:121] Grown io_buf to 65536\r\nI20241205 18:26:42.053949     6 dragonfly_connection.cc:969] Before dispatch_fb.join()\r\nI20241205 18:26:42.054078     6 dragonfly_connection.cc:971] After dispatch_fb.join()\r\nI20241205 18:26:42.056334     6 dragonfly_connection.cc:984] Error parser status 2\r\nI20241205 18:26:42.056417     6 dragonfly_connection.cc:754] Closed connection for peer id=1 addr=10.88.0.1:45752 laddr=10.88.0.43:6379 fd=676 name= tid=0 irqmatch=1 age=5 idle=0 db=0 flags=t phase=preclose lib-name= lib-ver=\r\n```",
  "created_at": "2024-12-07T19:44:03Z",
  "modified_files": [
    "helio",
    "src/facade/redis_parser.cc",
    "src/facade/redis_parser.h",
    "src/server/server_family.cc"
  ],
  "modified_test_files": [
    "src/facade/redis_parser_test.cc"
  ]
}