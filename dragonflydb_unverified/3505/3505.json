{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 3505,
  "instance_id": "dragonflydb__dragonfly-3505",
  "issue_numbers": [
    "2840"
  ],
  "base_commit": "a2e63f144c69261edffb15fd29a0ef0fb9c9deec",
  "patch": "diff --git a/src/server/debugcmd.cc b/src/server/debugcmd.cc\nindex 2f66b9a2cc1b..acdc0789b268 100644\n--- a/src/server/debugcmd.cc\n+++ b/src/server/debugcmd.cc\n@@ -373,7 +373,6 @@ void DebugCmd::Run(CmdArgList args) {\n         \"    arguments. Each descriptor is prefixed by its frequency count\",\n         \"OBJECT <key> [COMPRESS]\",\n         \"    Show low-level info about `key` and associated value.\",\n-        \"LOAD <filename>\",\n         \"RELOAD [option ...]\",\n         \"    Save the RDB on disk and reload it back to memory. Valid <option> values:\",\n         \"    * NOSAVE: the database will be loaded from an existing RDB file.\",\n@@ -431,10 +430,6 @@ void DebugCmd::Run(CmdArgList args) {\n     return Watched();\n   }\n \n-  if (subcmd == \"LOAD\" && args.size() == 2) {\n-    return Load(ArgS(args, 1));\n-  }\n-\n   if (subcmd == \"OBJECT\" && args.size() >= 2) {\n     string_view key = ArgS(args, 1);\n     args.remove_prefix(2);\n@@ -500,7 +495,19 @@ void DebugCmd::Reload(CmdArgList args) {\n   }\n \n   string last_save_file = sf_.GetLastSaveInfo().file_name;\n-  Load(last_save_file);\n+\n+  sf_.FlushAll(cntx_);\n+\n+  if (auto fut_ec = sf_.Load(last_save_file, ServerFamily::LoadExistingKeys::kFail); fut_ec) {\n+    GenericError ec = fut_ec->Get();\n+    if (ec) {\n+      string msg = ec.Format();\n+      LOG(WARNING) << \"Could not load file \" << msg;\n+      return cntx_->SendError(msg);\n+    }\n+  }\n+\n+  cntx_->SendOk();\n }\n \n void DebugCmd::Replica(CmdArgList args) {\n@@ -529,52 +536,6 @@ void DebugCmd::Replica(CmdArgList args) {\n   return cntx_->SendError(UnknownSubCmd(\"replica\", \"DEBUG\"));\n }\n \n-void DebugCmd::Load(string_view filename) {\n-  if (!ServerState::tlocal()->is_master) {\n-    return cntx_->SendError(\"Replica cannot load data\");\n-  }\n-\n-  auto new_state = sf_.service().SwitchState(GlobalState::ACTIVE, GlobalState::LOADING);\n-\n-  if (new_state != GlobalState::LOADING) {\n-    LOG(WARNING) << new_state << \" in progress, ignored\";\n-    return cntx_->SendError(\"Could not load file\");\n-  }\n-\n-  absl::Cleanup rev_state = [this] {\n-    sf_.service().SwitchState(GlobalState::LOADING, GlobalState::ACTIVE);\n-  };\n-\n-  const CommandId* cid = sf_.service().FindCmd(\"FLUSHALL\");\n-  intrusive_ptr<Transaction> flush_trans(new Transaction{cid});\n-  flush_trans->InitByArgs(cntx_->ns, 0, {});\n-  VLOG(1) << \"Performing flush\";\n-  error_code ec = sf_.Drakarys(flush_trans.get(), DbSlice::kDbAll);\n-  if (ec) {\n-    LOG(ERROR) << \"Error flushing db \" << ec.message();\n-  }\n-\n-  fs::path path(filename);\n-\n-  if (filename.empty()) {\n-    fs::path dir_path(GetFlag(FLAGS_dir));\n-    string filename = GetFlag(FLAGS_dbfilename);\n-    dir_path.append(filename);\n-    path = dir_path;\n-  }\n-\n-  if (auto fut_ec = sf_.Load(path.generic_string()); fut_ec) {\n-    GenericError ec = fut_ec->Get();\n-    if (ec) {\n-      string msg = ec.Format();\n-      LOG(WARNING) << \"Could not load file \" << msg;\n-      return cntx_->SendError(msg);\n-    }\n-  }\n-\n-  cntx_->SendOk();\n-}\n-\n optional<DebugCmd::PopulateOptions> DebugCmd::ParsePopulateArgs(CmdArgList args) {\n   if (args.size() < 2) {\n     cntx_->SendError(UnknownSubCmd(\"populate\", \"DEBUG\"));\ndiff --git a/src/server/debugcmd.h b/src/server/debugcmd.h\nindex 607e0ecb9a30..de8ead10e04f 100644\n--- a/src/server/debugcmd.h\n+++ b/src/server/debugcmd.h\n@@ -30,9 +30,6 @@ class DebugCmd {\n \n   void Run(CmdArgList args);\n \n-  // A public function that loads a snapshot.\n-  void Load(std::string_view filename);\n-\n   static void Shutdown();\n \n  private:\ndiff --git a/src/server/dflycmd.cc b/src/server/dflycmd.cc\nindex 82b15b6a95fd..e3559e084a66 100644\n--- a/src/server/dflycmd.cc\n+++ b/src/server/dflycmd.cc\n@@ -163,11 +163,33 @@ void DflyCmd::Run(CmdArgList args, ConnectionContext* cntx) {\n     return ReplicaOffset(args, cntx);\n   }\n \n-  if (sub_cmd == \"LOAD\" && args.size() == 2) {\n-    DebugCmd debug_cmd{sf_, cntx};\n-    debug_cmd.Load(ArgS(args, 1));\n-    return;\n+  if (sub_cmd == \"LOAD\") {\n+    return Load(args, cntx);\n+  }\n+\n+  if (sub_cmd == \"HELP\") {\n+    string_view help_arr[] = {\n+        \"DFLY <subcommand> [<arg> [value] [opt] ...]. Subcommands are:\",\n+        \"THREAD\",\n+        \"    Returns connection thread index and number of threads\",\n+        \"THREAD <thread-id>\",\n+        \"    Migrates connection to thread <thread-id>\",\n+        \"EXPIRE\",\n+        \"    Collects all expired items.\",\n+        \"REPLICAOFFSET\",\n+        \"    Returns LSN (log sequence number) per shard. These are the sequential ids of the \",\n+        \"    journal entry.\",\n+        \"LOAD <filename> [APPEND]\",\n+        \"    Loads <filename> RDB/DFS file into the data store.\",\n+        \"    * APPEND: Existing keys are NOT removed before loading the file, conflicting \",\n+        \"      keys (that exist in both data store and in file) are overridden.\",\n+        \"HELP\",\n+        \"    Prints this help.\",\n+    };\n+    auto* rb = static_cast<RedisReplyBuilder*>(cntx->reply_builder());\n+    return rb->SendSimpleStrArr(help_arr);\n   }\n+\n   cntx->SendError(kSyntaxErr);\n }\n \n@@ -500,6 +522,41 @@ void DflyCmd::ReplicaOffset(CmdArgList args, ConnectionContext* cntx) {\n   }\n }\n \n+void DflyCmd::Load(CmdArgList args, ConnectionContext* cntx) {\n+  CmdArgParser parser{args};\n+  parser.ExpectTag(\"LOAD\");\n+  string_view filename = parser.Next();\n+  ServerFamily::LoadExistingKeys existing_keys = ServerFamily::LoadExistingKeys::kFail;\n+\n+  if (parser.HasNext()) {\n+    parser.ExpectTag(\"APPEND\");\n+    existing_keys = ServerFamily::LoadExistingKeys::kOverride;\n+  }\n+\n+  if (parser.HasNext()) {\n+    parser.Error();\n+  }\n+\n+  if (parser.HasError()) {\n+    return cntx->SendError(kSyntaxErr);\n+  }\n+\n+  if (existing_keys == ServerFamily::LoadExistingKeys::kFail) {\n+    sf_->FlushAll(cntx);\n+  }\n+\n+  if (auto fut_ec = sf_->Load(filename, existing_keys); fut_ec) {\n+    GenericError ec = fut_ec->Get();\n+    if (ec) {\n+      string msg = ec.Format();\n+      LOG(WARNING) << \"Could not load file \" << msg;\n+      return cntx->SendError(msg);\n+    }\n+  }\n+\n+  cntx->SendOk();\n+}\n+\n OpStatus DflyCmd::StartFullSyncInThread(FlowInfo* flow, Context* cntx, EngineShard* shard) {\n   DCHECK(!flow->full_sync_fb.IsJoinable());\n   DCHECK(shard);\ndiff --git a/src/server/dflycmd.h b/src/server/dflycmd.h\nindex 0112871a3a89..6f52dff733fb 100644\n--- a/src/server/dflycmd.h\n+++ b/src/server/dflycmd.h\n@@ -199,6 +199,8 @@ class DflyCmd {\n   // Return journal records num sent for each flow of replication.\n   void ReplicaOffset(CmdArgList args, ConnectionContext* cntx);\n \n+  void Load(CmdArgList args, ConnectionContext* cntx);\n+\n   // Start full sync in thread. Start FullSyncFb. Called for each flow.\n   facade::OpStatus StartFullSyncInThread(FlowInfo* flow, Context* cntx, EngineShard* shard);\n \ndiff --git a/src/server/rdb_load.cc b/src/server/rdb_load.cc\nindex 926f16af5d6c..ad1f0a859cda 100644\n--- a/src/server/rdb_load.cc\n+++ b/src/server/rdb_load.cc\n@@ -35,6 +35,8 @@ extern \"C\" {\n #include \"core/sorted_map.h\"\n #include \"core/string_map.h\"\n #include \"core/string_set.h\"\n+#include \"server/cluster/cluster_defs.h\"\n+#include \"server/cluster/cluster_family.h\"\n #include \"server/engine_shard_set.h\"\n #include \"server/error.h\"\n #include \"server/hset_family.h\"\n@@ -2481,7 +2483,7 @@ void RdbLoader::LoadItemsBuffer(DbIndex db_ind, const ItemsBuf& ib) {\n \n     auto& res = *op_res;\n     res.it->first.SetSticky(item->is_sticky);\n-    if (!res.is_new) {\n+    if (!override_existing_keys_ && !res.is_new) {\n       LOG(WARNING) << \"RDB has duplicated key '\" << item->key << \"' in DB \" << db_ind;\n     }\n \n@@ -2520,6 +2522,13 @@ error_code RdbLoader::LoadKeyValPair(int type, ObjSettings* settings) {\n     return ec;\n   }\n \n+  if (!load_unowned_slots_ && cluster::IsClusterEnabled()) {\n+    const cluster::ClusterConfig* cluster_config = cluster::ClusterFamily::cluster_config();\n+    if (cluster_config != nullptr && !cluster_config->IsMySlot(item->key)) {\n+      return kOk;  // Ignoring item\n+    }\n+  }\n+\n   /* Check if the key already expired. This function is used when loading\n    * an RDB file from disk, either at startup, or when an RDB was\n    * received from the master. In the latter case, the master is\ndiff --git a/src/server/rdb_load.h b/src/server/rdb_load.h\nindex 60fa0e1940fe..3eafe91e1f73 100644\n--- a/src/server/rdb_load.h\n+++ b/src/server/rdb_load.h\n@@ -181,7 +181,16 @@ class RdbLoader : protected RdbLoaderBase {\n \n   ~RdbLoader();\n \n+  void SetOverrideExistingKeys(bool override) {\n+    override_existing_keys_ = override;\n+  }\n+\n+  void SetLoadUnownedSlots(bool load_unowned) {\n+    load_unowned_slots_ = load_unowned;\n+  }\n+\n   std::error_code Load(::io::Source* src);\n+\n   void set_source_limit(size_t n) {\n     source_limit_ = n;\n   }\n@@ -273,6 +282,8 @@ class RdbLoader : protected RdbLoaderBase {\n \n  private:\n   Service* service_;\n+  bool override_existing_keys_ = false;\n+  bool load_unowned_slots_ = false;\n   ScriptMgr* script_mgr_;\n   std::vector<ItemsBuf> shard_buf_;\n \ndiff --git a/src/server/replica.cc b/src/server/replica.cc\nindex e0af2732d9db..426df939af8f 100644\n--- a/src/server/replica.cc\n+++ b/src/server/replica.cc\n@@ -425,6 +425,7 @@ error_code Replica::InitiatePSync() {\n     }\n \n     RdbLoader loader(NULL);\n+    loader.SetLoadUnownedSlots(true);\n     loader.set_source_limit(snapshot_size);\n     // TODO: to allow registering callbacks within loader to send '\\n' pings back to master.\n     // Also to allow updating last_io_time_.\n@@ -935,6 +936,7 @@ DflyShardReplica::DflyShardReplica(ServerContext server_context, MasterContext m\n       flow_id_(flow_id) {\n   executor_ = std::make_unique<JournalExecutor>(service);\n   rdb_loader_ = std::make_unique<RdbLoader>(&service_);\n+  rdb_loader_->SetLoadUnownedSlots(true);\n }\n \n DflyShardReplica::~DflyShardReplica() {\ndiff --git a/src/server/server_family.cc b/src/server/server_family.cc\nindex 5ae91b35f83c..30296f329e84 100644\n--- a/src/server/server_family.cc\n+++ b/src/server/server_family.cc\n@@ -874,7 +874,7 @@ void ServerFamily::LoadFromSnapshot() {\n   if (load_path_result) {\n     const std::string load_path = *load_path_result;\n     if (!load_path.empty()) {\n-      load_result_ = Load(load_path);\n+      load_result_ = Load(load_path, LoadExistingKeys::kFail);\n     }\n   } else {\n     if (std::error_code(load_path_result.error()) == std::errc::no_such_file_or_directory) {\n@@ -935,13 +935,40 @@ struct AggregateLoadResult {\n   std::atomic<size_t> keys_read;\n };\n \n+void ServerFamily::FlushAll(ConnectionContext* cntx) {\n+  const CommandId* cid = service_.FindCmd(\"FLUSHALL\");\n+  boost::intrusive_ptr<Transaction> flush_trans(new Transaction{cid});\n+  flush_trans->InitByArgs(cntx->ns, 0, {});\n+  VLOG(1) << \"Performing flush\";\n+  error_code ec = Drakarys(flush_trans.get(), DbSlice::kDbAll);\n+  if (ec) {\n+    LOG(ERROR) << \"Error flushing db \" << ec.message();\n+  }\n+}\n+\n // Load starts as many fibers as there are files to load each one separately.\n // It starts one more fiber that waits for all load fibers to finish and returns the first\n // error (if any occured) with a future.\n-std::optional<fb2::Future<GenericError>> ServerFamily::Load(const std::string& load_path) {\n+std::optional<fb2::Future<GenericError>> ServerFamily::Load(string_view load_path,\n+                                                            LoadExistingKeys existing_keys) {\n+  fs::path path(load_path);\n+\n+  if (load_path.empty()) {\n+    fs::path dir_path(GetFlag(FLAGS_dir));\n+    string filename = GetFlag(FLAGS_dbfilename);\n+    dir_path.append(filename);\n+    path = dir_path;\n+  }\n+\n   DCHECK_GT(shard_count(), 0u);\n \n-  auto paths_result = snapshot_storage_->LoadPaths(load_path);\n+  if (ServerState::tlocal() && !ServerState::tlocal()->is_master) {\n+    fb2::Future<GenericError> future;\n+    future.Resolve(string(\"Replica cannot load data\"));\n+    return future;\n+  }\n+\n+  auto paths_result = snapshot_storage_->LoadPaths(path.generic_string());\n   if (!paths_result) {\n     LOG(ERROR) << \"Failed to load snapshot: \" << paths_result.error().Format();\n \n@@ -952,7 +979,7 @@ std::optional<fb2::Future<GenericError>> ServerFamily::Load(const std::string& l\n \n   std::vector<std::string> paths = *paths_result;\n \n-  LOG(INFO) << \"Loading \" << load_path;\n+  LOG(INFO) << \"Loading \" << path.generic_string();\n \n   auto new_state = service_.SwitchState(GlobalState::ACTIVE, GlobalState::LOADING);\n   if (new_state != GlobalState::LOADING) {\n@@ -979,8 +1006,8 @@ std::optional<fb2::Future<GenericError>> ServerFamily::Load(const std::string& l\n       proactor = pool.GetNextProactor();\n     }\n \n-    auto load_fiber = [this, aggregated_result, path = std::move(path)]() {\n-      auto load_result = LoadRdb(path);\n+    auto load_fiber = [this, aggregated_result, existing_keys, path = std::move(path)]() {\n+      auto load_result = LoadRdb(path, existing_keys);\n       if (load_result.has_value())\n         aggregated_result->keys_read.fetch_add(*load_result);\n       else\n@@ -1040,13 +1067,18 @@ void ServerFamily::SnapshotScheduling() {\n   }\n }\n \n-io::Result<size_t> ServerFamily::LoadRdb(const std::string& rdb_file) {\n+io::Result<size_t> ServerFamily::LoadRdb(const std::string& rdb_file,\n+                                         LoadExistingKeys existing_keys) {\n   error_code ec;\n   io::ReadonlyFileOrError res = snapshot_storage_->OpenReadFile(rdb_file);\n   if (res) {\n     io::FileSource fs(*res);\n \n     RdbLoader loader{&service_};\n+    if (existing_keys == LoadExistingKeys::kOverride) {\n+      loader.SetOverrideExistingKeys(true);\n+    }\n+\n     ec = loader.Load(&fs);\n     if (!ec) {\n       VLOG(1) << \"Done loading RDB from \" << rdb_file << \", keys loaded: \" << loader.keys_loaded();\ndiff --git a/src/server/server_family.h b/src/server/server_family.h\nindex 388613a283db..627a901cc5ec 100644\n--- a/src/server/server_family.h\n+++ b/src/server/server_family.h\n@@ -196,9 +196,13 @@ class ServerFamily {\n \n   LastSaveInfo GetLastSaveInfo() const;\n \n+  void FlushAll(ConnectionContext* cntx);\n+\n   // Load snapshot from file (.rdb file or summary.dfs file) and return\n   // future with error_code.\n-  std::optional<util::fb2::Future<GenericError>> Load(const std::string& file_name);\n+  enum class LoadExistingKeys { kFail, kOverride };\n+  std::optional<util::fb2::Future<GenericError>> Load(std::string_view file_name,\n+                                                      LoadExistingKeys existing_keys);\n \n   bool TEST_IsSaving() const;\n \n@@ -286,7 +290,7 @@ class ServerFamily {\n   void ReplicaOfInternal(CmdArgList args, ConnectionContext* cntx, ActionOnConnectionFail on_error);\n \n   // Returns the number of loaded keys if successful.\n-  io::Result<size_t> LoadRdb(const std::string& rdb_file);\n+  io::Result<size_t> LoadRdb(const std::string& rdb_file, LoadExistingKeys existing_keys);\n \n   void SnapshotScheduling();\n \n",
  "test_patch": "diff --git a/src/server/cluster/cluster_family_test.cc b/src/server/cluster/cluster_family_test.cc\nindex feaa1d6d5875..a2489e1e948b 100644\n--- a/src/server/cluster/cluster_family_test.cc\n+++ b/src/server/cluster/cluster_family_test.cc\n@@ -597,7 +597,7 @@ TEST_F(ClusterFamilyTest, ClusterFirstConfigCallDropsEntriesNotOwnedByNode) {\n   EXPECT_EQ(Run({\"save\", \"df\"}), \"OK\");\n \n   auto save_info = service_->server_family().GetLastSaveInfo();\n-  EXPECT_EQ(Run({\"debug\", \"load\", save_info.file_name}), \"OK\");\n+  EXPECT_EQ(Run({\"dfly\", \"load\", save_info.file_name}), \"OK\");\n   EXPECT_EQ(CheckedInt({\"dbsize\"}), 50000);\n \n   ConfigSingleNodeCluster(\"abcd1234\");\ndiff --git a/src/server/rdb_test.cc b/src/server/rdb_test.cc\nindex b56a6162d9f9..1c4863d135b7 100644\n--- a/src/server/rdb_test.cc\n+++ b/src/server/rdb_test.cc\n@@ -167,7 +167,7 @@ TEST_F(RdbTest, ComressionModeSaveDragonflyAndReload) {\n     ASSERT_EQ(resp, \"OK\");\n \n     auto save_info = service_->server_family().GetLastSaveInfo();\n-    resp = Run({\"debug\", \"load\", save_info.file_name});\n+    resp = Run({\"dfly\", \"load\", save_info.file_name});\n     ASSERT_EQ(resp, \"OK\");\n     ASSERT_EQ(50000, CheckedInt({\"dbsize\"}));\n   }\n@@ -182,7 +182,7 @@ TEST_F(RdbTest, RdbLoaderOnReadCompressedDataShouldNotEnterEnsureReadFlow) {\n   ASSERT_EQ(resp, \"OK\");\n \n   auto save_info = service_->server_family().GetLastSaveInfo();\n-  resp = Run({\"debug\", \"load\", save_info.file_name});\n+  resp = Run({\"dfly\", \"load\", save_info.file_name});\n   ASSERT_EQ(resp, \"OK\");\n }\n \n@@ -265,7 +265,7 @@ TEST_F(RdbTest, ReloadExpired) {\n   ASSERT_EQ(resp, \"OK\");\n   auto save_info = service_->server_family().GetLastSaveInfo();\n   AdvanceTime(2000);\n-  resp = Run({\"debug\", \"load\", save_info.file_name});\n+  resp = Run({\"dfly\", \"load\", save_info.file_name});\n   ASSERT_EQ(resp, \"OK\");\n   resp = Run({\"get\", \"key\"});\n   ASSERT_THAT(resp, ArgType(RespExpr::NIL));\n@@ -543,4 +543,26 @@ TEST_F(RdbTest, SBF) {\n   EXPECT_THAT(Run({\"BF.EXISTS\", \"k\", \"1\"}), IntArg(1));\n }\n \n+TEST_F(RdbTest, DflyLoadAppend) {\n+  // Create an RDB with (k1,1) value in it saved as `filename`\n+  EXPECT_EQ(Run({\"set\", \"k1\", \"1\"}), \"OK\");\n+  EXPECT_EQ(Run({\"save\", \"df\"}), \"OK\");\n+  string filename = service_->server_family().GetLastSaveInfo().file_name;\n+\n+  // Without APPEND option - db should be flushed\n+  EXPECT_EQ(Run({\"set\", \"k1\", \"TO-BE-FLUSHED\"}), \"OK\");\n+  EXPECT_EQ(Run({\"set\", \"k2\", \"TO-BE-FLUSHED\"}), \"OK\");\n+  EXPECT_EQ(Run({\"dfly\", \"load\", filename}), \"OK\");\n+  EXPECT_THAT(Run({\"dbsize\"}), IntArg(1));\n+  EXPECT_EQ(Run({\"get\", \"k1\"}), \"1\");\n+\n+  // With APPEND option - db shouldn't be flushed, but k1 should be overridden\n+  EXPECT_EQ(Run({\"set\", \"k1\", \"TO-BE-OVERRIDDEN\"}), \"OK\");\n+  EXPECT_EQ(Run({\"set\", \"k2\", \"2\"}), \"OK\");\n+  EXPECT_EQ(Run({\"dfly\", \"load\", filename, \"append\"}), \"OK\");\n+  EXPECT_THAT(Run({\"dbsize\"}), IntArg(2));\n+  EXPECT_EQ(Run({\"get\", \"k1\"}), \"1\");\n+  EXPECT_EQ(Run({\"get\", \"k2\"}), \"2\");\n+}\n+\n }  // namespace dfly\ndiff --git a/tests/dragonfly/snapshot_test.py b/tests/dragonfly/snapshot_test.py\nindex 46e6a1ad35e2..f558bfd8976a 100644\n--- a/tests/dragonfly/snapshot_test.py\n+++ b/tests/dragonfly/snapshot_test.py\n@@ -57,7 +57,7 @@ async def test_consistency(df_factory, format: str, seeder_opts: dict):\n     await async_client.execute_command(\"SAVE\", format)\n     assert await async_client.flushall()\n     await async_client.execute_command(\n-        \"DEBUG\",\n+        \"DFLY\",\n         \"LOAD\",\n         f\"{dbfilename}.rdb\" if format == \"RDB\" else f\"{dbfilename}-summary.dfs\",\n     )\n@@ -85,7 +85,7 @@ async def test_multidb(df_factory, format: str):\n     await async_client.execute_command(\"SAVE\", format)\n     assert await async_client.flushall()\n     await async_client.execute_command(\n-        \"DEBUG\",\n+        \"DFLY\",\n         \"LOAD\",\n         f\"{dbfilename}.rdb\" if format == \"RDB\" else f\"{dbfilename}-summary.dfs\",\n     )\n@@ -271,7 +271,7 @@ async def test_s3_snapshot(self, async_client):\n         await async_client.execute_command(\"SAVE DF snapshot\")\n         assert await async_client.flushall()\n         await async_client.execute_command(\n-            \"DEBUG LOAD \"\n+            \"DFLY LOAD \"\n             + os.environ[\"DRAGONFLY_S3_BUCKET\"]\n             + str(self.tmp_dir)\n             + \"/snapshot-summary.dfs\"\n@@ -451,7 +451,7 @@ async def test_tiered_entries(async_client: aioredis.Redis):\n     await async_client.execute_command(\"SAVE\", \"DF\")\n     assert await async_client.flushall()\n     await async_client.execute_command(\n-        \"DEBUG\",\n+        \"DFLY\",\n         \"LOAD\",\n         \"tiered-entries-summary.dfs\",\n     )\n@@ -488,7 +488,7 @@ async def test_tiered_entries_throttle(async_client: aioredis.Redis):\n \n     load_task = asyncio.create_task(\n         async_client.execute_command(\n-            \"DEBUG\",\n+            \"DFLY\",\n             \"LOAD\",\n             \"tiered-entries-summary.dfs\",\n         )\n",
  "problem_statement": "Add support loading multiple rdb files\nDFLY LOAD [NOFLUSH] filename\n",
  "hints_text": "Was it done @adiholden ?\nnot yet @romange ",
  "created_at": "2024-08-13T12:58:30Z",
  "modified_files": [
    "src/server/debugcmd.cc",
    "src/server/debugcmd.h",
    "src/server/dflycmd.cc",
    "src/server/dflycmd.h",
    "src/server/rdb_load.cc",
    "src/server/rdb_load.h",
    "src/server/replica.cc",
    "src/server/server_family.cc",
    "src/server/server_family.h"
  ],
  "modified_test_files": [
    "src/server/cluster/cluster_family_test.cc",
    "src/server/rdb_test.cc",
    "tests/dragonfly/snapshot_test.py"
  ]
}