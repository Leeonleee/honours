{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 4448,
  "instance_id": "dragonflydb__dragonfly-4448",
  "issue_numbers": [
    "4202"
  ],
  "base_commit": "80e4012ab1d882bcfce124477581c67ecb34e373",
  "patch": "diff --git a/src/facade/cmd_arg_parser.h b/src/facade/cmd_arg_parser.h\nindex 645453915d7a..8c3b0c01fb9f 100644\n--- a/src/facade/cmd_arg_parser.h\n+++ b/src/facade/cmd_arg_parser.h\n@@ -174,6 +174,10 @@ struct CmdArgParser {\n     return cur_i_ + i <= args_.size() && !error_;\n   }\n \n+  size_t GetCurrentIndex() const {\n+    return cur_i_;\n+  }\n+\n  private:\n   template <class T, class... Cases>\n   std::optional<std::decay_t<T>> MapImpl(std::string_view arg, std::string_view tag, T&& value,\ndiff --git a/src/redis/stream.h b/src/redis/stream.h\nindex 9e03540ea155..daa6809d69c9 100644\n--- a/src/redis/stream.h\n+++ b/src/redis/stream.h\n@@ -125,6 +125,9 @@ typedef struct {\n /* Prototypes of exported APIs. */\n // struct client;\n \n+// Use this to in streamTrimByLength and streamTrimByID\n+#define NO_TRIM_LIMIT (-1)\n+\n /* Flags for streamCreateConsumer */\n #define SCC_DEFAULT       0\n #define SCC_NO_NOTIFY     (1<<0) /* Do not notify key space if consumer created */\n@@ -163,9 +166,12 @@ int streamAppendItem(stream *s, robj **argv, int64_t numfields, streamID *added_\n int streamDeleteItem(stream *s, streamID *id);\n void streamGetEdgeID(stream *s, int first, int skip_tombstones, streamID *edge_id);\n long long streamEstimateDistanceFromFirstEverEntry(stream *s, streamID *id);\n-int64_t streamTrim(stream *s, streamAddTrimArgs *args);\n-int64_t streamTrimByLength(stream *s, long long maxlen, int approx);\n-int64_t streamTrimByID(stream *s, streamID minid, int approx);\n+int64_t streamTrim(stream *s, streamAddTrimArgs *args, streamID *last_id);\n+\n+// If you don't want to specify a limit, use NO_TRIM_LIMIT\n+int64_t streamTrimByLength(stream *s, long long maxlen, int approx, streamID *last_id, long long limit);\n+int64_t streamTrimByID(stream *s, streamID minid, int approx, streamID *last_id, long long limit);\n+\n void streamFreeCG(streamCG *cg);\n void streamDelConsumer(streamCG *cg, streamConsumer *consumer);\n void streamLastValidID(stream *s, streamID *maxid);\ndiff --git a/src/redis/t_stream.c b/src/redis/t_stream.c\nindex 27a10b10021f..64c5892c582e 100644\n--- a/src/redis/t_stream.c\n+++ b/src/redis/t_stream.c\n@@ -300,7 +300,7 @@ void streamGetEdgeID(stream *s, int first, int skip_tombstones, streamID *edge_i\n  * that should be trimmed, there is a chance we will still have entries with\n  * IDs < 'id' (or number of elements >= maxlen in case of MAXLEN).\n  */\n-int64_t streamTrim(stream *s, streamAddTrimArgs *args) {\n+int64_t streamTrim(stream *s, streamAddTrimArgs *args, streamID *last_id) {\n     size_t maxlen = args->maxlen;\n     streamID *id = &args->minid;\n     int approx = args->approx_trim;\n@@ -315,6 +315,8 @@ int64_t streamTrim(stream *s, streamAddTrimArgs *args) {\n     raxSeek(&ri,\"^\",NULL,0);\n \n     int64_t deleted = 0;\n+    streamID last_deleted_id = {0, 0}; // Initialize last deleted ID\n+    \n     while (raxNext(&ri)) {\n         if (trim_strategy == TRIM_STRATEGY_MAXLEN && s->length <= maxlen)\n             break;\n@@ -331,16 +333,24 @@ int64_t streamTrim(stream *s, streamAddTrimArgs *args) {\n         streamID master_id = {0}; /* For MINID */\n         if (trim_strategy == TRIM_STRATEGY_MAXLEN) {\n             remove_node = s->length - entries >= maxlen;\n+            if (remove_node) {\n+                streamDecodeID(ri.key, &master_id);\n+                // Write last ID to last_deleted_id\n+                lpGetEdgeStreamID(lp, 0, &master_id, &last_deleted_id);\n+            }\n         } else {\n             /* Read the master ID from the radix tree key. */\n             streamDecodeID(ri.key, &master_id);\n-\n+            \n             /* Read last ID. */\n             streamID last_id = {0, 0};\n             lpGetEdgeStreamID(lp, 0, &master_id, &last_id);\n \n             /* We can remove the entire node id its last ID < 'id' */\n             remove_node = streamCompareID(&last_id, id) < 0;\n+            if (remove_node) {\n+                last_deleted_id = last_id;\n+            }\n         }\n \n         if (remove_node) {\n@@ -356,6 +366,10 @@ int64_t streamTrim(stream *s, streamAddTrimArgs *args) {\n          * stop here. */\n         if (approx) break;\n \n+        if (trim_strategy == TRIM_STRATEGY_MAXLEN) {\n+            streamDecodeID(ri.key, &master_id);\n+        }\n+\n         /* Now we have to trim entries from within 'lp' */\n         int64_t deleted_from_lp = 0;\n \n@@ -386,11 +400,7 @@ int64_t streamTrim(stream *s, streamAddTrimArgs *args) {\n             int64_t seq_delta = lpGetInteger(p);\n             p = lpNext(lp, p); /* Skip ID seq delta */\n \n-            streamID currid = {0}; /* For MINID */\n-            if (trim_strategy == TRIM_STRATEGY_MINID) {\n-                currid.ms = master_id.ms + ms_delta;\n-                currid.seq = master_id.seq + seq_delta;\n-            }\n+            streamID currid = {master_id.ms + ms_delta, master_id.seq + seq_delta};\n \n             int stop;\n             if (trim_strategy == TRIM_STRATEGY_MAXLEN) {\n@@ -422,6 +432,7 @@ int64_t streamTrim(stream *s, streamAddTrimArgs *args) {\n                 deleted_from_lp++;\n                 s->length--;\n                 p = lp + delta;\n+                last_deleted_id = currid;\n             }\n         }\n         deleted += deleted_from_lp;\n@@ -458,29 +469,42 @@ int64_t streamTrim(stream *s, streamAddTrimArgs *args) {\n         streamGetEdgeID(s,1,1,&s->first_id);\n     }\n \n+    /* Set the last deleted ID, if applicable. */\n+    if (last_id) {\n+        *last_id = last_deleted_id;\n+    }\n+\n     return deleted;\n }\n \n /* Trims a stream by length. Returns the number of deleted items. */\n-int64_t streamTrimByLength(stream *s, long long maxlen, int approx) {\n+int64_t streamTrimByLength(stream *s, long long maxlen, int approx, streamID *last_id, long long limit) {\n+    if (limit == NO_TRIM_LIMIT) {\n+        limit = approx ? 100 * server.stream_node_max_entries : 0;\n+    }\n+    \n     streamAddTrimArgs args = {\n         .trim_strategy = TRIM_STRATEGY_MAXLEN,\n         .approx_trim = approx,\n-        .limit = approx ? 100 * server.stream_node_max_entries : 0,\n+        .limit = limit,\n         .maxlen = maxlen\n     };\n-    return streamTrim(s, &args);\n+    return streamTrim(s, &args, last_id);\n }\n \n /* Trims a stream by minimum ID. Returns the number of deleted items. */\n-int64_t streamTrimByID(stream *s, streamID minid, int approx) {\n+int64_t streamTrimByID(stream *s, streamID minid, int approx, streamID *last_id, long long limit) {\n+    if (limit == NO_TRIM_LIMIT) {\n+        limit = approx ? 100 * server.stream_node_max_entries : 0;\n+    }\n+    \n     streamAddTrimArgs args = {\n         .trim_strategy = TRIM_STRATEGY_MINID,\n         .approx_trim = approx,\n-        .limit = approx ? 100 * server.stream_node_max_entries : 0,\n+        .limit = limit,\n         .minid = minid\n     };\n-    return streamTrim(s, &args);\n+    return streamTrim(s, &args, last_id);\n }\n \n /* Initialize the stream iterator, so that we can call iterating functions\ndiff --git a/src/server/stream_family.cc b/src/server/stream_family.cc\nindex c64ddde04438..d02e7e207953 100644\n--- a/src/server/stream_family.cc\n+++ b/src/server/stream_family.cc\n@@ -48,6 +48,14 @@ struct Record {\n \n using RecordVec = vector<Record>;\n \n+using nonstd::make_unexpected;\n+\n+template <typename T> using ParseResult = io::Result<T, ErrorReply>;\n+\n+nonstd::unexpected_type<ErrorReply> CreateSyntaxError(std::string_view message) {\n+  return make_unexpected(ErrorReply{message, kSyntaxErrType});\n+}\n+\n struct ParsedStreamId {\n   streamID val;\n \n@@ -66,25 +74,43 @@ struct RangeId {\n   bool exclude = false;\n };\n \n-enum class TrimStrategy {\n-  kNone = TRIM_STRATEGY_NONE,\n-  kMaxLen = TRIM_STRATEGY_MAXLEN,\n-  kMinId = TRIM_STRATEGY_MINID,\n-};\n+struct TrimOpts {\n+  bool IsMaxLen() const {\n+    return std::holds_alternative<uint32_t>(length_or_id);\n+  }\n \n-struct AddTrimOpts {\n-  string_view key;\n-  ParsedStreamId minid;\n-  uint32_t max_len = kuint32max;\n-  uint32_t limit = 0;\n-  TrimStrategy trim_strategy = TrimStrategy::kNone;\n-  bool trim_approx = false;\n+  uint32_t AsMaxLen() const {\n+    return std::get<uint32_t>(length_or_id);\n+  }\n \n-  // XADD only.\n+  const ParsedStreamId& AsMinId() const {\n+    return std::get<ParsedStreamId>(length_or_id);\n+  }\n+\n+  // First is MaxLen, second is MinId.\n+  std::variant<uint32_t, ParsedStreamId> length_or_id;\n+  int32_t limit = NO_TRIM_LIMIT;\n+  bool approx = false;\n+};\n+\n+struct AddOpts {\n+  std::optional<TrimOpts> trim_opts;\n   ParsedStreamId parsed_id;\n   bool no_mkstream = false;\n };\n \n+/* Used to journal the XADD command.\n+   The actual stream ID assigned after adding may differ from the one specified in the command.\n+   So, for the replica, we need to specify the exact ID that was actually added. */\n+struct AddArgsJournaler {\n+  void SetStreamId(std::string_view stream_id) {\n+    add_args[stream_id_index] = stream_id;\n+  }\n+\n+  CmdArgVec add_args;\n+  size_t stream_id_index;\n+};\n+\n struct NACKInfo {\n   streamID pel_id;\n   string consumer_name;\n@@ -166,6 +192,8 @@ struct ReadOpts {\n   bool noack = false;\n };\n \n+const char kTrimOptionConflictErr[] =\n+    \"MAXLEN and MINID options at the same time are not compatible\";\n const char kInvalidStreamId[] = \"Invalid stream ID specified as stream command argument\";\n const char kXGroupKeyNotFound[] =\n     \"The XGROUP subcommand requires the key to exist. \"\n@@ -599,45 +627,44 @@ streamNACK* StreamCreateNACK(streamConsumer* consumer, uint64_t now_ms) {\n   return nack;\n }\n \n-int StreamTrim(const AddTrimOpts& opts, stream* s) {\n-  if (!opts.limit) {\n-    if (opts.trim_strategy == TrimStrategy::kMaxLen) {\n-      /* Notify xtrim event if needed. */\n-      return streamTrimByLength(s, opts.max_len, opts.trim_approx);\n-      // TODO: when replicating, we should propagate it as exact limit in case of trimming.\n-    } else if (opts.trim_strategy == TrimStrategy::kMinId) {\n-      return streamTrimByID(s, opts.minid.val, opts.trim_approx);\n-    }\n-  } else {\n-    streamAddTrimArgs trim_args = {};\n-    trim_args.trim_strategy = static_cast<int>(opts.trim_strategy);\n-    trim_args.approx_trim = opts.trim_approx;\n-    trim_args.limit = opts.limit;\n+std::string StreamsIdToString(streamID id) {\n+  return absl::StrCat(id.ms, \"-\", id.seq);\n+}\n \n-    if (opts.trim_strategy == TrimStrategy::kMaxLen) {\n-      trim_args.maxlen = opts.max_len;\n-    } else if (opts.trim_strategy == TrimStrategy::kMinId) {\n-      trim_args.minid = opts.minid.val;\n+/* The first value represents the number of deleted items, and the second is the last trimmed ID. */\n+std::pair<int64_t, streamID> TrimStream(const TrimOpts& opts, stream* s) {\n+  streamID last_id = {0, 0};\n+\n+  auto trim = [&]() {\n+    if (opts.IsMaxLen()) {\n+      return streamTrimByLength(s, opts.AsMaxLen(), opts.approx, &last_id, opts.limit);\n+    } else {\n+      const auto& min_id = opts.AsMinId().val;\n+      return streamTrimByID(s, min_id, opts.approx, &last_id, opts.limit);\n     }\n-    return streamTrim(s, &trim_args);\n-  }\n+  };\n \n-  return 0;\n+  const int64_t deleted_items_number = trim();\n+  return {deleted_items_number, last_id};\n+}\n+\n+bool JournalAsMinId(const TrimOpts& opts) {\n+  return opts.approx || opts.IsMaxLen();\n }\n \n-OpResult<streamID> OpAdd(const OpArgs& op_args, const AddTrimOpts& opts, CmdArgList args) {\n+OpResult<streamID> OpAdd(const OpArgs& op_args, string_view key, const AddOpts& opts,\n+                         CmdArgList args, AddArgsJournaler journaler) {\n   DCHECK(!args.empty() && args.size() % 2 == 0);\n+\n   auto& db_slice = op_args.GetDbSlice();\n-  DbSlice::AddOrFindResult add_res;\n \n+  DbSlice::AddOrFindResult add_res;\n   if (opts.no_mkstream) {\n-    auto res_it = db_slice.FindMutable(op_args.db_cntx, opts.key, OBJ_STREAM);\n-    if (!res_it) {\n-      return res_it.status();\n-    }\n+    auto res_it = db_slice.FindMutable(op_args.db_cntx, key, OBJ_STREAM);\n+    RETURN_ON_BAD_STATUS(res_it);\n     add_res = std::move(*res_it);\n   } else {\n-    auto op_res = db_slice.AddOrFind(op_args.db_cntx, opts.key);\n+    auto op_res = db_slice.AddOrFind(op_args.db_cntx, key);\n     RETURN_ON_BAD_STATUS(op_res);\n     add_res = std::move(*op_res);\n   }\n@@ -670,13 +697,42 @@ OpResult<streamID> OpAdd(const OpArgs& op_args, const AddTrimOpts& opts, CmdArgL\n     return OpStatus::OUT_OF_MEMORY;\n   }\n \n-  StreamTrim(opts, stream_inst);\n+  std::pair<int64_t, streamID> trim_result{};\n+  if (opts.trim_opts) {\n+    trim_result = TrimStream(opts.trim_opts.value(), stream_inst);\n+  }\n \n   mem_tracker.UpdateStreamSize(it->second);\n \n+  if (op_args.shard->journal()) {\n+    std::string result_id_as_string = StreamsIdToString(result_id);\n+\n+    if (opts.trim_opts && JournalAsMinId(opts.trim_opts.value())) {\n+      // We need to set exact MinId in the journal.\n+      std::string last_id = StreamsIdToString(trim_result.second);\n+      CmdArgVec journal_args = {key, \"MINID\"sv, \"=\"sv, last_id};\n+      journal_args.reserve(args.size() + 4);\n+\n+      if (opts.no_mkstream) {\n+        journal_args.push_back(\"NOMKSTREAM\"sv);\n+      }\n+\n+      journal_args.push_back(result_id_as_string);\n+\n+      for (size_t i = 0; i < args.size(); i++) {\n+        journal_args.push_back(args[i]);\n+      }\n+\n+      RecordJournal(op_args, \"XADD\"sv, journal_args);\n+    } else {\n+      journaler.SetStreamId(result_id_as_string);\n+      RecordJournal(op_args, \"XADD\"sv, journaler.add_args);\n+    }\n+  }\n+\n   auto blocking_controller = op_args.db_cntx.ns->GetBlockingController(op_args.shard->shard_id());\n   if (blocking_controller) {\n-    blocking_controller->AwakeWatched(op_args.db_cntx.db_index, opts.key);\n+    blocking_controller->AwakeWatched(op_args.db_cntx.db_index, key);\n   }\n \n   return result_id;\n@@ -1934,9 +1990,10 @@ void XGroupHelp(CmdArgList args, const CommandContext& cmd_cntx) {\n   return rb->SendSimpleStrArr(help_arr);\n }\n \n-OpResult<int64_t> OpTrim(const OpArgs& op_args, const AddTrimOpts& opts) {\n+OpResult<int64_t> OpTrim(const OpArgs& op_args, std::string_view key, const TrimOpts& opts,\n+                         bool journal_as_minid) {\n   auto& db_slice = op_args.GetDbSlice();\n-  auto res_it = db_slice.FindMutable(op_args.db_cntx, opts.key, OBJ_STREAM);\n+  auto res_it = db_slice.FindMutable(op_args.db_cntx, key, OBJ_STREAM);\n   if (!res_it) {\n     if (res_it.status() == OpStatus::KEY_NOTFOUND) {\n       return 0;\n@@ -1949,77 +2006,93 @@ OpResult<int64_t> OpTrim(const OpArgs& op_args, const AddTrimOpts& opts) {\n   CompactObj& cobj = res_it->it->second;\n   stream* s = (stream*)cobj.RObjPtr();\n \n-  auto res = StreamTrim(opts, s);\n+  auto res = TrimStream(opts, s);\n \n   mem_tracker.UpdateStreamSize(cobj);\n-  return res;\n+\n+  if (op_args.shard->journal() && journal_as_minid) {\n+    std::string last_id = StreamsIdToString(res.second);\n+    RecordJournal(op_args, \"XTRIM\"sv, ArgSlice{key, \"MINID\"sv, \"=\"sv, last_id});\n+  }\n+\n+  return res.first;\n }\n \n-optional<pair<AddTrimOpts, unsigned>> ParseAddOrTrimArgsOrReply(CmdArgList args, bool is_xadd,\n-                                                                SinkReplyBuilder* builder) {\n-  AddTrimOpts opts;\n-  opts.key = ArgS(args, 0);\n+ParseResult<TrimOpts> ParseTrimOpts(bool max_len, CmdArgParser* parser) {\n+  TrimOpts opts;\n+  opts.approx = parser->Check(\"~\");\n+  if (!opts.approx) {\n+    parser->Check(\"=\");\n+  }\n \n-  unsigned id_indx = 1;\n-  for (; id_indx < args.size(); ++id_indx) {\n-    string arg = absl::AsciiStrToUpper(ArgS(args, id_indx));\n-    size_t remaining_args = args.size() - id_indx - 1;\n+  if (max_len) {\n+    opts.length_or_id = parser->Next<uint32_t>();\n+  } else {\n+    ParsedStreamId parsed_id;\n+    if (!ParseID(parser->Next(), false, 0, &parsed_id)) {\n+      return CreateSyntaxError(kSyntaxErr);\n+    }\n \n-    if (is_xadd && arg == \"NOMKSTREAM\") {\n+    opts.length_or_id = parsed_id;  // trivial copy\n+  }\n+\n+  if (parser->Check(\"LIMIT\")) {\n+    if (!opts.approx) {\n+      return CreateSyntaxError(kSyntaxErr);\n+    }\n+\n+    opts.limit = parser->Next<uint32_t>();\n+  }\n+\n+  return opts;\n+}\n+\n+ParseResult<TrimOpts> ParseTrimOpts(CmdArgParser* parser) {\n+  bool max_len = parser->Check(\"MAXLEN\");\n+  if (!max_len) {\n+    parser->ExpectTag(\"MINID\");\n+  }\n+\n+  auto res = ParseTrimOpts(max_len, parser);\n+\n+  if (parser->Check(\"MAXLEN\") || parser->Check(\"MINID\")) {\n+    return CreateSyntaxError(kTrimOptionConflictErr);\n+  }\n+\n+  return res;\n+}\n+\n+ParseResult<AddOpts> ParseAddOpts(CmdArgParser* parser) {\n+  AddOpts opts;\n+  while (parser->HasNext()) {\n+    if (parser->Check(\"NOMKSTREAM\")) {\n       opts.no_mkstream = true;\n-    } else if ((arg == \"MAXLEN\" || arg == \"MINID\") && remaining_args >= 1) {\n-      if (opts.trim_strategy != TrimStrategy::kNone) {\n-        builder->SendError(\"MAXLEN and MINID options at the same time are not compatible\",\n-                           kSyntaxErr);\n-        return std::nullopt;\n-      }\n+      continue;\n+    }\n \n-      if (arg == \"MAXLEN\") {\n-        opts.trim_strategy = TrimStrategy::kMaxLen;\n-      } else {\n-        opts.trim_strategy = TrimStrategy::kMinId;\n+    bool max_len = parser->Check(\"MAXLEN\");\n+    if (max_len || parser->Check(\"MINID\")) {\n+      if (opts.trim_opts) {\n+        return CreateSyntaxError(kTrimOptionConflictErr);\n       }\n \n-      id_indx++;\n-      arg = ArgS(args, id_indx);\n-      if (remaining_args >= 2 && arg == \"~\") {\n-        opts.trim_approx = true;\n-        id_indx++;\n-        arg = ArgS(args, id_indx);\n-      } else if (remaining_args >= 2 && arg == \"=\") {\n-        opts.trim_approx = false;\n-        id_indx++;\n-        arg = ArgS(args, id_indx);\n+      auto trim_opts = ParseTrimOpts(max_len, parser);\n+      if (!trim_opts) {\n+        return make_unexpected(trim_opts.error());\n       }\n \n-      if (opts.trim_strategy == TrimStrategy::kMaxLen && !absl::SimpleAtoi(arg, &opts.max_len)) {\n-        builder->SendError(kInvalidIntErr);\n-        return std::nullopt;\n-      }\n-      if (opts.trim_strategy == TrimStrategy::kMinId && !ParseID(arg, false, 0, &opts.minid)) {\n-        builder->SendError(kSyntaxErr);\n-        return std::nullopt;\n-      }\n-    } else if (arg == \"LIMIT\" && remaining_args >= 1 && opts.trim_strategy != TrimStrategy::kNone) {\n-      if (!opts.trim_approx) {\n-        builder->SendError(kSyntaxErr);\n-        return std::nullopt;\n-      }\n-      ++id_indx;\n-      if (!absl::SimpleAtoi(ArgS(args, id_indx), &opts.limit)) {\n-        builder->SendError(kSyntaxErr);\n-        return std::nullopt;\n+      opts.trim_opts = trim_opts.value();  // trivial copy\n+    } else {\n+      // It is StreamId\n+      std::string_view id = parser->Next();\n+      if (!ParseID(id, true, 0, &opts.parsed_id)) {\n+        return CreateSyntaxError(kInvalidStreamId);\n       }\n-    } else if (is_xadd) {\n-      // There are still remaining field args.\n       break;\n-    } else {\n-      builder->SendError(kSyntaxErr);\n-      return std::nullopt;\n     }\n   }\n \n-  return make_pair(opts, id_indx);\n+  return opts;\n }\n \n struct StreamReplies {\n@@ -2547,46 +2620,47 @@ bool ParseXpendingOptions(CmdArgList& args, PendingOpts& opts, SinkReplyBuilder*\n }  // namespace\n \n void StreamFamily::XAdd(CmdArgList args, const CommandContext& cmd_cntx) {\n-  auto parse_resp = ParseAddOrTrimArgsOrReply(args, true, cmd_cntx.rb);\n-  if (!parse_resp) {\n-    return;\n-  }\n+  CmdArgParser parser{args};\n+  auto* rb = static_cast<RedisReplyBuilder*>(cmd_cntx.rb);\n \n-  auto add_opts = parse_resp->first;\n-  auto id_indx = parse_resp->second;\n+  string_view key = parser.Next();\n \n-  args.remove_prefix(id_indx);\n-  if (args.size() < 2 || args.size() % 2 == 0) {\n-    return cmd_cntx.rb->SendError(WrongNumArgsError(\"XADD\"), kSyntaxErrType);\n+  auto parsed_add_opts = ParseAddOpts(&parser);\n+\n+  if (auto err = parser.Error(); err || !parsed_add_opts) {\n+    rb->SendError(!parsed_add_opts ? parsed_add_opts.error() : err->MakeReply());\n+    return;\n   }\n \n-  string_view id = ArgS(args, 0);\n+  // Save the index of the stream ID in the arguments list.\n+  // We need this during journaling\n+  // It is (parser.GetCurrentIndex() - 1) because the stream id is the last parsed argument in the\n+  // ParseAddOpts\n+  const size_t stream_id_index_in_args = parser.GetCurrentIndex() - 1;\n+  AddArgsJournaler journaler{{args.begin(), args.end()}, stream_id_index_in_args};\n \n-  if (!ParseID(id, true, 0, &add_opts.parsed_id)) {\n-    return cmd_cntx.rb->SendError(kInvalidStreamId, kSyntaxErrType);\n+  CmdArgList fields = parser.Tail();\n+  if (fields.empty() || fields.size() % 2 != 0) {\n+    return rb->SendError(WrongNumArgsError(\"XADD\"), kSyntaxErrType);\n   }\n \n-  args.remove_prefix(1);\n   auto cb = [&](Transaction* t, EngineShard* shard) {\n-    return OpAdd(t->GetOpArgs(shard), add_opts, args);\n+    return OpAdd(t->GetOpArgs(shard), key, parsed_add_opts.value(), fields, journaler);\n   };\n \n   OpResult<streamID> add_result = cmd_cntx.tx->ScheduleSingleHopT(cb);\n-  auto* rb = static_cast<RedisReplyBuilder*>(cmd_cntx.rb);\n \n   if (add_result) {\n-    return rb->SendBulkString(StreamIdRepr(*add_result));\n-  }\n-\n-  if (add_result == OpStatus::KEY_NOTFOUND) {\n-    return rb->SendNull();\n-  }\n-\n-  if (add_result.status() == OpStatus::STREAM_ID_SMALL) {\n-    return cmd_cntx.rb->SendError(LeqTopIdError(\"XADD\"));\n+    rb->SendBulkString(StreamIdRepr(*add_result));\n+  } else {\n+    if (add_result == OpStatus::KEY_NOTFOUND) {\n+      rb->SendNull();\n+    } else if (add_result == OpStatus::STREAM_ID_SMALL) {\n+      rb->SendError(LeqTopIdError(\"XADD\"));\n+    } else {\n+      rb->SendError(add_result.status());\n+    }\n   }\n-\n-  return cmd_cntx.rb->SendError(add_result.status());\n }\n \n absl::InlinedVector<streamID, 8> GetXclaimIds(CmdArgList& args) {\n@@ -3173,22 +3247,35 @@ void StreamFamily::XSetId(CmdArgList args, const CommandContext& cmd_cntx) {\n }\n \n void StreamFamily::XTrim(CmdArgList args, const CommandContext& cmd_cntx) {\n-  auto parse_resp = ParseAddOrTrimArgsOrReply(args, true, cmd_cntx.rb);\n-  if (!parse_resp) {\n+  CmdArgParser parser{args};\n+  auto* rb = static_cast<RedisReplyBuilder*>(cmd_cntx.rb);\n+\n+  std::string_view key = parser.Next();\n+\n+  auto parsed_trim_opts = ParseTrimOpts(&parser);\n+  if (!parsed_trim_opts || !parser.Finalize()) {\n+    rb->SendError(!parsed_trim_opts ? parsed_trim_opts.error() : parser.Error()->MakeReply());\n     return;\n   }\n \n-  auto trim_opts = parse_resp->first;\n+  auto& trim_opts = parsed_trim_opts.value();\n+\n+  // We can auto-journal if we are not trimming approximately or by maxlen\n+  const bool enable_auto_journaling = !JournalAsMinId(trim_opts);\n+  if (enable_auto_journaling) {\n+    cmd_cntx.tx->ReviveAutoJournal();\n+  }\n \n   auto cb = [&](Transaction* t, EngineShard* shard) {\n-    return OpTrim(t->GetOpArgs(shard), trim_opts);\n+    return OpTrim(t->GetOpArgs(shard), key, trim_opts, !enable_auto_journaling);\n   };\n \n   OpResult<int64_t> trim_result = cmd_cntx.tx->ScheduleSingleHopT(cb);\n   if (trim_result) {\n-    return cmd_cntx.rb->SendLong(*trim_result);\n+    rb->SendLong(*trim_result);\n+  } else {\n+    rb->SendError(trim_result.status());\n   }\n-  return cmd_cntx.rb->SendError(trim_result.status());\n }\n \n void StreamFamily::XAck(CmdArgList args, const CommandContext& cmd_cntx) {\n@@ -3315,7 +3402,9 @@ void StreamFamily::Register(CommandRegistry* registry) {\n   using CI = CommandId;\n   registry->StartFamily();\n   constexpr auto kReadFlags = CO::READONLY | CO::BLOCKING | CO::VARIADIC_KEYS;\n-  *registry << CI{\"XADD\", CO::WRITE | CO::DENYOOM | CO::FAST, -5, 1, 1, acl::kXAdd}.HFUNC(XAdd)\n+  *registry << CI{\"XADD\",    CO::WRITE | CO::DENYOOM | CO::FAST | CO::NO_AUTOJOURNAL, -5, 1, 1,\n+                  acl::kXAdd}\n+                   .HFUNC(XAdd)\n             << CI{\"XCLAIM\", CO::WRITE | CO::FAST, -6, 1, 1, acl::kXClaim}.HFUNC(XClaim)\n             << CI{\"XDEL\", CO::WRITE | CO::FAST, -3, 1, 1, acl::kXDel}.HFUNC(XDel)\n             << CI{\"XGROUP\", CO::WRITE | CO::DENYOOM, -3, 2, 2, acl::kXGroup}.HFUNC(XGroup)\n@@ -3327,7 +3416,8 @@ void StreamFamily::Register(CommandRegistry* registry) {\n             << CI{\"XREAD\", kReadFlags, -3, 3, 3, acl::kXRead}.HFUNC(XRead)\n             << CI{\"XREADGROUP\", kReadFlags, -6, 6, 6, acl::kXReadGroup}.HFUNC(XReadGroup)\n             << CI{\"XSETID\", CO::WRITE, 3, 1, 1, acl::kXSetId}.HFUNC(XSetId)\n-            << CI{\"XTRIM\", CO::WRITE | CO::FAST, -4, 1, 1, acl::kXTrim}.HFUNC(XTrim)\n+            << CI{\"XTRIM\", CO::WRITE | CO::FAST | CO::NO_AUTOJOURNAL, -4, 1, 1, acl::kXTrim}.HFUNC(\n+                   XTrim)\n             << CI{\"_XGROUP_HELP\", CO::NOSCRIPT | CO::HIDDEN, 2, 0, 0, acl::kXGroupHelp}.SetHandler(\n                    XGroupHelp)\n             << CI{\"XACK\", CO::WRITE | CO::FAST, -4, 1, 1, acl::kXAck}.HFUNC(XAck)\n",
  "test_patch": "diff --git a/src/server/stream_family_test.cc b/src/server/stream_family_test.cc\nindex 0872b7953fe4..56e05f22e996 100644\n--- a/src/server/stream_family_test.cc\n+++ b/src/server/stream_family_test.cc\n@@ -693,7 +693,7 @@ TEST_F(StreamFamilyTest, XTrimInvalidArgs) {\n \n   // Invalid limit.\n   resp = Run({\"xtrim\", \"foo\", \"maxlen\", \"~\", \"2\", \"limit\", \"nan\"});\n-  EXPECT_THAT(resp, ErrArg(\"syntax error\"));\n+  EXPECT_THAT(resp, ErrArg(\"value is not an integer or out of range\"));\n }\n TEST_F(StreamFamilyTest, XPending) {\n   Run({\"xadd\", \"foo\", \"1-0\", \"k1\", \"v1\"});\ndiff --git a/tests/dragonfly/replication_test.py b/tests/dragonfly/replication_test.py\nindex a542c01bfa3f..add96839c48d 100644\n--- a/tests/dragonfly/replication_test.py\n+++ b/tests/dragonfly/replication_test.py\n@@ -2715,7 +2715,7 @@ async def get_memory(client, field):\n     logging.info(f\"Replica Used memory {replica_used_memory}, peak memory {replica_peak_memory}\")\n     assert replica_peak_memory < 1.1 * replica_used_memory\n \n-    # Check replica data consisten\n+    # Check replica data consistent\n     replica_data = await StaticSeeder.capture(c_replica)\n     master_data = await StaticSeeder.capture(c_master)\n     assert master_data == replica_data\n@@ -2734,3 +2734,39 @@ async def test_master_too_big(df_factory):\n     # We should never sync due to used memory too high during full sync\n     with pytest.raises(TimeoutError):\n         await wait_available_async(c_replica, timeout=10)\n+\n+\n+@dfly_args({\"proactor_threads\": 4})\n+async def test_stream_approximate_trimming(df_factory):\n+    master = df_factory.create()\n+    replica = df_factory.create()\n+\n+    df_factory.start_all([master, replica])\n+    c_master = master.client()\n+    c_replica = replica.client()\n+\n+    await c_replica.execute_command(f\"REPLICAOF localhost {master.port}\")\n+    await wait_for_replicas_state(c_replica)\n+\n+    # Step 1: Populate master with 100 streams, each containing 200 entries\n+    num_streams = 100\n+    entries_per_stream = 200\n+\n+    for i in range(num_streams):\n+        stream_name = f\"stream{i}\"\n+        for j in range(entries_per_stream):\n+            await c_master.execute_command(\"XADD\", stream_name, \"*\", f\"field{j}\", f\"value{j}\")\n+\n+    # Step 2: Trim each stream to a random size between 70 and 200\n+    for i in range(num_streams):\n+        stream_name = f\"stream{i}\"\n+        trim_size = random.randint(70, entries_per_stream)\n+        await c_master.execute_command(\"XTRIM\", stream_name, \"MAXLEN\", \"~\", trim_size)\n+\n+    # Wait for replica sync\n+    await asyncio.sleep(1)\n+\n+    # Check replica data consistent\n+    master_data = await StaticSeeder.capture(c_master)\n+    replica_data = await StaticSeeder.capture(c_replica)\n+    assert master_data == replica_data\n",
  "problem_statement": "streams XADD/XTRIM require journal rewrite during the replication\nXADD may trim the stream, XTRIM does it as well.\r\nTheir arguments may specify the intent in declarative way like `~ 1000` or `COUNT 1000`.\r\n\r\nCurrently, Dragonfly does not rewrite journal stream commands at all.\r\n\r\nDragonfly master should rewrite it into `... MINID = <id>` to provide exact state semantics for slave to comply.\n",
  "hints_text": "",
  "created_at": "2025-01-13T19:20:34Z",
  "modified_files": [
    "src/facade/cmd_arg_parser.h",
    "src/redis/stream.h",
    "src/redis/t_stream.c",
    "src/server/stream_family.cc"
  ],
  "modified_test_files": [
    "src/server/stream_family_test.cc",
    "tests/dragonfly/replication_test.py"
  ]
}