{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 2693,
  "instance_id": "dragonflydb__dragonfly-2693",
  "issue_numbers": [
    "2668"
  ],
  "base_commit": "7e0536fd4cad3c85ecc47390e1f3632a1676db78",
  "patch": "diff --git a/src/server/main_service.cc b/src/server/main_service.cc\nindex 9ed4840b56d3..84a9d9318acd 100644\n--- a/src/server/main_service.cc\n+++ b/src/server/main_service.cc\n@@ -798,6 +798,7 @@ void Service::Init(util::AcceptServer* acceptor, std::vector<facade::Listener*>\n   config_registry.Register(\"dbnum\");  // equivalent to databases in redis.\n   config_registry.Register(\"dir\");\n   config_registry.RegisterMutable(\"masterauth\");\n+  config_registry.RegisterMutable(\"masteruser\");\n   config_registry.RegisterMutable(\"tcp_keepalive\");\n   config_registry.RegisterMutable(\"replica_partial_sync\");\n   config_registry.RegisterMutable(\"max_eviction_per_heartbeat\");\n@@ -1131,6 +1132,13 @@ void Service::DispatchCommand(CmdArgList args, facade::ConnectionContext* cntx)\n     if (auto& exec_info = dfly_cntx->conn_state.exec_info; exec_info.IsCollecting())\n       exec_info.state = ConnectionState::ExecInfo::EXEC_ERROR;\n \n+    // We need to skip this because ACK's should not be replied to\n+    // Bonus points because this allows to continue replication with ACL users who got\n+    // their access revoked and reinstated\n+    if (cid->name() == \"REPLCONF\" && absl::EqualsIgnoreCase(ArgS(args_no_cmd, 0), \"ACK\")) {\n+      LOG(ERROR) << \"Tried to reply to REPLCONF\";\n+      return;\n+    }\n     dfly_cntx->SendError(std::move(*err));\n     return;\n   }\n@@ -1233,6 +1241,12 @@ bool Service::InvokeCmd(const CommandId* cid, CmdArgList tail_args, ConnectionCo\n   DCHECK(!cid->Validate(tail_args));\n \n   if (auto err = VerifyCommandExecution(cid, cntx, tail_args); err) {\n+    // We need to skip this because ACK's should not be replied to\n+    // Bonus points because this allows to continue replication with ACL users who got\n+    // their access revoked and reinstated\n+    if (cid->name() == \"REPLCONF\" && absl::EqualsIgnoreCase(ArgS(tail_args, 0), \"ACK\")) {\n+      return true;\n+    }\n     cntx->SendError(std::move(*err));\n     return true;  // return false only for internal error aborts\n   }\ndiff --git a/src/server/protocol_client.cc b/src/server/protocol_client.cc\nindex 93cf78c282e7..7cbb47ce1d3e 100644\n--- a/src/server/protocol_client.cc\n+++ b/src/server/protocol_client.cc\n@@ -34,6 +34,7 @@ extern \"C\" {\n #include \"util/tls/tls_socket.h\"\n #endif\n \n+ABSL_FLAG(std::string, masteruser, \"\", \"username for authentication with master\");\n ABSL_FLAG(std::string, masterauth, \"\", \"password for authentication with master\");\n ABSL_FLAG(bool, tls_replication, false, \"Enable TLS on replication\");\n \n@@ -236,9 +237,12 @@ error_code ProtocolClient::ConnectAndAuth(std::chrono::milliseconds connect_time\n    CHECK_EQ(0, setsockopt(sock_->native_handle(), IPPROTO_TCP, TCP_KEEPCNT, &intv, sizeof(intv)));\n   */\n   auto masterauth = absl::GetFlag(FLAGS_masterauth);\n+  auto masteruser = absl::GetFlag(FLAGS_masteruser);\n+  ResetParser(false);\n   if (!masterauth.empty()) {\n-    ResetParser(false);\n-    RETURN_ON_ERR(SendCommandAndReadResponse(StrCat(\"AUTH \", masterauth)));\n+    auto cmd = masteruser.empty() ? StrCat(\"AUTH \", masterauth)\n+                                  : StrCat(\"AUTH \", masteruser, \" \", masterauth);\n+    RETURN_ON_ERR(SendCommandAndReadResponse(cmd));\n     PC_RETURN_ON_BAD_RESPONSE(CheckRespIsSimpleReply(\"OK\"));\n   }\n   return error_code{};\ndiff --git a/src/server/replica.cc b/src/server/replica.cc\nindex 597f1cbcd51c..ad832a249c40 100644\n--- a/src/server/replica.cc\n+++ b/src/server/replica.cc\n@@ -3,7 +3,10 @@\n //\n #include \"server/replica.h\"\n \n+#include <chrono>\n+\n #include \"absl/strings/match.h\"\n+#include \"util/fibers/fiber2.h\"\n \n extern \"C\" {\n #include \"redis/rdb.h\"\n@@ -73,6 +76,7 @@ Replica::Replica(string host, uint16_t port, Service* se, std::string_view id)\n Replica::~Replica() {\n   sync_fb_.JoinIfNeeded();\n   acks_fb_.JoinIfNeeded();\n+  acl_check_fb_.JoinIfNeeded();\n }\n \n static const char kConnErr[] = \"could not connect to master: \";\n@@ -140,12 +144,11 @@ void Replica::Stop() {\n     state_mask_.store(0);  // Specifically ~R_ENABLED.\n   });\n \n-  waker_.notifyAll();\n-\n   // Make sure the replica fully stopped and did all cleanup,\n   // so we can freely release resources (connections).\n   sync_fb_.JoinIfNeeded();\n   acks_fb_.JoinIfNeeded();\n+  acl_check_fb_.JoinIfNeeded();\n }\n \n void Replica::Pause(bool pause) {\n@@ -586,20 +589,21 @@ error_code Replica::ConsumeRedisStream() {\n \n     io_buf.ConsumeInput(response->left_in_buffer);\n     repl_offs_ += response->total_read;\n-    waker_.notify();  // Notify to trigger ACKs.\n+    replica_waker_.notify();  // Notify to trigger ACKs.\n   }\n }\n \n error_code Replica::ConsumeDflyStream() {\n   // Set new error handler that closes flow sockets.\n   auto err_handler = [this](const auto& ge) {\n+    // Trigger acl-checker\n+    replica_waker_.notifyAll();\n     // Make sure the flows are not in a state transition\n     lock_guard lk{flows_op_mu_};\n     DefaultErrorHandler(ge);\n     for (auto& flow : shard_flows_) {\n       flow->Cancel();\n     }\n-\n     multi_shard_exe_->CancelAllBlockingEntities();\n   };\n   RETURN_ON_ERR(cntx_.SwitchErrorHandler(std::move(err_handler)));\n@@ -621,7 +625,13 @@ error_code Replica::ConsumeDflyStream() {\n     lock_guard lk{flows_op_mu_};\n     shard_set->pool()->AwaitFiberOnAll(std::move(shard_cb));\n   }\n+\n+  if (master_context_.version >= DflyVersion::VER3) {\n+    acl_check_fb_ = fb2::Fiber(\"acl-check\", &Replica::AclCheckFb, this);\n+  }\n+\n   JoinDflyFlows();\n+  acl_check_fb_.JoinIfNeeded();\n \n   last_journal_LSNs_.emplace();\n   for (auto& flow : shard_flows_) {\n@@ -793,7 +803,7 @@ void DflyShardReplica::StableSyncDflyReadFb(Context* cntx) {\n   }\n \n   while (!cntx->IsCancelled()) {\n-    waker_.await([&]() {\n+    shard_replica_waker_.await([&]() {\n       return ((trans_data_queue_.size() < kYieldAfterItemsInQueue) || cntx->IsCancelled());\n     });\n     if (cntx->IsCancelled())\n@@ -824,7 +834,7 @@ void DflyShardReplica::StableSyncDflyReadFb(Context* cntx) {\n         ExecuteTxWithNoShardSync(std::move(*tx_data), cntx);\n       }\n     }\n-    waker_.notify();\n+    shard_replica_waker_.notify();\n   }\n }\n \n@@ -845,12 +855,59 @@ void Replica::RedisStreamAcksFb() {\n     }\n     ack_offs_ = repl_offs_;\n \n-    waker_.await_until(\n+    replica_waker_.await_until(\n         [&]() { return repl_offs_ > ack_offs_ + kAckRecordMaxInterval || cntx_.IsCancelled(); },\n         next_ack_tp);\n   }\n }\n \n+class AclCheckerClient : public ProtocolClient {\n+ public:\n+  AclCheckerClient(ServerContext server, Context* cntx)\n+      : ProtocolClient(std::move(server)), cntx_(cntx) {\n+    Connect();\n+  }\n+\n+  void CheckAclRoundTrip() {\n+    if (auto ec = SendCommandAndReadResponse(StrCat(\"REPLCONF acl-check \", \"0\")); ec) {\n+      cntx_->Cancel();\n+      LOG(INFO) << \"Error in REPLCONF acl-check: \" << ec.message();\n+    } else if (!CheckRespIsSimpleReply(\"OK\")) {\n+      cntx_->Cancel();\n+      LOG(INFO) << \"Error: \" << ToSV(LastResponseArgs().front().GetBuf());\n+    }\n+  }\n+\n+ private:\n+  void Connect() {\n+    VLOG(1) << \"Connecting with acl client\";\n+    auto ec = ConnectAndAuth(absl::GetFlag(FLAGS_master_connect_timeout_ms) * 1ms, cntx_);\n+    if (ec) {\n+      LOG(INFO) << \"Failed to connect with acl client \" << ec.message();\n+      cntx_->Cancel();\n+    }\n+  }\n+\n+  Context* cntx_;\n+};\n+\n+void Replica::AclCheckFb() {\n+  // We need a new client with a different socket for acl-checks\n+  // instead of using the ACK's fiber. This is because acks should\n+  // not be replied (which makes them unusable for periodic ACL checks).\n+  // Also there are N ACK fibers per replica instance while we only need\n+  // one fiber to periodically check for ACL changes. Therefore,\n+  // we decouple the logic via AclCheckFb.\n+  AclCheckerClient acl_client(server(), &cntx_);\n+\n+  while (!cntx_.IsCancelled()) {\n+    acl_client.CheckAclRoundTrip();\n+    // We poll for ACL changes every second\n+    replica_waker_.await_until([&]() { return cntx_.IsCancelled(); },\n+                               std::chrono::steady_clock::now() + std::chrono::seconds(1));\n+  }\n+}\n+\n void DflyShardReplica::StableSyncDflyAcksFb(Context* cntx) {\n   constexpr size_t kAckRecordMaxInterval = 1024;\n   std::chrono::duration ack_time_max_interval =\n@@ -873,7 +930,7 @@ void DflyShardReplica::StableSyncDflyAcksFb(Context* cntx) {\n     }\n     ack_offs_ = current_offset;\n \n-    waker_.await_until(\n+    shard_replica_waker_.await_until(\n         [&]() {\n           return journal_rec_executed_.load(std::memory_order_relaxed) >\n                      ack_offs_ + kAckRecordMaxInterval ||\n@@ -922,7 +979,8 @@ void DflyShardReplica::InsertTxDataToShardResource(TransactionData&& tx_data) {\n \n void DflyShardReplica::StableSyncDflyExecFb(Context* cntx) {\n   while (!cntx->IsCancelled()) {\n-    waker_.await([&]() { return (!trans_data_queue_.empty() || cntx->IsCancelled()); });\n+    shard_replica_waker_.await(\n+        [&]() { return (!trans_data_queue_.empty() || cntx->IsCancelled()); });\n     if (cntx->IsCancelled()) {\n       return;\n     }\n@@ -930,7 +988,7 @@ void DflyShardReplica::StableSyncDflyExecFb(Context* cntx) {\n     auto& data = trans_data_queue_.front();\n     ExecuteTx(std::move(data.first), data.second, cntx);\n     trans_data_queue_.pop();\n-    waker_.notify();\n+    shard_replica_waker_.notify();\n   }\n }\n \n@@ -1130,7 +1188,7 @@ void DflyShardReplica::JoinFlow() {\n \n void DflyShardReplica::Cancel() {\n   CloseSocket();\n-  waker_.notifyAll();\n+  shard_replica_waker_.notifyAll();\n }\n \n }  // namespace dfly\ndiff --git a/src/server/replica.h b/src/server/replica.h\nindex e19d8070c7bb..f2182dc51710 100644\n--- a/src/server/replica.h\n+++ b/src/server/replica.h\n@@ -102,6 +102,8 @@ class Replica : ProtocolClient {\n   // Send DFLY ${kind} to the master instance.\n   std::error_code SendNextPhaseRequest(std::string_view kind);\n \n+  void AclCheckFb();\n+\n  private: /* Utility */\n   struct PSyncResponse {\n     // string - end of sync token (diskless)\n@@ -148,7 +150,8 @@ class Replica : ProtocolClient {\n   // In redis replication mode.\n   util::fb2::Fiber sync_fb_;\n   util::fb2::Fiber acks_fb_;\n-  util::fb2::EventCount waker_;\n+  util::fb2::Fiber acl_check_fb_;\n+  util::fb2::EventCount replica_waker_;\n \n   std::vector<std::unique_ptr<DflyShardReplica>> shard_flows_;\n   // A vector of the last executer LSNs when a replication is interrupted.\n@@ -214,7 +217,7 @@ class DflyShardReplica : public ProtocolClient {\n \n   std::queue<std::pair<TransactionData, bool>> trans_data_queue_;\n   static constexpr size_t kYieldAfterItemsInQueue = 50;\n-  util::fb2::EventCount waker_;  // waker for trans_data_queue_\n+  util::fb2::EventCount shard_replica_waker_;  // waker for trans_data_queue_\n   bool use_multi_shard_exe_sync_;\n \n   std::unique_ptr<JournalExecutor> executor_;\ndiff --git a/src/server/server_family.cc b/src/server/server_family.cc\nindex b3e337f5e7b4..c242146dbd11 100644\n--- a/src/server/server_family.cc\n+++ b/src/server/server_family.cc\n@@ -2480,6 +2480,9 @@ void ServerFamily::ReplConf(CmdArgList args, ConnectionContext* cntx) {\n       VLOG(2) << \"Received client ACK=\" << ack;\n       cntx->replication_flow->last_acked_lsn = ack;\n       return;\n+    } else if (cmd == \"ACL-CHECK\") {\n+      cntx->SendOk();\n+      return;\n     } else {\n       VLOG(1) << \"Error \" << cmd << \" \" << arg << \" \" << args.size();\n       goto err;\ndiff --git a/src/server/version.h b/src/server/version.h\nindex b975c131b5b0..fbf4e9af5625 100644\n--- a/src/server/version.h\n+++ b/src/server/version.h\n@@ -29,8 +29,12 @@ enum class DflyVersion {\n   // Supports limited partial sync\n   VER2,\n \n+  // 1.15 < ver\n+  // ACL with user replication\n+  VER3,\n+\n   // Always points to the latest version\n-  CURRENT_VER = VER2,\n+  CURRENT_VER = VER3,\n };\n \n }  // namespace dfly\n",
  "test_patch": "diff --git a/tests/dragonfly/replication_test.py b/tests/dragonfly/replication_test.py\nindex 1baa3a235a8c..aec109d0da98 100644\n--- a/tests/dragonfly/replication_test.py\n+++ b/tests/dragonfly/replication_test.py\n@@ -2058,3 +2058,41 @@ async def save_replica():\n     assert not await is_saving(c_replica)\n \n     await disconnect_clients(c_master, *[c_replica])\n+\n+\n+@pytest.mark.asyncio\n+async def test_user_acl_replication(df_local_factory):\n+    master = df_local_factory.create(proactor_threads=4)\n+    replica = df_local_factory.create(proactor_threads=4)\n+    df_local_factory.start_all([master, replica])\n+\n+    c_master = master.client()\n+    await c_master.execute_command(\"ACL SETUSER tmp >tmp ON +ping +dfly +replconf\")\n+    await c_master.execute_command(\"SET foo bar\")\n+    assert 1 == await c_master.execute_command(\"DBSIZE\")\n+\n+    c_replica = replica.client()\n+    await c_replica.execute_command(\"CONFIG SET masteruser tmp\")\n+    await c_replica.execute_command(\"CONFIG SET masterauth tmp\")\n+    await c_replica.execute_command(f\"REPLICAOF localhost {master.port}\")\n+\n+    await wait_available_async(c_replica)\n+    assert 1 == await c_replica.execute_command(\"DBSIZE\")\n+\n+    # revoke acl's from tmp\n+    await c_master.execute_command(\"ACL SETUSER tmp -replconf\")\n+    async with async_timeout.timeout(5):\n+        while True:\n+            role = await c_replica.execute_command(\"INFO REPLICATION\")\n+            # fancy of way of extracting the field master_link_status\n+            is_down = role.split(\"\\r\\n\")[4].split(\":\")[1]\n+            if is_down == \"down\":\n+                break\n+            await asyncio.sleep(1)\n+\n+    await c_master.execute_command(\"SET bar foo\")\n+\n+    # reinstate and let replication continue\n+    await c_master.execute_command(\"ACL SETUSER tmp +replconf\")\n+    await check_all_replicas_finished([c_replica], c_master, 5)\n+    assert 2 == await c_replica.execute_command(\"DBSIZE\")\n",
  "problem_statement": "set masteruser support on replicas\n**Did you search GitHub Issues and GitHub Discussions First?**\r\nYes.\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nSetting another masteruser than \"default\" on replicas seems impossible right now. Ideally I would like to use a custom masteruser for admin operations so `set masteruser` is needed on this case.\r\n\r\n**Describe the solution you'd like**\r\nconfiguration option available on replicas called `masteruser`  as it's called in Redis would suffice.\n",
  "hints_text": "Hi @safa-topal, thank you for reporting this. I will take care of this :)\n@safa-topal  FYI, we also have `admin_nopass` flag so that in case you open an admin interface bound to management internal network you can access nodes via this port without any authentication.\nThanks @kostasrim, @romange. Good to know, though on this case `admin_nopass` won't help because requirement is to define a different user for replication than `default` user.",
  "created_at": "2024-03-05T18:44:48Z",
  "modified_files": [
    "src/server/main_service.cc",
    "src/server/protocol_client.cc",
    "src/server/replica.cc",
    "src/server/replica.h",
    "src/server/server_family.cc",
    "src/server/version.h"
  ],
  "modified_test_files": [
    "tests/dragonfly/replication_test.py"
  ]
}