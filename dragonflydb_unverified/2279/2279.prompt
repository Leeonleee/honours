You will be provided with a partial code base and an issue statement explaining a problem to resolve.

<issue>
Issue with redis-py pipelines and FT command execution
**Describe the bug**
When using a standard connection pool or standalone connection in Python with redis-py(5.0.1) FT.* commands complete successfully. However, if you pipeline them (scenario below) they seem cause the Dragonfly container/pod to crash with the following error:
```shell
dragonfly-1  | I20231208 15:17:28.355697     8 uring_proactor.cc:160] IORing with 1024 entries, allocated 102720 bytes, cq_entries is 2048
dragonfly-1  | I20231208 15:17:28.430027     1 proactor_pool.cc:146] Running 8 io threads
dragonfly-1  | I20231208 15:17:28.440903     1 snapshot_storage.cc:106] Load snapshot: Searching for snapshot in directory: "/data"
dragonfly-1  | I20231208 15:17:28.441177     1 server_family.cc:673] Loading /data/dump-2023-12-08T14:57:40-summary.dfs
dragonfly-1  | I20231208 15:17:28.445775     9 listener_interface.cc:101] sock[19] AcceptServer - listening on port 6379
dragonfly-1  | I20231208 15:17:28.446219    12 server_family.cc:727] Load finished, num keys read: 0
dragonfly-1  | F20231208 15:19:36.467346    14 transaction.cc:232] Check failed: absl::StartsWith(cid_->name(), "EVAL") EXEC
dragonfly-1  | *** Check failure stack trace: ***
dragonfly-1  |     @     0x55cbbad679f3  google::LogMessage::SendToLog()
dragonfly-1  |     @     0x55cbbad601b7  google::LogMessage::Flush()
dragonfly-1  |     @     0x55cbbad61b3f  google::LogMessageFatal::~LogMessageFatal()
dragonfly-1  |     @     0x55cbba67add2  dfly::Transaction::InitByKeys()
dragonfly-1  |     @     0x55cbba67b92c  dfly::Transaction::StartMultiLockedAhead()
dragonfly-1  |     @     0x55cbba46dfe2  dfly::StartMultiExec()
dragonfly-1  |     @     0x55cbba46f365  dfly::Service::Exec()
dragonfly-1  |     @     0x55cbba5a0bbe  dfly::CommandId::Invoke()
dragonfly-1  |     @     0x55cbba464eef  dfly::Service::InvokeCmd()
dragonfly-1  |     @     0x55cbba4713bd  dfly::Service::DispatchCommand()
dragonfly-1  |     @     0x55cbba738536  facade::Connection::DispatchOperations::operator()()
dragonfly-1  |     @     0x55cbba73db68  facade::Connection::DispatchFiber()
dragonfly-1  |     @     0x55cbba73e077  _ZN5boost7context6detail11fiber_entryINS1_12fiber_recordINS0_5fiberENS0_21basic_fixedsize_stackINS0_12stack_traitsEEEZN4util3fb26detail15WorkerFiberImplIZN6facade10Connection27LaunchDispatchFiberIfNeededEvEUlvE_JEEC4IS7_EESt17basic_string_viewIcSt11char_traitsIcEERKNS0_12preallocatedEOT_OSE_EUlOS4_E_EEEEvNS1_10transfer_tE
dragonfly-1  |     @     0x55cbbab844ff  make_fcontext
dragonfly-1  | *** SIGABRT received at time=1702048776 on cpu 6 ***
dragonfly-1  | PC: @     0x7f1d9560600b  (unknown)  raise
dragonfly-1  | [failure_signal_handler.cc : 345] RAW: Signal 11 raised at PC=0x7f1d955e5941 while already in AbslFailureSignalHandler()
dragonfly-1  | *** SIGSEGV received at time=1702048776 on cpu 6 ***
dragonfly-1  | PC: @     0x7f1d955e5941  (unknown)  abort
dragonfly-1 exited with code 139
```

**To Reproduce**
Steps to reproduce the behavior:
1. Using the following docker-compose yaml:
```yaml
version: '3.8'
services:
  dragonfly:
    image: 'docker.dragonflydb.io/dragonflydb/dragonfly'
    environment:
      - DFLY_requirepass=xxxxx
    ulimits:
      memlock: -1
    ports:
      - "6379:6379"
    # For better performance, consider `host` mode instead `port` to avoid docker NAT.
    # `host` mode is NOT currently supported in Swarm Mode.
    # https://docs.docker.com/compose/compose-file/compose-file-v3/#network_mode
    network_mode: "host"
    volumes:
      - dragonflydata:/data
    restart: unless-stopped
volumes:
  dragonflydata:
```
2. Start with docker-compose
3. Using redis-cli, create a simple index using:
```shell
FT.CREATE idx:something_something          
  ON HASH                       
    PREFIX 1 "something_something  :"          
  SCHEMA
    origin TEXT SORTABLE                     
    dest TEXT SORTABLE                  
    data_timestamp NUMERIC SORTABLE
```
4. In python, create a simple script to attempt to execute `FT._LIST` like so:
```python
import redis

pool = redis.ConnectionPool(
    max_connections=10000, host="localhost", port=6379, password="xxxxx", db=0
)
r = redis.Redis(connection_pool=pool)
r = r.pipeline()

print(r.execute_command("FT._LIST").execute()) # This will crash the container (it will immediately restart because of the policy but...)
# Note that I have tried the same code on a reids-stack-server 7.2.0-v6 instance and it is functional.
```


**Expected behavior**
`FT.*` Commands can be executed in a pipeline as they are on Redis via redis-py/python code.

**Environment (please complete the following information):**
 - OS: [Ubuntu 23.10]
 - Kernel: Linux dragonfly-dev 6.5.0-1008-gcp #8-Ubuntu SMP Fri Oct 20 20:32:54 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux
 - Containerized?: Docker Compose, Docker
 - Dragonfly Version: v1.13.0

**Reproducible Code Snippet**
```
See step 4 above.
```

**Additional context**
It is worth noting I can use things like HGET/HSET/INFO within a Pipeline context successfully so this seems to be isolated to FT commands from my cursory exploration.
This isn't pressing or anything just wanted to let you all know that this came up and I can find any handy solutions for it. If you need any add'l info I'll be happy to pass it along. Until then I will just avoid Pipelines with FT commands!
</issue>

I need you to solve the provided issue by generating a code fix that can be applied directly to the repository

Respond below:
