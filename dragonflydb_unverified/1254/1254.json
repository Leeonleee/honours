{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 1254,
  "instance_id": "dragonflydb__dragonfly-1254",
  "issue_numbers": [
    "1245"
  ],
  "base_commit": "2f6dbe45c03aea0c031740657af8b3ade9c251d2",
  "patch": "diff --git a/src/facade/conn_context.h b/src/facade/conn_context.h\nindex 542d4ecf299a..0176112bba85 100644\n--- a/src/facade/conn_context.h\n+++ b/src/facade/conn_context.h\n@@ -45,13 +45,16 @@ class ConnectionContext {\n   }\n \n   // connection state / properties.\n-  bool async_dispatch : 1;  // whether this connection is currently handled by dispatch fiber.\n   bool conn_closing : 1;\n   bool req_auth : 1;\n   bool replica_conn : 1;\n   bool authenticated : 1;\n-  bool force_dispatch : 1;    // whether we should route all requests to the dispatch fiber.\n-  bool journal_emulated : 1;  // whether it is used to dispatch journal commands.\n+  bool async_dispatch : 1;    // whether this connection is amid an async dispatch\n+  bool sync_dispatch : 1;     // whether this connection is amid a sync dispatch\n+  bool journal_emulated : 1;  // whether it is used to dispatch journal commands\n+\n+  // How many async subscription sources are active: monitor and/or pubsub - at most 2.\n+  uint8_t subscriptions;\n \n  private:\n   Connection* owner_;\ndiff --git a/src/facade/dragonfly_connection.cc b/src/facade/dragonfly_connection.cc\nindex 15b599547f0d..258eff65c670 100644\n--- a/src/facade/dragonfly_connection.cc\n+++ b/src/facade/dragonfly_connection.cc\n@@ -102,18 +102,14 @@ struct Connection::Shutdown {\n \n Connection::PubMessage::PubMessage(string pattern, shared_ptr<char[]> buf, size_t channel_len,\n                                    size_t message_len)\n-    : data{MessageData{pattern, move(buf), channel_len, message_len}} {\n+    : pattern{move(pattern)}, buf{move(buf)}, channel_len{channel_len}, message_len{message_len} {\n }\n \n-Connection::PubMessage::PubMessage(bool add, string_view channel, uint32_t channel_cnt)\n-    : data{SubscribeData{add, string{channel}, channel_cnt}} {\n-}\n-\n-string_view Connection::PubMessage::MessageData::Channel() const {\n+string_view Connection::PubMessage::Channel() const {\n   return {buf.get(), channel_len};\n }\n \n-string_view Connection::PubMessage::MessageData::Message() const {\n+string_view Connection::PubMessage::Message() const {\n   return {buf.get() + channel_len, message_len};\n }\n \n@@ -179,8 +175,7 @@ template <class... Ts> Overloaded(Ts...) -> Overloaded<Ts...>;\n size_t Connection::MessageHandle::UsedMemory() const {\n   // TODO: don't count inline size\n   auto pub_size = [](const PubMessage& msg) -> size_t {\n-    const auto* md = get_if<PubMessage::MessageData>(&msg.data);\n-    return sizeof(PubMessage) + (md ? (md->channel_len + md->message_len) : 0u);\n+    return sizeof(PubMessage) + (msg.channel_len + msg.message_len);\n   };\n   auto msg_size = [](const PipelineMessage& arg) -> size_t {\n     return sizeof(PipelineMessage) + arg.args.capacity() * sizeof(MutableSlice) +\n@@ -202,28 +197,18 @@ void Connection::DispatchOperations::operator()(const MonitorMessage& msg) {\n void Connection::DispatchOperations::operator()(const PubMessage& pub_msg) {\n   RedisReplyBuilder* rbuilder = (RedisReplyBuilder*)builder;\n   ++stats->async_writes_cnt;\n-  auto send_msg = [rbuilder](const PubMessage::MessageData& data) {\n-    unsigned i = 0;\n-    string_view arr[4];\n-    if (data.pattern.empty()) {\n-      arr[i++] = \"message\";\n-    } else {\n-      arr[i++] = \"pmessage\";\n-      arr[i++] = data.pattern;\n-    }\n-    arr[i++] = data.Channel();\n-    arr[i++] = data.Message();\n-    rbuilder->SendStringArr(absl::Span<string_view>{arr, i},\n-                            RedisReplyBuilder::CollectionType::PUSH);\n-  };\n-  auto send_sub = [rbuilder](const PubMessage::SubscribeData& data) {\n-    const char* action[2] = {\"unsubscribe\", \"subscribe\"};\n-    rbuilder->StartCollection(3, RedisReplyBuilder::CollectionType::PUSH);\n-    rbuilder->SendBulkString(action[data.add]);\n-    rbuilder->SendBulkString(data.channel);\n-    rbuilder->SendLong(data.channel_cnt);\n-  };\n-  visit(Overloaded{send_msg, send_sub}, pub_msg.data);\n+  unsigned i = 0;\n+  array<string_view, 4> arr;\n+  if (pub_msg.pattern.empty()) {\n+    arr[i++] = \"message\";\n+  } else {\n+    arr[i++] = \"pmessage\";\n+    arr[i++] = pub_msg.pattern;\n+  }\n+  arr[i++] = pub_msg.Channel();\n+  arr[i++] = pub_msg.Message();\n+  rbuilder->SendStringArr(absl::Span<string_view>{arr.data(), i},\n+                          RedisReplyBuilder::CollectionType::PUSH);\n }\n \n void Connection::DispatchOperations::operator()(Connection::PipelineMessage& msg) {\n@@ -231,10 +216,8 @@ void Connection::DispatchOperations::operator()(Connection::PipelineMessage& msg\n \n   DVLOG(2) << \"Dispatching pipeline: \" << ToSV(msg.args.front());\n \n-  self->cc_->async_dispatch = true;\n   self->service_->DispatchCommand(CmdArgList{msg.args.data(), msg.args.size()}, self->cc_.get());\n   self->last_interaction_ = time(nullptr);\n-  self->cc_->async_dispatch = false;\n }\n \n Connection::Connection(Protocol protocol, util::HttpListenerBase* http_listener, SSL_CTX* ctx,\n@@ -542,7 +525,44 @@ void Connection::ConnectionFlow(FiberSocketBase* peer) {\n   --stats_->num_conns;\n }\n \n-auto Connection::ParseRedis() -> ParserStatus {\n+void Connection::DispatchCommand(uint32_t consumed, mi_heap_t* heap) {\n+  bool can_dispatch_sync = (consumed >= io_buf_.InputLen());\n+\n+  // Avoid sync dispatch if an async dispatch is already in progress, or else they'll interleave.\n+  if (cc_->async_dispatch)\n+    can_dispatch_sync = false;\n+\n+  // Avoid sync dispatch if we already have pending async messages or\n+  // can potentially receive some (subscriptions > 0). Otherwise the dispatch\n+  // fiber might be constantly blocked by sync_dispatch.\n+  if (dispatch_q_.size() > 0 || cc_->subscriptions > 0)\n+    can_dispatch_sync = false;\n+\n+  if (can_dispatch_sync) {\n+    ShrinkPipelinePool();  // Gradually release pipeline request pool.\n+\n+    RespToArgList(tmp_parse_args_, &tmp_cmd_vec_);\n+\n+    {\n+      cc_->sync_dispatch = true;\n+      service_->DispatchCommand(absl::MakeSpan(tmp_cmd_vec_), cc_.get());\n+      cc_->sync_dispatch = false;\n+    }\n+\n+    last_interaction_ = time(nullptr);\n+\n+    // We might have blocked the dispatch queue from processing, wake it up.\n+    if (dispatch_q_.size() > 0)\n+      evc_.notify();\n+\n+  } else {\n+    SendAsync(MessageHandle{FromArgs(move(tmp_parse_args_), heap)});\n+    if (dispatch_q_.size() > 10)\n+      ThisFiber::Yield();\n+  }\n+}\n+\n+Connection::ParserStatus Connection::ParseRedis() {\n   uint32_t consumed = 0;\n \n   RedisParser::Result result = RedisParser::OK;\n@@ -558,28 +578,7 @@ auto Connection::ParseRedis() -> ParserStatus {\n         DVLOG(2) << \"Got Args with first token \" << ToSV(first.GetBuf());\n       }\n \n-      // An optimization to skip dispatch_q_ if no pipelining is identified.\n-      // We use ASYNC_DISPATCH as a lock to avoid out-of-order replies when the\n-      // dispatch fiber pulls the last record but is still processing the command and then this\n-      // fiber enters the condition below and executes out of order.\n-      bool is_sync_dispatch = !cc_->async_dispatch && !cc_->force_dispatch;\n-      if (dispatch_q_.empty() && is_sync_dispatch && consumed >= io_buf_.InputLen()) {\n-        // Gradually release the request pool.\n-        ShrinkPipelinePool();\n-\n-        RespToArgList(tmp_parse_args_, &tmp_cmd_vec_);\n-\n-        DVLOG(2) << \"Sync dispatch \" << ToSV(tmp_cmd_vec_.front());\n-\n-        CmdArgList cmd_list{tmp_cmd_vec_.data(), tmp_cmd_vec_.size()};\n-        service_->DispatchCommand(cmd_list, cc_.get());\n-        last_interaction_ = time(nullptr);\n-      } else {\n-        // Dispatch via queue to speedup input reading.\n-        SendAsync(MessageHandle{FromArgs(move(tmp_parse_args_), tlh)});\n-        if (dispatch_q_.size() > 10)\n-          ThisFiber::Yield();\n-      }\n+      DispatchCommand(consumed, tlh);\n     }\n     io_buf_.ConsumeInput(consumed);\n   } while (RedisParser::OK == result && !builder->GetError());\n@@ -742,7 +741,8 @@ void Connection::DispatchFiber(util::FiberSocketBase* peer) {\n   uint64_t request_cache_limit = absl::GetFlag(FLAGS_request_cache_limit);\n \n   while (!builder->GetError()) {\n-    evc_.await([this] { return cc_->conn_closing || !dispatch_q_.empty(); });\n+    evc_.await(\n+        [this] { return cc_->conn_closing || (!dispatch_q_.empty() && !cc_->sync_dispatch); });\n     if (cc_->conn_closing)\n       break;\n \n@@ -751,11 +751,16 @@ void Connection::DispatchFiber(util::FiberSocketBase* peer) {\n \n     builder->SetBatchMode(dispatch_q_.size() > 0);\n \n-    std::visit(dispatch_op, msg.handle);\n+    {\n+      cc_->async_dispatch = true;\n+      std::visit(dispatch_op, msg.handle);\n+      cc_->async_dispatch = false;\n+    }\n \n     dispatch_q_bytes_.fetch_sub(msg.UsedMemory(), memory_order_relaxed);\n     evc_bp_.notify();\n \n+    // Retain pipeline message in pool.\n     if (auto* pipe = get_if<PipelineMessagePtr>(&msg.handle); pipe) {\n       if (stats_->pipeline_cache_capacity < request_cache_limit) {\n         stats_->pipeline_cache_capacity += (*pipe)->StorageCapacity();\n@@ -859,7 +864,12 @@ void Connection::SendAsync(MessageHandle msg) {\n   dispatch_q_bytes_.fetch_add(msg.UsedMemory(), memory_order_relaxed);\n \n   dispatch_q_.push_back(move(msg));\n-  if (dispatch_q_.size() == 1) {\n+\n+  // Don't notify if a sync dispatch is in progress, it will wake after finishing.\n+  // This might only happen if we started receving messages while `SUBSCRIBE`\n+  // is still updating thread local data (see channel_store). We need to make sure its\n+  // ack is sent before all other messages.\n+  if (dispatch_q_.size() == 1 && !cc_->sync_dispatch) {\n     evc_.notify();\n   }\n }\ndiff --git a/src/facade/dragonfly_connection.h b/src/facade/dragonfly_connection.h\nindex 5f546047c6f5..d242fa9b90b6 100644\n--- a/src/facade/dragonfly_connection.h\n+++ b/src/facade/dragonfly_connection.h\n@@ -62,26 +62,13 @@ class Connection : public util::Connection {\n \n   // PubSub message, either incoming message for active subscription or reply for new subscription.\n   struct PubMessage {\n-    // Represents incoming message.\n-    struct MessageData {\n-      std::string pattern{};            // non-empty for pattern subscriber\n-      std::shared_ptr<char[]> buf;      // stores channel name and message\n-      size_t channel_len, message_len;  // lengths in buf\n-\n-      std::string_view Channel() const;\n-      std::string_view Message() const;\n-    };\n-\n-    // Represents reply for subscribe/unsubscribe.\n-    struct SubscribeData {\n-      bool add;\n-      std::string channel;\n-      uint32_t channel_cnt;\n-    };\n-\n-    std::variant<MessageData, SubscribeData> data;\n-\n-    PubMessage(bool add, std::string_view channel, uint32_t channel_cnt);\n+    std::string pattern{};            // non-empty for pattern subscriber\n+    std::shared_ptr<char[]> buf;      // stores channel name and message\n+    size_t channel_len, message_len;  // lengths in buf\n+\n+    std::string_view Channel() const;\n+    std::string_view Message() const;\n+\n     PubMessage(std::string pattern, std::shared_ptr<char[]> buf, size_t channel_len,\n                size_t message_len);\n   };\n@@ -194,6 +181,9 @@ class Connection : public util::Connection {\n   // Returns true if HTTP header is detected.\n   io::Result<bool> CheckForHttpProto(util::FiberSocketBase* peer);\n \n+  // Dispatch last command parsed by ParseRedis\n+  void DispatchCommand(uint32_t consumed, mi_heap_t* heap);\n+\n   // Handles events from dispatch queue.\n   void DispatchFiber(util::FiberSocketBase* peer);\n \ndiff --git a/src/facade/facade.cc b/src/facade/facade.cc\nindex decbd30e96d0..d7437fb9bcfb 100644\n--- a/src/facade/facade.cc\n+++ b/src/facade/facade.cc\n@@ -115,13 +115,15 @@ ConnectionContext::ConnectionContext(::io::Sink* stream, Connection* owner) : ow\n       break;\n   }\n \n-  async_dispatch = false;\n   conn_closing = false;\n   req_auth = false;\n   replica_conn = false;\n   authenticated = false;\n-  force_dispatch = false;\n+  async_dispatch = false;\n+  sync_dispatch = false;\n   journal_emulated = false;\n+\n+  subscriptions = 0;\n }\n \n RedisReplyBuilder* ConnectionContext::operator->() {\ndiff --git a/src/server/conn_context.cc b/src/server/conn_context.cc\nindex a18ad224833e..2e04cd7ba6b0 100644\n--- a/src/server/conn_context.cc\n+++ b/src/server/conn_context.cc\n@@ -105,7 +105,7 @@ vector<unsigned> ChangeSubscriptions(bool pattern, CmdArgList args, bool to_add,\n     DCHECK(to_add);\n \n     conn_state.subscribe_info.reset(new ConnectionState::SubscribeInfo);\n-    conn->force_dispatch = true;  // to be able to read input and still write the output.\n+    conn->subscriptions++;\n   }\n \n   auto& sinfo = *conn->conn_state.subscribe_info.get();\n@@ -134,7 +134,8 @@ vector<unsigned> ChangeSubscriptions(bool pattern, CmdArgList args, bool to_add,\n   // removed.\n   if (!to_add && conn_state.subscribe_info->IsEmpty()) {\n     conn_state.subscribe_info.reset();\n-    conn->force_dispatch = false;\n+    DCHECK_GE(conn->subscriptions, 1u);\n+    conn->subscriptions--;\n   }\n \n   return result;\n@@ -145,7 +146,11 @@ void ConnectionContext::ChangeSubscription(bool to_add, bool to_reply, CmdArgLis\n \n   if (to_reply) {\n     for (size_t i = 0; i < result.size(); ++i) {\n-      owner()->SendPubMessageAsync({to_add, ArgS(args, i), result[i]});\n+      const char* action[2] = {\"unsubscribe\", \"subscribe\"};\n+      (*this)->StartCollection(3, RedisReplyBuilder::CollectionType::PUSH);\n+      (*this)->SendBulkString(action[to_add]);\n+      (*this)->SendBulkString(ArgS(args, i));\n+      (*this)->SendLong(result[i]);\n     }\n   }\n }\ndiff --git a/src/server/conn_context.h b/src/server/conn_context.h\nindex 373b5a6b9279..5343d46b540a 100644\n--- a/src/server/conn_context.h\n+++ b/src/server/conn_context.h\n@@ -176,7 +176,7 @@ class ConnectionContext : public facade::ConnectionContext {\n \n  private:\n   void EnableMonitoring(bool enable) {\n-    force_dispatch = enable;  // required to support the monitoring\n+    subscriptions++;  // required to support the monitoring\n     monitor = enable;\n   }\n   void SendSubscriptionChangedResponse(std::string_view action,\ndiff --git a/src/server/main_service.cc b/src/server/main_service.cc\nindex 1a2b1db3fe70..1d41e3e17456 100644\n--- a/src/server/main_service.cc\n+++ b/src/server/main_service.cc\n@@ -735,8 +735,8 @@ bool Service::VerifyCommand(const CommandId* cid, CmdArgList args, ConnectionCon\n   }\n \n   if (under_multi) {\n-    if (cmd_name == \"SELECT\") {\n-      (*dfly_cntx)->SendError(\"Can not call SELECT within a transaction\");\n+    if (cmd_name == \"SELECT\" || absl::EndsWith(cmd_name, \"SUBSCRIBE\")) {\n+      (*dfly_cntx)->SendError(absl::StrCat(\"Can not call \", cmd_name, \" within a transaction\"));\n       return false;\n     }\n \n",
  "test_patch": "diff --git a/src/server/test_utils.cc b/src/server/test_utils.cc\nindex 9afd0cada70f..0ba6f4b9ce3a 100644\n--- a/src/server/test_utils.cc\n+++ b/src/server/test_utils.cc\n@@ -62,16 +62,7 @@ TestConnection::TestConnection(Protocol protocol, io::StringSink* sink)\n }\n \n void TestConnection::SendPubMessageAsync(PubMessage pmsg) {\n-  if (auto* ptr = std::get_if<PubMessage::MessageData>(&pmsg.data); ptr != nullptr) {\n-    messages.push_back(move(*ptr));\n-  } else if (auto* ptr = std::get_if<PubMessage::SubscribeData>(&pmsg.data); ptr != nullptr) {\n-    RedisReplyBuilder builder(sink_);\n-    const char* action[2] = {\"unsubscribe\", \"subscribe\"};\n-    builder.StartArray(3);\n-    builder.SendBulkString(action[ptr->add]);\n-    builder.SendBulkString(ptr->channel);\n-    builder.SendLong(ptr->channel_cnt);\n-  }\n+  messages.push_back(move(pmsg));\n }\n \n class BaseFamilyTest::TestConnWrapper {\n@@ -84,7 +75,7 @@ class BaseFamilyTest::TestConnWrapper {\n   RespVec ParseResponse(bool fully_consumed);\n \n   // returns: type(pmessage), pattern, channel, message.\n-  const facade::Connection::PubMessage::MessageData& GetPubMessage(size_t index) const;\n+  const facade::Connection::PubMessage& GetPubMessage(size_t index) const;\n \n   ConnectionContext* cmd_cntx() {\n     return &cmd_cntx_;\n@@ -375,7 +366,7 @@ RespVec BaseFamilyTest::TestConnWrapper::ParseResponse(bool fully_consumed) {\n   return res;\n }\n \n-const facade::Connection::PubMessage::MessageData& BaseFamilyTest::TestConnWrapper::GetPubMessage(\n+const facade::Connection::PubMessage& BaseFamilyTest::TestConnWrapper::GetPubMessage(\n     size_t index) const {\n   CHECK_LT(index, dummy_conn_->messages.size());\n   return dummy_conn_->messages[index];\n@@ -406,8 +397,8 @@ size_t BaseFamilyTest::SubscriberMessagesLen(string_view conn_id) const {\n   return it->second->conn()->messages.size();\n }\n \n-const facade::Connection::PubMessage::MessageData& BaseFamilyTest::GetPublishedMessage(\n-    string_view conn_id, size_t index) const {\n+const facade::Connection::PubMessage& BaseFamilyTest::GetPublishedMessage(string_view conn_id,\n+                                                                          size_t index) const {\n   auto it = connections_.find(conn_id);\n   CHECK(it != connections_.end());\n \ndiff --git a/src/server/test_utils.h b/src/server/test_utils.h\nindex e30710cafff6..b3f5c2ab4af7 100644\n--- a/src/server/test_utils.h\n+++ b/src/server/test_utils.h\n@@ -23,7 +23,7 @@ class TestConnection : public facade::Connection {\n \n   void SendPubMessageAsync(PubMessage pmsg) final;\n \n-  std::vector<PubMessage::MessageData> messages;\n+  std::vector<PubMessage> messages;\n \n  private:\n   io::StringSink* sink_;\n@@ -87,8 +87,8 @@ class BaseFamilyTest : public ::testing::Test {\n   std::string GetId() const;\n   size_t SubscriberMessagesLen(std::string_view conn_id) const;\n \n-  const facade::Connection::PubMessage::MessageData& GetPublishedMessage(std::string_view conn_id,\n-                                                                         size_t index) const;\n+  const facade::Connection::PubMessage& GetPublishedMessage(std::string_view conn_id,\n+                                                            size_t index) const;\n \n   static unsigned NumLocked();\n \ndiff --git a/tests/dragonfly/connection_test.py b/tests/dragonfly/connection_test.py\nindex 8de7696185c8..30ea1eb7ba18 100644\n--- a/tests/dragonfly/connection_test.py\n+++ b/tests/dragonfly/connection_test.py\n@@ -335,3 +335,14 @@ async def test_subscribe_pipelined(async_client: aioredis.Redis):\n     pipe.execute_command('subscribe channel').execute_command(\n         'subscribe channel')\n     await pipe.echo('bye bye').execute()\n+\n+async def test_subscribe_in_pipeline(async_client: aioredis.Redis):\n+    pipe = async_client.pipeline(transaction=False)\n+    pipe.echo(\"one\")\n+    pipe.execute_command(\"SUBSCRIBE ch1\")\n+    pipe.echo(\"two\")\n+    pipe.execute_command(\"SUBSCRIBE ch2\")\n+    pipe.echo(\"three\")\n+    res = await pipe.execute()\n+\n+    assert res == ['one', ['subscribe', 'ch1', 1], 'two', ['subscribe', 'ch2', 2], 'three']\n",
  "problem_statement": "PubSub out of order confirmations\nHi, congratulations on the release of 1.3.0! I am very excited about the new release.\r\n\r\nHowever, I found there is an out-of-order issue for the SUBSCRIBE/PSUBSCRIBE responses while testing the latest release with my RESP3 client (https://github.com/redis/rueidis) by the following code:\r\n\r\n```go\r\npackage main\r\n\r\nimport (\r\n\t\"context\"\r\n\t\"fmt\"\r\n\t\"github.com/redis/rueidis\"\r\n)\r\n\r\nfunc main() {\r\n\tclient, err := rueidis.NewClient(rueidis.ClientOption{\r\n\t\tInitAddress:  []string{\"127.0.0.1:6379\"},\r\n\t\tDisableCache: true,\r\n\t})\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tdefer client.Close()\r\n\tfor _, resp := range client.DoMulti(\r\n\t\tcontext.Background(),\r\n\t\tclient.B().Set().Key(\"key1\").Value(\"1\").Build(),\r\n\t\tclient.B().Get().Key(\"key1\").Build(),\r\n\t\tclient.B().Subscribe().Channel(\"ch1\").Build(),\r\n\t\tclient.B().Set().Key(\"key2\").Value(\"2\").Build(),\r\n\t\tclient.B().Get().Key(\"key2\").Build(),\r\n\t\tclient.B().Psubscribe().Pattern(\"ch2\").Build(),\r\n\t) {\r\n\t\tfmt.Println(resp.ToString())\r\n\t}\r\n}\r\n\r\n```\r\n\r\nThis code works will pipeline the following commands to the server in RESP3:\r\n```\r\nSET key1 1\r\nGET key1\r\nSUBSCRIBE ch1\r\nSET key2 2\r\nGET key2\r\nPSUBSCRIBE ch2\r\n```\r\n\r\nand it works well with the official redis but easily get failed on the dragonfly.\r\n\r\nThat is because the dragonfly sends responses in an out-of-order way:\r\n\r\n```\r\nredis:\r\n+ OK\r\n$ 1\r\n> subscribe ch1\r\n+ OK\r\n$ 2\r\n> psubscribe ch2\r\n```\r\n```\r\ndragonfly:\r\n+ OK\r\n$ 1\r\n+ OK\r\n$ 2\r\n> psubscribe ch2\r\n> subscribe ch1\r\n```\r\n\r\nI believe the out-of-order behavior is a bug because a SUBSCRIBE/PSUBSCRIBE/SSUBSCRIBE command may still result in an ERR response and the correct order is the only way to check if the command succeeded.\r\n\n",
  "hints_text": "@dranikpg  probably due to tx squashing. Can you please take a look?\r\n\r\n@rueian  I see you use `DoMulti` for performance reasons, but you could just use pipelining (without multi/exec). \r\nDo you also need atomicity semantics that come with `MULTI` ?\nHey @romange,\r\n\r\n`DoMulti` indeed just uses pipelining without multi/exec.\r\n\r\nI think in terms of the above case, there is no need for multi/exec. It is just a common scenario that normal commands and pubsub commands are mixed together in a RESP3 connection.\r\n\r\nHowever, since you mentioned, I also tried with multi/exec:\r\n\r\n```go\r\npackage main\r\n\r\nimport (\r\n\t\"context\"\r\n\t\"fmt\"\r\n\t\"github.com/redis/rueidis\"\r\n)\r\n\r\nfunc main() {\r\n\tclient, err := rueidis.NewClient(rueidis.ClientOption{\r\n\t\tInitAddress:  []string{\"127.0.0.1:6379\"},\r\n\t\tDisableCache: true,\r\n\t})\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tdefer client.Close()\r\n\ttx, err := client.DoMulti(\r\n\t\tcontext.Background(),\r\n\t\tclient.B().Multi().Build(),\r\n\t\tclient.B().Set().Key(\"key1\").Value(\"1\").Build(),\r\n\t\tclient.B().Get().Key(\"key1\").Build(),\r\n\t\tclient.B().Subscribe().Channel(\"ch1\").Build(),\r\n\t\tclient.B().Set().Key(\"key2\").Value(\"2\").Build(),\r\n\t\tclient.B().Get().Key(\"key2\").Build(),\r\n\t\tclient.B().Psubscribe().Pattern(\"ch2\").Build(),\r\n\t\tclient.B().Exec().Build(),\r\n\t)[7].ToArray()\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tfor _, resp := range tx {\r\n\t\tfmt.Println(resp)\r\n\t}\r\n}\r\n```\r\n\r\nThe above code sends:\r\n\r\n```\r\nMULTI\r\nSET key1 1\r\nGET key1\r\nSUBSCRIBE ch1\r\nSET key2 2\r\nGET key2\r\nPSUBSCRIBE ch2\r\nEXEC\r\n```\r\nand here is what a redis responds with:\r\n```\r\nredis:\r\n+ OK\r\n+ QUEUED\r\n+ QUEUED\r\n+ QUEUED\r\n+ QUEUED\r\n+ QUEUED\r\n+ QUEUED\r\n*\r\n  + OK\r\n  $ 1\r\n  > subscribe ch1\r\n  + OK\r\n  $ 2\r\n  > psubscribe ch2\r\n```\r\nand here is what a dragonfly responds with:\r\n```\r\ndragonfly:\r\n+ OK\r\n+ QUEUED\r\n+ QUEUED\r\n+ QUEUED\r\n+ QUEUED\r\n+ QUEUED\r\n+ QUEUED\r\n*\r\n  + OK\r\n  $ 1\r\n  + OK\r\n  $ 2\r\n  > psubscribe ch2\r\n  > subscribe ch1\r\n```\nThank you @rueian ! We will look into it.",
  "created_at": "2023-05-19T21:25:18Z",
  "modified_files": [
    "src/facade/conn_context.h",
    "src/facade/dragonfly_connection.cc",
    "src/facade/dragonfly_connection.h",
    "src/facade/facade.cc",
    "src/server/conn_context.cc",
    "src/server/conn_context.h",
    "src/server/main_service.cc"
  ],
  "modified_test_files": [
    "src/server/test_utils.cc",
    "src/server/test_utils.h",
    "tests/dragonfly/connection_test.py"
  ]
}