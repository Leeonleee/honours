{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 2735,
  "instance_id": "dragonflydb__dragonfly-2735",
  "issue_numbers": [
    "2734"
  ],
  "base_commit": "f7292de4e7d34ca54c03cd90b066bc65eac725bf",
  "patch": "diff --git a/src/server/cluster/cluster_family.cc b/src/server/cluster/cluster_family.cc\nindex e9e79134a187..8483c7606274 100644\n--- a/src/server/cluster/cluster_family.cc\n+++ b/src/server/cluster/cluster_family.cc\n@@ -89,13 +89,13 @@ ClusterShard ClusterFamily::GetEmulatedShardInfo(ConnectionContext* cntx) const\n                    .port = static_cast<uint16_t>(absl::GetFlag(FLAGS_port))};\n \n     for (const auto& replica : server_family_->GetDflyCmd()->GetReplicasRoleInfo()) {\n-      info.replicas.push_back({.id = etl.remote_client_id_,\n+      info.replicas.push_back({.id = replica.id,\n                                .ip = replica.address,\n                                .port = static_cast<uint16_t>(replica.listening_port)});\n     }\n   } else {\n-    info.master = {\n-        .id = etl.remote_client_id_, .ip = replication_info->host, .port = replication_info->port};\n+    // TODO: We currently don't save the master's ID in the replica\n+    info.master = {.id = \"\", .ip = replication_info->host, .port = replication_info->port};\n     info.replicas.push_back({.id = id_,\n                              .ip = cntx->conn()->LocalBindAddress(),\n                              .port = static_cast<uint16_t>(absl::GetFlag(FLAGS_port))});\ndiff --git a/src/server/dflycmd.cc b/src/server/dflycmd.cc\nindex 31ffa5cc2e88..efefbff705e0 100644\n--- a/src/server/dflycmd.cc\n+++ b/src/server/dflycmd.cc\n@@ -571,6 +571,20 @@ auto DflyCmd::CreateSyncSession(ConnectionContext* cntx)\n   return *it;\n }\n \n+auto DflyCmd::GetReplicaInfo(ConnectionContext* cntx) -> std::shared_ptr<ReplicaInfo> {\n+  if (cntx == nullptr) {\n+    return nullptr;\n+  }\n+\n+  unique_lock lk(mu_);\n+  auto it = replica_infos_.find(cntx->conn_state.replication_info.repl_session_id);\n+  if (it == replica_infos_.end()) {\n+    return nullptr;\n+  }\n+\n+  return it->second;\n+}\n+\n void DflyCmd::OnClose(ConnectionContext* cntx) {\n   unsigned session_id = cntx->conn_state.replication_info.repl_session_id;\n   if (!session_id)\n@@ -659,7 +673,8 @@ std::vector<ReplicaRoleInfo> DflyCmd::GetReplicasRoleInfo() const {\n     } else {\n       lag = std::numeric_limits<LSN>::max();\n     }\n-    vec.push_back(ReplicaRoleInfo{info->address, info->listening_port, SyncStateName(state), lag});\n+    vec.push_back(\n+        ReplicaRoleInfo{info->id, info->address, info->listening_port, SyncStateName(state), lag});\n   }\n   return vec;\n }\ndiff --git a/src/server/dflycmd.h b/src/server/dflycmd.h\nindex 1927df6cabd1..19d5297d5d16 100644\n--- a/src/server/dflycmd.h\n+++ b/src/server/dflycmd.h\n@@ -114,6 +114,7 @@ class DflyCmd {\n     SyncState replica_state;  // always guarded by ReplicaInfo::mu\n     Context cntx;\n \n+    std::string id;\n     std::string address;\n     uint32_t listening_port;\n     DflyVersion version = DflyVersion::VER0;\n@@ -139,6 +140,8 @@ class DflyCmd {\n   // Create new sync session.\n   std::pair<uint32_t, std::shared_ptr<ReplicaInfo>> CreateSyncSession(ConnectionContext* cntx);\n \n+  std::shared_ptr<ReplicaInfo> GetReplicaInfo(ConnectionContext* cntx);\n+\n   std::vector<ReplicaRoleInfo> GetReplicasRoleInfo() const;\n \n   void GetReplicationMemoryStats(ReplicationMemoryStats* out) const;\ndiff --git a/src/server/server_family.cc b/src/server/server_family.cc\nindex 41aaf52d3920..df245afe5dd9 100644\n--- a/src/server/server_family.cc\n+++ b/src/server/server_family.cc\n@@ -2460,10 +2460,11 @@ void ServerFamily::ReplConf(CmdArgList args, ConnectionContext* cntx) {\n       }\n       cntx->conn_state.replication_info.repl_listening_port = replica_listening_port;\n     } else if (cmd == \"CLIENT-ID\" && args.size() == 2) {\n-      std::string client_id{arg};\n-      auto& pool = service_.proactor_pool();\n-      pool.AwaitFiberOnAll(\n-          [&](util::ProactorBase* pb) { ServerState::tlocal()->remote_client_id_ = arg; });\n+      auto info = dfly_cmd_->GetReplicaInfo(cntx);\n+      DCHECK(info != nullptr);\n+      if (info) {\n+        info->id = arg;\n+      }\n     } else if (cmd == \"CLIENT-VERSION\" && args.size() == 2) {\n       unsigned version;\n       if (!absl::SimpleAtoi(arg, &version)) {\ndiff --git a/src/server/server_family.h b/src/server/server_family.h\nindex a33c05b62cea..7975b2205b0a 100644\n--- a/src/server/server_family.h\n+++ b/src/server/server_family.h\n@@ -52,6 +52,7 @@ class Service;\n class ScriptMgr;\n \n struct ReplicaRoleInfo {\n+  std::string id;\n   std::string address;\n   uint32_t listening_port;\n   std::string_view state;\ndiff --git a/src/server/server_state.h b/src/server/server_state.h\nindex 7d575cf0aaa7..85408b028622 100644\n--- a/src/server/server_state.h\n+++ b/src/server/server_state.h\n@@ -245,7 +245,6 @@ class ServerState {  // public struct - to allow initialization.\n   Stats stats;\n \n   bool is_master = true;\n-  std::string remote_client_id_;  // for cluster support\n   uint32_t log_slower_than_usec = UINT32_MAX;\n \n   acl::UserRegistry* user_registry;\n",
  "test_patch": "diff --git a/tests/dragonfly/cluster_test.py b/tests/dragonfly/cluster_test.py\nindex 684d2a6dd49f..901c49454c9c 100644\n--- a/tests/dragonfly/cluster_test.py\n+++ b/tests/dragonfly/cluster_test.py\n@@ -4,6 +4,7 @@\n import redis\n from redis import asyncio as aioredis\n import asyncio\n+from dataclasses import dataclass\n \n from .instance import DflyInstanceFactory, DflyInstance\n from .utility import *\n@@ -69,61 +70,120 @@ def test_cluster_slots_command(self, df_server, cluster_client: redis.RedisClust\n         assert expected == res\n \n \n-def verify_slots_result(\n-    ip: str, port: int, answer: list, rep_ip: str = None, rep_port: int = None\n-) -> bool:\n+@dataclass\n+class ReplicaInfo:\n+    id: string\n+    port: int\n+\n+\n+def verify_slots_result(port: int, answer: list, replicas) -> bool:\n     def is_local_host(ip: str) -> bool:\n         return ip == \"127.0.0.1\" or ip == \"localhost\"\n \n     assert answer[0] == 0  # start shard\n     assert answer[1] == 16383  # last shard\n-    if rep_ip is not None:\n-        assert len(answer) == 4  # the network info\n-        rep_info = answer[3]\n-        assert len(rep_info) == 3\n-        ip_addr = str(rep_info[0], \"utf-8\")\n-        assert ip_addr == rep_ip or (is_local_host(ip_addr) and is_local_host(ip))\n-        assert rep_info[1] == rep_port\n-    else:\n-        assert len(answer) == 3\n+\n     info = answer[2]\n     assert len(info) == 3\n     ip_addr = str(info[0], \"utf-8\")\n-    assert ip_addr == ip or (is_local_host(ip_addr) and is_local_host(ip))\n+    assert is_local_host(ip_addr)\n     assert info[1] == port\n+\n+    # Replicas\n+    assert len(answer) == 3 + len(replicas)\n+    for i in range(3, len(replicas)):\n+        replica = replicas[i - 3]\n+        rep_info = answer[i]\n+        assert len(rep_info) == 3\n+        ip_addr = str(rep_info[0], \"utf-8\")\n+        assert is_local_host(ip_addr)\n+        assert rep_info[1] == replica.port\n+        assert rep_info[2] == replica.id\n+\n     return True\n \n \n @dfly_args({\"proactor_threads\": 4, \"cluster_mode\": \"emulated\"})\n-async def test_cluster_slots_in_replicas(df_local_factory):\n+async def test_emulated_cluster_with_replicas(df_local_factory):\n     master = df_local_factory.create(port=BASE_PORT)\n-    replica = df_local_factory.create(port=BASE_PORT + 1, logtostdout=True)\n+    replicas = [df_local_factory.create(port=BASE_PORT + i, logtostdout=True) for i in range(1, 3)]\n \n-    df_local_factory.start_all([master, replica])\n+    df_local_factory.start_all([master, *replicas])\n \n     c_master = aioredis.Redis(port=master.port)\n-    c_replica = aioredis.Redis(port=replica.port)\n+    master_id = (await c_master.execute_command(\"dflycluster myid\")).decode(\"utf-8\")\n+\n+    c_replicas = [aioredis.Redis(port=replica.port) for replica in replicas]\n+    replica_ids = [\n+        (await c_replica.execute_command(\"dflycluster myid\")).decode(\"utf-8\")\n+        for c_replica in c_replicas\n+    ]\n+\n+    for replica, c_replica in zip(replicas, c_replicas):\n+        res = await c_replica.execute_command(\"CLUSTER SLOTS\")\n+        assert len(res) == 1\n+        assert verify_slots_result(port=replica.port, answer=res[0], replicas=[])\n \n-    res = await c_replica.execute_command(\"CLUSTER SLOTS\")\n-    assert len(res) == 1\n-    assert verify_slots_result(ip=\"127.0.0.1\", port=replica.port, answer=res[0])\n     res = await c_master.execute_command(\"CLUSTER SLOTS\")\n-    assert verify_slots_result(ip=\"127.0.0.1\", port=master.port, answer=res[0])\n+    assert verify_slots_result(port=master.port, answer=res[0], replicas=[])\n+\n+    # Connect replicas to master\n+    for replica, c_replica in zip(replicas, c_replicas):\n+        rc = await c_replica.execute_command(f\"REPLICAOF localhost {master.port}\")\n+        assert str(rc, \"utf-8\") == \"OK\"\n \n-    # Connect replica to master\n-    rc = await c_replica.execute_command(f\"REPLICAOF localhost {master.port}\")\n-    assert str(rc, \"utf-8\") == \"OK\"\n     await asyncio.sleep(0.5)\n-    res = await c_replica.execute_command(\"CLUSTER SLOTS\")\n-    assert verify_slots_result(\n-        ip=\"127.0.0.1\", port=master.port, answer=res[0], rep_ip=\"127.0.0.1\", rep_port=replica.port\n-    )\n+\n+    for replica, c_replica in zip(replicas, c_replicas):\n+        res = await c_replica.execute_command(\"CLUSTER SLOTS\")\n+        assert verify_slots_result(\n+            port=master.port, answer=res[0], replicas=[ReplicaInfo(replica.port, id)]\n+        )\n+\n     res = await c_master.execute_command(\"CLUSTER SLOTS\")\n     assert verify_slots_result(\n-        ip=\"127.0.0.1\", port=master.port, answer=res[0], rep_ip=\"127.0.0.1\", rep_port=replica.port\n+        port=master.port,\n+        answer=res[0],\n+        replicas=[ReplicaInfo(id, replica.port) for id, replica in zip(replica_ids, replicas)],\n     )\n \n-    await close_clients(c_master, c_replica)\n+    assert await c_master.execute_command(\"CLUSTER NODES\") == {\n+        f\"127.0.0.1:{master.port}\": {\n+            \"connected\": True,\n+            \"epoch\": \"0\",\n+            \"flags\": \"myself,master\",\n+            \"last_ping_sent\": \"0\",\n+            \"last_pong_rcvd\": \"0\",\n+            \"master_id\": \"-\",\n+            \"migrations\": [],\n+            \"node_id\": master_id,\n+            \"slots\": [[\"0\", \"16383\"]],\n+        },\n+        f\"127.0.0.1:{replicas[0].port}\": {\n+            \"connected\": True,\n+            \"epoch\": \"0\",\n+            \"flags\": \"slave\",\n+            \"last_ping_sent\": \"0\",\n+            \"last_pong_rcvd\": \"0\",\n+            \"master_id\": master_id,\n+            \"migrations\": [],\n+            \"node_id\": replica_ids[0],\n+            \"slots\": [],\n+        },\n+        f\"127.0.0.1:{replicas[1].port}\": {\n+            \"connected\": True,\n+            \"epoch\": \"0\",\n+            \"flags\": \"slave\",\n+            \"last_ping_sent\": \"0\",\n+            \"last_pong_rcvd\": \"0\",\n+            \"master_id\": master_id,\n+            \"migrations\": [],\n+            \"node_id\": replica_ids[1],\n+            \"slots\": [],\n+        },\n+    }\n+\n+    await close_clients(c_master, *c_replicas)\n \n \n @dfly_args({\"cluster_mode\": \"emulated\", \"cluster_announce_ip\": \"127.0.0.2\"})\n@@ -966,9 +1026,6 @@ async def test_cluster_data_migration(df_local_factory: DflyInstanceFactory):\n     await close_clients(*c_nodes, *c_nodes_admin)\n \n \n-from dataclasses import dataclass\n-\n-\n @dataclass\n class NodeInfo:\n     instance: DflyInstance\ndiff --git a/tests/dragonfly/conftest.py b/tests/dragonfly/conftest.py\nindex 05439cb131a2..bd426d746db8 100644\n--- a/tests/dragonfly/conftest.py\n+++ b/tests/dragonfly/conftest.py\n@@ -340,14 +340,15 @@ def copy_failed_logs_and_clean_tmp_folder(report):\n     if not path_exists:\n         os.makedirs(failed_path)\n \n-    last_log_file = open(\"/tmp/last_test_log_files.txt\", \"r\")\n-    files = last_log_file.readlines()\n-    logging.error(f\"Test failed {report.nodeid} with logs: \")\n-    for file in files:\n-        # copy to failed folder\n-        file = file.rstrip(\"\\n\")\n-        logging.error(f\"\ud83e\udeb5\ud83e\udeb5\ud83e\udeb5\ud83e\udeb5\ud83e\udeb5\ud83e\udeb5 {file} \ud83e\udeb5\ud83e\udeb5\ud83e\udeb5\ud83e\udeb5\ud83e\udeb5\ud83e\udeb5\")\n-        shutil.copy(file, failed_path)\n+    if os.path.isfile(\"/tmp/last_test_log_files.txt\"):\n+        last_log_file = open(\"/tmp/last_test_log_files.txt\", \"r\")\n+        files = last_log_file.readlines()\n+        logging.error(f\"Test failed {report.nodeid} with logs: \")\n+        for file in files:\n+            # copy to failed folder\n+            file = file.rstrip(\"\\n\")\n+            logging.error(f\"\ud83e\udeb5\ud83e\udeb5\ud83e\udeb5\ud83e\udeb5\ud83e\udeb5\ud83e\udeb5 {file} \ud83e\udeb5\ud83e\udeb5\ud83e\udeb5\ud83e\udeb5\ud83e\udeb5\ud83e\udeb5\")\n+            shutil.copy(file, failed_path)\n \n \n def pytest_exception_interact(node, call, report):\n",
  "problem_statement": "Masters override replica's ID\nAs seen in #2726, we currently only save 1 replica ID per master.\r\nThis is a bug, as there could be multiple replicas connected to a single master. In that case, today, we falsely send the latest connected replica id in `CLUSTER NODES`.\n",
  "hints_text": "",
  "created_at": "2024-03-17T10:43:08Z",
  "modified_files": [
    "src/server/cluster/cluster_family.cc",
    "src/server/dflycmd.cc",
    "src/server/dflycmd.h",
    "src/server/server_family.cc",
    "src/server/server_family.h",
    "src/server/server_state.h"
  ],
  "modified_test_files": [
    "tests/dragonfly/cluster_test.py",
    "tests/dragonfly/conftest.py"
  ]
}