{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 3514,
  "instance_id": "dragonflydb__dragonfly-3514",
  "issue_numbers": [
    "3504"
  ],
  "base_commit": "86e79e13c55f8b2687d29176e4db2fd6a8547b76",
  "patch": "diff --git a/src/core/compact_object.cc b/src/core/compact_object.cc\nindex dc8fbfc7fdbb..6d7db4ae1895 100644\n--- a/src/core/compact_object.cc\n+++ b/src/core/compact_object.cc\n@@ -574,6 +574,12 @@ size_t CompactObj::Size() const {\n       case ROBJ_TAG:\n         raw_size = u_.r_obj.Size();\n         break;\n+      case JSON_TAG:\n+        raw_size = u_.json_obj.json_len;\n+        break;\n+      case SBF_TAG:\n+        raw_size = u_.sbf->current_size();\n+        break;\n       default:\n         LOG(DFATAL) << \"Should not reach \" << int(taglen_);\n     }\n@@ -684,9 +690,11 @@ void CompactObj::SetJson(JsonType&& j) {\n   if (taglen_ == JSON_TAG && u_.json_obj.encoding == kEncodingJsonCons) {\n     // already json\n     DCHECK(u_.json_obj.json_ptr != nullptr);  // must be allocated\n+    u_.json_obj.json_len = j.size();\n     u_.json_obj.json_ptr->swap(j);\n   } else {\n     SetMeta(JSON_TAG);\n+    u_.json_obj.json_len = j.size();\n     u_.json_obj.json_ptr = AllocateMR<JsonType>(std::move(j));\n     u_.json_obj.encoding = kEncodingJsonCons;\n   }\n@@ -842,6 +850,11 @@ bool CompactObj::HasAllocated() const {\n   return true;\n }\n \n+bool CompactObj::TagAllowsEmptyValue() const {\n+  const auto type = ObjType();\n+  return type == OBJ_JSON || type == OBJ_STREAM || type == OBJ_STRING || type == OBJ_SBF;\n+}\n+\n void __attribute__((noinline)) CompactObj::GetString(string* res) const {\n   res->resize(Size());\n   GetString(res->data());\ndiff --git a/src/core/compact_object.h b/src/core/compact_object.h\nindex 1dcb0aa72528..fb50ae6ca1c5 100644\n--- a/src/core/compact_object.h\n+++ b/src/core/compact_object.h\n@@ -398,6 +398,12 @@ class CompactObj {\n \n   bool HasAllocated() const;\n \n+  bool TagAllowsEmptyValue() const;\n+\n+  uint8_t Tag() const {\n+    return taglen_;\n+  }\n+\n  private:\n   void EncodeString(std::string_view str);\n   size_t DecodedLen(size_t sz) const;\ndiff --git a/src/server/container_utils.cc b/src/server/container_utils.cc\nindex aea658012f8c..14eca9bbc274 100644\n--- a/src/server/container_utils.cc\n+++ b/src/server/container_utils.cc\n@@ -34,7 +34,7 @@ struct ShardFFResult {\n \n // Returns (iterator, args-index) if found, KEY_NOTFOUND otherwise.\n // If multiple keys are found, returns the first index in the ArgSlice.\n-OpResult<std::pair<DbSlice::ConstIterator, unsigned>> FindFirstReadOnly(const DbSlice& db_slice,\n+OpResult<std::pair<DbSlice::ConstIterator, unsigned>> FindFirstReadOnly(DbSlice& db_slice,\n                                                                         const DbContext& cntx,\n                                                                         const ShardArgs& args,\n                                                                         int req_obj_type) {\ndiff --git a/src/server/db_slice.cc b/src/server/db_slice.cc\nindex d19dbba6edc2..ec36fd55ba8c 100644\n--- a/src/server/db_slice.cc\n+++ b/src/server/db_slice.cc\n@@ -426,14 +426,25 @@ OpResult<DbSlice::ItAndUpdater> DbSlice::FindMutableInternal(const Context& cntx\n   }\n }\n \n-DbSlice::ItAndExpConst DbSlice::FindReadOnly(const Context& cntx, std::string_view key) const {\n+bool DbSlice::DelEmptyPrimeValue(const Context& cntx, Iterator it) {\n+  auto& pv = it->second;\n+  if (!pv.TagAllowsEmptyValue() && pv.Size() == 0) {\n+    auto key = it.key();\n+    LOG(ERROR) << \"Found empty key: \" << key << \" with obj type \" << pv.ObjType();\n+    Del(cntx, it);\n+    return true;\n+  }\n+  return false;\n+}\n+\n+DbSlice::ItAndExpConst DbSlice::FindReadOnly(const Context& cntx, std::string_view key) {\n   auto res = FindInternal(cntx, key, std::nullopt, UpdateStatsMode::kReadStats);\n   return {ConstIterator(res->it, StringOrView::FromView(key)),\n           ExpConstIterator(res->exp_it, StringOrView::FromView(key))};\n }\n \n OpResult<DbSlice::ConstIterator> DbSlice::FindReadOnly(const Context& cntx, string_view key,\n-                                                       unsigned req_obj_type) const {\n+                                                       unsigned req_obj_type) {\n   auto res = FindInternal(cntx, key, req_obj_type, UpdateStatsMode::kReadStats);\n   if (res.ok()) {\n     return ConstIterator(res->it, StringOrView::FromView(key));\n@@ -443,7 +454,7 @@ OpResult<DbSlice::ConstIterator> DbSlice::FindReadOnly(const Context& cntx, stri\n \n OpResult<DbSlice::PrimeItAndExp> DbSlice::FindInternal(const Context& cntx, std::string_view key,\n                                                        std::optional<unsigned> req_obj_type,\n-                                                       UpdateStatsMode stats_mode) const {\n+                                                       UpdateStatsMode stats_mode) {\n   if (!IsDbValid(cntx.db_index)) {\n     return OpStatus::KEY_NOTFOUND;\n   }\n@@ -537,6 +548,9 @@ OpResult<DbSlice::PrimeItAndExp> DbSlice::FindInternal(const Context& cntx, std:\n   // We do not use TopKey feature, so disable it until we redesign it.\n   // db.top_keys.Touch(key);\n \n+  if (DelEmptyPrimeValue(cntx, Iterator(res.it, StringOrView::FromView(key)))) {\n+    return OpStatus::KEY_NOTFOUND;\n+  }\n   return res;\n }\n \ndiff --git a/src/server/db_slice.h b/src/server/db_slice.h\nindex f741018eb093..af13788dfb5c 100644\n--- a/src/server/db_slice.h\n+++ b/src/server/db_slice.h\n@@ -292,9 +292,9 @@ class DbSlice {\n     ExpConstIterator exp_it;\n   };\n \n-  ItAndExpConst FindReadOnly(const Context& cntx, std::string_view key) const;\n+  ItAndExpConst FindReadOnly(const Context& cntx, std::string_view key);\n   OpResult<ConstIterator> FindReadOnly(const Context& cntx, std::string_view key,\n-                                       unsigned req_obj_type) const;\n+                                       unsigned req_obj_type);\n \n   struct AddOrFindResult {\n     Iterator it;\n@@ -515,6 +515,8 @@ class DbSlice {\n   void PreUpdate(DbIndex db_ind, Iterator it, std::string_view key);\n   void PostUpdate(DbIndex db_ind, Iterator it, std::string_view key, size_t orig_size);\n \n+  bool DelEmptyPrimeValue(const Context& cntx, Iterator it);\n+\n   OpResult<AddOrFindResult> AddOrUpdateInternal(const Context& cntx, std::string_view key,\n                                                 PrimeValue obj, uint64_t expire_at_ms,\n                                                 bool force_update);\n@@ -555,7 +557,7 @@ class DbSlice {\n \n   OpResult<PrimeItAndExp> FindInternal(const Context& cntx, std::string_view key,\n                                        std::optional<unsigned> req_obj_type,\n-                                       UpdateStatsMode stats_mode) const;\n+                                       UpdateStatsMode stats_mode);\n   OpResult<ItAndUpdater> FindMutableInternal(const Context& cntx, std::string_view key,\n                                              std::optional<unsigned> req_obj_type);\n \ndiff --git a/src/server/rdb_load.cc b/src/server/rdb_load.cc\nindex a4b25b31c0d2..be12324ff87a 100644\n--- a/src/server/rdb_load.cc\n+++ b/src/server/rdb_load.cc\n@@ -2465,10 +2465,21 @@ void RdbLoader::LoadItemsBuffer(DbIndex db_ind, const ItemsBuf& ib) {\n   for (const auto* item : ib) {\n     PrimeValue pv;\n     if (ec_ = FromOpaque(item->val, &pv); ec_) {\n+      if ((*ec_).value() == errc::empty_key) {\n+        LOG(ERROR) << \"Found empty key: \" << item->key << \" in DB \" << db_ind << \" rdb_type \"\n+                   << item->val.rdb_type;\n+        continue;\n+      }\n       LOG(ERROR) << \"Could not load value for key '\" << item->key << \"' in DB \" << db_ind;\n       stop_early_ = true;\n       break;\n     }\n+    // We need this extra check because we don't return empty_key\n+    if (!pv.TagAllowsEmptyValue() && pv.Size() == 0) {\n+      LOG(ERROR) << \"Found empty key: \" << item->key << \" in DB \" << db_ind << \" rdb_type \"\n+                 << item->val.rdb_type;\n+      continue;\n+    }\n \n     if (item->expire_ms > 0 && db_cntx.time_now_ms >= item->expire_ms)\n       continue;\ndiff --git a/src/server/rdb_load.h b/src/server/rdb_load.h\nindex 3eafe91e1f73..caf71d4a13ef 100644\n--- a/src/server/rdb_load.h\n+++ b/src/server/rdb_load.h\n@@ -59,7 +59,7 @@ class RdbLoaderBase {\n \n   struct OpaqueObj {\n     RdbVariant obj;\n-    int rdb_type;\n+    int rdb_type{0};\n   };\n \n   struct LoadBlob {\ndiff --git a/src/server/rdb_save.cc b/src/server/rdb_save.cc\nindex d5d7ce906383..12f6297f5970 100644\n--- a/src/server/rdb_save.cc\n+++ b/src/server/rdb_save.cc\n@@ -337,6 +337,13 @@ error_code RdbSerializer::SelectDb(uint32_t dbid) {\n // Called by snapshot\n io::Result<uint8_t> RdbSerializer::SaveEntry(const PrimeKey& pk, const PrimeValue& pv,\n                                              uint64_t expire_ms, DbIndex dbid) {\n+  if (!pv.TagAllowsEmptyValue() && pv.Size() == 0) {\n+    string_view key = pk.GetSlice(&tmp_str_);\n+    LOG(ERROR) << \"SaveEntry skipped empty PrimeValue with key: \" << key << \" with tag \"\n+               << pv.Tag();\n+    return 0;\n+  }\n+\n   DVLOG(3) << \"Selecting \" << dbid << \" previous: \" << last_entry_db_index_;\n   SelectDb(dbid);\n \n@@ -357,9 +364,9 @@ io::Result<uint8_t> RdbSerializer::SaveEntry(const PrimeKey& pk, const PrimeValu\n       return make_unexpected(ec);\n   }\n \n-  string_view key = pk.GetSlice(&tmp_str_);\n   uint8_t rdb_type = RdbObjectType(pv);\n \n+  string_view key = pk.GetSlice(&tmp_str_);\n   DVLOG(3) << ((void*)this) << \": Saving key/val start \" << key << \" in dbid=\" << dbid;\n \n   if (auto ec = WriteOpcode(rdb_type); ec)\n",
  "test_patch": "diff --git a/tests/dragonfly/hash_family_test.py b/tests/dragonfly/hash_family_test.py\nnew file mode 100644\nindex 000000000000..d09a05988339\n--- /dev/null\n+++ b/tests/dragonfly/hash_family_test.py\n@@ -0,0 +1,19 @@\n+import pytest\n+import asyncio\n+from .utility import *\n+\n+\n+@pytest.mark.asyncio\n+async def test_empty_hash_as_zipmap_bug(async_client):\n+    await async_client.execute_command(\"HSET foo a_field a_value\")\n+    await async_client.execute_command(\"HSETEX foo 1 b_field b_value\")\n+    await async_client.execute_command(\"HDEL foo a_field\")\n+\n+    @assert_eventually\n+    async def check_if_empty():\n+        assert await async_client.execute_command(\"HGETALL foo\") == []\n+\n+    await check_if_empty()\n+\n+    # Key does not exist and it's empty\n+    assert await async_client.execute_command(f\"EXISTS foo\") == 0\ndiff --git a/tests/dragonfly/instance.py b/tests/dragonfly/instance.py\nindex 852983159628..4d316cff6f99 100644\n--- a/tests/dragonfly/instance.py\n+++ b/tests/dragonfly/instance.py\n@@ -349,7 +349,7 @@ def create(self, existing_port=None, path=None, version=100, **kwargs) -> DflyIn\n             # Add 1 byte limit for big values\n             args.setdefault(\"serialization_max_chunk_size\", 1)\n \n-        if version >= 1.21:\n+        if version > 1.21:\n             args.setdefault(\"use_new_io\")\n \n         for k, v in args.items():\ndiff --git a/tests/dragonfly/replication_test.py b/tests/dragonfly/replication_test.py\nindex 763ab6a46674..c56bab1f62c8 100644\n--- a/tests/dragonfly/replication_test.py\n+++ b/tests/dragonfly/replication_test.py\n@@ -1,4 +1,5 @@\n import random\n+\n from itertools import chain, repeat\n import re\n import pytest\n@@ -28,12 +29,12 @@\n M_STRESS = [pytest.mark.slow, pytest.mark.opt_only]\n \n \n-async def wait_for_replicas_state(*clients, state=\"online\", timeout=0.05):\n+async def wait_for_replicas_state(*clients, state=\"online\", node_role=\"slave\", timeout=0.05):\n     \"\"\"Wait until all clients (replicas) reach passed state\"\"\"\n     while len(clients) > 0:\n         await asyncio.sleep(timeout)\n         roles = await asyncio.gather(*(c.role() for c in clients))\n-        clients = [c for c, role in zip(clients, roles) if role[0] != \"slave\" or role[3] != state]\n+        clients = [c for c, role in zip(clients, roles) if role[0] != node_role or role[3] != state]\n \n \n \"\"\"\n@@ -2410,3 +2411,103 @@ async def test_replicate_old_master(\n     assert await c_replica.execute_command(\"get\", \"k1\") == \"v1\"\n \n     await disconnect_clients(c_master, c_replica)\n+\n+\n+# This Test was intorduced in response to a bug when replicating empty hashmaps (encoded as\n+# ziplists) created with HSET, HSETEX, HDEL and then replicated 2 times.\n+# For more information plz refer to the issue on gh:\n+# https://github.com/dragonflydb/dragonfly/issues/3504\n+@dfly_args({\"proactor_threads\": 1})\n+@pytest.mark.asyncio\n+async def test_empty_hash_map_replicate_old_master(df_factory):\n+    cpu = platform.processor()\n+    if cpu != \"x86_64\":\n+        pytest.skip(f\"Supported only on x64, running on {cpu}\")\n+\n+    dfly_version = \"v1.21.2\"\n+    released_dfly_path = download_dragonfly_release(dfly_version)\n+    # old versions\n+    instances = [df_factory.create(path=released_dfly_path, version=1.21) for i in range(3)]\n+    # new version\n+    instances.append(df_factory.create())\n+\n+    df_factory.start_all(instances)\n+\n+    old_c_master = instances[0].client()\n+    # Create an empty hashmap\n+    await old_c_master.execute_command(\"HSET foo a_field a_value\")\n+    await old_c_master.execute_command(\"HSETEX foo 2 b_field b_value\")\n+    await old_c_master.execute_command(\"HDEL foo a_field\")\n+\n+    @assert_eventually\n+    async def check_if_empty():\n+        assert await old_c_master.execute_command(\"HGETALL foo\") == []\n+\n+    await check_if_empty()\n+    assert await old_c_master.execute_command(f\"EXISTS foo\") == 1\n+    await old_c_master.close()\n+\n+    async def assert_body(client, result=1, state=\"online\", node_role=\"slave\"):\n+        async with async_timeout.timeout(10):\n+            await wait_for_replicas_state(client, state=state, node_role=node_role)\n+\n+        assert await client.execute_command(f\"EXISTS foo\") == result\n+        assert await client.execute_command(\"REPLTAKEOVER 1\") == \"OK\"\n+\n+    index = 0\n+    last_old_replica = 2\n+\n+    # Adjacent pairs\n+    for a, b in zip(instances, instances[1:]):\n+        logging.debug(index)\n+        client_b = b.client()\n+        assert await client_b.execute_command(f\"REPLICAOF localhost {a.port}\") == \"OK\"\n+\n+        if index != last_old_replica:\n+            await assert_body(client_b, state=\"stable_sync\", node_role=\"replica\")\n+        else:\n+            await assert_body(client_b, result=0)\n+\n+        index = index + 1\n+        await client_b.close()\n+\n+\n+# This Test was intorduced in response to a bug when replicating empty hash maps with\n+# HSET, HSETEX, HDEL and then loaded via replication.\n+# For more information plz refer to the issue on gh:\n+# https://github.com/dragonflydb/dragonfly/issues/3504\n+@dfly_args({\"proactor_threads\": 1})\n+@pytest.mark.asyncio\n+async def test_empty_hashmap_loading_bug(df_factory: DflyInstanceFactory):\n+    cpu = platform.processor()\n+    if cpu != \"x86_64\":\n+        pytest.skip(f\"Supported only on x64, running on {cpu}\")\n+\n+    dfly_version = \"v1.21.2\"\n+    released_dfly_path = download_dragonfly_release(dfly_version)\n+\n+    master = df_factory.create(path=released_dfly_path, version=1.21)\n+    master.start()\n+\n+    c_master = master.client()\n+    # Create an empty hashmap\n+    await c_master.execute_command(\"HSET foo a_field a_value\")\n+    await c_master.execute_command(\"HSETEX foo 2 b_field b_value\")\n+    await c_master.execute_command(\"HDEL foo a_field\")\n+\n+    @assert_eventually\n+    async def check_if_empty():\n+        assert await c_master.execute_command(\"HGETALL foo\") == []\n+\n+    await check_if_empty()\n+    assert await c_master.execute_command(f\"EXISTS foo\") == 1\n+\n+    replica = df_factory.create()\n+    replica.start()\n+    c_replica = replica.client()\n+\n+    await c_replica.execute_command(f\"REPLICAOF localhost {master.port}\")\n+    await wait_for_replicas_state(c_replica)\n+    assert await c_replica.execute_command(f\"dbsize\") == 0\n+\n+    await close_clients(c_master, c_replica)\n",
  "problem_statement": "Allow loading empty objects\nToday we reject loading empty objects, as logically they should never exist in the first place.\r\nHowever, there are examples in which empty objects could exist (due to per-element expiration), which we should handle:\r\n\r\n1. Get an empty StringMap on node A\r\n2. Replicate A to node B, we have also a StringMap there, but with expiration_used_ = false\r\n3. Replica B to A, it will be loaded as a listpack as we don't have info about expiration\r\n4. We have an empty listpack on A, replicate again to B\r\n\r\nWe should take the following actions:\r\n\r\n- [ ] Create some function to determine, for all object types, if they are empty (string, hashmap, list, etc)\r\n- [ ] Do not serialize empty objects to replica/rdb\r\n- [ ] In `DbSlice` API (`Find`, `AddOrFind`, ...) check if objects are empty. If so, remove them.\r\n- [ ] When loading (replica/rdb), check if the loaded object is empty, and if so do not add it to the data store\n",
  "hints_text": "",
  "created_at": "2024-08-14T14:12:16Z",
  "modified_files": [
    "src/core/compact_object.cc",
    "src/core/compact_object.h",
    "src/server/container_utils.cc",
    "src/server/db_slice.cc",
    "src/server/db_slice.h",
    "src/server/rdb_load.cc",
    "src/server/rdb_load.h",
    "src/server/rdb_save.cc"
  ],
  "modified_test_files": [
    "b/tests/dragonfly/hash_family_test.py",
    "tests/dragonfly/instance.py",
    "tests/dragonfly/replication_test.py"
  ]
}