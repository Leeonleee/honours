{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 2992,
  "instance_id": "dragonflydb__dragonfly-2992",
  "issue_numbers": [
    "2968"
  ],
  "base_commit": "07d076a658f85bc8ba199606361945571ba5c9ed",
  "patch": "diff --git a/src/server/cluster/cluster_family.cc b/src/server/cluster/cluster_family.cc\nindex 3f7facd85c47..5c1349428266 100644\n--- a/src/server/cluster/cluster_family.cc\n+++ b/src/server/cluster/cluster_family.cc\n@@ -814,8 +814,7 @@ bool RemoveIncomingMigrationImpl(std::vector<std::shared_ptr<IncomingSlotMigrati\n void ClusterFamily::RemoveIncomingMigrations(const std::vector<MigrationInfo>& migrations) {\n   lock_guard lk(migration_mu_);\n   for (const auto& m : migrations) {\n-    auto was_removed = RemoveIncomingMigrationImpl(incoming_migrations_jobs_, m.node_id);\n-    DCHECK(was_removed);\n+    RemoveIncomingMigrationImpl(incoming_migrations_jobs_, m.node_id);\n     VLOG(1) << \"Migration was canceled from: \" << m.node_id;\n   }\n }\n@@ -835,6 +834,17 @@ void ClusterFamily::InitMigration(CmdArgList args, ConnectionContext* cntx) {\n   if (auto err = parser.Error(); err)\n     return cntx->SendError(err->MakeReply());\n \n+  const auto& incoming_migrations = cluster_config()->GetIncomingMigrations();\n+  bool found = any_of(incoming_migrations.begin(), incoming_migrations.end(),\n+                      [&](const MigrationInfo& info) {\n+                        // TODO: also compare slot ranges (in an order-agnostic way)\n+                        return info.node_id == source_id;\n+                      });\n+  if (!found) {\n+    VLOG(1) << \"Unrecognized incoming migration from \" << source_id;\n+    return cntx->SendError(OutgoingMigration::kUnknownMigration);\n+  }\n+\n   VLOG(1) << \"Init migration \" << source_id;\n \n   lock_guard lk(migration_mu_);\ndiff --git a/src/server/cluster/incoming_slot_migration.cc b/src/server/cluster/incoming_slot_migration.cc\nindex cee46f422db6..c4b959b6d57d 100644\n--- a/src/server/cluster/incoming_slot_migration.cc\n+++ b/src/server/cluster/incoming_slot_migration.cc\n@@ -109,7 +109,7 @@ IncomingSlotMigration::IncomingSlotMigration(string source_id, Service* se, Slot\n       service_(*se),\n       slots_(std::move(slots)),\n       state_(MigrationState::C_CONNECTING),\n-      bc_(shards_num) {\n+      bc_(0) {\n   shard_flows_.resize(shards_num);\n   for (unsigned i = 0; i < shards_num; ++i) {\n     shard_flows_[i].reset(new ClusterShardMigration(i, &service_));\n@@ -137,6 +137,7 @@ void IncomingSlotMigration::StartFlow(uint32_t shard, util::FiberSocketBase* sou\n   VLOG(1) << \"Start flow for shard: \" << shard;\n   state_.store(MigrationState::C_SYNC);\n \n+  bc_->Add();\n   shard_flows_[shard]->Start(&cntx_, source, bc_);\n }\n \ndiff --git a/src/server/cluster/outgoing_slot_migration.cc b/src/server/cluster/outgoing_slot_migration.cc\nindex ba9a6b7c8662..14efc8de2412 100644\n--- a/src/server/cluster/outgoing_slot_migration.cc\n+++ b/src/server/cluster/outgoing_slot_migration.cc\n@@ -57,11 +57,17 @@ class OutgoingMigration::SliceSlotMigration : private ProtocolClient {\n       return;\n     }\n \n+    // Check if migration was cancelled while we yielded so far.\n+    if (cancelled_) {\n+      return;\n+    }\n+\n     streamer_.Start(Sock());\n   }\n \n   void Cancel() {\n     streamer_.Cancel();\n+    cancelled_ = true;\n   }\n \n   void Finalize() {\n@@ -74,6 +80,7 @@ class OutgoingMigration::SliceSlotMigration : private ProtocolClient {\n \n  private:\n   RestoreStreamer streamer_;\n+  bool cancelled_ = false;\n };\n \n OutgoingMigration::OutgoingMigration(MigrationInfo info, ClusterFamily* cf, ServerFamily* sf)\n@@ -88,26 +95,42 @@ OutgoingMigration::~OutgoingMigration() {\n   main_sync_fb_.JoinIfNeeded();\n }\n \n+bool OutgoingMigration::ChangeState(MigrationState new_state) {\n+  std::lock_guard lk(state_mu_);\n+  if (state_ == MigrationState::C_FINISHED) {\n+    return false;\n+  }\n+\n+  state_ = new_state;\n+  return true;\n+}\n+\n void OutgoingMigration::Finish(bool is_error) {\n-  std::lock_guard lk(finish_mu_);\n-  if (state_.load() != MigrationState::C_FINISHED) {\n-    const auto new_state = is_error ? MigrationState::C_ERROR : MigrationState::C_FINISHED;\n-    state_.store(new_state);\n+  const auto new_state = is_error ? MigrationState::C_ERROR : MigrationState::C_FINISHED;\n+  if (ChangeState(new_state)) {\n     shard_set->pool()->AwaitFiberOnAll([this](util::ProactorBase* pb) {\n-      if (const auto* shard = EngineShard::tlocal(); shard)\n-        slot_migrations_[shard->shard_id()]->Cancel();\n+      if (const auto* shard = EngineShard::tlocal(); shard) {\n+        auto& flow = slot_migrations_[shard->shard_id()];\n+        if (flow != nullptr) {\n+          flow->Cancel();\n+        }\n+      }\n     });\n   }\n }\n \n MigrationState OutgoingMigration::GetState() const {\n-  return state_.load();\n+  std::lock_guard lk(state_mu_);\n+  return state_;\n }\n \n void OutgoingMigration::SyncFb() {\n   // we retry starting migration until \"cancel\" is happened\n-  while (state_.load() != MigrationState::C_FINISHED) {\n-    state_.store(MigrationState::C_CONNECTING);\n+  while (GetState() != MigrationState::C_FINISHED) {\n+    if (!ChangeState(MigrationState::C_CONNECTING)) {\n+      break;\n+    }\n+\n     last_error_ = cntx_.GetError();\n     cntx_.Reset(nullptr);\n \n@@ -137,11 +160,15 @@ void OutgoingMigration::SyncFb() {\n     }\n \n     if (!CheckRespIsSimpleReply(\"OK\")) {\n-      cntx_.ReportError(GenericError(std::string(ToSV(LastResponseArgs().front().GetBuf()))));\n+      if (!CheckRespIsSimpleReply(kUnknownMigration)) {\n+        cntx_.ReportError(GenericError(std::string(ToSV(LastResponseArgs().front().GetBuf()))));\n+      }\n       continue;\n     }\n \n-    state_.store(MigrationState::C_SYNC);\n+    if (!ChangeState(MigrationState::C_SYNC)) {\n+      break;\n+    }\n \n     shard_set->pool()->AwaitFiberOnAll([this](util::ProactorBase* pb) {\n       if (auto* shard = EngineShard::tlocal(); shard) {\n@@ -163,7 +190,7 @@ void OutgoingMigration::SyncFb() {\n     VLOG(1) << \"Migrations snapshot is finished\";\n \n     long attempt = 0;\n-    while (state_.load() != MigrationState::C_FINISHED && !FinalyzeMigration(++attempt)) {\n+    while (GetState() != MigrationState::C_FINISHED && !FinalizeMigration(++attempt)) {\n       // process commands that were on pause and try again\n       ThisFiber::SleepFor(500ms);\n     }\n@@ -174,7 +201,7 @@ void OutgoingMigration::SyncFb() {\n   }\n }\n \n-bool OutgoingMigration::FinalyzeMigration(long attempt) {\n+bool OutgoingMigration::FinalizeMigration(long attempt) {\n   // if it's not the 1st attempt and flows are work correctly we try to reconnect and ACK one more\n   // time\n   if (attempt > 1) {\ndiff --git a/src/server/cluster/outgoing_slot_migration.h b/src/server/cluster/outgoing_slot_migration.h\nindex 6bbd821173d0..aa2a1b0d3fb2 100644\n--- a/src/server/cluster/outgoing_slot_migration.h\n+++ b/src/server/cluster/outgoing_slot_migration.h\n@@ -54,6 +54,7 @@ class OutgoingMigration : private ProtocolClient {\n   }\n \n   static constexpr long kInvalidAttempt = -1;\n+  static constexpr std::string_view kUnknownMigration = \"UNKNOWN_MIGRATION\";\n \n  private:\n   // should be run for all shards\n@@ -68,11 +69,12 @@ class OutgoingMigration : private ProtocolClient {\n \n   void SyncFb();\n   // return true if migration is finalized even with C_ERROR state\n-  bool FinalyzeMigration(long attempt);\n+  bool FinalizeMigration(long attempt);\n+\n+  bool ChangeState(MigrationState new_state) ABSL_LOCKS_EXCLUDED(state_mu_);\n \n  private:\n   MigrationInfo migration_info_;\n-  mutable util::fb2::Mutex finish_mu_;\n   std::vector<std::unique_ptr<SliceSlotMigration>> slot_migrations_;\n   ServerFamily* server_family_;\n   ClusterFamily* cf_;\n@@ -80,8 +82,8 @@ class OutgoingMigration : private ProtocolClient {\n \n   util::fb2::Fiber main_sync_fb_;\n \n-  // Atomic only for simple read operation, writes - from the same thread, reads - from any thread\n-  std::atomic<MigrationState> state_ = MigrationState::C_NO_STATE;\n+  mutable util::fb2::Mutex state_mu_;\n+  MigrationState state_ ABSL_GUARDED_BY(state_mu_) = MigrationState::C_NO_STATE;\n };\n \n }  // namespace dfly::cluster\n",
  "test_patch": "diff --git a/tests/dragonfly/cluster_test.py b/tests/dragonfly/cluster_test.py\nindex c503a12db6c3..cd25d931412c 100644\n--- a/tests/dragonfly/cluster_test.py\n+++ b/tests/dragonfly/cluster_test.py\n@@ -77,11 +77,15 @@ async def push_config(config, admin_connections):\n \n \n async def wait_for_status(admin_client, node_id, status):\n-    while status not in await admin_client.execute_command(\n-        \"DFLYCLUSTER\", \"SLOT-MIGRATION-STATUS\", node_id\n-    ):\n-        logging.debug(\"SLOT-MIGRATION-STATUS is not %s\", status)\n-        await asyncio.sleep(0.05)\n+    while True:\n+        response = await admin_client.execute_command(\n+            \"DFLYCLUSTER\", \"SLOT-MIGRATION-STATUS\", node_id\n+        )\n+        if status in response:\n+            break\n+        else:\n+            logging.debug(f\"SLOT-MIGRATION-STATUS is {response}, not {status}\")\n+            await asyncio.sleep(0.05)\n \n \n async def get_node_id(admin_connection):\n@@ -955,42 +959,21 @@ async def test_config_consistency(df_local_factory: DflyInstanceFactory):\n       ]\n     \"\"\"\n \n-    # push config only to source node\n+    # Push config to source node. Migration will not start until target node gets the config as well.\n     await push_config(\n         migation_config.replace(\"LAST_SLOT_CUTOFF\", \"5259\").replace(\"NEXT_SLOT_CUTOFF\", \"5260\"),\n         [c_nodes_admin[0]],\n     )\n+    await wait_for_status(c_nodes_admin[0], node_ids[1], \"CONNECTING\")\n+    await wait_for_status(c_nodes_admin[1], node_ids[0], \"NO_STATE\")\n \n-    while \"SYNC\" not in await c_nodes_admin[0].execute_command(\n-        \"DFLYCLUSTER\", \"SLOT-MIGRATION-STATUS\", node_ids[1]\n-    ):\n-        logging.debug(\"source SLOT-MIGRATION-STATUS is not SYNC\")\n-        await asyncio.sleep(0.05)\n-\n-    while \"SYNC\" not in await c_nodes_admin[1].execute_command(\n-        \"DFLYCLUSTER\", \"SLOT-MIGRATION-STATUS\", node_ids[0]\n-    ):\n-        logging.debug(\"target SLOT-MIGRATION-STATUS is not SYNC\")\n-        await asyncio.sleep(0.05)\n-\n-    # migration shouldn't be finished until we set the same config to target node\n-    await asyncio.sleep(0.5)\n-\n-    # push config to target node\n     await push_config(\n         migation_config.replace(\"LAST_SLOT_CUTOFF\", \"5259\").replace(\"NEXT_SLOT_CUTOFF\", \"5260\"),\n         [c_nodes_admin[1]],\n     )\n \n-    while \"FINISHED\" not in await c_nodes_admin[1].execute_command(\n-        \"DFLYCLUSTER\", \"SLOT-MIGRATION-STATUS\", node_ids[0]\n-    ):\n-        logging.debug(\"SLOT-MIGRATION-STATUS is not FINISHED\")\n-        await asyncio.sleep(0.05)\n-\n-    assert await c_nodes_admin[0].execute_command(\"DFLYCLUSTER\", \"SLOT-MIGRATION-STATUS\") == [\n-        f\"\"\"out {node_ids[1]} FINISHED keys:0 errors: 0\"\"\"\n-    ]\n+    await wait_for_status(c_nodes_admin[1], node_ids[0], \"FINISHED\")\n+    await wait_for_status(c_nodes_admin[0], node_ids[1], \"FINISHED\")\n \n     # remove finished migrations\n     await push_config(\n@@ -1416,7 +1399,6 @@ async def test_cluster_migration_cancel(df_local_factory: DflyInstanceFactory):\n     ]\n     logging.debug(\"Migrating slots 6000-8000\")\n     await push_config(json.dumps(generate_config(nodes)), [node.admin_client for node in nodes])\n-    await asyncio.sleep(0.5)\n \n     logging.debug(\"Cancelling migration\")\n     nodes[0].migrations = []\n",
  "problem_statement": "deadlock if slot migration is canceled after beggining\nAlso not all keys are removed after cancel from the target node\n",
  "hints_text": "",
  "created_at": "2024-05-01T11:49:43Z",
  "modified_files": [
    "src/server/cluster/cluster_family.cc",
    "src/server/cluster/incoming_slot_migration.cc",
    "src/server/cluster/outgoing_slot_migration.cc",
    "src/server/cluster/outgoing_slot_migration.h"
  ],
  "modified_test_files": [
    "tests/dragonfly/cluster_test.py"
  ]
}