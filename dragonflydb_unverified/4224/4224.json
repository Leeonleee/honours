{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 4224,
  "instance_id": "dragonflydb__dragonfly-4224",
  "issue_numbers": [
    "4207"
  ],
  "base_commit": "872e49b0b8eae3a346d33e910fea3fb92f6401c5",
  "patch": "diff --git a/src/server/cluster/outgoing_slot_migration.cc b/src/server/cluster/outgoing_slot_migration.cc\nindex b77c44c0b727..9abe9cf08bc5 100644\n--- a/src/server/cluster/outgoing_slot_migration.cc\n+++ b/src/server/cluster/outgoing_slot_migration.cc\n@@ -37,7 +37,7 @@ class OutgoingMigration::SliceSlotMigration : private ProtocolClient {\n   }\n \n   ~SliceSlotMigration() {\n-    streamer_.Cancel();\n+    Cancel();\n     cntx_.JoinErrorHandler();\n   }\n \n@@ -81,6 +81,7 @@ class OutgoingMigration::SliceSlotMigration : private ProtocolClient {\n   }\n \n   void Cancel() {\n+    cntx_.Cancel();\n     streamer_.Cancel();\n   }\n \ndiff --git a/src/server/container_utils.cc b/src/server/container_utils.cc\nindex 07c5e51ba55d..31f08c9e5917 100644\n--- a/src/server/container_utils.cc\n+++ b/src/server/container_utils.cc\n@@ -274,13 +274,13 @@ bool IterateMap(const PrimeValue& pv, const IterateKVFunc& func) {\n   bool finished = true;\n \n   if (pv.Encoding() == kEncodingListPack) {\n-    uint8_t intbuf[LP_INTBUF_SIZE];\n+    uint8_t k_intbuf[LP_INTBUF_SIZE], v_intbuf[LP_INTBUF_SIZE];\n     uint8_t* lp = (uint8_t*)pv.RObjPtr();\n     uint8_t* fptr = lpFirst(lp);\n     while (fptr) {\n-      string_view key = LpGetView(fptr, intbuf);\n+      string_view key = LpGetView(fptr, k_intbuf);\n       fptr = lpNext(lp, fptr);\n-      string_view val = LpGetView(fptr, intbuf);\n+      string_view val = LpGetView(fptr, v_intbuf);\n       fptr = lpNext(lp, fptr);\n       if (!func(ContainerEntry{key.data(), key.size()}, ContainerEntry{val.data(), val.size()})) {\n         finished = false;\ndiff --git a/src/server/journal/streamer.cc b/src/server/journal/streamer.cc\nindex d6654d3aa9eb..c224d25dc95e 100644\n--- a/src/server/journal/streamer.cc\n+++ b/src/server/journal/streamer.cc\n@@ -41,7 +41,9 @@ JournalStreamer::JournalStreamer(journal::Journal* journal, Context* cntx)\n }\n \n JournalStreamer::~JournalStreamer() {\n-  DCHECK_EQ(in_flight_bytes_, 0u);\n+  if (!cntx_->IsCancelled()) {\n+    DCHECK_EQ(in_flight_bytes_, 0u);\n+  }\n   VLOG(1) << \"~JournalStreamer\";\n }\n \n@@ -79,7 +81,9 @@ void JournalStreamer::Cancel() {\n   VLOG(1) << \"JournalStreamer::Cancel\";\n   waker_.notifyAll();\n   journal_->UnregisterOnChange(journal_cb_id_);\n-  WaitForInflightToComplete();\n+  if (!cntx_->IsCancelled()) {\n+    WaitForInflightToComplete();\n+  }\n }\n \n size_t JournalStreamer::GetTotalBufferCapacities() const {\n@@ -215,8 +219,15 @@ void RestoreStreamer::Run() {\n       return;\n \n     cursor = db_slice_->Traverse(pt, cursor, [&](PrimeTable::bucket_iterator it) {\n+      if (fiber_cancelled_)  // Could be cancelled any time as Traverse may preempt\n+        return;\n+\n       db_slice_->FlushChangeToEarlierCallbacks(0 /*db_id always 0 for cluster*/,\n                                                DbSlice::Iterator::FromPrime(it), snapshot_version_);\n+\n+      if (fiber_cancelled_)  // Could have been cancelled in above call too\n+        return;\n+\n       WriteBucket(it);\n     });\n \ndiff --git a/src/server/multi_command_squasher.cc b/src/server/multi_command_squasher.cc\nindex a2b8d7bf937e..c6b7ffbb1882 100644\n--- a/src/server/multi_command_squasher.cc\n+++ b/src/server/multi_command_squasher.cc\n@@ -112,6 +112,8 @@ MultiCommandSquasher::SquashResult MultiCommandSquasher::TrySquash(StoredCmd* cm\n \n   cmd->Fill(&tmp_keylist_);\n   auto args = absl::MakeSpan(tmp_keylist_);\n+  if (args.empty())\n+    return SquashResult::NOT_SQUASHED;\n \n   auto keys = DetermineKeys(cmd->Cid(), args);\n   if (!keys.ok())\n",
  "test_patch": "diff --git a/tests/dragonfly/cluster_test.py b/tests/dragonfly/cluster_test.py\nindex d75e1c74addb..27fce9d43399 100644\n--- a/tests/dragonfly/cluster_test.py\n+++ b/tests/dragonfly/cluster_test.py\n@@ -1290,7 +1290,7 @@ async def test_migration_with_key_ttl(df_factory):\n \n \n @dfly_args({\"proactor_threads\": 4, \"cluster_mode\": \"yes\"})\n-async def test_network_disconnect_during_migration(df_factory, df_seeder_factory):\n+async def test_network_disconnect_during_migration(df_factory):\n     instances = [\n         df_factory.create(port=BASE_PORT + i, admin_port=BASE_PORT + i + 1000) for i in range(2)\n     ]\n@@ -1328,7 +1328,7 @@ async def test_network_disconnect_during_migration(df_factory, df_seeder_factory\n \n     await proxy.start()\n \n-    await wait_for_status(nodes[0].admin_client, nodes[1].id, \"FINISHED\", 20)\n+    await wait_for_status(nodes[0].admin_client, nodes[1].id, \"FINISHED\", 60)\n     nodes[0].migrations = []\n     nodes[0].slots = []\n     nodes[1].slots = [(0, 16383)]\n@@ -1336,6 +1336,7 @@ async def test_network_disconnect_during_migration(df_factory, df_seeder_factory\n     await push_config(json.dumps(generate_config(nodes)), [node.admin_client for node in nodes])\n \n     assert (await StaticSeeder.capture(nodes[1].client)) == start_capture\n+    await proxy.close()\n \n \n @pytest.mark.parametrize(\n",
  "problem_statement": "test_network_disconnect_during_migration with big_value_serialization and compression off\nTo reproduce check this branch: https://github.com/dragonflydb/dragonfly/actions/runs/12049150090/job/33595305922?pr=4199#step:12:245\r\n\r\nand the failure at: https://github.com/dragonflydb/dragonfly/actions/runs/12049150090/job/33595305922?pr=4199#step:12:245\r\n\r\n1. Turn big value serialization to the minum\r\n2. Turn compression off\r\n\r\n\r\nTest fails on the CI and it did not fail for me locally. Although to be honest I haven't run it in a loop so maybe it does :man_shrugging: \n",
  "hints_text": "https://github.com/dragonflydb/dragonfly/actions/runs/12055962717/job/33617458972?pr=4073#step:12:772 \nAlso fuzzy migration with serialization=1. \r\n\r\nI accumulate those here because they all fall under the same mechanism/flow (value is big, so we serialize it as multiple journal writes)\nand another one https://github.com/dragonflydb/dragonfly/actions/runs/12052270050/job/33619080857?pr=4212#step:12:849 \nIn total it's 3 different tests from the cluster family. My suspicion is that they all fail because of the same reason so I grouped them here. \r\n\r\n@chakaz I hope the 3 tests will be more helpful than one",
  "created_at": "2024-11-28T20:34:57Z",
  "modified_files": [
    "src/server/cluster/outgoing_slot_migration.cc",
    "src/server/container_utils.cc",
    "src/server/journal/streamer.cc",
    "src/server/multi_command_squasher.cc"
  ],
  "modified_test_files": [
    "tests/dragonfly/cluster_test.py"
  ]
}