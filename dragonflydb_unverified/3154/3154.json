{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 3154,
  "instance_id": "dragonflydb__dragonfly-3154",
  "issue_numbers": [
    "1657"
  ],
  "base_commit": "3fd43eeda8e90c079605f7f562de4f79be1c7c92",
  "patch": "diff --git a/src/core/bloom.cc b/src/core/bloom.cc\nindex ca55fa19f071..179cd19b5aaa 100644\n--- a/src/core/bloom.cc\n+++ b/src/core/bloom.cc\n@@ -8,6 +8,7 @@\n #include <absl/numeric/bits.h>\n #include <xxhash.h>\n \n+#include <algorithm>\n #include <cmath>\n \n #include \"base/logging.h\"\ndiff --git a/src/facade/dragonfly_connection.cc b/src/facade/dragonfly_connection.cc\nindex ae7c12249f0d..53dca46777ee 100644\n--- a/src/facade/dragonfly_connection.cc\n+++ b/src/facade/dragonfly_connection.cc\n@@ -275,22 +275,6 @@ struct Connection::Shutdown {\n   }\n };\n \n-Connection::PubMessage::PubMessage(string pattern, shared_ptr<char[]> buf, size_t channel_len,\n-                                   size_t message_len)\n-    : pattern{std::move(pattern)},\n-      buf{std::move(buf)},\n-      channel_len{channel_len},\n-      message_len{message_len} {\n-}\n-\n-string_view Connection::PubMessage::Channel() const {\n-  return {buf.get(), channel_len};\n-}\n-\n-string_view Connection::PubMessage::Message() const {\n-  return {buf.get() + channel_len, message_len};\n-}\n-\n void Connection::PipelineMessage::SetArgs(const RespVec& args) {\n   auto* next = storage.data();\n   for (size_t i = 0; i < args.size(); ++i) {\n@@ -361,7 +345,7 @@ size_t Connection::PipelineMessage::StorageCapacity() const {\n size_t Connection::MessageHandle::UsedMemory() const {\n   struct MessageSize {\n     size_t operator()(const PubMessagePtr& msg) {\n-      return sizeof(PubMessage) + (msg->channel_len + msg->message_len);\n+      return sizeof(PubMessage) + (msg->channel.size() + msg->message.size());\n     }\n     size_t operator()(const PipelineMessagePtr& msg) {\n       return sizeof(PipelineMessage) + msg->args.capacity() * sizeof(MutableSlice) +\n@@ -449,8 +433,8 @@ void Connection::DispatchOperations::operator()(const PubMessage& pub_msg) {\n     arr[i++] = \"pmessage\";\n     arr[i++] = pub_msg.pattern;\n   }\n-  arr[i++] = pub_msg.Channel();\n-  arr[i++] = pub_msg.Message();\n+  arr[i++] = pub_msg.channel;\n+  arr[i++] = pub_msg.message;\n   rbuilder->SendStringArr(absl::Span<string_view>{arr.data(), i},\n                           RedisReplyBuilder::CollectionType::PUSH);\n }\ndiff --git a/src/facade/dragonfly_connection.h b/src/facade/dragonfly_connection.h\nindex 2635f1197d16..951864e976b9 100644\n--- a/src/facade/dragonfly_connection.h\n+++ b/src/facade/dragonfly_connection.h\n@@ -71,15 +71,9 @@ class Connection : public util::Connection {\n \n   // PubSub message, either incoming message for active subscription or reply for new subscription.\n   struct PubMessage {\n-    std::string pattern{};            // non-empty for pattern subscriber\n-    std::shared_ptr<char[]> buf;      // stores channel name and message\n-    size_t channel_len, message_len;  // lengths in buf\n-\n-    std::string_view Channel() const;\n-    std::string_view Message() const;\n-\n-    PubMessage(std::string pattern, std::shared_ptr<char[]> buf, size_t channel_len,\n-               size_t message_len);\n+    std::string pattern{};              // non-empty for pattern subscriber\n+    std::shared_ptr<char[]> buf;        // stores channel name and message\n+    std::string_view channel, message;  // channel and message parts from buf\n   };\n \n   // Pipeline message, accumulated Redis command to be executed.\ndiff --git a/src/facade/reply_builder.cc b/src/facade/reply_builder.cc\nindex d0f3b9df7fd7..80b296a5413a 100644\n--- a/src/facade/reply_builder.cc\n+++ b/src/facade/reply_builder.cc\n@@ -496,7 +496,7 @@ void RedisReplyBuilder::SendMGetResponse(MGetResponse resp) {\n \n void RedisReplyBuilder::SendSimpleStrArr(StrSpan arr) {\n   string res = absl::StrCat(\"*\", arr.Size(), kCRLF);\n-  for (std::string_view str : arr)\n+  for (string_view str : arr)\n     StrAppend(&res, \"+\", str, kCRLF);\n \n   SendRaw(res);\ndiff --git a/src/server/CMakeLists.txt b/src/server/CMakeLists.txt\nindex 852f84bb3018..bac10edc2e20 100644\n--- a/src/server/CMakeLists.txt\n+++ b/src/server/CMakeLists.txt\n@@ -32,7 +32,7 @@ add_library(dfly_transaction db_slice.cc malloc_stats.cc blocking_controller.cc\n             common.cc journal/journal.cc journal/types.cc journal/journal_slice.cc\n             server_state.cc table.cc  top_keys.cc transaction.cc tx_base.cc\n             serializer_commons.cc journal/serializer.cc journal/executor.cc journal/streamer.cc\n-            ${TX_LINUX_SRCS} acl/acl_log.cc slowlog.cc)\n+            ${TX_LINUX_SRCS} acl/acl_log.cc slowlog.cc channel_store.cc)\n \n SET(DF_SEARCH_SRCS search/search_family.cc search/doc_index.cc search/doc_accessors.cc\n     search/aggregator.cc)\n@@ -43,7 +43,7 @@ if (\"${CMAKE_SYSTEM_NAME}\" STREQUAL \"Linux\")\n   cxx_test(tiered_storage_test dfly_test_lib LABELS DFLY)\n endif()\n \n-add_library(dragonfly_lib bloom_family.cc engine_shard_set.cc channel_store.cc\n+add_library(dragonfly_lib bloom_family.cc engine_shard_set.cc\n             config_registry.cc conn_context.cc debugcmd.cc dflycmd.cc\n             generic_family.cc hset_family.cc http_api.cc json_family.cc\n             list_family.cc main_service.cc memory_cmd.cc rdb_load.cc rdb_save.cc replica.cc\ndiff --git a/src/server/channel_store.cc b/src/server/channel_store.cc\nindex 822f82d9d2fe..d1d7dbe83586 100644\n--- a/src/server/channel_store.cc\n+++ b/src/server/channel_store.cc\n@@ -10,6 +10,8 @@ extern \"C\" {\n #include \"redis/util.h\"\n }\n \n+#include <absl/container/fixed_array.h>\n+\n #include \"base/logging.h\"\n #include \"server/engine_shard_set.h\"\n #include \"server/server_state.h\"\n@@ -23,6 +25,32 @@ bool Matches(string_view pattern, string_view channel) {\n   return stringmatchlen(pattern.data(), pattern.size(), channel.data(), channel.size(), 0) == 1;\n }\n \n+// Build functor for sending messages to connection\n+auto BuildSender(string_view channel, facade::ArgRange messages) {\n+  absl::FixedArray<string_view, 1> views(messages.Size());\n+  size_t messages_size = accumulate(messages.begin(), messages.end(), 0,\n+                                    [](int sum, string_view str) { return sum + str.size(); });\n+  auto buf = shared_ptr<char[]>{new char[channel.size() + messages_size]};\n+  {\n+    memcpy(buf.get(), channel.data(), channel.size());\n+    char* ptr = buf.get() + channel.size();\n+\n+    size_t i = 0;\n+    for (string_view message : messages) {\n+      memcpy(ptr, message.data(), message.size());\n+      views[i++] = {ptr, message.size()};\n+      ptr += message.size();\n+    }\n+  }\n+\n+  return [channel, buf = std::move(buf), views = std::move(views)](facade::Connection* conn,\n+                                                                   string pattern) {\n+    string_view channel_view{buf.get(), channel.size()};\n+    for (std::string_view message_view : views)\n+      conn->SendPubMessageAsync({std::move(pattern), buf, channel_view, message_view});\n+  };\n+}\n+\n }  // namespace\n \n bool ChannelStore::Subscriber::ByThread(const Subscriber& lhs, const Subscriber& rhs) {\n@@ -95,6 +123,39 @@ void ChannelStore::Destroy() {\n \n ChannelStore::ControlBlock ChannelStore::control_block;\n \n+unsigned ChannelStore::SendMessages(std::string_view channel, facade::ArgRange messages) const {\n+  vector<Subscriber> subscribers = FetchSubscribers(channel);\n+  if (subscribers.empty())\n+    return 0;\n+\n+  // Make sure none of the threads publish buffer limits is reached. We don't reserve memory ahead\n+  // and don't prevent the buffer from possibly filling, but the approach is good enough for\n+  // limiting fast producers. Most importantly, we can use DispatchBrief below as we block here\n+  optional<uint32_t> last_thread;\n+  for (auto& sub : subscribers) {\n+    DCHECK_LE(last_thread.value_or(0), sub.Thread());\n+    if (last_thread && *last_thread == sub.Thread())  // skip same thread\n+      continue;\n+\n+    if (sub.EnsureMemoryBudget())  // Invalid pointers are skipped\n+      last_thread = sub.Thread();\n+  }\n+\n+  auto subscribers_ptr = make_shared<decltype(subscribers)>(std::move(subscribers));\n+  auto cb = [subscribers_ptr, send = BuildSender(channel, messages)](unsigned idx, auto*) {\n+    auto it = lower_bound(subscribers_ptr->begin(), subscribers_ptr->end(), idx,\n+                          ChannelStore::Subscriber::ByThreadId);\n+    while (it != subscribers_ptr->end() && it->Thread() == idx) {\n+      if (auto* ptr = it->Get(); ptr)\n+        send(ptr, it->pattern);\n+      it++;\n+    }\n+  };\n+  shard_set->pool()->DispatchBrief(std::move(cb));\n+\n+  return subscribers_ptr->size();\n+}\n+\n vector<ChannelStore::Subscriber> ChannelStore::FetchSubscribers(string_view channel) const {\n   vector<Subscriber> res;\n \ndiff --git a/src/server/channel_store.h b/src/server/channel_store.h\nindex 7f09d4b5003b..2a67606c5244 100644\n--- a/src/server/channel_store.h\n+++ b/src/server/channel_store.h\n@@ -54,6 +54,9 @@ class ChannelStore {\n \n   ChannelStore();\n \n+  // Send messages to channel, block on connection backpressure\n+  unsigned SendMessages(std::string_view channel, facade::ArgRange messages) const;\n+\n   // Fetch all subscribers for channel, including matching patterns.\n   std::vector<Subscriber> FetchSubscribers(std::string_view channel) const;\n \ndiff --git a/src/server/db_slice.cc b/src/server/db_slice.cc\nindex 901b2c9996e8..97cf5caa5ce8 100644\n--- a/src/server/db_slice.cc\n+++ b/src/server/db_slice.cc\n@@ -9,6 +9,7 @@\n #include \"base/flags.h\"\n #include \"base/logging.h\"\n #include \"generic_family.h\"\n+#include \"server/channel_store.h\"\n #include \"server/cluster/cluster_defs.h\"\n #include \"server/engine_shard_set.h\"\n #include \"server/error.h\"\n@@ -33,6 +34,9 @@ ABSL_FLAG(double, table_growth_margin, 0.4,\n           \"Prevents table from growing if number of free slots x average object size x this ratio \"\n           \"is larger than memory budget.\");\n \n+ABSL_FLAG(std::string, notify_keyspace_events, \"\",\n+          \"notify-keyspace-events. Only Ex is supported for now\");\n+\n namespace dfly {\n \n using namespace std;\n@@ -204,9 +208,7 @@ unsigned PrimeEvictionPolicy::Evict(const PrimeTable::HotspotBuckets& eb, PrimeT\n \n     // log the evicted keys to journal.\n     if (auto journal = db_slice_->shard_owner()->journal(); journal) {\n-      ArgSlice delete_args(&key, 1);\n-      journal->RecordEntry(0, journal::Op::EXPIRED, cntx_.db_index, 1, cluster::KeySlot(key),\n-                           Payload(\"DEL\", delete_args), false);\n+      RecordExpiry(cntx_.db_index, key);\n     }\n \n     db_slice_->PerformDeletion(DbSlice::Iterator(last_slot_it, StringOrView::FromView(key)), table);\n@@ -268,6 +270,13 @@ DbSlice::DbSlice(uint32_t index, bool caching_mode, EngineShard* owner)\n   CreateDb(0);\n   expire_base_[0] = expire_base_[1] = 0;\n   soft_budget_limit_ = (0.3 * max_memory_limit / shard_set->size());\n+\n+  std::string keyspace_events = GetFlag(FLAGS_notify_keyspace_events);\n+  if (!keyspace_events.empty() && keyspace_events != \"Ex\") {\n+    LOG(ERROR) << \"Only Ex is currently supported\";\n+    exit(0);\n+  }\n+  expired_keys_events_recording_ = !keyspace_events.empty();\n }\n \n DbSlice::~DbSlice() {\n@@ -1047,11 +1056,15 @@ DbSlice::PrimeItAndExp DbSlice::ExpireIfNeeded(const Context& cntx, PrimeIterato\n                << \", expire table size: \" << db->expire.size()\n                << \", prime table size: \" << db->prime.size() << util::fb2::GetStacktrace();\n   }\n+\n   // Replicate expiry\n   if (auto journal = owner_->journal(); journal) {\n     RecordExpiry(cntx.db_index, key);\n   }\n \n+  if (expired_keys_events_recording_)\n+    db->expired_keys_events_.emplace_back(key);\n+\n   auto obj_type = it->second.ObjType();\n   if (doc_del_cb_ && (obj_type == OBJ_JSON || obj_type == OBJ_HASH)) {\n     doc_del_cb_(key, cntx, it->second);\n@@ -1157,6 +1170,13 @@ auto DbSlice::DeleteExpiredStep(const Context& cntx, unsigned count) -> DeleteEx\n     }\n   }\n \n+  // Send and clear accumulated expired key events\n+  if (auto& events = db_arr_[cntx.db_index]->expired_keys_events_; !events.empty()) {\n+    ChannelStore* store = ServerState::tlocal()->channel_store();\n+    store->SendMessages(absl::StrCat(\"__keyevent@\", cntx.db_index, \"__:expired\"), events);\n+    events.clear();\n+  }\n+\n   return result;\n }\n \n@@ -1185,6 +1205,8 @@ void DbSlice::FreeMemWithEvictionStep(DbIndex db_ind, size_t increase_goal_bytes\n   string tmp;\n   int32_t starting_segment_id = rand() % num_segments;\n   size_t used_memory_before = owner_->UsedMemory();\n+\n+  bool record_keys = owner_->journal() != nullptr || expired_keys_events_recording_;\n   vector<string> keys_to_journal;\n \n   {\n@@ -1213,9 +1235,8 @@ void DbSlice::FreeMemWithEvictionStep(DbIndex db_ind, size_t increase_goal_bytes\n           if (lt.Find(LockTag(key)).has_value())\n             continue;\n \n-          if (auto journal = owner_->journal(); journal) {\n-            keys_to_journal.push_back(string(key));\n-          }\n+          if (record_keys)\n+            keys_to_journal.emplace_back(key);\n \n           PerformDeletion(Iterator(evict_it, StringOrView::FromView(key)), db_table.get());\n           ++evicted;\n@@ -1233,12 +1254,12 @@ void DbSlice::FreeMemWithEvictionStep(DbIndex db_ind, size_t increase_goal_bytes\n finish:\n   // send the deletion to the replicas.\n   // fiber preemption could happen in this phase.\n-  if (auto journal = owner_->journal(); journal) {\n-    for (string_view key : keys_to_journal) {\n-      ArgSlice delete_args(&key, 1);\n-      journal->RecordEntry(0, journal::Op::EXPIRED, db_ind, 1, cluster::KeySlot(key),\n-                           Payload(\"DEL\", delete_args), false);\n-    }\n+  for (string_view key : keys_to_journal) {\n+    if (auto journal = owner_->journal(); journal)\n+      RecordExpiry(db_ind, key);\n+\n+    if (expired_keys_events_recording_)\n+      db_table->expired_keys_events_.emplace_back(key);\n   }\n \n   auto time_finish = absl::GetCurrentTimeNanos();\ndiff --git a/src/server/db_slice.h b/src/server/db_slice.h\nindex 5da9ce571617..47dd967eb091 100644\n--- a/src/server/db_slice.h\n+++ b/src/server/db_slice.h\n@@ -553,6 +553,9 @@ class DbSlice {\n   // Registered by shard indices on when first document index is created.\n   DocDeletionCallback doc_del_cb_;\n \n+  // Record whenever a key expired to DbTable::expired_keys_events_ for keyspace notifications\n+  bool expired_keys_events_recording_ = true;\n+\n   struct Hash {\n     size_t operator()(const facade::Connection::WeakRef& c) const {\n       return std::hash<uint32_t>()(c.GetClientId());\ndiff --git a/src/server/main_service.cc b/src/server/main_service.cc\nindex 399d25a051e8..1b38e35ed483 100644\n--- a/src/server/main_service.cc\n+++ b/src/server/main_service.cc\n@@ -2243,49 +2243,10 @@ void Service::Exec(CmdArgList args, ConnectionContext* cntx) {\n \n void Service::Publish(CmdArgList args, ConnectionContext* cntx) {\n   string_view channel = ArgS(args, 0);\n-  string_view msg = ArgS(args, 1);\n+  string_view messages[] = {ArgS(args, 1)};\n \n   auto* cs = ServerState::tlocal()->channel_store();\n-  vector<ChannelStore::Subscriber> subscribers = cs->FetchSubscribers(channel);\n-  int num_published = subscribers.size();\n-  if (!subscribers.empty()) {\n-    // Make sure neither of the threads limits is reached.\n-    // This check actually doesn't reserve any memory ahead and doesn't prevent the buffer\n-    // from eventually filling up, especially if multiple clients are unblocked simultaneously,\n-    // but is generally good enough to limit too fast producers.\n-    // Most importantly, this approach allows not blocking and not awaiting in the dispatch below,\n-    // thus not adding any overhead to backpressure checks.\n-    optional<uint32_t> last_thread;\n-    for (auto& sub : subscribers) {\n-      DCHECK_LE(last_thread.value_or(0), sub.Thread());\n-      if (last_thread && *last_thread == sub.Thread())  // skip same thread\n-        continue;\n-\n-      if (sub.EnsureMemoryBudget())  // Invalid pointers are skipped\n-        last_thread = sub.Thread();\n-    }\n-\n-    auto subscribers_ptr = make_shared<decltype(subscribers)>(std::move(subscribers));\n-    auto buf = shared_ptr<char[]>{new char[channel.size() + msg.size()]};\n-    memcpy(buf.get(), channel.data(), channel.size());\n-    memcpy(buf.get() + channel.size(), msg.data(), msg.size());\n-\n-    auto cb = [subscribers_ptr, buf, channel, msg](unsigned idx, util::ProactorBase*) {\n-      auto it = lower_bound(subscribers_ptr->begin(), subscribers_ptr->end(), idx,\n-                            ChannelStore::Subscriber::ByThreadId);\n-\n-      while (it != subscribers_ptr->end() && it->Thread() == idx) {\n-        if (auto* ptr = it->Get(); ptr) {\n-          ptr->SendPubMessageAsync(\n-              {std::move(it->pattern), std::move(buf), channel.size(), msg.size()});\n-        }\n-        it++;\n-      }\n-    };\n-    shard_set->pool()->DispatchBrief(std::move(cb));\n-  }\n-\n-  cntx->SendLong(num_published);\n+  cntx->SendLong(cs->SendMessages(channel, messages));\n }\n \n void Service::Subscribe(CmdArgList args, ConnectionContext* cntx) {\ndiff --git a/src/server/table.h b/src/server/table.h\nindex 97f2e612ed5f..cfc44d0b4d08 100644\n--- a/src/server/table.h\n+++ b/src/server/table.h\n@@ -123,6 +123,9 @@ struct DbTable : boost::intrusive_ref_counter<DbTable, boost::thread_unsafe_coun\n   // Stores a list of dependant connections for each watched key.\n   absl::flat_hash_map<std::string, std::vector<ConnectionState::ExecInfo*>> watched_keys;\n \n+  // Keyspace notifications: list of expired keys since last batch of messages was published.\n+  mutable std::vector<std::string> expired_keys_events_;\n+\n   mutable DbTableStats stats;\n   std::vector<SlotStats> slots_stats;\n   ExpireTable::Cursor expire_cursor;\n",
  "test_patch": "diff --git a/src/server/dragonfly_test.cc b/src/server/dragonfly_test.cc\nindex 2d7219f42f90..aa15589359f5 100644\n--- a/src/server/dragonfly_test.cc\n+++ b/src/server/dragonfly_test.cc\n@@ -514,8 +514,8 @@ TEST_F(DflyEngineTest, PSubscribe) {\n   ASSERT_EQ(1, SubscriberMessagesLen(\"IO1\"));\n \n   const auto& msg = GetPublishedMessage(\"IO1\", 0);\n-  EXPECT_EQ(\"foo\", msg.Message());\n-  EXPECT_EQ(\"ab\", msg.Channel());\n+  EXPECT_EQ(\"foo\", msg.message);\n+  EXPECT_EQ(\"ab\", msg.channel);\n   EXPECT_EQ(\"a*\", msg.pattern);\n }\n \ndiff --git a/tests/dragonfly/connection_test.py b/tests/dragonfly/connection_test.py\nindex 9eaf81af20c7..cda6d6d32af4 100755\n--- a/tests/dragonfly/connection_test.py\n+++ b/tests/dragonfly/connection_test.py\n@@ -410,6 +410,32 @@ async def subscribe_worker():\n     await async_pool.disconnect()\n \n \n+@dfly_args({\"notify_keyspace_events\": \"Ex\"})\n+async def test_keyspace_events(async_client: aioredis.Redis):\n+    pclient = async_client.pubsub()\n+    await pclient.subscribe(\"__keyevent@0__:expired\")\n+\n+    keys = []\n+    for i in range(10, 50):\n+        keys.append(f\"k{i}\")\n+        await async_client.set(keys[-1], \"X\", px=200 + i * 10)\n+\n+    # We don't support immediate expiration:\n+    # keys += ['immediate']\n+    # await async_client.set(keys[-1], 'Y', exat=123) # expired 50 years ago\n+\n+    events = []\n+    async for message in pclient.listen():\n+        if message[\"type\"] == \"subscribe\":\n+            continue\n+\n+        events.append(message)\n+        if len(events) >= len(keys):\n+            break\n+\n+    assert set(ev[\"data\"] for ev in events) == set(keys)\n+\n+\n async def test_big_command(df_server, size=8 * 1024):\n     reader, writer = await asyncio.open_connection(\"127.0.0.1\", df_server.port)\n \n",
  "problem_statement": "Support keyspace notifications\nRedis support [keyspace notifications](https://redis.io/docs/manual/keyspace-notifications/#configuration) by command `CONFIG SET notify-keyspace-events xE`, but dragonfly does not support it:\r\n```\r\nCONFIG SET notify-keyspace-events xE\r\n(error) ERR CONFIG SET failed (possibly related to argument 'notify-keyspace-events').\r\n```\r\n\r\nI'd like to subscribe to timeout key events. Is there any solution?\n",
  "hints_text": "Dragonfly does not support key events. Specifically, timeout events is not designed well in Redis and does not guarantee accurate events for all the keys. Can you please describe your use-case for this ?\n@romange My scenario is to monitor which key expires in real time, which was previously achieved by subscribing to redis's key expiration event. In my system, key expiration means that the tasks corresponding to this key may not be handled in a timely manner, and a mechanism is needed to monitor these tasks that are not handled in time. It is true that the redis key event is not a reliable method, but it does not need to implement too many functions alone, so it is convenient.\n> @romange My scenario is to monitor which key expires in real time, which was previously achieved by subscribing to redis's key expiration event. In my system, key expiration means that the tasks corresponding to this key may not be handled in a timely manner, and a mechanism is needed to monitor these tasks that are not handled in time. It is true that the redis key event is not a reliable method, but it does not need to implement too many functions alone, so it is convenient.\r\n\r\nAre there other methods besides the one you mentioned? Because I'm using the same thing in my project",
  "created_at": "2024-06-10T08:58:46Z",
  "modified_files": [
    "src/core/bloom.cc",
    "src/facade/dragonfly_connection.cc",
    "src/facade/dragonfly_connection.h",
    "src/facade/reply_builder.cc",
    "src/server/CMakeLists.txt",
    "src/server/channel_store.cc",
    "src/server/channel_store.h",
    "src/server/db_slice.cc",
    "src/server/db_slice.h",
    "src/server/main_service.cc",
    "src/server/table.h"
  ],
  "modified_test_files": [
    "src/server/dragonfly_test.cc",
    "tests/dragonfly/connection_test.py"
  ]
}