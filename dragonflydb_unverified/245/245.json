{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 245,
  "instance_id": "dragonflydb__dragonfly-245",
  "issue_numbers": [
    "219"
  ],
  "base_commit": "77bb34fab5f1dbaf5749fa4199f28e58b59922ed",
  "patch": "diff --git a/src/core/compact_object.h b/src/core/compact_object.h\nindex 00665b6a1c09..1af5d1ca05ea 100644\n--- a/src/core/compact_object.h\n+++ b/src/core/compact_object.h\n@@ -108,6 +108,7 @@ class CompactObj {\n     ASCII1_ENC_BIT = 8,\n     ASCII2_ENC_BIT = 0x10,\n     IO_PENDING = 0x20,\n+    STICKY = 0x40,\n   };\n \n   static constexpr uint8_t kEncMask = ASCII1_ENC_BIT | ASCII2_ENC_BIT;\n@@ -213,6 +214,18 @@ class CompactObj {\n     }\n   }\n \n+  bool IsSticky() const {\n+    return mask_ & STICKY;\n+  }\n+\n+  void SetSticky(bool s) {\n+    if (s) {\n+      mask_ |= STICKY;\n+    } else {\n+      mask_ &= ~STICKY;\n+    }\n+  }\n+\n   unsigned Encoding() const;\n   unsigned ObjType() const;\n \ndiff --git a/src/core/dash.h b/src/core/dash.h\nindex d023d88d8014..0106509f465b 100644\n--- a/src/core/dash.h\n+++ b/src/core/dash.h\n@@ -240,9 +240,10 @@ class DashTable : public detail::DashTableBase {\n   // Returns true if an element was deleted i.e the rightmost slot was busy.\n   bool ShiftRight(bucket_iterator it);\n \n-  iterator BumpUp(iterator it) {\n+  template<typename BumpPolicy>\n+  iterator BumpUp(iterator it, const BumpPolicy& bp) {\n     SegmentIterator seg_it =\n-        segment_[it.seg_id_]->BumpUp(it.bucket_id_, it.slot_id_, DoHash(it->first));\n+        segment_[it.seg_id_]->BumpUp(it.bucket_id_, it.slot_id_, DoHash(it->first), bp);\n \n     return iterator{this, it.seg_id_, seg_it.index, seg_it.slot};\n   }\ndiff --git a/src/core/dash_internal.h b/src/core/dash_internal.h\nindex 7eb178fb96f7..a8bd045a1dd9 100644\n--- a/src/core/dash_internal.h\n+++ b/src/core/dash_internal.h\n@@ -522,7 +522,7 @@ template <typename _Key, typename _Value, typename Policy = DefaultSegmentPolicy\n   }\n \n   // Bumps up this entry making it more \"important\" for the eviction policy.\n-  Iterator BumpUp(uint8_t bid, SlotId slot, Hash_t key_hash);\n+  template<typename BumpPolicy> Iterator BumpUp(uint8_t bid, SlotId slot, Hash_t key_hash, const BumpPolicy& ev);\n \n   // Tries to move stash entries back to their normal buckets (exact or neighour).\n   // Returns number of entries that succeeded to unload.\n@@ -1544,7 +1544,8 @@ auto Segment<Key, Value, Policy>::FindValidStartingFrom(unsigned bid, unsigned s\n }\n \n template <typename Key, typename Value, typename Policy>\n-auto Segment<Key, Value, Policy>::BumpUp(uint8_t bid, SlotId slot, Hash_t key_hash) -> Iterator {\n+template <typename BumpPolicy>\n+auto Segment<Key, Value, Policy>::BumpUp(uint8_t bid, SlotId slot, Hash_t key_hash, const BumpPolicy& bp) -> Iterator {\n   auto& from = bucket_[bid];\n \n   uint8_t target_bid = BucketIndex(key_hash);\n@@ -1554,12 +1555,12 @@ auto Segment<Key, Value, Policy>::BumpUp(uint8_t bid, SlotId slot, Hash_t key_ha\n \n   if (bid < kNumBuckets) {\n     // non stash case.\n-    if (slot > 0) {\n+    if (slot > 0 && bp.CanBumpDown(from.key[slot - 1])) {\n       from.Swap(slot - 1, slot);\n       return Iterator{bid, uint8_t(slot - 1)};\n     }\n     // TODO: We could promote further, by swapping probing bucket with its previous one.\n-    return  Iterator{bid, slot};\n+    return Iterator{bid, slot};\n   }\n \n   // stash bucket\n@@ -1587,6 +1588,13 @@ auto Segment<Key, Value, Policy>::BumpUp(uint8_t bid, SlotId slot, Hash_t key_ha\n   constexpr unsigned kLastSlot = kNumSlots - 1;\n   assert(swapb.GetBusy() & (1 << kLastSlot));\n \n+  // Don't move sticky items back to the stash because they're not evictable\n+  // TODO: search for first swappable item\n+  if (!bp.CanBumpDown(swapb.key[kLastSlot])) {\n+    target.SetStashPtr(stash_pos, fp_hash, &next);\n+    return Iterator{bid, slot};\n+  }\n+\n   uint8_t swap_fp = swapb.Fp(kLastSlot);\n \n   // is_probing for the existing entry in swapb. It's unrelated to bucket_offs,\ndiff --git a/src/server/db_slice.cc b/src/server/db_slice.cc\nindex ca10452e6b24..f972b45a98bc 100644\n--- a/src/server/db_slice.cc\n+++ b/src/server/db_slice.cc\n@@ -89,6 +89,14 @@ class PrimeEvictionPolicy {\n   const bool can_evict_;\n };\n \n+class PrimeBumpPolicy {\n+public:\n+  // returns true if key can be made less important for eviction (opposite of bump up)\n+  bool CanBumpDown(const CompactObj& key) const {\n+    return !key.IsSticky();\n+  }\n+};\n+\n \n unsigned PrimeEvictionPolicy::GarbageCollect(const PrimeTable::HotspotBuckets& eb, PrimeTable* me) {\n   unsigned res = 0;\n@@ -124,6 +132,10 @@ unsigned PrimeEvictionPolicy::Evict(const PrimeTable::HotspotBuckets& eb, PrimeT\n   auto last_slot_it = bucket_it;\n   last_slot_it += (PrimeTable::kBucketWidth - 1);\n   if (!last_slot_it.is_done()) {\n+    // don't evict sticky items\n+    if (last_slot_it->first.IsSticky()) {\n+      return 0;\n+    }\n     if (last_slot_it->second.HasExpire()) {\n       ExpireTable* expire_tbl = db_slice_->GetTables(db_indx_).second;\n       CHECK_EQ(1u, expire_tbl->Erase(last_slot_it->first));\n@@ -259,7 +271,7 @@ pair<PrimeIterator, ExpireIterator> DbSlice::FindExt(DbIndex db_ind, string_view\n       db.prime.CVCUponBump(change_cb_.front().first, res.first, bump_cb);\n     }\n \n-    res.first = db.prime.BumpUp(res.first);\n+    res.first = db.prime.BumpUp(res.first, PrimeBumpPolicy{});\n     ++events_.bumpups;\n   }\n \ndiff --git a/src/server/generic_family.cc b/src/server/generic_family.cc\nindex ad370d084ffa..7b99a30d8bff 100644\n--- a/src/server/generic_family.cc\n+++ b/src/server/generic_family.cc\n@@ -52,6 +52,7 @@ class Renamer {\n     string_view key;\n     PrimeValue ref_val;\n     uint64_t expire_ts;\n+    bool sticky;\n     bool found = false;\n   };\n \n@@ -77,6 +78,7 @@ void Renamer::Find(Transaction* t) {\n     if (IsValid(it)) {\n       res->ref_val = it->second.AsRef();\n       res->expire_ts = db_slice.ExpireTime(exp_it);\n+      res->sticky = it->first.IsSticky();\n     }\n     return OpStatus::OK;\n   };\n@@ -157,6 +159,8 @@ OpStatus Renamer::UpdateDest(Transaction* t, EngineShard* es) {\n       dest_it = db_slice.AddNew(db_indx_, dest_key, std::move(pv_), src_res_.expire_ts);\n     }\n \n+    dest_it->first.SetSticky(src_res_.sticky);\n+\n     if (!is_prior_list && dest_it->second.ObjType() == OBJ_LIST && es->blocking_controller()) {\n       es->blocking_controller()->AwakeWatched(db_indx_, dest_key);\n     }\n@@ -436,6 +440,29 @@ void GenericFamily::PexpireAt(CmdArgList args, ConnectionContext* cntx) {\n   }\n }\n \n+void GenericFamily::Stick(CmdArgList args, ConnectionContext* cntx) {\n+  Transaction* transaction = cntx->transaction;\n+  VLOG(1) << \"Stick \" << ArgS(args, 1);\n+\n+  atomic_uint32_t result{0};\n+\n+  auto cb = [&result](const Transaction* t, EngineShard* shard) {\n+    ArgSlice args = t->ShardArgsInShard(shard->shard_id());\n+    auto res = OpStick(t->GetOpArgs(shard), args);\n+    result.fetch_add(res.value_or(0), memory_order_relaxed);\n+\n+    return OpStatus::OK;\n+  };\n+\n+  OpStatus status = transaction->ScheduleSingleHop(std::move(cb));\n+  CHECK_EQ(OpStatus::OK, status);\n+\n+  DVLOG(2) << \"Stick ts \" << transaction->txid();\n+\n+  uint32_t match_cnt = result.load(memory_order_relaxed);\n+  (*cntx)->SendLong(match_cnt);\n+}\n+\n void GenericFamily::Rename(CmdArgList args, ConnectionContext* cntx) {\n   OpResult<void> st = RenameGeneric(args, false, cntx);\n   (*cntx)->SendError(st.status());\n@@ -693,6 +720,7 @@ OpResult<void> GenericFamily::OpRen(const OpArgs& op_args, string_view from_key,\n     is_prior_list = (to_it->second.ObjType() == OBJ_LIST);\n   }\n \n+  bool sticky = from_it->first.IsSticky();\n   uint64_t exp_ts = db_slice.ExpireTime(from_expire);\n \n   // we keep the value we want to move.\n@@ -718,12 +746,31 @@ OpResult<void> GenericFamily::OpRen(const OpArgs& op_args, string_view from_key,\n     to_it = db_slice.AddNew(op_args.db_ind, to_key, std::move(from_obj), exp_ts);\n   }\n \n+  to_it->first.SetSticky(sticky);\n+\n   if (!is_prior_list && to_it->second.ObjType() == OBJ_LIST && es->blocking_controller()) {\n     es->blocking_controller()->AwakeWatched(op_args.db_ind, to_key);\n   }\n   return OpStatus::OK;\n }\n \n+OpResult<uint32_t> GenericFamily::OpStick(const OpArgs& op_args, ArgSlice keys) {\n+  DVLOG(1) << \"Stick: \" << keys[0];\n+\n+  auto& db_slice = op_args.shard->db_slice();\n+\n+  uint32_t res = 0;\n+  for (uint32_t i = 0; i < keys.size(); ++i) {\n+    auto [it, _] = db_slice.FindExt(op_args.db_ind, keys[i]);\n+    if (IsValid(it) && !it->first.IsSticky()) {\n+      it->first.SetSticky(true);\n+      ++res;\n+    }\n+  }\n+\n+  return res;\n+}\n+\n using CI = CommandId;\n \n #define HFUNC(x) SetHandler(&GenericFamily::x)\n@@ -750,7 +797,8 @@ void GenericFamily::Register(CommandRegistry* registry) {\n             << CI{\"TTL\", CO::READONLY | CO::FAST, 2, 1, 1, 1}.HFUNC(Ttl)\n             << CI{\"PTTL\", CO::READONLY | CO::FAST, 2, 1, 1, 1}.HFUNC(Pttl)\n             << CI{\"TYPE\", CO::READONLY | CO::FAST | CO::LOADING, 2, 1, 1, 1}.HFUNC(Type)\n-            << CI{\"UNLINK\", CO::WRITE, -2, 1, -1, 1}.HFUNC(Del);\n+            << CI{\"UNLINK\", CO::WRITE, -2, 1, -1, 1}.HFUNC(Del)\n+            << CI{\"STICK\", CO::WRITE, -2, 1, -1, 1}.HFUNC(Stick);\n }\n \n }  // namespace dfly\ndiff --git a/src/server/generic_family.h b/src/server/generic_family.h\nindex 6e1073a2c03a..1ace67908947 100644\n--- a/src/server/generic_family.h\n+++ b/src/server/generic_family.h\n@@ -45,6 +45,7 @@ class GenericFamily {\n   static void ExpireAt(CmdArgList args, ConnectionContext* cntx);\n   static void Keys(CmdArgList args, ConnectionContext* cntx);\n   static void PexpireAt(CmdArgList args, ConnectionContext* cntx);\n+  static void Stick(CmdArgList args, ConnectionContext* cntx);\n \n   static void Rename(CmdArgList args, ConnectionContext* cntx);\n   static void RenameNx(CmdArgList args, ConnectionContext* cntx);\n@@ -67,6 +68,7 @@ class GenericFamily {\n   static OpResult<uint32_t> OpExists(const OpArgs& op_args, ArgSlice keys);\n   static OpResult<void> OpRen(const OpArgs& op_args, std::string_view from, std::string_view to,\n                               bool skip_exists);\n+  static OpResult<uint32_t> OpStick(const OpArgs& op_args, ArgSlice keys);\n };\n \n }  // namespace dfly\n",
  "test_patch": "diff --git a/src/core/dash_test.cc b/src/core/dash_test.cc\nindex 6cd1177b5d02..8435fb434f5f 100644\n--- a/src/core/dash_test.cc\n+++ b/src/core/dash_test.cc\n@@ -75,6 +75,12 @@ struct UInt64Policy : public BasicDashPolicy {\n   }\n };\n \n+struct RelaxedBumpPolicy {\n+  bool CanBumpDown(uint64_t key) const {\n+    return true;\n+  }\n+};\n+\n class CappedResource final : public std::pmr::memory_resource {\n  public:\n   explicit CappedResource(size_t cap) : cap_(cap) {\n@@ -350,7 +356,7 @@ TEST_F(DashTest, BumpUp) {\n   EXPECT_EQ(touched_bid[0], 1);\n \n   // Bump up\n-  segment_.BumpUp(kFirstStashId, 5, hash);\n+  segment_.BumpUp(kFirstStashId, 5, hash, RelaxedBumpPolicy{});\n \n   // expect the key to move\n   EXPECT_TRUE(segment_.GetBucket(1).IsFull());\n@@ -365,13 +371,40 @@ TEST_F(DashTest, BumpUp) {\n   EXPECT_EQ(1, segment_.CVCOnBump(2, kSecondStashId, 9, hash, touched_bid));\n   EXPECT_EQ(touched_bid[0], kSecondStashId);\n \n-  segment_.BumpUp(kSecondStashId, 9, hash);\n+  segment_.BumpUp(kSecondStashId, 9, hash, RelaxedBumpPolicy{});\n   ASSERT_TRUE(key == segment_.Key(0, kNumSlots - 1) || key == segment_.Key(1, kNumSlots - 1));\n   EXPECT_TRUE(segment_.GetBucket(kSecondStashId).IsFull());\n   EXPECT_TRUE(Contains(key));\n   EXPECT_TRUE(segment_.Key(kSecondStashId, 9));\n }\n \n+TEST_F(DashTest, BumpPolicy) {\n+  struct RestrictedBumpPolicy {\n+    bool CanBumpDown(uint64_t key) const {\n+      return false;\n+    }\n+  };\n+\n+  set<Segment::Key_t> keys = FillSegment(0);\n+  constexpr unsigned kFirstStashId = Segment::kNumBuckets;\n+\n+  EXPECT_TRUE(segment_.GetBucket(0).IsFull());\n+  EXPECT_TRUE(segment_.GetBucket(1).IsFull());\n+  EXPECT_TRUE(segment_.GetBucket(kFirstStashId).IsFull());\n+\n+  // check items are immovable in bucket\n+  Segment::Key_t key = segment_.Key(1, 2);\n+  uint64_t hash = dt_.DoHash(key);\n+  segment_.BumpUp(1, 2, hash, RestrictedBumpPolicy{});\n+  EXPECT_EQ(key, segment_.Key(1, 2));\n+\n+  // check items don't swap from stash\n+  key = segment_.Key(kFirstStashId, 2);\n+  hash = dt_.DoHash(key);\n+  segment_.BumpUp(kFirstStashId, 2, hash, RestrictedBumpPolicy{});\n+  EXPECT_EQ(key, segment_.Key(kFirstStashId, 2));\n+}\n+\n TEST_F(DashTest, Insert2) {\n   uint64_t k = 1191;\n   ASSERT_EQ(2019837007031366716, UInt64Policy::HashFn(k));\n@@ -954,7 +987,7 @@ TEST_P(EvictionPolicyTest, HitRateZipf) {\n                << it.slot_id();\n     } else {\n       if (use_bumps)\n-        dt_.BumpUp(it);\n+        dt_.BumpUp(it, RelaxedBumpPolicy{});\n       ++hits;\n     }\n   }\n@@ -984,7 +1017,7 @@ TEST_P(EvictionPolicyTest, HitRateZipfShr) {\n         }\n       } else {\n         if (use_bumps) {\n-          dt_.BumpUp(it);\n+          dt_.BumpUp(it, RelaxedBumpPolicy{});\n           DVLOG(1) << \"Bump up key \" << key << \" \" << it.bucket_id() << \" slot \" << it.slot_id();\n         } else {\n           DVLOG(1) << \"Hit on key \" << key;\ndiff --git a/src/server/dragonfly_test.cc b/src/server/dragonfly_test.cc\nindex c4148efb22a2..0dd6e978c06b 100644\n--- a/src/server/dragonfly_test.cc\n+++ b/src/server/dragonfly_test.cc\n@@ -499,6 +499,32 @@ TEST_F(DflyEngineTest, Bug207) {\n   }\n }\n \n+TEST_F(DflyEngineTest, StickyEviction) {\n+  shard_set->TEST_EnableHeartBeat();\n+  shard_set->TEST_EnableCacheMode();\n+  max_memory_limit = 0;\n+\n+  string tmp_val(100, '.');\n+\n+  ssize_t failed = -1;\n+  for (ssize_t i = 0; i < 5000; ++i) {\n+    auto set_resp = Run({\"set\", StrCat(\"key\", i), tmp_val});\n+    auto stick_resp = Run({\"stick\", StrCat(\"key\", i)});\n+\n+    if (set_resp != \"OK\") {\n+      failed = i;\n+      break;\n+    }\n+    ASSERT_THAT(stick_resp, IntArg(1));\n+  }\n+\n+  ASSERT_GE(failed, 0);\n+  // Make sure neither of the sticky values was evicted\n+  for (ssize_t i = 0; i < failed; ++i) {\n+    ASSERT_THAT(Run({\"exists\", StrCat(\"key\", i)}), IntArg(1));\n+  }\n+}\n+\n TEST_F(DflyEngineTest, PSubscribe) {\n   single_response_ = false;\n   auto resp = pp_->at(1)->Await([&] { return Run({\"psubscribe\", \"a*\", \"b*\"}); });\ndiff --git a/src/server/generic_family_test.cc b/src/server/generic_family_test.cc\nindex 9f5bcea64693..b9d5343e65a8 100644\n--- a/src/server/generic_family_test.cc\n+++ b/src/server/generic_family_test.cc\n@@ -165,6 +165,42 @@ TEST_F(GenericFamilyTest, RenameNx) {\n   ASSERT_EQ(Run({\"get\", \"y\"}), x_val);\n }\n \n+TEST_F(GenericFamilyTest, Stick) {\n+  // check stick returns zero on non-existent keys\n+  ASSERT_THAT(Run({\"stick\", \"a\", \"b\"}), IntArg(0));\n+\n+  for (auto key: {\"a\", \"b\", \"c\", \"d\"}) {\n+    Run({\"set\", key, \".\"});\n+  }\n+\n+  // check stick is applied only once\n+  ASSERT_THAT(Run({\"stick\", \"a\", \"b\"}), IntArg(2));\n+  ASSERT_THAT(Run({\"stick\", \"a\", \"b\"}), IntArg(0));\n+  ASSERT_THAT(Run({\"stick\", \"a\", \"c\"}), IntArg(1));\n+  ASSERT_THAT(Run({\"stick\", \"b\", \"d\"}), IntArg(1));\n+  ASSERT_THAT(Run({\"stick\", \"c\", \"d\"}), IntArg(0));\n+\n+  // check stickyness presists during writes\n+  Run({\"set\", \"a\", \"new\"});\n+  ASSERT_THAT(Run({\"stick\", \"a\"}), IntArg(0));\n+  Run({\"append\", \"a\", \"-value\"});\n+  ASSERT_THAT(Run({\"stick\", \"a\"}), IntArg(0));\n+\n+  // check rename persists stickyness\n+  Run({\"rename\", \"a\", \"k\"});\n+  ASSERT_THAT(Run({\"stick\", \"k\"}), IntArg(0));\n+\n+  // check rename perists stickyness on multiple shards\n+  Run({\"del\", \"b\"});\n+  string b_val(32, 'b');\n+  string x_val(32, 'x');\n+  Run({\"mset\", \"b\", b_val, \"x\", x_val});\n+  ASSERT_EQ(2, last_cmd_dbg_info_.shards_count);\n+  Run({\"stick\", \"x\"});\n+  Run({\"rename\", \"x\", \"b\"});\n+  ASSERT_THAT(Run({\"stick\", \"b\"}), IntArg(0));\n+}\n+\n \n using testing::AnyOf;\n using testing::Each;\n",
  "problem_statement": "introduce STICK command\nDF (similarly to Redis OSS) allows process-wide configuration (`cache_mode`) of whether to support records eviction or not.\r\n\r\nThe community asked on multiple occasions for a feature that allows whitelisting keys, so that the eviction policy won't kick them out. \r\nSometimes it's useful when the datastore is mostly cache but has some metadata keys that store the cache state.\r\n\r\nI suggest introducing a new command, something like STICK or BIND or GLUE. \r\nSay, `STICK key1 key2 key3` will mark those keys (only those that already exist) as non-evictable. Of course, explicit DEL or TTL will still work on them as expected.\n",
  "hints_text": "* What should the updated eviction process look like? Currently it just pops from a random stash bucket. But what if all its values are sticky? Probably scan the whole segment? Or is that too costly in case of repeated failure?\r\n\r\n* Stickyness shoud just be a `MaskBit` in `CompactObj`, right?\nGood questions, @dranikpg .\r\n\r\n1. You are considering a corner case where STICK keys are the majority. Since this feature is experimental, I would first implement the simplest fallback solution - return \"out of memory\" error. This path already exists for non-caching mode. Then we could improve it IF there will be a customer adoption for this feature. \r\n\r\n2. Yes, the code there is a bit messy, and some things are experimental, but that's what I would do \ud83d\udcaf \nGreat, I'll try this out then if its free to take up\nGo for it!",
  "created_at": "2022-08-18T08:57:33Z",
  "modified_files": [
    "src/core/compact_object.h",
    "src/core/dash.h",
    "src/core/dash_internal.h",
    "src/server/db_slice.cc",
    "src/server/generic_family.cc",
    "src/server/generic_family.h"
  ],
  "modified_test_files": [
    "src/core/dash_test.cc",
    "src/server/dragonfly_test.cc",
    "src/server/generic_family_test.cc"
  ]
}