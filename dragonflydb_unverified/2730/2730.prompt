You will be provided with a partial code base and an issue statement explaining a problem to resolve.

<issue>
fiber stack allocator
Currently, we allocate stacks using an allocator that allocates 64KB ranges per fiber stack (16 pages long).
Upon inspection of what pages are touched I noticed that we load 3 pages per each stack:  page 0 at the beginning of the range and pages 14, 15 at the end of the range.  2 pages at the end are explained by the fact that stack starts at page 15 and progresses downwards from higher addresses to lower. However, page 0 is preloaded unnecessary because of the implementation details of the allocator which uses first bytes of each block/range as its internal metadata.

We could implement our own allocator over mmap.

1. Simplest option is to mmap(64KB)/unmap directly per each stack allocation/deallocation . Then we would have an optimal RSS usage but this would require a syscall per each allocation/deallocation.
2. Another option is to have an allocator that would mmap 2MB pages, and use 32bit mask per page to allocate 64KB ranges from each page. Upon each fiber-stack destruction  we would use `io_uring/IORING_OP_MADVISE DONT_NEED` to unload asynchronously a range from each range from the RSS. If a 2MB page becomes fully available we would unmap it completely, otherwise we would manage descriptors of partial pages in the queue per thread. This resembles the design of an allocator library though because the stack sizes are 4KB aligned and with predefined sizes, the implementation will be much simpler.
</issue>

I need you to solve the provided issue by generating a code fix that can be applied directly to the repository

Respond below:
