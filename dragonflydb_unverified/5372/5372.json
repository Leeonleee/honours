{
  "repo": "dragonflydb/dragonfly",
  "pull_number": 5372,
  "instance_id": "dragonflydb__dragonfly-5372",
  "issue_numbers": [
    "5092"
  ],
  "base_commit": "54c0c4b067ede777b4659f5bd064aab637d416b9",
  "patch": "diff --git a/src/server/command_registry.cc b/src/server/command_registry.cc\nindex 829ea775a9cc..fd291d1a3f4d 100644\n--- a/src/server/command_registry.cc\n+++ b/src/server/command_registry.cc\n@@ -32,6 +32,8 @@ ABSL_FLAG(vector<string>, command_alias, {},\n           \"Add an alias for given command(s), format is: <alias>=<original>, <alias>=<original>. \"\n           \"Aliases must be set identically on replicas, if applicable\");\n \n+ABSL_FLAG(bool, latency_tracking, false, \"If true, track latency for commands\");\n+\n namespace dfly {\n \n using namespace facade;\n@@ -188,7 +190,12 @@ uint64_t CommandId::Invoke(CmdArgList args, const CommandContext& cmd_cntx) cons\n \n   ++ent.first;\n   ent.second += execution_time_usec;\n-\n+  static const bool is_latency_tracked = GetFlag(FLAGS_latency_tracking);\n+  if (is_latency_tracked) {\n+    if (hdr_histogram* cmd_histogram = latency_histogram_; cmd_histogram != nullptr) {\n+      hdr_record_value(cmd_histogram, execution_time_usec);\n+    }\n+  }\n   return execution_time_usec;\n }\n \n@@ -212,6 +219,10 @@ optional<facade::ErrorReply> CommandId::Validate(CmdArgList tail_args) const {\n   return nullopt;\n }\n \n+hdr_histogram* CommandId::LatencyHist() const {\n+  return latency_histogram_;\n+}\n+\n CommandRegistry::CommandRegistry() {\n   cmd_rename_map_ = ParseCmdlineArgMap(FLAGS_rename_command);\n \n@@ -321,6 +332,15 @@ std::pair<const CommandId*, ArgSlice> CommandRegistry::FindExtended(string_view\n   return {res, tail_args};\n }\n \n+absl::flat_hash_map<std::string, hdr_histogram*> CommandRegistry::LatencyMap() const {\n+  absl::flat_hash_map<std::string, hdr_histogram*> cmd_latencies;\n+  cmd_latencies.reserve(cmd_map_.size());\n+  for (const auto& [cmd_name, cmd] : cmd_map_) {\n+    cmd_latencies.insert({absl::AsciiStrToLower(cmd_name), cmd.LatencyHist()});\n+  }\n+  return cmd_latencies;\n+}\n+\n namespace CO {\n \n const char* OptName(CO::CommandOpt fl) {\ndiff --git a/src/server/command_registry.h b/src/server/command_registry.h\nindex 582ed8db4b86..83540a441491 100644\n--- a/src/server/command_registry.h\n+++ b/src/server/command_registry.h\n@@ -187,6 +187,8 @@ class CommandId : public facade::CommandId {\n     return is_alias_;\n   }\n \n+  hdr_histogram* LatencyHist() const;\n+\n  private:\n   // The following fields must copy manually in the move constructor.\n   bool implicit_acl_;\n@@ -249,6 +251,8 @@ class CommandRegistry {\n   std::pair<const CommandId*, facade::ArgSlice> FindExtended(std::string_view cmd,\n                                                              facade::ArgSlice tail_args) const;\n \n+  absl::flat_hash_map<std::string, hdr_histogram*> LatencyMap() const;\n+\n  private:\n   absl::flat_hash_map<std::string, CommandId> cmd_map_;\n   absl::flat_hash_map<std::string, std::string> cmd_rename_map_;\ndiff --git a/src/server/server_family.cc b/src/server/server_family.cc\nindex bf24e6ee92dd..b6e88c70b358 100644\n--- a/src/server/server_family.cc\n+++ b/src/server/server_family.cc\n@@ -237,6 +237,13 @@ using strings::HumanReadableNumBytes;\n \n namespace {\n \n+// TODO these should be configurable as command line flag and at runtime via config set\n+constexpr std::array<double, 3> kLatencyPercentiles = {50.0, 99.0, 99.9};\n+\n+bool is_histogram_empty(const hdr_histogram* h) {\n+  return hdr_min(h) == std::numeric_limits<int64_t>::max();\n+}\n+\n const auto kRedisVersion = \"7.4.0\";\n \n using EngineFunc = void (ServerFamily::*)(CmdArgList args, const CommandContext&);\n@@ -2388,6 +2395,7 @@ Metrics ServerFamily::GetMetrics(Namespace* ns) const {\n   UpdateMax(&peak_stats_.conn_read_buf_capacity, result.facade_stats.conn_stats.read_buf_capacity);\n \n   result.peak_stats = peak_stats_;\n+  result.cmd_latency_map = service_.mutable_registry()->LatencyMap();\n \n   uint64_t delta_ms = (absl::GetCurrentTimeNanos() - start) / 1'000'000;\n   if (delta_ms > 30) {\n@@ -2873,6 +2881,31 @@ string ServerFamily::FormatInfoMetrics(const Metrics& m, std::string_view sectio\n     append(\"total_migrated_keys\", m.shard_stats.total_migrated_keys);\n   }\n \n+  if (should_enter(\"LATENCYSTATS\")) {\n+    for (const auto& [cmd_name, hist] : m.cmd_latency_map) {\n+      if (!hist) {\n+        continue;\n+      }\n+\n+      if (is_histogram_empty(hist)) {\n+        continue;\n+      }\n+\n+      absl::InlinedVector<std::string, 4> stats;\n+      for (const auto percentile : kLatencyPercentiles) {\n+        const auto value = hdr_value_at_percentile(hist, percentile);\n+        // If the percentile is an integer, print it as an integer, otherwise print it as a double\n+        if (std::trunc(percentile) == percentile) {\n+          stats.emplace_back(absl::StrFormat(\"p%d=%d\", static_cast<int64_t>(percentile), value));\n+        } else {\n+          stats.emplace_back(absl::StrFormat(\"p%g=%d\", percentile, value));\n+        }\n+      }\n+\n+      append(absl::StrFormat(\"latency_percentiles_usec_%s\", cmd_name), absl::StrJoin(stats, \",\"));\n+    }\n+  }\n+\n   return info;\n }\n \ndiff --git a/src/server/server_family.h b/src/server/server_family.h\nindex da47d83f942b..e70063207abd 100644\n--- a/src/server/server_family.h\n+++ b/src/server/server_family.h\n@@ -132,6 +132,8 @@ struct Metrics {\n   size_t migration_errors_total;\n \n   LoadingStats loading_stats;\n+\n+  absl::flat_hash_map<std::string, hdr_histogram*> cmd_latency_map;\n };\n \n struct LastSaveInfo {\n",
  "test_patch": "diff --git a/src/server/dragonfly_test.cc b/src/server/dragonfly_test.cc\nindex 7bca1711a8f3..326aed2dd4fe 100644\n--- a/src/server/dragonfly_test.cc\n+++ b/src/server/dragonfly_test.cc\n@@ -28,6 +28,7 @@ ABSL_DECLARE_FLAG(std::vector<std::string>, rename_command);\n ABSL_DECLARE_FLAG(bool, lua_resp2_legacy_float);\n ABSL_DECLARE_FLAG(double, eviction_memory_budget_threshold);\n ABSL_DECLARE_FLAG(std::vector<std::string>, command_alias);\n+ABSL_DECLARE_FLAG(bool, latency_tracking);\n \n namespace dfly {\n \n@@ -887,7 +888,8 @@ TEST_F(DflyEngineTest, CommandMetricLabels) {\n class DflyCommandAliasTest : public DflyEngineTest {\n  protected:\n   DflyCommandAliasTest() {\n-    absl::SetFlag(&FLAGS_command_alias, {\"___set=set\", \"___ping=ping\"});\n+    SetFlag(&FLAGS_command_alias, {\"___set=set\", \"___ping=ping\"});\n+    SetFlag(&FLAGS_latency_tracking, true);\n   }\n \n   absl::FlagSaver saver_;\n@@ -920,4 +922,18 @@ TEST_F(DflyCommandAliasTest, Aliasing) {\n   EXPECT_THAT(metrics.cmd_stats_map, Contains(Pair(\"exec\", Key(1))));\n }\n \n+TEST_F(DflyCommandAliasTest, AliasesShareHistogramPtr) {\n+  EXPECT_EQ(Run({\"SET\", \"foo\", \"bar\"}), \"OK\");\n+  EXPECT_EQ(Run({\"___SET\", \"a\", \"b\"}), \"OK\");\n+  EXPECT_EQ(Run({\"___ping\"}), \"PONG\");\n+\n+  const auto command_histograms = GetMetrics().cmd_latency_map;\n+  for (const auto& key : {\"set\", \"___set\", \"___ping\", \"ping\"}) {\n+    EXPECT_TRUE(command_histograms.contains(key));\n+  }\n+\n+  EXPECT_EQ(command_histograms.at(\"set\"), command_histograms.at(\"___set\"));\n+  EXPECT_EQ(command_histograms.at(\"ping\"), command_histograms.at(\"___ping\"));\n+}\n+\n }  // namespace dfly\ndiff --git a/tests/dragonfly/server_family_test.py b/tests/dragonfly/server_family_test.py\nindex 2d3b880d967c..73637dcd9c8a 100644\n--- a/tests/dragonfly/server_family_test.py\n+++ b/tests/dragonfly/server_family_test.py\n@@ -221,3 +221,24 @@ def match_label_value(s: Sample, name, func):\n         for sample in metrics[\"dragonfly_connected_clients\"].samples:\n             match_label_value(sample, \"main\", lambda v: v == 2)\n             match_label_value(sample, \"other\", lambda v: v == 1)\n+\n+\n+@dfly_args({\"latency_tracking\": True})\n+async def test_latency_stats(async_client: aioredis.Redis):\n+    for _ in range(100):\n+        await async_client.set(\"foo\", \"bar\")\n+        await async_client.get(\"foo\")\n+        await async_client.get(\"bar\")\n+        await async_client.hgetall(\"missing\")\n+\n+    latency_stats = await async_client.info(\"LATENCYSTATS\")\n+    for expected in {\"hgetall\", \"set\", \"get\"}:\n+        key = f\"latency_percentiles_usec_{expected}\"\n+        assert key in latency_stats\n+        assert latency_stats[key].keys() == {\"p50\", \"p99\", \"p99.9\"}\n+\n+\n+async def test_latency_stats_disabled_by_default(async_client: aioredis.Redis):\n+    for _ in range(100):\n+        await async_client.set(\"foo\", \"bar\")\n+    assert await async_client.info(\"LATENCYSTATS\") == {}\n",
  "problem_statement": "Support for redis_latency_percentiles_usec Metric in DragonFlyDB\n**Title:** Support for `redis_latency_percentiles_usec` Metric in DragonFlyDB\n\n**Issue Summary:**\n\nWhen using the `oliver006/redis_exporter` with DragonFlyDB, we're not seeing the `redis_latency_percentiles_usec` metric that is typically available when the exporter is connected to Redis. This becomes a problem for monitoring setups \u2014 especially Grafana dashboards \u2014 that rely on this metric to track latency percentiles.\n\n**Environment:**\n\n- DragonFlyDB version: [latest Docker image]\n- Redis Exporter version: `oliver006/redis_exporter:v1.51.0`\n- Prometheus version: `v2.44.0`\n- Grafana version: `9.5.2`\n\n**Steps to Reproduce:**\n\n1. Run both Redis and DragonFlyDB in the same environment (e.g., via Docker Compose).\n2. Set up `oliver006/redis_exporter` for each service with the same config.\n3. Scrape metrics using Prometheus.\n4. Check for the `redis_latency_percentiles_usec` metric in Prometheus.\n5. It appears for Redis but not for DragonFly.\n\n**What We Expected:**\n\nWe expected both Redis and DragonFlyDB to expose this metric so we could reuse the same dashboards and alerts across both.\n\n**What Actually Happens:**\n\nThe metric is missing from DragonFlyDB, so panels that rely on latency percentiles (like P99, P95, P50) are empty or broken when connected to a DragonFly instance.\n\n**Why This Matters:**\n\nLatency percentiles like P99, P95, and P50 are key metrics for understanding system performance \u2014 especially under load. They help identify tail latency and are widely used in SLOs and operational dashboards. Not having this data makes it harder to monitor and compare performance between Redis and DragonFlyDB.\n\n**Other Notes:**\n\nWe did confirm that other metrics like `redis_commands_processed_total` and `redis_commands_duration_seconds_count` are being exposed correctly by both Redis and DragonFlyDB via the exporter. So the issue seems specific to the latency percentile metric.\n\nWe\u2019re aware that DragonFly provides its own Prometheus endpoint with histograms that can be used to calculate percentiles via `histogram_quantile()`, but having `redis_latency_percentiles_usec` directly available would be a big help for compatibility with existing tools and dashboards.\n\nWould love to know if this metric could be supported in the future, or if there's a recommended workaround for this use case.\n\n",
  "hints_text": "Hi @swasthikshetty10 , thanks for creating the issue. I will look into this.\nFor the overview of algorithms that allow computing percentiles:\nhttps://docs.google.com/document/d/1CR2w1E799Ar5_3OyKowP3fsOgFAtUdsd-rJrVKArWbg/edit?tab=t.0\n\nValkey uses hdr_histogram (https://github.com/HdrHistogram/HdrHistogram_c)\nwe need to be able to merge statistics (since each thread manages its own). \nhttps://github.com/cafaro/UDDSketch talks about mergeability as its differrentiating property.\n\nI am still curious how it is done in valkey, as it may have multiple io threads. In any case, based on my 10 min research UDDSketch may be the way to go.\nwe need histogram per command and each histogram contain multiple buckets. so it will be wasteful to also use thread-local data-structures for that. Long story short, I will use [HdrHistogram_c](https://github.com/HdrHistogram/HdrHistogram_c) \nthat has atomicity support and I will try to limit the updates to avoid contention on this histogram.\nTo clarify - in addition to the info section like this:\n\n```\n# Latencystats\nlatency_percentiles_usec_ping:p50=2.007,p99=2.007,p99.9=2.007\nlatency_percentiles_usec_set:p50=13.055,p99=13.055,p99.9=13.055\n....\n```\n\nthere is also a `latency histogram [cmd]` command (currently not implemented)\nbut can be implemented as well.",
  "created_at": "2025-06-27T07:15:56Z",
  "modified_files": [
    "src/server/command_registry.cc",
    "src/server/command_registry.h",
    "src/server/server_family.cc",
    "src/server/server_family.h"
  ],
  "modified_test_files": [
    "src/server/dragonfly_test.cc",
    "tests/dragonfly/server_family_test.py"
  ]
}